2025-02-02 17:15:57,467 - INFO - Starting training with the following parameters:
2025-02-02 17:15:57,468 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product |
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.0001         |
| epochs          | 1000           |

2025-02-02 17:16:01,601 - INFO - Epoch 0: val_loss=1.5553, val_acc=0.00%
2025-02-02 17:16:02,391 - INFO - ####################Training epoch 0####################
2025-02-02 17:16:02,486 - INFO - Epoch 0: train_loss=1.0472
2025-02-02 17:16:04,313 - INFO - Epoch 0: train_loss=1.1997
2025-02-02 17:16:04,448 - INFO - Epoch 0: train_loss=1.3650
2025-02-02 17:16:05,586 - INFO - Epoch 0: val_loss=1.5201, val_acc=0.00%
2025-02-02 17:16:05,674 - INFO - ####################Training epoch 1####################
2025-02-02 17:16:06,862 - INFO - Epoch 1: train_loss=1.0934
2025-02-02 17:16:07,037 - INFO - Epoch 1: train_loss=1.1410
2025-02-02 17:16:07,172 - INFO - Epoch 1: train_loss=1.0590
2025-02-02 17:16:08,384 - INFO - Epoch 1: val_loss=1.5077, val_acc=33.33%
2025-02-02 17:16:08,413 - INFO - ####################Training epoch 2####################
2025-02-02 17:16:09,636 - INFO - Epoch 2: train_loss=0.9664
2025-02-02 17:16:09,813 - INFO - Epoch 2: train_loss=1.0833
2025-02-02 17:16:09,950 - INFO - Epoch 2: train_loss=1.3473
2025-02-02 17:16:11,184 - INFO - Epoch 2: val_loss=1.5776, val_acc=33.33%
2025-02-02 17:16:11,228 - INFO - ####################Training epoch 3####################
2025-02-02 17:16:12,480 - INFO - Epoch 3: train_loss=1.1039
2025-02-02 17:16:12,654 - INFO - Epoch 3: train_loss=0.9620
2025-02-02 17:16:12,791 - INFO - Epoch 3: train_loss=1.1327
2025-02-02 17:16:13,981 - INFO - Epoch 3: val_loss=1.6380, val_acc=33.33%
2025-02-02 17:16:13,985 - INFO - ####################Training epoch 4####################
2025-02-02 17:16:15,215 - INFO - Epoch 4: train_loss=1.1192
2025-02-02 17:16:15,392 - INFO - Epoch 4: train_loss=0.9990
2025-02-02 17:16:15,530 - INFO - Epoch 4: train_loss=0.8712
2025-02-02 17:16:16,760 - INFO - Epoch 4: val_loss=1.7161, val_acc=33.33%
2025-02-02 17:16:16,764 - INFO - ####################Training epoch 5####################
2025-02-02 17:16:17,959 - INFO - Epoch 5: train_loss=1.0513
2025-02-02 17:16:18,124 - INFO - Epoch 5: train_loss=0.9059
2025-02-02 17:16:18,260 - INFO - Epoch 5: train_loss=1.1285
2025-02-02 17:16:19,498 - INFO - Epoch 5: val_loss=1.7783, val_acc=0.00%
2025-02-02 17:16:19,545 - INFO - ####################Training epoch 6####################
2025-02-02 17:16:20,801 - INFO - Epoch 6: train_loss=0.9255
2025-02-02 17:16:20,978 - INFO - Epoch 6: train_loss=1.0004
2025-02-02 17:16:21,118 - INFO - Epoch 6: train_loss=1.1159
2025-02-02 17:16:22,315 - INFO - Epoch 6: val_loss=1.8334, val_acc=0.00%
2025-02-02 17:16:22,343 - INFO - ####################Training epoch 7####################
2025-02-02 17:16:23,475 - INFO - Epoch 7: train_loss=0.9573
2025-02-02 17:16:23,648 - INFO - Epoch 7: train_loss=0.9786
2025-02-02 17:16:23,784 - INFO - Epoch 7: train_loss=1.0058
2025-02-02 17:16:24,972 - INFO - Epoch 7: val_loss=1.8468, val_acc=0.00%
2025-02-02 17:16:24,976 - INFO - ####################Training epoch 8####################
2025-02-02 17:16:26,070 - INFO - Epoch 8: train_loss=0.9512
2025-02-02 17:16:26,244 - INFO - Epoch 8: train_loss=0.9708
2025-02-02 17:16:26,379 - INFO - Epoch 8: train_loss=0.9088
2025-02-02 17:16:27,569 - INFO - Epoch 8: val_loss=1.8429, val_acc=33.33%
2025-02-02 17:16:27,573 - INFO - ####################Training epoch 9####################
2025-02-02 17:16:28,814 - INFO - Epoch 9: train_loss=0.9644
2025-02-02 17:16:28,990 - INFO - Epoch 9: train_loss=0.9368
2025-02-02 17:16:29,128 - INFO - Epoch 9: train_loss=0.9376
2025-02-02 17:16:30,287 - INFO - Epoch 9: val_loss=1.8348, val_acc=33.33%
2025-02-02 17:16:30,291 - INFO - ####################Training epoch 10####################
2025-02-02 17:16:31,475 - INFO - Epoch 10: train_loss=0.9227
2025-02-02 17:16:31,647 - INFO - Epoch 10: train_loss=0.9604
2025-02-02 17:16:31,783 - INFO - Epoch 10: train_loss=0.9166
2025-02-02 17:16:32,948 - INFO - Epoch 10: val_loss=1.8454, val_acc=33.33%
2025-02-02 17:16:32,951 - INFO - ####################Training epoch 11####################
2025-02-02 17:16:34,078 - INFO - Epoch 11: train_loss=0.8547
2025-02-02 17:16:34,250 - INFO - Epoch 11: train_loss=1.0388
2025-02-02 17:16:34,386 - INFO - Epoch 11: train_loss=0.8488
2025-02-02 17:16:35,566 - INFO - Epoch 11: val_loss=1.8551, val_acc=33.33%
2025-02-02 17:16:35,570 - INFO - ####################Training epoch 12####################
2025-02-02 17:16:36,727 - INFO - Epoch 12: train_loss=0.9158
2025-02-02 17:16:36,894 - INFO - Epoch 12: train_loss=0.9124
2025-02-02 17:16:37,029 - INFO - Epoch 12: train_loss=0.9755
2025-02-02 17:16:38,205 - INFO - Epoch 12: val_loss=1.8681, val_acc=33.33%
2025-02-02 17:16:38,209 - INFO - ####################Training epoch 13####################
2025-02-02 17:16:39,341 - INFO - Epoch 13: train_loss=0.8421
2025-02-02 17:16:39,507 - INFO - Epoch 13: train_loss=0.9465
2025-02-02 17:16:39,642 - INFO - Epoch 13: train_loss=1.0475
2025-02-02 17:16:40,787 - INFO - Epoch 13: val_loss=1.8845, val_acc=33.33%
2025-02-02 17:16:40,791 - INFO - ####################Training epoch 14####################
2025-02-02 17:16:41,967 - INFO - Epoch 14: train_loss=0.8961
2025-02-02 17:16:42,135 - INFO - Epoch 14: train_loss=0.8708
2025-02-02 17:16:42,273 - INFO - Epoch 14: train_loss=1.0428
2025-02-02 17:16:43,397 - INFO - Epoch 14: val_loss=1.8960, val_acc=33.33%
2025-02-02 17:16:43,401 - INFO - ####################Training epoch 15####################
2025-02-02 17:16:44,581 - INFO - Epoch 15: train_loss=0.7659
2025-02-02 17:16:44,758 - INFO - Epoch 15: train_loss=0.9895
2025-02-02 17:16:44,899 - INFO - Epoch 15: train_loss=1.0423
2025-02-02 17:16:46,073 - INFO - Epoch 15: val_loss=1.9068, val_acc=33.33%
2025-02-02 17:16:46,077 - INFO - ####################Training epoch 16####################
2025-02-02 17:16:47,307 - INFO - Epoch 16: train_loss=0.7933
2025-02-02 17:16:47,476 - INFO - Epoch 16: train_loss=0.9647
2025-02-02 17:16:47,612 - INFO - Epoch 16: train_loss=1.0273
2025-02-02 17:16:48,806 - INFO - Epoch 16: val_loss=1.9206, val_acc=33.33%
2025-02-02 17:16:48,810 - INFO - ####################Training epoch 17####################
2025-02-02 17:16:50,015 - INFO - Epoch 17: train_loss=0.8449
2025-02-02 17:16:50,190 - INFO - Epoch 17: train_loss=0.9713
2025-02-02 17:16:50,327 - INFO - Epoch 17: train_loss=0.8620
2025-02-02 17:16:51,459 - INFO - Epoch 17: val_loss=1.9339, val_acc=33.33%
2025-02-02 17:16:51,463 - INFO - ####################Training epoch 18####################
2025-02-02 17:16:52,653 - INFO - Epoch 18: train_loss=0.9096
2025-02-02 17:16:52,828 - INFO - Epoch 18: train_loss=0.8325
2025-02-02 17:16:52,963 - INFO - Epoch 18: train_loss=1.0148
2025-02-02 17:16:54,182 - INFO - Epoch 18: val_loss=1.9459, val_acc=33.33%
2025-02-02 17:16:54,186 - INFO - ####################Training epoch 19####################
2025-02-02 17:16:55,442 - INFO - Epoch 19: train_loss=0.8528
2025-02-02 17:16:55,618 - INFO - Epoch 19: train_loss=0.9928
2025-02-02 17:16:55,752 - INFO - Epoch 19: train_loss=0.7330
2025-02-02 17:16:56,999 - INFO - Epoch 19: val_loss=1.9539, val_acc=33.33%
2025-02-02 17:16:57,003 - INFO - ####################Training epoch 20####################
2025-02-02 17:16:58,174 - INFO - Epoch 20: train_loss=0.8748
2025-02-02 17:16:58,350 - INFO - Epoch 20: train_loss=0.9212
2025-02-02 17:16:58,491 - INFO - Epoch 20: train_loss=0.8225
2025-02-02 17:16:59,728 - INFO - Epoch 20: val_loss=1.9559, val_acc=33.33%
2025-02-02 17:16:59,732 - INFO - ####################Training epoch 21####################
2025-02-02 17:17:00,886 - INFO - Epoch 21: train_loss=0.8046
2025-02-02 17:17:01,057 - INFO - Epoch 21: train_loss=0.9478
2025-02-02 17:17:01,191 - INFO - Epoch 21: train_loss=0.9199
2025-02-02 17:17:02,496 - INFO - Epoch 21: val_loss=1.9616, val_acc=33.33%
2025-02-02 17:17:02,500 - INFO - ####################Training epoch 22####################
2025-02-02 17:17:03,377 - INFO - Epoch 22: train_loss=1.0066
2025-02-02 17:17:03,552 - INFO - Epoch 22: train_loss=0.7935
2025-02-02 17:17:03,692 - INFO - Epoch 22: train_loss=0.7927
2025-02-02 17:17:04,806 - INFO - Epoch 22: val_loss=1.9621, val_acc=33.33%
2025-02-02 17:17:04,810 - INFO - ####################Training epoch 23####################
2025-02-02 17:17:05,460 - INFO - Epoch 23: train_loss=0.8818
2025-02-02 17:17:05,628 - INFO - Epoch 23: train_loss=0.8802
2025-02-02 17:17:05,763 - INFO - Epoch 23: train_loss=0.8629
2025-02-02 17:17:06,412 - INFO - Epoch 23: val_loss=1.9653, val_acc=33.33%
2025-02-02 17:17:06,416 - INFO - ####################Training epoch 24####################
2025-02-02 17:17:07,066 - INFO - Epoch 24: train_loss=0.8806
2025-02-02 17:17:07,223 - INFO - Epoch 24: train_loss=0.8449
2025-02-02 17:17:07,357 - INFO - Epoch 24: train_loss=0.9691
2025-02-02 17:17:07,983 - INFO - Epoch 24: val_loss=1.9706, val_acc=33.33%
2025-02-02 17:17:07,987 - INFO - ####################Training epoch 25####################
2025-02-02 17:17:08,606 - INFO - Epoch 25: train_loss=0.8704
2025-02-02 17:17:08,766 - INFO - Epoch 25: train_loss=0.9267
2025-02-02 17:17:08,901 - INFO - Epoch 25: train_loss=0.7600
2025-02-02 17:17:09,529 - INFO - Epoch 25: val_loss=1.9714, val_acc=33.33%
2025-02-02 17:17:09,533 - INFO - ####################Training epoch 26####################
2025-02-02 17:17:10,178 - INFO - Epoch 26: train_loss=0.8526
2025-02-02 17:17:10,335 - INFO - Epoch 26: train_loss=0.8312
2025-02-02 17:17:10,469 - INFO - Epoch 26: train_loss=1.0340
2025-02-02 17:17:11,134 - INFO - Epoch 26: val_loss=1.9739, val_acc=33.33%
2025-02-02 17:17:11,137 - INFO - ####################Training epoch 27####################
2025-02-02 17:17:11,776 - INFO - Epoch 27: train_loss=0.9353
2025-02-02 17:17:11,933 - INFO - Epoch 27: train_loss=0.9296
2025-02-02 17:17:12,078 - INFO - Epoch 27: train_loss=0.5811
2025-02-02 17:17:12,733 - INFO - Epoch 27: val_loss=1.9778, val_acc=33.33%
2025-02-02 17:17:12,737 - INFO - ####################Training epoch 28####################
2025-02-02 17:17:13,390 - INFO - Epoch 28: train_loss=0.8306
2025-02-02 17:17:13,548 - INFO - Epoch 28: train_loss=0.9517
2025-02-02 17:17:13,682 - INFO - Epoch 28: train_loss=0.7725
2025-02-02 17:17:14,356 - INFO - Epoch 28: val_loss=1.9741, val_acc=33.33%
2025-02-02 17:17:14,360 - INFO - ####################Training epoch 29####################
2025-02-02 17:17:14,984 - INFO - Epoch 29: train_loss=0.9318
2025-02-02 17:17:15,142 - INFO - Epoch 29: train_loss=0.7287
2025-02-02 17:17:15,294 - INFO - Epoch 29: train_loss=1.0675
2025-02-02 17:17:15,934 - INFO - Epoch 29: val_loss=1.9794, val_acc=33.33%
2025-02-02 17:17:15,938 - INFO - ####################Training epoch 30####################
2025-02-02 17:17:16,579 - INFO - Epoch 30: train_loss=0.9129
2025-02-02 17:17:16,737 - INFO - Epoch 30: train_loss=0.9390
2025-02-02 17:17:16,871 - INFO - Epoch 30: train_loss=0.5966
2025-02-02 17:17:17,510 - INFO - Epoch 30: val_loss=1.9777, val_acc=33.33%
2025-02-02 17:17:17,513 - INFO - ####################Training epoch 31####################
2025-02-02 17:17:18,159 - INFO - Epoch 31: train_loss=0.8495
2025-02-02 17:17:18,316 - INFO - Epoch 31: train_loss=0.8425
2025-02-02 17:17:18,451 - INFO - Epoch 31: train_loss=0.9930
2025-02-02 17:17:19,135 - INFO - Epoch 31: val_loss=1.9848, val_acc=33.33%
2025-02-02 17:17:19,139 - INFO - ####################Training epoch 32####################
2025-02-02 17:17:19,773 - INFO - Epoch 32: train_loss=0.8026
2025-02-02 17:17:19,930 - INFO - Epoch 32: train_loss=0.9052
2025-02-02 17:17:20,065 - INFO - Epoch 32: train_loss=0.9526
2025-02-02 17:17:20,730 - INFO - Epoch 32: val_loss=1.9799, val_acc=33.33%
2025-02-02 17:17:20,734 - INFO - ####################Training epoch 33####################
2025-02-02 17:17:21,368 - INFO - Epoch 33: train_loss=0.8668
2025-02-02 17:17:21,525 - INFO - Epoch 33: train_loss=0.9229
2025-02-02 17:17:21,659 - INFO - Epoch 33: train_loss=0.7348
2025-02-02 17:17:22,370 - INFO - Epoch 33: val_loss=1.9825, val_acc=33.33%
2025-02-02 17:17:22,374 - INFO - ####################Training epoch 34####################
2025-02-02 17:17:23,019 - INFO - Epoch 34: train_loss=0.8778
2025-02-02 17:17:23,176 - INFO - Epoch 34: train_loss=0.9325
2025-02-02 17:17:23,311 - INFO - Epoch 34: train_loss=0.6792
2025-02-02 17:17:23,936 - INFO - Epoch 34: val_loss=1.9840, val_acc=33.33%
2025-02-02 17:17:23,940 - INFO - ####################Training epoch 35####################
2025-02-02 17:17:24,582 - INFO - Epoch 35: train_loss=0.7484
2025-02-02 17:17:24,740 - INFO - Epoch 35: train_loss=0.9037
2025-02-02 17:17:24,875 - INFO - Epoch 35: train_loss=1.0728
2025-02-02 17:17:25,587 - INFO - Epoch 35: val_loss=1.9867, val_acc=33.33%
2025-02-02 17:17:25,591 - INFO - ####################Training epoch 36####################
2025-02-02 17:17:26,230 - INFO - Epoch 36: train_loss=0.9867
2025-02-02 17:17:26,387 - INFO - Epoch 36: train_loss=0.7329
2025-02-02 17:17:26,521 - INFO - Epoch 36: train_loss=0.9048
2025-02-02 17:17:27,190 - INFO - Epoch 36: val_loss=1.9880, val_acc=33.33%
2025-02-02 17:17:27,194 - INFO - ####################Training epoch 37####################
2025-02-02 17:17:27,821 - INFO - Epoch 37: train_loss=0.8777
2025-02-02 17:17:27,979 - INFO - Epoch 37: train_loss=0.8479
2025-02-02 17:17:28,114 - INFO - Epoch 37: train_loss=0.8856
2025-02-02 17:17:28,796 - INFO - Epoch 37: val_loss=1.9908, val_acc=33.33%
2025-02-02 17:17:28,800 - INFO - ####################Training epoch 38####################
2025-02-02 17:17:29,442 - INFO - Epoch 38: train_loss=0.7138
2025-02-02 17:17:29,601 - INFO - Epoch 38: train_loss=1.0076
2025-02-02 17:17:29,736 - INFO - Epoch 38: train_loss=0.8832
2025-02-02 17:17:30,394 - INFO - Epoch 38: val_loss=1.9862, val_acc=33.33%
2025-02-02 17:17:30,398 - INFO - ####################Training epoch 39####################
2025-02-02 17:17:31,043 - INFO - Epoch 39: train_loss=0.9328
2025-02-02 17:17:31,201 - INFO - Epoch 39: train_loss=0.7362
2025-02-02 17:17:31,337 - INFO - Epoch 39: train_loss=1.0120
2025-02-02 17:17:32,083 - INFO - Epoch 39: val_loss=1.9932, val_acc=33.33%
2025-02-02 17:17:32,087 - INFO - ####################Training epoch 40####################
2025-02-02 17:17:32,761 - INFO - Epoch 40: train_loss=0.8160
2025-02-02 17:17:32,920 - INFO - Epoch 40: train_loss=0.8277
2025-02-02 17:17:33,055 - INFO - Epoch 40: train_loss=1.0795
2025-02-02 17:17:33,766 - INFO - Epoch 40: val_loss=1.9922, val_acc=33.33%
2025-02-02 17:17:33,770 - INFO - ####################Training epoch 41####################
2025-02-02 17:17:34,451 - INFO - Epoch 41: train_loss=0.8820
2025-02-02 17:17:34,610 - INFO - Epoch 41: train_loss=0.8125
2025-02-02 17:17:34,745 - INFO - Epoch 41: train_loss=0.9600
2025-02-02 17:17:35,489 - INFO - Epoch 41: val_loss=1.9937, val_acc=33.33%
2025-02-02 17:17:35,493 - INFO - ####################Training epoch 42####################
2025-02-02 17:17:36,182 - INFO - Epoch 42: train_loss=0.9191
2025-02-02 17:17:36,341 - INFO - Epoch 42: train_loss=0.7836
2025-02-02 17:17:36,476 - INFO - Epoch 42: train_loss=0.9329
2025-02-02 17:17:37,184 - INFO - Epoch 42: val_loss=1.9900, val_acc=33.33%
2025-02-02 17:17:37,188 - INFO - ####################Training epoch 43####################
2025-02-02 17:17:37,866 - INFO - Epoch 43: train_loss=0.9032
2025-02-02 17:17:38,033 - INFO - Epoch 43: train_loss=0.9255
2025-02-02 17:17:38,167 - INFO - Epoch 43: train_loss=0.6217
2025-02-02 17:17:38,835 - INFO - Epoch 43: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:17:38,839 - INFO - ####################Training epoch 44####################
2025-02-02 17:17:39,504 - INFO - Epoch 44: train_loss=0.9766
2025-02-02 17:17:39,661 - INFO - Epoch 44: train_loss=0.6979
2025-02-02 17:17:39,795 - INFO - Epoch 44: train_loss=1.0081
2025-02-02 17:17:40,449 - INFO - Epoch 44: val_loss=1.9900, val_acc=33.33%
2025-02-02 17:17:40,452 - INFO - ####################Training epoch 45####################
2025-02-02 17:17:41,107 - INFO - Epoch 45: train_loss=0.8132
2025-02-02 17:17:41,292 - INFO - Epoch 45: train_loss=0.9368
2025-02-02 17:17:41,426 - INFO - Epoch 45: train_loss=0.8152
2025-02-02 17:17:42,098 - INFO - Epoch 45: val_loss=1.9903, val_acc=33.33%
2025-02-02 17:17:42,102 - INFO - ####################Training epoch 46####################
2025-02-02 17:17:42,755 - INFO - Epoch 46: train_loss=0.9329
2025-02-02 17:17:42,914 - INFO - Epoch 46: train_loss=0.7869
2025-02-02 17:17:43,048 - INFO - Epoch 46: train_loss=0.8750
2025-02-02 17:17:43,701 - INFO - Epoch 46: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:17:43,705 - INFO - ####################Training epoch 47####################
2025-02-02 17:17:44,351 - INFO - Epoch 47: train_loss=0.8361
2025-02-02 17:17:44,527 - INFO - Epoch 47: train_loss=0.9475
2025-02-02 17:17:44,660 - INFO - Epoch 47: train_loss=0.7210
2025-02-02 17:17:45,335 - INFO - Epoch 47: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:17:45,339 - INFO - ####################Training epoch 48####################
2025-02-02 17:17:45,981 - INFO - Epoch 48: train_loss=0.8402
2025-02-02 17:17:46,138 - INFO - Epoch 48: train_loss=1.0333
2025-02-02 17:17:46,272 - INFO - Epoch 48: train_loss=0.4899
2025-02-02 17:17:46,949 - INFO - Epoch 48: val_loss=1.9981, val_acc=33.33%
2025-02-02 17:17:46,953 - INFO - ####################Training epoch 49####################
2025-02-02 17:17:47,603 - INFO - Epoch 49: train_loss=0.7803
2025-02-02 17:17:47,769 - INFO - Epoch 49: train_loss=0.9471
2025-02-02 17:17:47,903 - INFO - Epoch 49: train_loss=0.8674
2025-02-02 17:17:48,569 - INFO - Epoch 49: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:17:48,573 - INFO - ####################Training epoch 50####################
2025-02-02 17:17:49,210 - INFO - Epoch 50: train_loss=0.9241
2025-02-02 17:17:49,368 - INFO - Epoch 50: train_loss=0.7790
2025-02-02 17:17:49,502 - INFO - Epoch 50: train_loss=0.9115
2025-02-02 17:17:50,147 - INFO - Epoch 50: val_loss=1.9996, val_acc=33.33%
2025-02-02 17:17:50,151 - INFO - ####################Training epoch 51####################
2025-02-02 17:17:50,777 - INFO - Epoch 51: train_loss=0.7651
2025-02-02 17:17:50,936 - INFO - Epoch 51: train_loss=0.9341
2025-02-02 17:17:51,071 - INFO - Epoch 51: train_loss=0.9485
2025-02-02 17:17:51,737 - INFO - Epoch 51: val_loss=1.9983, val_acc=33.33%
2025-02-02 17:17:51,740 - INFO - ####################Training epoch 52####################
2025-02-02 17:17:52,421 - INFO - Epoch 52: train_loss=0.8454
2025-02-02 17:17:52,579 - INFO - Epoch 52: train_loss=0.9026
2025-02-02 17:17:52,714 - INFO - Epoch 52: train_loss=0.7980
2025-02-02 17:17:53,395 - INFO - Epoch 52: val_loss=1.9940, val_acc=33.33%
2025-02-02 17:17:53,399 - INFO - ####################Training epoch 53####################
2025-02-02 17:17:54,030 - INFO - Epoch 53: train_loss=0.8671
2025-02-02 17:17:54,188 - INFO - Epoch 53: train_loss=0.8781
2025-02-02 17:17:54,323 - INFO - Epoch 53: train_loss=0.8246
2025-02-02 17:17:54,989 - INFO - Epoch 53: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:17:54,992 - INFO - ####################Training epoch 54####################
2025-02-02 17:17:55,647 - INFO - Epoch 54: train_loss=0.9422
2025-02-02 17:17:55,805 - INFO - Epoch 54: train_loss=0.7808
2025-02-02 17:17:55,940 - INFO - Epoch 54: train_loss=0.8620
2025-02-02 17:17:56,609 - INFO - Epoch 54: val_loss=1.9967, val_acc=33.33%
2025-02-02 17:17:56,612 - INFO - ####################Training epoch 55####################
2025-02-02 17:17:57,253 - INFO - Epoch 55: train_loss=0.9200
2025-02-02 17:17:57,411 - INFO - Epoch 55: train_loss=0.8486
2025-02-02 17:17:57,546 - INFO - Epoch 55: train_loss=0.7560
2025-02-02 17:17:58,189 - INFO - Epoch 55: val_loss=1.9998, val_acc=33.33%
2025-02-02 17:17:58,193 - INFO - ####################Training epoch 56####################
2025-02-02 17:17:58,830 - INFO - Epoch 56: train_loss=0.8105
2025-02-02 17:17:58,989 - INFO - Epoch 56: train_loss=0.9428
2025-02-02 17:17:59,123 - INFO - Epoch 56: train_loss=0.7874
2025-02-02 17:17:59,758 - INFO - Epoch 56: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:17:59,762 - INFO - ####################Training epoch 57####################
2025-02-02 17:18:00,422 - INFO - Epoch 57: train_loss=0.7759
2025-02-02 17:18:00,579 - INFO - Epoch 57: train_loss=0.9140
2025-02-02 17:18:00,713 - INFO - Epoch 57: train_loss=0.9471
2025-02-02 17:18:01,366 - INFO - Epoch 57: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:18:01,370 - INFO - ####################Training epoch 58####################
2025-02-02 17:18:02,022 - INFO - Epoch 58: train_loss=0.7837
2025-02-02 17:18:02,180 - INFO - Epoch 58: train_loss=0.8781
2025-02-02 17:18:02,314 - INFO - Epoch 58: train_loss=1.0193
2025-02-02 17:18:02,959 - INFO - Epoch 58: val_loss=1.9987, val_acc=33.33%
2025-02-02 17:18:02,963 - INFO - ####################Training epoch 59####################
2025-02-02 17:18:03,605 - INFO - Epoch 59: train_loss=0.8729
2025-02-02 17:18:03,763 - INFO - Epoch 59: train_loss=0.7522
2025-02-02 17:18:03,898 - INFO - Epoch 59: train_loss=1.1101
2025-02-02 17:18:04,572 - INFO - Epoch 59: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:18:04,576 - INFO - ####################Training epoch 60####################
2025-02-02 17:18:05,231 - INFO - Epoch 60: train_loss=0.8418
2025-02-02 17:18:05,389 - INFO - Epoch 60: train_loss=0.9129
2025-02-02 17:18:05,524 - INFO - Epoch 60: train_loss=0.7912
2025-02-02 17:18:06,197 - INFO - Epoch 60: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:18:06,200 - INFO - ####################Training epoch 61####################
2025-02-02 17:18:06,848 - INFO - Epoch 61: train_loss=0.8542
2025-02-02 17:18:07,006 - INFO - Epoch 61: train_loss=0.8149
2025-02-02 17:18:07,141 - INFO - Epoch 61: train_loss=1.0082
2025-02-02 17:18:07,809 - INFO - Epoch 61: val_loss=1.9931, val_acc=33.33%
2025-02-02 17:18:07,812 - INFO - ####################Training epoch 62####################
2025-02-02 17:18:08,456 - INFO - Epoch 62: train_loss=0.9531
2025-02-02 17:18:08,619 - INFO - Epoch 62: train_loss=0.7321
2025-02-02 17:18:08,753 - INFO - Epoch 62: train_loss=0.9566
2025-02-02 17:18:09,410 - INFO - Epoch 62: val_loss=1.9895, val_acc=33.33%
2025-02-02 17:18:09,413 - INFO - ####################Training epoch 63####################
2025-02-02 17:18:10,064 - INFO - Epoch 63: train_loss=0.9516
2025-02-02 17:18:10,223 - INFO - Epoch 63: train_loss=0.6827
2025-02-02 17:18:10,358 - INFO - Epoch 63: train_loss=1.0903
2025-02-02 17:18:11,051 - INFO - Epoch 63: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:18:11,055 - INFO - ####################Training epoch 64####################
2025-02-02 17:18:11,737 - INFO - Epoch 64: train_loss=0.8744
2025-02-02 17:18:11,895 - INFO - Epoch 64: train_loss=0.8484
2025-02-02 17:18:12,031 - INFO - Epoch 64: train_loss=0.8754
2025-02-02 17:18:12,719 - INFO - Epoch 64: val_loss=2.0027, val_acc=33.33%
2025-02-02 17:18:12,723 - INFO - ####################Training epoch 65####################
2025-02-02 17:18:13,379 - INFO - Epoch 65: train_loss=0.8613
2025-02-02 17:18:13,537 - INFO - Epoch 65: train_loss=0.8319
2025-02-02 17:18:13,671 - INFO - Epoch 65: train_loss=0.9395
2025-02-02 17:18:14,328 - INFO - Epoch 65: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:18:14,331 - INFO - ####################Training epoch 66####################
2025-02-02 17:18:14,982 - INFO - Epoch 66: train_loss=1.0630
2025-02-02 17:18:15,141 - INFO - Epoch 66: train_loss=0.7647
2025-02-02 17:18:15,275 - INFO - Epoch 66: train_loss=0.6064
2025-02-02 17:18:15,909 - INFO - Epoch 66: val_loss=2.0008, val_acc=33.33%
2025-02-02 17:18:15,913 - INFO - ####################Training epoch 67####################
2025-02-02 17:18:16,553 - INFO - Epoch 67: train_loss=0.9442
2025-02-02 17:18:16,710 - INFO - Epoch 67: train_loss=0.8242
2025-02-02 17:18:16,844 - INFO - Epoch 67: train_loss=0.7590
2025-02-02 17:18:17,547 - INFO - Epoch 67: val_loss=1.9950, val_acc=33.33%
2025-02-02 17:18:17,550 - INFO - ####################Training epoch 68####################
2025-02-02 17:18:18,197 - INFO - Epoch 68: train_loss=0.8100
2025-02-02 17:18:18,355 - INFO - Epoch 68: train_loss=0.8799
2025-02-02 17:18:18,490 - INFO - Epoch 68: train_loss=0.9573
2025-02-02 17:18:19,155 - INFO - Epoch 68: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:18:19,158 - INFO - ####################Training epoch 69####################
2025-02-02 17:18:19,814 - INFO - Epoch 69: train_loss=0.7938
2025-02-02 17:18:19,971 - INFO - Epoch 69: train_loss=0.9190
2025-02-02 17:18:20,105 - INFO - Epoch 69: train_loss=0.9026
2025-02-02 17:18:20,759 - INFO - Epoch 69: val_loss=1.9953, val_acc=33.33%
2025-02-02 17:18:20,763 - INFO - ####################Training epoch 70####################
2025-02-02 17:18:21,417 - INFO - Epoch 70: train_loss=0.8579
2025-02-02 17:18:21,575 - INFO - Epoch 70: train_loss=0.8661
2025-02-02 17:18:21,709 - INFO - Epoch 70: train_loss=0.8619
2025-02-02 17:18:22,360 - INFO - Epoch 70: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:18:22,364 - INFO - ####################Training epoch 71####################
2025-02-02 17:18:23,020 - INFO - Epoch 71: train_loss=0.8366
2025-02-02 17:18:23,178 - INFO - Epoch 71: train_loss=0.8715
2025-02-02 17:18:23,312 - INFO - Epoch 71: train_loss=0.8990
2025-02-02 17:18:23,981 - INFO - Epoch 71: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:18:23,985 - INFO - ####################Training epoch 72####################
2025-02-02 17:18:24,633 - INFO - Epoch 72: train_loss=0.8422
2025-02-02 17:18:24,791 - INFO - Epoch 72: train_loss=0.9415
2025-02-02 17:18:24,925 - INFO - Epoch 72: train_loss=0.7213
2025-02-02 17:18:25,585 - INFO - Epoch 72: val_loss=2.0013, val_acc=33.33%
2025-02-02 17:18:25,589 - INFO - ####################Training epoch 73####################
2025-02-02 17:18:26,244 - INFO - Epoch 73: train_loss=0.8580
2025-02-02 17:18:26,402 - INFO - Epoch 73: train_loss=0.7688
2025-02-02 17:18:26,536 - INFO - Epoch 73: train_loss=1.1101
2025-02-02 17:18:27,173 - INFO - Epoch 73: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:18:27,177 - INFO - ####################Training epoch 74####################
2025-02-02 17:18:27,824 - INFO - Epoch 74: train_loss=0.9532
2025-02-02 17:18:27,982 - INFO - Epoch 74: train_loss=0.7820
2025-02-02 17:18:28,116 - INFO - Epoch 74: train_loss=0.8467
2025-02-02 17:18:28,768 - INFO - Epoch 74: val_loss=2.0006, val_acc=33.33%
2025-02-02 17:18:28,772 - INFO - ####################Training epoch 75####################
2025-02-02 17:18:29,424 - INFO - Epoch 75: train_loss=0.7652
2025-02-02 17:18:29,582 - INFO - Epoch 75: train_loss=1.0469
2025-02-02 17:18:29,716 - INFO - Epoch 75: train_loss=0.6456
2025-02-02 17:18:30,391 - INFO - Epoch 75: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:18:30,394 - INFO - ####################Training epoch 76####################
2025-02-02 17:18:31,037 - INFO - Epoch 76: train_loss=0.9409
2025-02-02 17:18:31,195 - INFO - Epoch 76: train_loss=0.7630
2025-02-02 17:18:31,329 - INFO - Epoch 76: train_loss=0.9128
2025-02-02 17:18:31,992 - INFO - Epoch 76: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:18:31,996 - INFO - ####################Training epoch 77####################
2025-02-02 17:18:32,654 - INFO - Epoch 77: train_loss=0.8380
2025-02-02 17:18:32,813 - INFO - Epoch 77: train_loss=0.8923
2025-02-02 17:18:32,948 - INFO - Epoch 77: train_loss=0.8490
2025-02-02 17:18:33,618 - INFO - Epoch 77: val_loss=1.9978, val_acc=33.33%
2025-02-02 17:18:33,622 - INFO - ####################Training epoch 78####################
2025-02-02 17:18:34,331 - INFO - Epoch 78: train_loss=0.8160
2025-02-02 17:18:34,489 - INFO - Epoch 78: train_loss=0.8442
2025-02-02 17:18:34,624 - INFO - Epoch 78: train_loss=1.0283
2025-02-02 17:18:35,279 - INFO - Epoch 78: val_loss=1.9967, val_acc=33.33%
2025-02-02 17:18:35,283 - INFO - ####################Training epoch 79####################
2025-02-02 17:18:35,919 - INFO - Epoch 79: train_loss=0.8622
2025-02-02 17:18:36,077 - INFO - Epoch 79: train_loss=0.8785
2025-02-02 17:18:36,212 - INFO - Epoch 79: train_loss=0.8165
2025-02-02 17:18:36,858 - INFO - Epoch 79: val_loss=1.9992, val_acc=33.33%
2025-02-02 17:18:36,862 - INFO - ####################Training epoch 80####################
2025-02-02 17:18:37,513 - INFO - Epoch 80: train_loss=0.9309
2025-02-02 17:18:37,670 - INFO - Epoch 80: train_loss=0.8956
2025-02-02 17:18:37,806 - INFO - Epoch 80: train_loss=0.6139
2025-02-02 17:18:38,484 - INFO - Epoch 80: val_loss=2.0013, val_acc=33.33%
2025-02-02 17:18:38,488 - INFO - ####################Training epoch 81####################
2025-02-02 17:18:39,138 - INFO - Epoch 81: train_loss=0.8735
2025-02-02 17:18:39,296 - INFO - Epoch 81: train_loss=0.9593
2025-02-02 17:18:39,432 - INFO - Epoch 81: train_loss=0.5975
2025-02-02 17:18:40,091 - INFO - Epoch 81: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:18:40,095 - INFO - ####################Training epoch 82####################
2025-02-02 17:18:40,747 - INFO - Epoch 82: train_loss=0.8968
2025-02-02 17:18:40,907 - INFO - Epoch 82: train_loss=0.7968
2025-02-02 17:18:41,042 - INFO - Epoch 82: train_loss=0.9467
2025-02-02 17:18:41,717 - INFO - Epoch 82: val_loss=1.9916, val_acc=33.33%
2025-02-02 17:18:41,721 - INFO - ####################Training epoch 83####################
2025-02-02 17:18:42,391 - INFO - Epoch 83: train_loss=0.8054
2025-02-02 17:18:42,551 - INFO - Epoch 83: train_loss=0.9481
2025-02-02 17:18:42,686 - INFO - Epoch 83: train_loss=0.7873
2025-02-02 17:18:43,336 - INFO - Epoch 83: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:18:43,340 - INFO - ####################Training epoch 84####################
2025-02-02 17:18:43,989 - INFO - Epoch 84: train_loss=0.8175
2025-02-02 17:18:44,148 - INFO - Epoch 84: train_loss=0.9594
2025-02-02 17:18:44,282 - INFO - Epoch 84: train_loss=0.7375
2025-02-02 17:18:44,937 - INFO - Epoch 84: val_loss=2.0004, val_acc=33.33%
2025-02-02 17:18:44,941 - INFO - ####################Training epoch 85####################
2025-02-02 17:18:45,583 - INFO - Epoch 85: train_loss=0.8845
2025-02-02 17:18:45,742 - INFO - Epoch 85: train_loss=0.7888
2025-02-02 17:18:45,876 - INFO - Epoch 85: train_loss=0.9781
2025-02-02 17:18:46,577 - INFO - Epoch 85: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:18:46,581 - INFO - ####################Training epoch 86####################
2025-02-02 17:18:47,242 - INFO - Epoch 86: train_loss=0.7596
2025-02-02 17:18:47,401 - INFO - Epoch 86: train_loss=0.8839
2025-02-02 17:18:47,536 - INFO - Epoch 86: train_loss=1.0743
2025-02-02 17:18:48,187 - INFO - Epoch 86: val_loss=2.0008, val_acc=33.33%
2025-02-02 17:18:48,191 - INFO - ####################Training epoch 87####################
2025-02-02 17:18:48,850 - INFO - Epoch 87: train_loss=0.8994
2025-02-02 17:18:49,008 - INFO - Epoch 87: train_loss=0.9257
2025-02-02 17:18:49,144 - INFO - Epoch 87: train_loss=0.6156
2025-02-02 17:18:49,818 - INFO - Epoch 87: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:18:49,822 - INFO - ####################Training epoch 88####################
2025-02-02 17:18:50,478 - INFO - Epoch 88: train_loss=0.8271
2025-02-02 17:18:50,636 - INFO - Epoch 88: train_loss=0.8734
2025-02-02 17:18:50,771 - INFO - Epoch 88: train_loss=0.9145
2025-02-02 17:18:51,457 - INFO - Epoch 88: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:18:51,462 - INFO - ####################Training epoch 89####################
2025-02-02 17:18:52,101 - INFO - Epoch 89: train_loss=1.0232
2025-02-02 17:18:52,258 - INFO - Epoch 89: train_loss=0.6731
2025-02-02 17:18:52,394 - INFO - Epoch 89: train_loss=0.9492
2025-02-02 17:18:53,072 - INFO - Epoch 89: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:18:53,076 - INFO - ####################Training epoch 90####################
2025-02-02 17:18:53,723 - INFO - Epoch 90: train_loss=0.9321
2025-02-02 17:18:53,880 - INFO - Epoch 90: train_loss=0.7508
2025-02-02 17:18:54,015 - INFO - Epoch 90: train_loss=0.9737
2025-02-02 17:18:54,684 - INFO - Epoch 90: val_loss=1.9996, val_acc=33.33%
2025-02-02 17:18:54,688 - INFO - ####################Training epoch 91####################
2025-02-02 17:18:55,344 - INFO - Epoch 91: train_loss=0.9931
2025-02-02 17:18:55,502 - INFO - Epoch 91: train_loss=0.7602
2025-02-02 17:18:55,636 - INFO - Epoch 91: train_loss=0.7884
2025-02-02 17:18:56,296 - INFO - Epoch 91: val_loss=2.0015, val_acc=33.33%
2025-02-02 17:18:56,300 - INFO - ####################Training epoch 92####################
2025-02-02 17:18:56,957 - INFO - Epoch 92: train_loss=0.7794
2025-02-02 17:18:57,115 - INFO - Epoch 92: train_loss=0.8679
2025-02-02 17:18:57,249 - INFO - Epoch 92: train_loss=1.0559
2025-02-02 17:18:57,894 - INFO - Epoch 92: val_loss=1.9954, val_acc=33.33%
2025-02-02 17:18:57,897 - INFO - ####################Training epoch 93####################
2025-02-02 17:18:58,545 - INFO - Epoch 93: train_loss=0.8501
2025-02-02 17:18:58,702 - INFO - Epoch 93: train_loss=0.7641
2025-02-02 17:18:58,837 - INFO - Epoch 93: train_loss=1.1402
2025-02-02 17:18:59,558 - INFO - Epoch 93: val_loss=1.9973, val_acc=33.33%
2025-02-02 17:18:59,562 - INFO - ####################Training epoch 94####################
2025-02-02 17:19:00,219 - INFO - Epoch 94: train_loss=0.8521
2025-02-02 17:19:00,376 - INFO - Epoch 94: train_loss=0.8176
2025-02-02 17:19:00,511 - INFO - Epoch 94: train_loss=1.0043
2025-02-02 17:19:01,158 - INFO - Epoch 94: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:19:01,165 - INFO - ####################Training epoch 95####################
2025-02-02 17:19:01,795 - INFO - Epoch 95: train_loss=0.9805
2025-02-02 17:19:01,953 - INFO - Epoch 95: train_loss=0.7968
2025-02-02 17:19:02,087 - INFO - Epoch 95: train_loss=0.7343
2025-02-02 17:19:02,735 - INFO - Epoch 95: val_loss=2.0000, val_acc=33.33%
2025-02-02 17:19:02,739 - INFO - ####################Training epoch 96####################
2025-02-02 17:19:03,375 - INFO - Epoch 96: train_loss=0.9991
2025-02-02 17:19:03,533 - INFO - Epoch 96: train_loss=0.7057
2025-02-02 17:19:03,667 - INFO - Epoch 96: train_loss=0.9073
2025-02-02 17:19:04,318 - INFO - Epoch 96: val_loss=2.0012, val_acc=33.33%
2025-02-02 17:19:04,322 - INFO - ####################Training epoch 97####################
2025-02-02 17:19:04,980 - INFO - Epoch 97: train_loss=0.9528
2025-02-02 17:19:05,137 - INFO - Epoch 97: train_loss=0.7422
2025-02-02 17:19:05,272 - INFO - Epoch 97: train_loss=0.9342
2025-02-02 17:19:05,924 - INFO - Epoch 97: val_loss=2.0002, val_acc=33.33%
2025-02-02 17:19:05,927 - INFO - ####################Training epoch 98####################
2025-02-02 17:19:06,569 - INFO - Epoch 98: train_loss=0.9072
2025-02-02 17:19:06,727 - INFO - Epoch 98: train_loss=0.8861
2025-02-02 17:19:06,862 - INFO - Epoch 98: train_loss=0.6976
2025-02-02 17:19:07,524 - INFO - Epoch 98: val_loss=1.9998, val_acc=33.33%
2025-02-02 17:19:07,528 - INFO - ####################Training epoch 99####################
2025-02-02 17:19:08,224 - INFO - Epoch 99: train_loss=0.8237
2025-02-02 17:19:08,381 - INFO - Epoch 99: train_loss=0.9839
2025-02-02 17:19:08,516 - INFO - Epoch 99: train_loss=0.6680
2025-02-02 17:19:09,163 - INFO - Epoch 99: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:19:09,167 - INFO - ####################Training epoch 100####################
2025-02-02 17:19:09,815 - INFO - Epoch 100: train_loss=0.8969
2025-02-02 17:19:09,972 - INFO - Epoch 100: train_loss=0.8123
2025-02-02 17:19:10,107 - INFO - Epoch 100: train_loss=0.9039
2025-02-02 17:19:10,752 - INFO - Epoch 100: val_loss=1.9952, val_acc=33.33%
2025-02-02 17:19:10,756 - INFO - ####################Training epoch 101####################
2025-02-02 17:19:11,399 - INFO - Epoch 101: train_loss=0.9598
2025-02-02 17:19:11,556 - INFO - Epoch 101: train_loss=0.7404
2025-02-02 17:19:11,691 - INFO - Epoch 101: train_loss=0.9210
2025-02-02 17:19:12,336 - INFO - Epoch 101: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:19:12,339 - INFO - ####################Training epoch 102####################
2025-02-02 17:19:12,980 - INFO - Epoch 102: train_loss=0.8749
2025-02-02 17:19:13,138 - INFO - Epoch 102: train_loss=0.9052
2025-02-02 17:19:13,272 - INFO - Epoch 102: train_loss=0.7266
2025-02-02 17:19:13,935 - INFO - Epoch 102: val_loss=1.9956, val_acc=33.33%
2025-02-02 17:19:13,938 - INFO - ####################Training epoch 103####################
2025-02-02 17:19:14,594 - INFO - Epoch 103: train_loss=0.8496
2025-02-02 17:19:14,751 - INFO - Epoch 103: train_loss=0.8725
2025-02-02 17:19:14,886 - INFO - Epoch 103: train_loss=0.8826
2025-02-02 17:19:15,530 - INFO - Epoch 103: val_loss=2.0022, val_acc=33.33%
2025-02-02 17:19:15,534 - INFO - ####################Training epoch 104####################
2025-02-02 17:19:16,188 - INFO - Epoch 104: train_loss=0.8020
2025-02-02 17:19:16,346 - INFO - Epoch 104: train_loss=0.8641
2025-02-02 17:19:16,481 - INFO - Epoch 104: train_loss=1.0265
2025-02-02 17:19:17,112 - INFO - Epoch 104: val_loss=2.0035, val_acc=33.33%
2025-02-02 17:19:17,116 - INFO - ####################Training epoch 105####################
2025-02-02 17:19:17,765 - INFO - Epoch 105: train_loss=0.8179
2025-02-02 17:19:17,923 - INFO - Epoch 105: train_loss=0.9927
2025-02-02 17:19:18,057 - INFO - Epoch 105: train_loss=0.6466
2025-02-02 17:19:18,746 - INFO - Epoch 105: val_loss=1.9983, val_acc=33.33%
2025-02-02 17:19:18,751 - INFO - ####################Training epoch 106####################
2025-02-02 17:19:19,427 - INFO - Epoch 106: train_loss=0.8570
2025-02-02 17:19:19,586 - INFO - Epoch 106: train_loss=0.9336
2025-02-02 17:19:19,720 - INFO - Epoch 106: train_loss=0.6896
2025-02-02 17:19:20,423 - INFO - Epoch 106: val_loss=1.9963, val_acc=33.33%
2025-02-02 17:19:20,427 - INFO - ####################Training epoch 107####################
2025-02-02 17:19:21,086 - INFO - Epoch 107: train_loss=0.8375
2025-02-02 17:19:21,244 - INFO - Epoch 107: train_loss=0.8756
2025-02-02 17:19:21,378 - INFO - Epoch 107: train_loss=0.8976
2025-02-02 17:19:22,031 - INFO - Epoch 107: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:19:22,035 - INFO - ####################Training epoch 108####################
2025-02-02 17:19:22,687 - INFO - Epoch 108: train_loss=0.7724
2025-02-02 17:19:22,845 - INFO - Epoch 108: train_loss=0.9176
2025-02-02 17:19:22,980 - INFO - Epoch 108: train_loss=0.9567
2025-02-02 17:19:23,649 - INFO - Epoch 108: val_loss=2.0004, val_acc=33.33%
2025-02-02 17:19:23,653 - INFO - ####################Training epoch 109####################
2025-02-02 17:19:24,299 - INFO - Epoch 109: train_loss=0.8555
2025-02-02 17:19:24,457 - INFO - Epoch 109: train_loss=0.9207
2025-02-02 17:19:24,593 - INFO - Epoch 109: train_loss=0.7365
2025-02-02 17:19:25,261 - INFO - Epoch 109: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:19:25,265 - INFO - ####################Training epoch 110####################
2025-02-02 17:19:25,888 - INFO - Epoch 110: train_loss=0.8793
2025-02-02 17:19:26,046 - INFO - Epoch 110: train_loss=0.8216
2025-02-02 17:19:26,180 - INFO - Epoch 110: train_loss=0.9215
2025-02-02 17:19:26,835 - INFO - Epoch 110: val_loss=1.9978, val_acc=33.33%
2025-02-02 17:19:26,839 - INFO - ####################Training epoch 111####################
2025-02-02 17:19:27,470 - INFO - Epoch 111: train_loss=0.9045
2025-02-02 17:19:27,627 - INFO - Epoch 111: train_loss=0.8617
2025-02-02 17:19:27,762 - INFO - Epoch 111: train_loss=0.7710
2025-02-02 17:19:28,406 - INFO - Epoch 111: val_loss=2.0019, val_acc=33.33%
2025-02-02 17:19:28,410 - INFO - ####################Training epoch 112####################
2025-02-02 17:19:29,067 - INFO - Epoch 112: train_loss=0.9020
2025-02-02 17:19:29,224 - INFO - Epoch 112: train_loss=0.8659
2025-02-02 17:19:29,359 - INFO - Epoch 112: train_loss=0.7497
2025-02-02 17:19:30,017 - INFO - Epoch 112: val_loss=1.9967, val_acc=33.33%
2025-02-02 17:19:30,021 - INFO - ####################Training epoch 113####################
2025-02-02 17:19:30,676 - INFO - Epoch 113: train_loss=0.9166
2025-02-02 17:19:30,834 - INFO - Epoch 113: train_loss=0.8071
2025-02-02 17:19:30,968 - INFO - Epoch 113: train_loss=0.8756
2025-02-02 17:19:31,627 - INFO - Epoch 113: val_loss=2.0011, val_acc=33.33%
2025-02-02 17:19:31,631 - INFO - ####################Training epoch 114####################
2025-02-02 17:19:32,272 - INFO - Epoch 114: train_loss=0.9143
2025-02-02 17:19:32,429 - INFO - Epoch 114: train_loss=0.9335
2025-02-02 17:19:32,564 - INFO - Epoch 114: train_loss=0.5602
2025-02-02 17:19:33,224 - INFO - Epoch 114: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:19:33,228 - INFO - ####################Training epoch 115####################
2025-02-02 17:19:33,876 - INFO - Epoch 115: train_loss=0.9737
2025-02-02 17:19:34,034 - INFO - Epoch 115: train_loss=0.7569
2025-02-02 17:19:34,169 - INFO - Epoch 115: train_loss=0.8299
2025-02-02 17:19:34,840 - INFO - Epoch 115: val_loss=1.9984, val_acc=33.33%
2025-02-02 17:19:34,844 - INFO - ####################Training epoch 116####################
2025-02-02 17:19:35,499 - INFO - Epoch 116: train_loss=0.9446
2025-02-02 17:19:35,657 - INFO - Epoch 116: train_loss=0.7447
2025-02-02 17:19:35,791 - INFO - Epoch 116: train_loss=0.9582
2025-02-02 17:19:36,468 - INFO - Epoch 116: val_loss=1.9968, val_acc=33.33%
2025-02-02 17:19:36,471 - INFO - ####################Training epoch 117####################
2025-02-02 17:19:37,125 - INFO - Epoch 117: train_loss=0.8204
2025-02-02 17:19:37,283 - INFO - Epoch 117: train_loss=0.8967
2025-02-02 17:19:37,418 - INFO - Epoch 117: train_loss=0.8843
2025-02-02 17:19:38,074 - INFO - Epoch 117: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:19:38,078 - INFO - ####################Training epoch 118####################
2025-02-02 17:19:38,739 - INFO - Epoch 118: train_loss=0.8396
2025-02-02 17:19:38,898 - INFO - Epoch 118: train_loss=0.8480
2025-02-02 17:19:39,032 - INFO - Epoch 118: train_loss=0.9661
2025-02-02 17:19:39,680 - INFO - Epoch 118: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:19:39,684 - INFO - ####################Training epoch 119####################
2025-02-02 17:19:40,317 - INFO - Epoch 119: train_loss=0.8299
2025-02-02 17:19:40,475 - INFO - Epoch 119: train_loss=0.9211
2025-02-02 17:19:40,609 - INFO - Epoch 119: train_loss=0.7891
2025-02-02 17:19:41,287 - INFO - Epoch 119: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:19:41,291 - INFO - ####################Training epoch 120####################
2025-02-02 17:19:41,971 - INFO - Epoch 120: train_loss=0.8127
2025-02-02 17:19:42,129 - INFO - Epoch 120: train_loss=0.8953
2025-02-02 17:19:42,263 - INFO - Epoch 120: train_loss=0.8998
2025-02-02 17:19:42,920 - INFO - Epoch 120: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:19:42,923 - INFO - ####################Training epoch 121####################
2025-02-02 17:19:43,585 - INFO - Epoch 121: train_loss=0.9111
2025-02-02 17:19:43,742 - INFO - Epoch 121: train_loss=0.7779
2025-02-02 17:19:43,877 - INFO - Epoch 121: train_loss=0.9651
2025-02-02 17:19:44,542 - INFO - Epoch 121: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:19:44,546 - INFO - ####################Training epoch 122####################
2025-02-02 17:19:45,184 - INFO - Epoch 122: train_loss=0.7357
2025-02-02 17:19:45,341 - INFO - Epoch 122: train_loss=0.9249
2025-02-02 17:19:45,476 - INFO - Epoch 122: train_loss=1.0163
2025-02-02 17:19:46,136 - INFO - Epoch 122: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:19:46,140 - INFO - ####################Training epoch 123####################
2025-02-02 17:19:46,785 - INFO - Epoch 123: train_loss=0.8417
2025-02-02 17:19:46,942 - INFO - Epoch 123: train_loss=0.9152
2025-02-02 17:19:47,076 - INFO - Epoch 123: train_loss=0.7837
2025-02-02 17:19:47,725 - INFO - Epoch 123: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:19:47,729 - INFO - ####################Training epoch 124####################
2025-02-02 17:19:48,350 - INFO - Epoch 124: train_loss=0.8532
2025-02-02 17:19:48,507 - INFO - Epoch 124: train_loss=0.8963
2025-02-02 17:19:48,641 - INFO - Epoch 124: train_loss=0.8075
2025-02-02 17:19:49,293 - INFO - Epoch 124: val_loss=1.9941, val_acc=33.33%
2025-02-02 17:19:49,297 - INFO - ####################Training epoch 125####################
2025-02-02 17:19:49,938 - INFO - Epoch 125: train_loss=0.8753
2025-02-02 17:19:50,110 - INFO - Epoch 125: train_loss=0.8982
2025-02-02 17:19:50,254 - INFO - Epoch 125: train_loss=0.7423
2025-02-02 17:19:50,931 - INFO - Epoch 125: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:19:50,934 - INFO - ####################Training epoch 126####################
2025-02-02 17:19:51,571 - INFO - Epoch 126: train_loss=0.8882
2025-02-02 17:19:51,729 - INFO - Epoch 126: train_loss=0.8004
2025-02-02 17:19:51,863 - INFO - Epoch 126: train_loss=0.9498
2025-02-02 17:19:52,554 - INFO - Epoch 126: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:19:52,559 - INFO - ####################Training epoch 127####################
2025-02-02 17:19:53,234 - INFO - Epoch 127: train_loss=0.8695
2025-02-02 17:19:53,392 - INFO - Epoch 127: train_loss=0.9303
2025-02-02 17:19:53,527 - INFO - Epoch 127: train_loss=0.6739
2025-02-02 17:19:54,201 - INFO - Epoch 127: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:19:54,204 - INFO - ####################Training epoch 128####################
2025-02-02 17:19:54,853 - INFO - Epoch 128: train_loss=0.9184
2025-02-02 17:19:55,011 - INFO - Epoch 128: train_loss=0.7704
2025-02-02 17:19:55,145 - INFO - Epoch 128: train_loss=0.9673
2025-02-02 17:19:55,808 - INFO - Epoch 128: val_loss=1.9931, val_acc=33.33%
2025-02-02 17:19:55,812 - INFO - ####################Training epoch 129####################
2025-02-02 17:19:56,462 - INFO - Epoch 129: train_loss=0.8344
2025-02-02 17:19:56,619 - INFO - Epoch 129: train_loss=0.8205
2025-02-02 17:19:56,753 - INFO - Epoch 129: train_loss=1.0518
2025-02-02 17:19:57,409 - INFO - Epoch 129: val_loss=1.9935, val_acc=33.33%
2025-02-02 17:19:57,412 - INFO - ####################Training epoch 130####################
2025-02-02 17:19:58,047 - INFO - Epoch 130: train_loss=1.0518
2025-02-02 17:19:58,204 - INFO - Epoch 130: train_loss=0.7838
2025-02-02 17:19:58,339 - INFO - Epoch 130: train_loss=0.5891
2025-02-02 17:19:59,044 - INFO - Epoch 130: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:19:59,048 - INFO - ####################Training epoch 131####################
2025-02-02 17:19:59,674 - INFO - Epoch 131: train_loss=0.7760
2025-02-02 17:19:59,832 - INFO - Epoch 131: train_loss=0.9380
2025-02-02 17:19:59,966 - INFO - Epoch 131: train_loss=0.8910
2025-02-02 17:20:00,624 - INFO - Epoch 131: val_loss=1.9978, val_acc=33.33%
2025-02-02 17:20:00,628 - INFO - ####################Training epoch 132####################
2025-02-02 17:20:01,278 - INFO - Epoch 132: train_loss=0.8516
2025-02-02 17:20:01,436 - INFO - Epoch 132: train_loss=0.8844
2025-02-02 17:20:01,570 - INFO - Epoch 132: train_loss=0.8463
2025-02-02 17:20:02,223 - INFO - Epoch 132: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:20:02,227 - INFO - ####################Training epoch 133####################
2025-02-02 17:20:02,882 - INFO - Epoch 133: train_loss=0.9073
2025-02-02 17:20:03,040 - INFO - Epoch 133: train_loss=0.7579
2025-02-02 17:20:03,174 - INFO - Epoch 133: train_loss=1.0030
2025-02-02 17:20:03,828 - INFO - Epoch 133: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:20:03,832 - INFO - ####################Training epoch 134####################
2025-02-02 17:20:04,477 - INFO - Epoch 134: train_loss=0.8345
2025-02-02 17:20:04,634 - INFO - Epoch 134: train_loss=0.8856
2025-02-02 17:20:04,769 - INFO - Epoch 134: train_loss=0.8958
2025-02-02 17:20:05,441 - INFO - Epoch 134: val_loss=1.9961, val_acc=33.33%
2025-02-02 17:20:05,445 - INFO - ####################Training epoch 135####################
2025-02-02 17:20:06,085 - INFO - Epoch 135: train_loss=0.7616
2025-02-02 17:20:06,243 - INFO - Epoch 135: train_loss=1.0411
2025-02-02 17:20:06,378 - INFO - Epoch 135: train_loss=0.6639
2025-02-02 17:20:07,035 - INFO - Epoch 135: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:20:07,045 - INFO - ####################Training epoch 136####################
2025-02-02 17:20:07,734 - INFO - Epoch 136: train_loss=0.8462
2025-02-02 17:20:07,893 - INFO - Epoch 136: train_loss=0.9209
2025-02-02 17:20:08,028 - INFO - Epoch 136: train_loss=0.7579
2025-02-02 17:20:08,678 - INFO - Epoch 136: val_loss=2.0005, val_acc=33.33%
2025-02-02 17:20:08,681 - INFO - ####################Training epoch 137####################
2025-02-02 17:20:09,333 - INFO - Epoch 137: train_loss=0.8481
2025-02-02 17:20:09,492 - INFO - Epoch 137: train_loss=0.7915
2025-02-02 17:20:09,627 - INFO - Epoch 137: train_loss=1.0878
2025-02-02 17:20:10,289 - INFO - Epoch 137: val_loss=1.9940, val_acc=33.33%
2025-02-02 17:20:10,293 - INFO - ####################Training epoch 138####################
2025-02-02 17:20:10,935 - INFO - Epoch 138: train_loss=0.9309
2025-02-02 17:20:11,093 - INFO - Epoch 138: train_loss=0.7966
2025-02-02 17:20:11,228 - INFO - Epoch 138: train_loss=0.8521
2025-02-02 17:20:11,891 - INFO - Epoch 138: val_loss=2.0045, val_acc=33.33%
2025-02-02 17:20:11,894 - INFO - ####################Training epoch 139####################
2025-02-02 17:20:12,527 - INFO - Epoch 139: train_loss=0.8846
2025-02-02 17:20:12,686 - INFO - Epoch 139: train_loss=0.8705
2025-02-02 17:20:12,821 - INFO - Epoch 139: train_loss=0.7865
2025-02-02 17:20:13,489 - INFO - Epoch 139: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:20:13,493 - INFO - ####################Training epoch 140####################
2025-02-02 17:20:14,148 - INFO - Epoch 140: train_loss=0.9381
2025-02-02 17:20:14,306 - INFO - Epoch 140: train_loss=0.9001
2025-02-02 17:20:14,441 - INFO - Epoch 140: train_loss=0.5872
2025-02-02 17:20:15,092 - INFO - Epoch 140: val_loss=1.9991, val_acc=33.33%
2025-02-02 17:20:15,096 - INFO - ####################Training epoch 141####################
2025-02-02 17:20:15,763 - INFO - Epoch 141: train_loss=0.8732
2025-02-02 17:20:15,921 - INFO - Epoch 141: train_loss=0.8851
2025-02-02 17:20:16,055 - INFO - Epoch 141: train_loss=0.7857
2025-02-02 17:20:16,723 - INFO - Epoch 141: val_loss=1.9963, val_acc=33.33%
2025-02-02 17:20:16,727 - INFO - ####################Training epoch 142####################
2025-02-02 17:20:17,384 - INFO - Epoch 142: train_loss=1.0359
2025-02-02 17:20:17,543 - INFO - Epoch 142: train_loss=0.7253
2025-02-02 17:20:17,677 - INFO - Epoch 142: train_loss=0.7689
2025-02-02 17:20:18,338 - INFO - Epoch 142: val_loss=1.9984, val_acc=33.33%
2025-02-02 17:20:18,342 - INFO - ####################Training epoch 143####################
2025-02-02 17:20:18,996 - INFO - Epoch 143: train_loss=0.8791
2025-02-02 17:20:19,153 - INFO - Epoch 143: train_loss=0.9334
2025-02-02 17:20:19,287 - INFO - Epoch 143: train_loss=0.6574
2025-02-02 17:20:19,942 - INFO - Epoch 143: val_loss=2.0022, val_acc=33.33%
2025-02-02 17:20:19,950 - INFO - ####################Training epoch 144####################
2025-02-02 17:20:20,605 - INFO - Epoch 144: train_loss=0.9008
2025-02-02 17:20:20,765 - INFO - Epoch 144: train_loss=0.7993
2025-02-02 17:20:20,899 - INFO - Epoch 144: train_loss=0.9237
2025-02-02 17:20:21,555 - INFO - Epoch 144: val_loss=1.9967, val_acc=33.33%
2025-02-02 17:20:21,559 - INFO - ####################Training epoch 145####################
2025-02-02 17:20:22,218 - INFO - Epoch 145: train_loss=0.8023
2025-02-02 17:20:22,376 - INFO - Epoch 145: train_loss=0.8743
2025-02-02 17:20:22,511 - INFO - Epoch 145: train_loss=0.9727
2025-02-02 17:20:23,178 - INFO - Epoch 145: val_loss=1.9994, val_acc=33.33%
2025-02-02 17:20:23,182 - INFO - ####################Training epoch 146####################
2025-02-02 17:20:23,828 - INFO - Epoch 146: train_loss=0.8850
2025-02-02 17:20:23,996 - INFO - Epoch 146: train_loss=0.7966
2025-02-02 17:20:24,131 - INFO - Epoch 146: train_loss=0.9789
2025-02-02 17:20:24,799 - INFO - Epoch 146: val_loss=1.9935, val_acc=33.33%
2025-02-02 17:20:24,803 - INFO - ####################Training epoch 147####################
2025-02-02 17:20:25,449 - INFO - Epoch 147: train_loss=0.8474
2025-02-02 17:20:25,607 - INFO - Epoch 147: train_loss=0.8730
2025-02-02 17:20:25,742 - INFO - Epoch 147: train_loss=0.8839
2025-02-02 17:20:26,408 - INFO - Epoch 147: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:20:26,412 - INFO - ####################Training epoch 148####################
2025-02-02 17:20:27,084 - INFO - Epoch 148: train_loss=0.8559
2025-02-02 17:20:27,243 - INFO - Epoch 148: train_loss=0.9226
2025-02-02 17:20:27,377 - INFO - Epoch 148: train_loss=0.7270
2025-02-02 17:20:28,053 - INFO - Epoch 148: val_loss=1.9941, val_acc=33.33%
2025-02-02 17:20:28,057 - INFO - ####################Training epoch 149####################
2025-02-02 17:20:28,712 - INFO - Epoch 149: train_loss=0.8289
2025-02-02 17:20:28,869 - INFO - Epoch 149: train_loss=0.8305
2025-02-02 17:20:29,003 - INFO - Epoch 149: train_loss=1.0280
2025-02-02 17:20:29,658 - INFO - Epoch 149: val_loss=1.9944, val_acc=33.33%
2025-02-02 17:20:29,663 - INFO - ####################Training epoch 150####################
2025-02-02 17:20:30,318 - INFO - Epoch 150: train_loss=1.0278
2025-02-02 17:20:30,476 - INFO - Epoch 150: train_loss=0.7655
2025-02-02 17:20:30,611 - INFO - Epoch 150: train_loss=0.6922
2025-02-02 17:20:31,267 - INFO - Epoch 150: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:20:31,271 - INFO - ####################Training epoch 151####################
2025-02-02 17:20:31,927 - INFO - Epoch 151: train_loss=0.7239
2025-02-02 17:20:32,085 - INFO - Epoch 151: train_loss=0.9096
2025-02-02 17:20:32,219 - INFO - Epoch 151: train_loss=1.1004
2025-02-02 17:20:32,944 - INFO - Epoch 151: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:20:32,948 - INFO - ####################Training epoch 152####################
2025-02-02 17:20:33,610 - INFO - Epoch 152: train_loss=0.9965
2025-02-02 17:20:33,767 - INFO - Epoch 152: train_loss=0.7382
2025-02-02 17:20:33,902 - INFO - Epoch 152: train_loss=0.8473
2025-02-02 17:20:34,566 - INFO - Epoch 152: val_loss=2.0005, val_acc=33.33%
2025-02-02 17:20:34,570 - INFO - ####################Training epoch 153####################
2025-02-02 17:20:35,199 - INFO - Epoch 153: train_loss=0.9231
2025-02-02 17:20:35,357 - INFO - Epoch 153: train_loss=0.7568
2025-02-02 17:20:35,491 - INFO - Epoch 153: train_loss=0.9776
2025-02-02 17:20:36,156 - INFO - Epoch 153: val_loss=1.9993, val_acc=33.33%
2025-02-02 17:20:36,160 - INFO - ####################Training epoch 154####################
2025-02-02 17:20:36,823 - INFO - Epoch 154: train_loss=0.8435
2025-02-02 17:20:36,981 - INFO - Epoch 154: train_loss=0.8179
2025-02-02 17:20:37,115 - INFO - Epoch 154: train_loss=1.0226
2025-02-02 17:20:37,772 - INFO - Epoch 154: val_loss=1.9996, val_acc=33.33%
2025-02-02 17:20:37,776 - INFO - ####################Training epoch 155####################
2025-02-02 17:20:38,435 - INFO - Epoch 155: train_loss=0.7577
2025-02-02 17:20:38,592 - INFO - Epoch 155: train_loss=0.8848
2025-02-02 17:20:38,727 - INFO - Epoch 155: train_loss=1.0624
2025-02-02 17:20:39,408 - INFO - Epoch 155: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:20:39,412 - INFO - ####################Training epoch 156####################
2025-02-02 17:20:40,055 - INFO - Epoch 156: train_loss=0.9452
2025-02-02 17:20:40,213 - INFO - Epoch 156: train_loss=0.7892
2025-02-02 17:20:40,348 - INFO - Epoch 156: train_loss=0.8322
2025-02-02 17:20:40,989 - INFO - Epoch 156: val_loss=2.0005, val_acc=33.33%
2025-02-02 17:20:40,993 - INFO - ####################Training epoch 157####################
2025-02-02 17:20:41,694 - INFO - Epoch 157: train_loss=0.8276
2025-02-02 17:20:41,851 - INFO - Epoch 157: train_loss=0.8645
2025-02-02 17:20:41,986 - INFO - Epoch 157: train_loss=0.9431
2025-02-02 17:20:42,665 - INFO - Epoch 157: val_loss=1.9931, val_acc=33.33%
2025-02-02 17:20:42,668 - INFO - ####################Training epoch 158####################
2025-02-02 17:20:43,317 - INFO - Epoch 158: train_loss=0.8308
2025-02-02 17:20:43,475 - INFO - Epoch 158: train_loss=1.0136
2025-02-02 17:20:43,610 - INFO - Epoch 158: train_loss=0.5665
2025-02-02 17:20:44,269 - INFO - Epoch 158: val_loss=1.9915, val_acc=33.33%
2025-02-02 17:20:44,272 - INFO - ####################Training epoch 159####################
2025-02-02 17:20:44,918 - INFO - Epoch 159: train_loss=0.9069
2025-02-02 17:20:45,077 - INFO - Epoch 159: train_loss=0.9019
2025-02-02 17:20:45,212 - INFO - Epoch 159: train_loss=0.6663
2025-02-02 17:20:45,868 - INFO - Epoch 159: val_loss=2.0001, val_acc=33.33%
2025-02-02 17:20:45,872 - INFO - ####################Training epoch 160####################
2025-02-02 17:20:46,527 - INFO - Epoch 160: train_loss=0.9698
2025-02-02 17:20:46,685 - INFO - Epoch 160: train_loss=0.7823
2025-02-02 17:20:46,820 - INFO - Epoch 160: train_loss=0.8000
2025-02-02 17:20:47,496 - INFO - Epoch 160: val_loss=1.9927, val_acc=33.33%
2025-02-02 17:20:47,500 - INFO - ####################Training epoch 161####################
2025-02-02 17:20:48,142 - INFO - Epoch 161: train_loss=0.9414
2025-02-02 17:20:48,300 - INFO - Epoch 161: train_loss=0.8699
2025-02-02 17:20:48,435 - INFO - Epoch 161: train_loss=0.6439
2025-02-02 17:20:49,099 - INFO - Epoch 161: val_loss=1.9963, val_acc=33.33%
2025-02-02 17:20:49,103 - INFO - ####################Training epoch 162####################
2025-02-02 17:20:49,779 - INFO - Epoch 162: train_loss=0.9089
2025-02-02 17:20:49,938 - INFO - Epoch 162: train_loss=0.8051
2025-02-02 17:20:50,073 - INFO - Epoch 162: train_loss=0.8888
2025-02-02 17:20:50,721 - INFO - Epoch 162: val_loss=1.9983, val_acc=33.33%
2025-02-02 17:20:50,725 - INFO - ####################Training epoch 163####################
2025-02-02 17:20:51,372 - INFO - Epoch 163: train_loss=0.8139
2025-02-02 17:20:51,529 - INFO - Epoch 163: train_loss=0.8551
2025-02-02 17:20:51,664 - INFO - Epoch 163: train_loss=1.0196
2025-02-02 17:20:52,333 - INFO - Epoch 163: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:20:52,337 - INFO - ####################Training epoch 164####################
2025-02-02 17:20:52,975 - INFO - Epoch 164: train_loss=0.8718
2025-02-02 17:20:53,134 - INFO - Epoch 164: train_loss=0.9207
2025-02-02 17:20:53,268 - INFO - Epoch 164: train_loss=0.6921
2025-02-02 17:20:53,919 - INFO - Epoch 164: val_loss=1.9940, val_acc=33.33%
2025-02-02 17:20:53,923 - INFO - ####################Training epoch 165####################
2025-02-02 17:20:54,558 - INFO - Epoch 165: train_loss=0.9316
2025-02-02 17:20:54,716 - INFO - Epoch 165: train_loss=0.8175
2025-02-02 17:20:54,851 - INFO - Epoch 165: train_loss=0.8075
2025-02-02 17:20:55,523 - INFO - Epoch 165: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:20:55,527 - INFO - ####################Training epoch 166####################
2025-02-02 17:20:56,153 - INFO - Epoch 166: train_loss=0.7307
2025-02-02 17:20:56,311 - INFO - Epoch 166: train_loss=0.9098
2025-02-02 17:20:56,445 - INFO - Epoch 166: train_loss=1.0815
2025-02-02 17:20:57,094 - INFO - Epoch 166: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:20:57,098 - INFO - ####################Training epoch 167####################
2025-02-02 17:20:57,753 - INFO - Epoch 167: train_loss=0.8608
2025-02-02 17:20:57,912 - INFO - Epoch 167: train_loss=0.9009
2025-02-02 17:20:58,048 - INFO - Epoch 167: train_loss=0.7771
2025-02-02 17:20:58,710 - INFO - Epoch 167: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:20:58,713 - INFO - ####################Training epoch 168####################
2025-02-02 17:20:59,337 - INFO - Epoch 168: train_loss=0.8687
2025-02-02 17:20:59,496 - INFO - Epoch 168: train_loss=0.8387
2025-02-02 17:20:59,631 - INFO - Epoch 168: train_loss=0.9080
2025-02-02 17:21:00,313 - INFO - Epoch 168: val_loss=2.0029, val_acc=33.33%
2025-02-02 17:21:00,317 - INFO - ####################Training epoch 169####################
2025-02-02 17:21:00,998 - INFO - Epoch 169: train_loss=0.7726
2025-02-02 17:21:01,156 - INFO - Epoch 169: train_loss=0.9427
2025-02-02 17:21:01,292 - INFO - Epoch 169: train_loss=0.8914
2025-02-02 17:21:01,986 - INFO - Epoch 169: val_loss=2.0020, val_acc=33.33%
2025-02-02 17:21:01,989 - INFO - ####################Training epoch 170####################
2025-02-02 17:21:02,611 - INFO - Epoch 170: train_loss=0.8002
2025-02-02 17:21:02,770 - INFO - Epoch 170: train_loss=0.7997
2025-02-02 17:21:02,904 - INFO - Epoch 170: train_loss=1.1654
2025-02-02 17:21:03,554 - INFO - Epoch 170: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:21:03,558 - INFO - ####################Training epoch 171####################
2025-02-02 17:21:04,205 - INFO - Epoch 171: train_loss=0.8297
2025-02-02 17:21:04,362 - INFO - Epoch 171: train_loss=0.9052
2025-02-02 17:21:04,497 - INFO - Epoch 171: train_loss=0.8340
2025-02-02 17:21:05,179 - INFO - Epoch 171: val_loss=1.9993, val_acc=33.33%
2025-02-02 17:21:05,183 - INFO - ####################Training epoch 172####################
2025-02-02 17:21:05,830 - INFO - Epoch 172: train_loss=0.9074
2025-02-02 17:21:05,988 - INFO - Epoch 172: train_loss=0.7464
2025-02-02 17:21:06,133 - INFO - Epoch 172: train_loss=1.0538
2025-02-02 17:21:06,825 - INFO - Epoch 172: val_loss=1.9973, val_acc=33.33%
2025-02-02 17:21:06,828 - INFO - ####################Training epoch 173####################
2025-02-02 17:21:07,472 - INFO - Epoch 173: train_loss=0.7773
2025-02-02 17:21:07,631 - INFO - Epoch 173: train_loss=0.9633
2025-02-02 17:21:07,765 - INFO - Epoch 173: train_loss=0.8309
2025-02-02 17:21:08,436 - INFO - Epoch 173: val_loss=1.9952, val_acc=33.33%
2025-02-02 17:21:08,440 - INFO - ####################Training epoch 174####################
2025-02-02 17:21:09,095 - INFO - Epoch 174: train_loss=1.0141
2025-02-02 17:21:09,253 - INFO - Epoch 174: train_loss=0.8452
2025-02-02 17:21:09,388 - INFO - Epoch 174: train_loss=0.5262
2025-02-02 17:21:10,066 - INFO - Epoch 174: val_loss=1.9994, val_acc=33.33%
2025-02-02 17:21:10,069 - INFO - ####################Training epoch 175####################
2025-02-02 17:21:10,719 - INFO - Epoch 175: train_loss=0.7288
2025-02-02 17:21:10,876 - INFO - Epoch 175: train_loss=1.0270
2025-02-02 17:21:11,011 - INFO - Epoch 175: train_loss=0.7763
2025-02-02 17:21:11,664 - INFO - Epoch 175: val_loss=1.9941, val_acc=33.33%
2025-02-02 17:21:11,668 - INFO - ####################Training epoch 176####################
2025-02-02 17:21:12,328 - INFO - Epoch 176: train_loss=0.8793
2025-02-02 17:21:12,486 - INFO - Epoch 176: train_loss=0.8635
2025-02-02 17:21:12,621 - INFO - Epoch 176: train_loss=0.8223
2025-02-02 17:21:13,268 - INFO - Epoch 176: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:21:13,272 - INFO - ####################Training epoch 177####################
2025-02-02 17:21:13,926 - INFO - Epoch 177: train_loss=0.8603
2025-02-02 17:21:14,084 - INFO - Epoch 177: train_loss=0.8223
2025-02-02 17:21:14,218 - INFO - Epoch 177: train_loss=0.9763
2025-02-02 17:21:14,879 - INFO - Epoch 177: val_loss=1.9968, val_acc=33.33%
2025-02-02 17:21:14,883 - INFO - ####################Training epoch 178####################
2025-02-02 17:21:15,597 - INFO - Epoch 178: train_loss=0.9563
2025-02-02 17:21:15,754 - INFO - Epoch 178: train_loss=0.8371
2025-02-02 17:21:15,889 - INFO - Epoch 178: train_loss=0.6884
2025-02-02 17:21:16,537 - INFO - Epoch 178: val_loss=1.9928, val_acc=33.33%
2025-02-02 17:21:16,541 - INFO - ####################Training epoch 179####################
2025-02-02 17:21:17,179 - INFO - Epoch 179: train_loss=0.8273
2025-02-02 17:21:17,337 - INFO - Epoch 179: train_loss=0.8719
2025-02-02 17:21:17,471 - INFO - Epoch 179: train_loss=0.9265
2025-02-02 17:21:18,140 - INFO - Epoch 179: val_loss=2.0033, val_acc=33.33%
2025-02-02 17:21:18,144 - INFO - ####################Training epoch 180####################
2025-02-02 17:21:18,800 - INFO - Epoch 180: train_loss=0.9550
2025-02-02 17:21:18,957 - INFO - Epoch 180: train_loss=0.7949
2025-02-02 17:21:19,092 - INFO - Epoch 180: train_loss=0.7997
2025-02-02 17:21:19,769 - INFO - Epoch 180: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:21:19,772 - INFO - ####################Training epoch 181####################
2025-02-02 17:21:20,425 - INFO - Epoch 181: train_loss=0.8780
2025-02-02 17:21:20,583 - INFO - Epoch 181: train_loss=0.8822
2025-02-02 17:21:20,718 - INFO - Epoch 181: train_loss=0.7788
2025-02-02 17:21:21,369 - INFO - Epoch 181: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:21:21,373 - INFO - ####################Training epoch 182####################
2025-02-02 17:21:22,010 - INFO - Epoch 182: train_loss=0.9152
2025-02-02 17:21:22,169 - INFO - Epoch 182: train_loss=0.7912
2025-02-02 17:21:22,304 - INFO - Epoch 182: train_loss=0.9125
2025-02-02 17:21:22,984 - INFO - Epoch 182: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:21:22,988 - INFO - ####################Training epoch 183####################
2025-02-02 17:21:23,664 - INFO - Epoch 183: train_loss=0.9385
2025-02-02 17:21:23,823 - INFO - Epoch 183: train_loss=0.7802
2025-02-02 17:21:23,957 - INFO - Epoch 183: train_loss=0.8854
2025-02-02 17:21:24,605 - INFO - Epoch 183: val_loss=1.9914, val_acc=33.33%
2025-02-02 17:21:24,609 - INFO - ####################Training epoch 184####################
2025-02-02 17:21:25,270 - INFO - Epoch 184: train_loss=0.9545
2025-02-02 17:21:25,428 - INFO - Epoch 184: train_loss=0.6910
2025-02-02 17:21:25,563 - INFO - Epoch 184: train_loss=1.0717
2025-02-02 17:21:26,235 - INFO - Epoch 184: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:21:26,239 - INFO - ####################Training epoch 185####################
2025-02-02 17:21:26,889 - INFO - Epoch 185: train_loss=0.8702
2025-02-02 17:21:27,047 - INFO - Epoch 185: train_loss=0.9096
2025-02-02 17:21:27,182 - INFO - Epoch 185: train_loss=0.7234
2025-02-02 17:21:27,824 - INFO - Epoch 185: val_loss=1.9928, val_acc=33.33%
2025-02-02 17:21:27,827 - INFO - ####################Training epoch 186####################
2025-02-02 17:21:28,482 - INFO - Epoch 186: train_loss=0.8839
2025-02-02 17:21:28,640 - INFO - Epoch 186: train_loss=0.7670
2025-02-02 17:21:28,774 - INFO - Epoch 186: train_loss=1.0406
2025-02-02 17:21:29,419 - INFO - Epoch 186: val_loss=1.9961, val_acc=33.33%
2025-02-02 17:21:29,422 - INFO - ####################Training epoch 187####################
2025-02-02 17:21:30,075 - INFO - Epoch 187: train_loss=0.9166
2025-02-02 17:21:30,232 - INFO - Epoch 187: train_loss=0.8183
2025-02-02 17:21:30,366 - INFO - Epoch 187: train_loss=0.8456
2025-02-02 17:21:31,036 - INFO - Epoch 187: val_loss=2.0004, val_acc=33.33%
2025-02-02 17:21:31,040 - INFO - ####################Training epoch 188####################
2025-02-02 17:21:31,755 - INFO - Epoch 188: train_loss=0.8967
2025-02-02 17:21:31,913 - INFO - Epoch 188: train_loss=0.9356
2025-02-02 17:21:32,047 - INFO - Epoch 188: train_loss=0.5968
2025-02-02 17:21:32,692 - INFO - Epoch 188: val_loss=1.9983, val_acc=33.33%
2025-02-02 17:21:32,696 - INFO - ####################Training epoch 189####################
2025-02-02 17:21:33,341 - INFO - Epoch 189: train_loss=0.8165
2025-02-02 17:21:33,499 - INFO - Epoch 189: train_loss=0.9091
2025-02-02 17:21:33,634 - INFO - Epoch 189: train_loss=0.8637
2025-02-02 17:21:34,318 - INFO - Epoch 189: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:21:34,322 - INFO - ####################Training epoch 190####################
2025-02-02 17:21:34,985 - INFO - Epoch 190: train_loss=0.8114
2025-02-02 17:21:35,144 - INFO - Epoch 190: train_loss=0.9113
2025-02-02 17:21:35,279 - INFO - Epoch 190: train_loss=0.8673
2025-02-02 17:21:35,957 - INFO - Epoch 190: val_loss=1.9941, val_acc=33.33%
2025-02-02 17:21:35,960 - INFO - ####################Training epoch 191####################
2025-02-02 17:21:36,623 - INFO - Epoch 191: train_loss=0.9473
2025-02-02 17:21:36,781 - INFO - Epoch 191: train_loss=0.7663
2025-02-02 17:21:36,916 - INFO - Epoch 191: train_loss=0.8888
2025-02-02 17:21:37,589 - INFO - Epoch 191: val_loss=2.0025, val_acc=33.33%
2025-02-02 17:21:37,593 - INFO - ####################Training epoch 192####################
2025-02-02 17:21:38,253 - INFO - Epoch 192: train_loss=0.7164
2025-02-02 17:21:38,410 - INFO - Epoch 192: train_loss=0.9660
2025-02-02 17:21:38,545 - INFO - Epoch 192: train_loss=0.9609
2025-02-02 17:21:39,187 - INFO - Epoch 192: val_loss=1.9930, val_acc=33.33%
2025-02-02 17:21:39,195 - INFO - ####################Training epoch 193####################
2025-02-02 17:21:39,837 - INFO - Epoch 193: train_loss=0.9147
2025-02-02 17:21:40,003 - INFO - Epoch 193: train_loss=0.8475
2025-02-02 17:21:40,139 - INFO - Epoch 193: train_loss=0.7727
2025-02-02 17:21:40,795 - INFO - Epoch 193: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:21:40,799 - INFO - ####################Training epoch 194####################
2025-02-02 17:21:41,457 - INFO - Epoch 194: train_loss=0.8026
2025-02-02 17:21:41,615 - INFO - Epoch 194: train_loss=0.9628
2025-02-02 17:21:41,750 - INFO - Epoch 194: train_loss=0.7552
2025-02-02 17:21:42,398 - INFO - Epoch 194: val_loss=1.9992, val_acc=33.33%
2025-02-02 17:21:42,402 - INFO - ####################Training epoch 195####################
2025-02-02 17:21:43,047 - INFO - Epoch 195: train_loss=0.8943
2025-02-02 17:21:43,205 - INFO - Epoch 195: train_loss=0.7676
2025-02-02 17:21:43,339 - INFO - Epoch 195: train_loss=1.0201
2025-02-02 17:21:44,001 - INFO - Epoch 195: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:21:44,005 - INFO - ####################Training epoch 196####################
2025-02-02 17:21:44,653 - INFO - Epoch 196: train_loss=0.9010
2025-02-02 17:21:44,811 - INFO - Epoch 196: train_loss=0.8467
2025-02-02 17:21:44,946 - INFO - Epoch 196: train_loss=0.8160
2025-02-02 17:21:45,608 - INFO - Epoch 196: val_loss=1.9996, val_acc=33.33%
2025-02-02 17:21:45,611 - INFO - ####################Training epoch 197####################
2025-02-02 17:21:46,250 - INFO - Epoch 197: train_loss=0.8734
2025-02-02 17:21:46,408 - INFO - Epoch 197: train_loss=0.9616
2025-02-02 17:21:46,542 - INFO - Epoch 197: train_loss=0.5860
2025-02-02 17:21:47,192 - INFO - Epoch 197: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:21:47,196 - INFO - ####################Training epoch 198####################
2025-02-02 17:21:47,836 - INFO - Epoch 198: train_loss=1.0463
2025-02-02 17:21:47,994 - INFO - Epoch 198: train_loss=0.7145
2025-02-02 17:21:48,129 - INFO - Epoch 198: train_loss=0.7668
2025-02-02 17:21:48,840 - INFO - Epoch 198: val_loss=1.9927, val_acc=33.33%
2025-02-02 17:21:48,844 - INFO - ####################Training epoch 199####################
2025-02-02 17:21:49,494 - INFO - Epoch 199: train_loss=0.9769
2025-02-02 17:21:49,652 - INFO - Epoch 199: train_loss=0.8586
2025-02-02 17:21:49,786 - INFO - Epoch 199: train_loss=0.5788
2025-02-02 17:21:50,448 - INFO - Epoch 199: val_loss=1.9920, val_acc=33.33%
2025-02-02 17:21:50,452 - INFO - ####################Training epoch 200####################
2025-02-02 17:21:51,085 - INFO - Epoch 200: train_loss=0.8639
2025-02-02 17:21:51,242 - INFO - Epoch 200: train_loss=0.7381
2025-02-02 17:21:51,377 - INFO - Epoch 200: train_loss=1.1645
2025-02-02 17:21:52,045 - INFO - Epoch 200: val_loss=1.9950, val_acc=33.33%
2025-02-02 17:21:52,049 - INFO - ####################Training epoch 201####################
2025-02-02 17:21:52,706 - INFO - Epoch 201: train_loss=0.9382
2025-02-02 17:21:52,864 - INFO - Epoch 201: train_loss=0.8188
2025-02-02 17:21:52,998 - INFO - Epoch 201: train_loss=0.7919
2025-02-02 17:21:53,651 - INFO - Epoch 201: val_loss=1.9948, val_acc=33.33%
2025-02-02 17:21:53,654 - INFO - ####################Training epoch 202####################
2025-02-02 17:21:54,295 - INFO - Epoch 202: train_loss=0.9339
2025-02-02 17:21:54,454 - INFO - Epoch 202: train_loss=0.8207
2025-02-02 17:21:54,588 - INFO - Epoch 202: train_loss=0.7926
2025-02-02 17:21:55,243 - INFO - Epoch 202: val_loss=2.0009, val_acc=33.33%
2025-02-02 17:21:55,246 - INFO - ####################Training epoch 203####################
2025-02-02 17:21:55,900 - INFO - Epoch 203: train_loss=0.8500
2025-02-02 17:21:56,058 - INFO - Epoch 203: train_loss=0.9706
2025-02-02 17:21:56,193 - INFO - Epoch 203: train_loss=0.6278
2025-02-02 17:21:56,893 - INFO - Epoch 203: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:21:56,896 - INFO - ####################Training epoch 204####################
2025-02-02 17:21:57,547 - INFO - Epoch 204: train_loss=0.8797
2025-02-02 17:21:57,704 - INFO - Epoch 204: train_loss=0.8383
2025-02-02 17:21:57,839 - INFO - Epoch 204: train_loss=0.8877
2025-02-02 17:21:58,508 - INFO - Epoch 204: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:21:58,511 - INFO - ####################Training epoch 205####################
2025-02-02 17:21:59,154 - INFO - Epoch 205: train_loss=0.7645
2025-02-02 17:21:59,312 - INFO - Epoch 205: train_loss=0.8945
2025-02-02 17:21:59,447 - INFO - Epoch 205: train_loss=1.0195
2025-02-02 17:22:00,100 - INFO - Epoch 205: val_loss=1.9977, val_acc=33.33%
2025-02-02 17:22:00,104 - INFO - ####################Training epoch 206####################
2025-02-02 17:22:00,752 - INFO - Epoch 206: train_loss=0.8661
2025-02-02 17:22:00,911 - INFO - Epoch 206: train_loss=0.7753
2025-02-02 17:22:01,045 - INFO - Epoch 206: train_loss=1.0760
2025-02-02 17:22:01,716 - INFO - Epoch 206: val_loss=1.9898, val_acc=33.33%
2025-02-02 17:22:01,720 - INFO - ####################Training epoch 207####################
2025-02-02 17:22:02,365 - INFO - Epoch 207: train_loss=0.8712
2025-02-02 17:22:02,522 - INFO - Epoch 207: train_loss=0.7666
2025-02-02 17:22:02,657 - INFO - Epoch 207: train_loss=1.0870
2025-02-02 17:22:03,308 - INFO - Epoch 207: val_loss=1.9946, val_acc=33.33%
2025-02-02 17:22:03,313 - INFO - ####################Training epoch 208####################
2025-02-02 17:22:03,957 - INFO - Epoch 208: train_loss=0.7613
2025-02-02 17:22:04,115 - INFO - Epoch 208: train_loss=0.9939
2025-02-02 17:22:04,250 - INFO - Epoch 208: train_loss=0.7830
2025-02-02 17:22:04,923 - INFO - Epoch 208: val_loss=1.9953, val_acc=33.33%
2025-02-02 17:22:04,927 - INFO - ####################Training epoch 209####################
2025-02-02 17:22:05,637 - INFO - Epoch 209: train_loss=0.8369
2025-02-02 17:22:05,795 - INFO - Epoch 209: train_loss=0.8457
2025-02-02 17:22:05,929 - INFO - Epoch 209: train_loss=0.9687
2025-02-02 17:22:06,579 - INFO - Epoch 209: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:22:06,583 - INFO - ####################Training epoch 210####################
2025-02-02 17:22:07,241 - INFO - Epoch 210: train_loss=0.8908
2025-02-02 17:22:07,398 - INFO - Epoch 210: train_loss=0.8677
2025-02-02 17:22:07,533 - INFO - Epoch 210: train_loss=0.7782
2025-02-02 17:22:08,187 - INFO - Epoch 210: val_loss=1.9964, val_acc=33.33%
2025-02-02 17:22:08,191 - INFO - ####################Training epoch 211####################
2025-02-02 17:22:08,871 - INFO - Epoch 211: train_loss=0.9013
2025-02-02 17:22:09,030 - INFO - Epoch 211: train_loss=0.7985
2025-02-02 17:22:09,165 - INFO - Epoch 211: train_loss=0.9290
2025-02-02 17:22:09,832 - INFO - Epoch 211: val_loss=1.9992, val_acc=33.33%
2025-02-02 17:22:09,835 - INFO - ####################Training epoch 212####################
2025-02-02 17:22:10,465 - INFO - Epoch 212: train_loss=0.7608
2025-02-02 17:22:10,623 - INFO - Epoch 212: train_loss=0.9395
2025-02-02 17:22:10,757 - INFO - Epoch 212: train_loss=0.9228
2025-02-02 17:22:11,434 - INFO - Epoch 212: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:22:11,438 - INFO - ####################Training epoch 213####################
2025-02-02 17:22:12,069 - INFO - Epoch 213: train_loss=0.8764
2025-02-02 17:22:12,227 - INFO - Epoch 213: train_loss=0.9053
2025-02-02 17:22:12,362 - INFO - Epoch 213: train_loss=0.7112
2025-02-02 17:22:13,029 - INFO - Epoch 213: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:22:13,033 - INFO - ####################Training epoch 214####################
2025-02-02 17:22:13,697 - INFO - Epoch 214: train_loss=0.7183
2025-02-02 17:22:13,858 - INFO - Epoch 214: train_loss=0.9295
2025-02-02 17:22:13,992 - INFO - Epoch 214: train_loss=1.0659
2025-02-02 17:22:14,660 - INFO - Epoch 214: val_loss=1.9968, val_acc=33.33%
2025-02-02 17:22:14,664 - INFO - ####################Training epoch 215####################
2025-02-02 17:22:15,312 - INFO - Epoch 215: train_loss=0.8618
2025-02-02 17:22:15,470 - INFO - Epoch 215: train_loss=0.8170
2025-02-02 17:22:15,604 - INFO - Epoch 215: train_loss=0.9710
2025-02-02 17:22:16,276 - INFO - Epoch 215: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:22:16,280 - INFO - ####################Training epoch 216####################
2025-02-02 17:22:16,926 - INFO - Epoch 216: train_loss=0.7138
2025-02-02 17:22:17,084 - INFO - Epoch 216: train_loss=0.9901
2025-02-02 17:22:17,219 - INFO - Epoch 216: train_loss=0.9146
2025-02-02 17:22:17,892 - INFO - Epoch 216: val_loss=1.9949, val_acc=33.33%
2025-02-02 17:22:17,896 - INFO - ####################Training epoch 217####################
2025-02-02 17:22:18,547 - INFO - Epoch 217: train_loss=0.7765
2025-02-02 17:22:18,705 - INFO - Epoch 217: train_loss=0.8773
2025-02-02 17:22:18,839 - INFO - Epoch 217: train_loss=1.0454
2025-02-02 17:22:19,477 - INFO - Epoch 217: val_loss=1.9924, val_acc=33.33%
2025-02-02 17:22:19,480 - INFO - ####################Training epoch 218####################
2025-02-02 17:22:20,136 - INFO - Epoch 218: train_loss=0.7902
2025-02-02 17:22:20,294 - INFO - Epoch 218: train_loss=0.9335
2025-02-02 17:22:20,428 - INFO - Epoch 218: train_loss=0.8649
2025-02-02 17:22:21,110 - INFO - Epoch 218: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:22:21,113 - INFO - ####################Training epoch 219####################
2025-02-02 17:22:21,767 - INFO - Epoch 219: train_loss=1.0033
2025-02-02 17:22:21,925 - INFO - Epoch 219: train_loss=0.7472
2025-02-02 17:22:22,060 - INFO - Epoch 219: train_loss=0.8025
2025-02-02 17:22:22,760 - INFO - Epoch 219: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:22:22,764 - INFO - ####################Training epoch 220####################
2025-02-02 17:22:23,425 - INFO - Epoch 220: train_loss=0.9589
2025-02-02 17:22:23,584 - INFO - Epoch 220: train_loss=0.7908
2025-02-02 17:22:23,718 - INFO - Epoch 220: train_loss=0.8043
2025-02-02 17:22:24,393 - INFO - Epoch 220: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:22:24,397 - INFO - ####################Training epoch 221####################
2025-02-02 17:22:25,042 - INFO - Epoch 221: train_loss=0.7950
2025-02-02 17:22:25,200 - INFO - Epoch 221: train_loss=0.9572
2025-02-02 17:22:25,335 - INFO - Epoch 221: train_loss=0.7924
2025-02-02 17:22:25,981 - INFO - Epoch 221: val_loss=2.0020, val_acc=33.33%
2025-02-02 17:22:25,985 - INFO - ####################Training epoch 222####################
2025-02-02 17:22:26,640 - INFO - Epoch 222: train_loss=0.8353
2025-02-02 17:22:26,799 - INFO - Epoch 222: train_loss=0.9011
2025-02-02 17:22:26,933 - INFO - Epoch 222: train_loss=0.8167
2025-02-02 17:22:27,599 - INFO - Epoch 222: val_loss=1.9952, val_acc=33.33%
2025-02-02 17:22:27,603 - INFO - ####################Training epoch 223####################
2025-02-02 17:22:28,238 - INFO - Epoch 223: train_loss=0.8035
2025-02-02 17:22:28,396 - INFO - Epoch 223: train_loss=0.9495
2025-02-02 17:22:28,530 - INFO - Epoch 223: train_loss=0.7965
2025-02-02 17:22:29,186 - INFO - Epoch 223: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:22:29,190 - INFO - ####################Training epoch 224####################
2025-02-02 17:22:29,842 - INFO - Epoch 224: train_loss=0.9368
2025-02-02 17:22:30,000 - INFO - Epoch 224: train_loss=0.7231
2025-02-02 17:22:30,135 - INFO - Epoch 224: train_loss=1.0271
2025-02-02 17:22:30,835 - INFO - Epoch 224: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:22:30,839 - INFO - ####################Training epoch 225####################
2025-02-02 17:22:31,492 - INFO - Epoch 225: train_loss=0.8140
2025-02-02 17:22:31,650 - INFO - Epoch 225: train_loss=0.8157
2025-02-02 17:22:31,785 - INFO - Epoch 225: train_loss=1.0957
2025-02-02 17:22:32,449 - INFO - Epoch 225: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:22:32,453 - INFO - ####################Training epoch 226####################
2025-02-02 17:22:33,091 - INFO - Epoch 226: train_loss=0.9817
2025-02-02 17:22:33,248 - INFO - Epoch 226: train_loss=0.8091
2025-02-02 17:22:33,383 - INFO - Epoch 226: train_loss=0.6957
2025-02-02 17:22:34,031 - INFO - Epoch 226: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:22:34,035 - INFO - ####################Training epoch 227####################
2025-02-02 17:22:34,686 - INFO - Epoch 227: train_loss=0.8834
2025-02-02 17:22:34,844 - INFO - Epoch 227: train_loss=0.8684
2025-02-02 17:22:34,978 - INFO - Epoch 227: train_loss=0.7987
2025-02-02 17:22:35,643 - INFO - Epoch 227: val_loss=1.9993, val_acc=33.33%
2025-02-02 17:22:35,646 - INFO - ####################Training epoch 228####################
2025-02-02 17:22:36,303 - INFO - Epoch 228: train_loss=0.9561
2025-02-02 17:22:36,461 - INFO - Epoch 228: train_loss=0.8276
2025-02-02 17:22:36,595 - INFO - Epoch 228: train_loss=0.7211
2025-02-02 17:22:37,258 - INFO - Epoch 228: val_loss=1.9968, val_acc=33.33%
2025-02-02 17:22:37,261 - INFO - ####################Training epoch 229####################
2025-02-02 17:22:37,917 - INFO - Epoch 229: train_loss=0.8700
2025-02-02 17:22:38,075 - INFO - Epoch 229: train_loss=0.8574
2025-02-02 17:22:38,209 - INFO - Epoch 229: train_loss=0.8627
2025-02-02 17:22:38,874 - INFO - Epoch 229: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:22:38,878 - INFO - ####################Training epoch 230####################
2025-02-02 17:22:39,579 - INFO - Epoch 230: train_loss=0.9557
2025-02-02 17:22:39,737 - INFO - Epoch 230: train_loss=0.8333
2025-02-02 17:22:39,872 - INFO - Epoch 230: train_loss=0.7009
2025-02-02 17:22:40,515 - INFO - Epoch 230: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:22:40,519 - INFO - ####################Training epoch 231####################
2025-02-02 17:22:41,175 - INFO - Epoch 231: train_loss=0.9215
2025-02-02 17:22:41,333 - INFO - Epoch 231: train_loss=0.7858
2025-02-02 17:22:41,467 - INFO - Epoch 231: train_loss=0.8921
2025-02-02 17:22:42,161 - INFO - Epoch 231: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:22:42,165 - INFO - ####################Training epoch 232####################
2025-02-02 17:22:42,837 - INFO - Epoch 232: train_loss=0.8896
2025-02-02 17:22:42,996 - INFO - Epoch 232: train_loss=0.8421
2025-02-02 17:22:43,130 - INFO - Epoch 232: train_loss=0.8485
2025-02-02 17:22:43,785 - INFO - Epoch 232: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:22:43,788 - INFO - ####################Training epoch 233####################
2025-02-02 17:22:44,444 - INFO - Epoch 233: train_loss=0.8285
2025-02-02 17:22:44,602 - INFO - Epoch 233: train_loss=0.9538
2025-02-02 17:22:44,737 - INFO - Epoch 233: train_loss=0.7175
2025-02-02 17:22:45,407 - INFO - Epoch 233: val_loss=1.9991, val_acc=33.33%
2025-02-02 17:22:45,411 - INFO - ####################Training epoch 234####################
2025-02-02 17:22:46,067 - INFO - Epoch 234: train_loss=0.8028
2025-02-02 17:22:46,226 - INFO - Epoch 234: train_loss=0.9471
2025-02-02 17:22:46,360 - INFO - Epoch 234: train_loss=0.8085
2025-02-02 17:22:47,027 - INFO - Epoch 234: val_loss=2.0016, val_acc=33.33%
2025-02-02 17:22:47,031 - INFO - ####################Training epoch 235####################
2025-02-02 17:22:47,718 - INFO - Epoch 235: train_loss=0.7993
2025-02-02 17:22:47,877 - INFO - Epoch 235: train_loss=0.9708
2025-02-02 17:22:48,011 - INFO - Epoch 235: train_loss=0.7637
2025-02-02 17:22:48,665 - INFO - Epoch 235: val_loss=1.9998, val_acc=33.33%
2025-02-02 17:22:48,668 - INFO - ####################Training epoch 236####################
2025-02-02 17:22:49,315 - INFO - Epoch 236: train_loss=0.7365
2025-02-02 17:22:49,473 - INFO - Epoch 236: train_loss=0.9292
2025-02-02 17:22:49,608 - INFO - Epoch 236: train_loss=0.9999
2025-02-02 17:22:50,280 - INFO - Epoch 236: val_loss=1.9967, val_acc=33.33%
2025-02-02 17:22:50,283 - INFO - ####################Training epoch 237####################
2025-02-02 17:22:50,941 - INFO - Epoch 237: train_loss=0.9505
2025-02-02 17:22:51,100 - INFO - Epoch 237: train_loss=0.7535
2025-02-02 17:22:51,236 - INFO - Epoch 237: train_loss=0.8946
2025-02-02 17:22:51,912 - INFO - Epoch 237: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:22:51,916 - INFO - ####################Training epoch 238####################
2025-02-02 17:22:52,561 - INFO - Epoch 238: train_loss=0.8179
2025-02-02 17:22:52,719 - INFO - Epoch 238: train_loss=0.8988
2025-02-02 17:22:52,855 - INFO - Epoch 238: train_loss=0.8783
2025-02-02 17:22:53,515 - INFO - Epoch 238: val_loss=1.9981, val_acc=33.33%
2025-02-02 17:22:53,519 - INFO - ####################Training epoch 239####################
2025-02-02 17:22:54,156 - INFO - Epoch 239: train_loss=0.8558
2025-02-02 17:22:54,313 - INFO - Epoch 239: train_loss=0.8590
2025-02-02 17:22:54,449 - INFO - Epoch 239: train_loss=0.8810
2025-02-02 17:22:55,103 - INFO - Epoch 239: val_loss=1.9940, val_acc=33.33%
2025-02-02 17:22:55,107 - INFO - ####################Training epoch 240####################
2025-02-02 17:22:55,765 - INFO - Epoch 240: train_loss=0.7953
2025-02-02 17:22:55,933 - INFO - Epoch 240: train_loss=0.8037
2025-02-02 17:22:56,069 - INFO - Epoch 240: train_loss=1.1705
2025-02-02 17:22:56,714 - INFO - Epoch 240: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:22:56,718 - INFO - ####################Training epoch 241####################
2025-02-02 17:22:57,375 - INFO - Epoch 241: train_loss=0.7353
2025-02-02 17:22:57,533 - INFO - Epoch 241: train_loss=1.0250
2025-02-02 17:22:57,669 - INFO - Epoch 241: train_loss=0.7725
2025-02-02 17:22:58,348 - INFO - Epoch 241: val_loss=2.0013, val_acc=33.33%
2025-02-02 17:22:58,352 - INFO - ####################Training epoch 242####################
2025-02-02 17:22:59,014 - INFO - Epoch 242: train_loss=0.8407
2025-02-02 17:22:59,173 - INFO - Epoch 242: train_loss=0.8606
2025-02-02 17:22:59,308 - INFO - Epoch 242: train_loss=0.9197
2025-02-02 17:22:59,963 - INFO - Epoch 242: val_loss=1.9930, val_acc=33.33%
2025-02-02 17:22:59,967 - INFO - ####################Training epoch 243####################
2025-02-02 17:23:00,622 - INFO - Epoch 243: train_loss=0.9505
2025-02-02 17:23:00,781 - INFO - Epoch 243: train_loss=0.7836
2025-02-02 17:23:00,916 - INFO - Epoch 243: train_loss=0.8487
2025-02-02 17:23:01,573 - INFO - Epoch 243: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:23:01,576 - INFO - ####################Training epoch 244####################
2025-02-02 17:23:02,233 - INFO - Epoch 244: train_loss=0.6957
2025-02-02 17:23:02,391 - INFO - Epoch 244: train_loss=1.0513
2025-02-02 17:23:02,526 - INFO - Epoch 244: train_loss=0.8231
2025-02-02 17:23:03,210 - INFO - Epoch 244: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:23:03,214 - INFO - ####################Training epoch 245####################
2025-02-02 17:23:03,870 - INFO - Epoch 245: train_loss=0.9142
2025-02-02 17:23:04,029 - INFO - Epoch 245: train_loss=0.7578
2025-02-02 17:23:04,171 - INFO - Epoch 245: train_loss=0.9964
2025-02-02 17:23:04,857 - INFO - Epoch 245: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:23:04,861 - INFO - ####################Training epoch 246####################
2025-02-02 17:23:05,524 - INFO - Epoch 246: train_loss=0.9303
2025-02-02 17:23:05,682 - INFO - Epoch 246: train_loss=0.9031
2025-02-02 17:23:05,817 - INFO - Epoch 246: train_loss=0.5891
2025-02-02 17:23:06,481 - INFO - Epoch 246: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:23:06,485 - INFO - ####################Training epoch 247####################
2025-02-02 17:23:07,143 - INFO - Epoch 247: train_loss=0.9590
2025-02-02 17:23:07,301 - INFO - Epoch 247: train_loss=0.9160
2025-02-02 17:23:07,436 - INFO - Epoch 247: train_loss=0.4819
2025-02-02 17:23:08,081 - INFO - Epoch 247: val_loss=1.9937, val_acc=33.33%
2025-02-02 17:23:08,085 - INFO - ####################Training epoch 248####################
2025-02-02 17:23:08,746 - INFO - Epoch 248: train_loss=0.7673
2025-02-02 17:23:08,905 - INFO - Epoch 248: train_loss=1.0173
2025-02-02 17:23:09,040 - INFO - Epoch 248: train_loss=0.7108
2025-02-02 17:23:09,677 - INFO - Epoch 248: val_loss=2.0000, val_acc=33.33%
2025-02-02 17:23:09,681 - INFO - ####################Training epoch 249####################
2025-02-02 17:23:10,317 - INFO - Epoch 249: train_loss=0.9391
2025-02-02 17:23:10,475 - INFO - Epoch 249: train_loss=0.7496
2025-02-02 17:23:10,610 - INFO - Epoch 249: train_loss=0.9571
2025-02-02 17:23:11,281 - INFO - Epoch 249: val_loss=2.0020, val_acc=33.33%
2025-02-02 17:23:11,285 - INFO - ####################Training epoch 250####################
2025-02-02 17:23:11,944 - INFO - Epoch 250: train_loss=0.7956
2025-02-02 17:23:12,101 - INFO - Epoch 250: train_loss=0.9993
2025-02-02 17:23:12,236 - INFO - Epoch 250: train_loss=0.6961
2025-02-02 17:23:12,962 - INFO - Epoch 250: val_loss=1.9979, val_acc=33.33%
2025-02-02 17:23:12,966 - INFO - ####################Training epoch 251####################
2025-02-02 17:23:13,629 - INFO - Epoch 251: train_loss=0.9685
2025-02-02 17:23:13,787 - INFO - Epoch 251: train_loss=0.6865
2025-02-02 17:23:13,922 - INFO - Epoch 251: train_loss=1.0378
2025-02-02 17:23:14,587 - INFO - Epoch 251: val_loss=1.9978, val_acc=33.33%
2025-02-02 17:23:14,590 - INFO - ####################Training epoch 252####################
2025-02-02 17:23:15,246 - INFO - Epoch 252: train_loss=0.8362
2025-02-02 17:23:15,404 - INFO - Epoch 252: train_loss=0.9280
2025-02-02 17:23:15,540 - INFO - Epoch 252: train_loss=0.7567
2025-02-02 17:23:16,241 - INFO - Epoch 252: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:23:16,245 - INFO - ####################Training epoch 253####################
2025-02-02 17:23:16,923 - INFO - Epoch 253: train_loss=0.7701
2025-02-02 17:23:17,080 - INFO - Epoch 253: train_loss=0.9584
2025-02-02 17:23:17,214 - INFO - Epoch 253: train_loss=0.8531
2025-02-02 17:23:17,881 - INFO - Epoch 253: val_loss=1.9905, val_acc=33.33%
2025-02-02 17:23:17,885 - INFO - ####################Training epoch 254####################
2025-02-02 17:23:18,543 - INFO - Epoch 254: train_loss=0.8917
2025-02-02 17:23:18,701 - INFO - Epoch 254: train_loss=0.8220
2025-02-02 17:23:18,835 - INFO - Epoch 254: train_loss=0.8928
2025-02-02 17:23:19,507 - INFO - Epoch 254: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:23:19,511 - INFO - ####################Training epoch 255####################
2025-02-02 17:23:20,172 - INFO - Epoch 255: train_loss=0.9723
2025-02-02 17:23:20,331 - INFO - Epoch 255: train_loss=0.7448
2025-02-02 17:23:20,465 - INFO - Epoch 255: train_loss=0.8802
2025-02-02 17:23:21,169 - INFO - Epoch 255: val_loss=2.0000, val_acc=33.33%
2025-02-02 17:23:21,172 - INFO - ####################Training epoch 256####################
2025-02-02 17:23:21,819 - INFO - Epoch 256: train_loss=0.8099
2025-02-02 17:23:21,976 - INFO - Epoch 256: train_loss=0.9628
2025-02-02 17:23:22,111 - INFO - Epoch 256: train_loss=0.7393
2025-02-02 17:23:22,768 - INFO - Epoch 256: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:23:22,772 - INFO - ####################Training epoch 257####################
2025-02-02 17:23:23,426 - INFO - Epoch 257: train_loss=0.8408
2025-02-02 17:23:23,584 - INFO - Epoch 257: train_loss=0.9124
2025-02-02 17:23:23,719 - INFO - Epoch 257: train_loss=0.7944
2025-02-02 17:23:24,399 - INFO - Epoch 257: val_loss=1.9920, val_acc=33.33%
2025-02-02 17:23:24,403 - INFO - ####################Training epoch 258####################
2025-02-02 17:23:25,031 - INFO - Epoch 258: train_loss=0.7704
2025-02-02 17:23:25,189 - INFO - Epoch 258: train_loss=0.9001
2025-02-02 17:23:25,323 - INFO - Epoch 258: train_loss=0.9936
2025-02-02 17:23:25,982 - INFO - Epoch 258: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:23:25,986 - INFO - ####################Training epoch 259####################
2025-02-02 17:23:26,650 - INFO - Epoch 259: train_loss=0.8043
2025-02-02 17:23:26,809 - INFO - Epoch 259: train_loss=0.9361
2025-02-02 17:23:26,943 - INFO - Epoch 259: train_loss=0.8291
2025-02-02 17:23:27,624 - INFO - Epoch 259: val_loss=2.0015, val_acc=33.33%
2025-02-02 17:23:27,629 - INFO - ####################Training epoch 260####################
2025-02-02 17:23:28,291 - INFO - Epoch 260: train_loss=0.9110
2025-02-02 17:23:28,449 - INFO - Epoch 260: train_loss=0.8544
2025-02-02 17:23:28,584 - INFO - Epoch 260: train_loss=0.7571
2025-02-02 17:23:29,241 - INFO - Epoch 260: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:23:29,245 - INFO - ####################Training epoch 261####################
2025-02-02 17:23:29,900 - INFO - Epoch 261: train_loss=0.9213
2025-02-02 17:23:30,058 - INFO - Epoch 261: train_loss=0.7212
2025-02-02 17:23:30,193 - INFO - Epoch 261: train_loss=1.0859
2025-02-02 17:23:30,940 - INFO - Epoch 261: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:23:30,944 - INFO - ####################Training epoch 262####################
2025-02-02 17:23:31,593 - INFO - Epoch 262: train_loss=0.8125
2025-02-02 17:23:31,751 - INFO - Epoch 262: train_loss=0.9629
2025-02-02 17:23:31,886 - INFO - Epoch 262: train_loss=0.7361
2025-02-02 17:23:32,533 - INFO - Epoch 262: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:23:32,537 - INFO - ####################Training epoch 263####################
2025-02-02 17:23:33,193 - INFO - Epoch 263: train_loss=0.8187
2025-02-02 17:23:33,351 - INFO - Epoch 263: train_loss=0.9122
2025-02-02 17:23:33,486 - INFO - Epoch 263: train_loss=0.8563
2025-02-02 17:23:34,150 - INFO - Epoch 263: val_loss=1.9941, val_acc=33.33%
2025-02-02 17:23:34,154 - INFO - ####################Training epoch 264####################
2025-02-02 17:23:34,806 - INFO - Epoch 264: train_loss=0.9021
2025-02-02 17:23:34,964 - INFO - Epoch 264: train_loss=0.8648
2025-02-02 17:23:35,099 - INFO - Epoch 264: train_loss=0.7601
2025-02-02 17:23:35,779 - INFO - Epoch 264: val_loss=2.0017, val_acc=33.33%
2025-02-02 17:23:35,783 - INFO - ####################Training epoch 265####################
2025-02-02 17:23:36,436 - INFO - Epoch 265: train_loss=0.8660
2025-02-02 17:23:36,593 - INFO - Epoch 265: train_loss=0.9070
2025-02-02 17:23:36,727 - INFO - Epoch 265: train_loss=0.7343
2025-02-02 17:23:37,399 - INFO - Epoch 265: val_loss=1.9973, val_acc=33.33%
2025-02-02 17:23:37,402 - INFO - ####################Training epoch 266####################
2025-02-02 17:23:38,047 - INFO - Epoch 266: train_loss=0.9410
2025-02-02 17:23:38,206 - INFO - Epoch 266: train_loss=0.9053
2025-02-02 17:23:38,340 - INFO - Epoch 266: train_loss=0.5614
2025-02-02 17:23:39,024 - INFO - Epoch 266: val_loss=2.0000, val_acc=33.33%
2025-02-02 17:23:39,030 - INFO - ####################Training epoch 267####################
2025-02-02 17:23:39,658 - INFO - Epoch 267: train_loss=0.8578
2025-02-02 17:23:39,815 - INFO - Epoch 267: train_loss=0.9414
2025-02-02 17:23:39,950 - INFO - Epoch 267: train_loss=0.6830
2025-02-02 17:23:40,595 - INFO - Epoch 267: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:23:40,598 - INFO - ####################Training epoch 268####################
2025-02-02 17:23:41,245 - INFO - Epoch 268: train_loss=0.8394
2025-02-02 17:23:41,403 - INFO - Epoch 268: train_loss=0.8819
2025-02-02 17:23:41,538 - INFO - Epoch 268: train_loss=0.8666
2025-02-02 17:23:42,219 - INFO - Epoch 268: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:23:42,223 - INFO - ####################Training epoch 269####################
2025-02-02 17:23:42,869 - INFO - Epoch 269: train_loss=0.8883
2025-02-02 17:23:43,027 - INFO - Epoch 269: train_loss=0.7995
2025-02-02 17:23:43,161 - INFO - Epoch 269: train_loss=0.9464
2025-02-02 17:23:43,843 - INFO - Epoch 269: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:23:43,847 - INFO - ####################Training epoch 270####################
2025-02-02 17:23:44,499 - INFO - Epoch 270: train_loss=0.9030
2025-02-02 17:23:44,657 - INFO - Epoch 270: train_loss=0.7942
2025-02-02 17:23:44,792 - INFO - Epoch 270: train_loss=0.9294
2025-02-02 17:23:45,457 - INFO - Epoch 270: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:23:45,461 - INFO - ####################Training epoch 271####################
2025-02-02 17:23:46,128 - INFO - Epoch 271: train_loss=0.9494
2025-02-02 17:23:46,286 - INFO - Epoch 271: train_loss=0.7991
2025-02-02 17:23:46,421 - INFO - Epoch 271: train_loss=0.7923
2025-02-02 17:23:47,100 - INFO - Epoch 271: val_loss=1.9967, val_acc=33.33%
2025-02-02 17:23:47,104 - INFO - ####################Training epoch 272####################
2025-02-02 17:23:47,815 - INFO - Epoch 272: train_loss=0.8302
2025-02-02 17:23:47,972 - INFO - Epoch 272: train_loss=1.0087
2025-02-02 17:23:48,106 - INFO - Epoch 272: train_loss=0.5642
2025-02-02 17:23:48,770 - INFO - Epoch 272: val_loss=1.9983, val_acc=33.33%
2025-02-02 17:23:48,774 - INFO - ####################Training epoch 273####################
2025-02-02 17:23:49,438 - INFO - Epoch 273: train_loss=0.9314
2025-02-02 17:23:49,595 - INFO - Epoch 273: train_loss=0.7925
2025-02-02 17:23:49,731 - INFO - Epoch 273: train_loss=0.8726
2025-02-02 17:23:50,405 - INFO - Epoch 273: val_loss=1.9984, val_acc=33.33%
2025-02-02 17:23:50,408 - INFO - ####################Training epoch 274####################
2025-02-02 17:23:51,065 - INFO - Epoch 274: train_loss=0.8444
2025-02-02 17:23:51,223 - INFO - Epoch 274: train_loss=0.8667
2025-02-02 17:23:51,357 - INFO - Epoch 274: train_loss=0.8861
2025-02-02 17:23:52,023 - INFO - Epoch 274: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:23:52,027 - INFO - ####################Training epoch 275####################
2025-02-02 17:23:52,684 - INFO - Epoch 275: train_loss=0.8048
2025-02-02 17:23:52,842 - INFO - Epoch 275: train_loss=0.7814
2025-02-02 17:23:52,977 - INFO - Epoch 275: train_loss=1.2038
2025-02-02 17:23:53,655 - INFO - Epoch 275: val_loss=1.9973, val_acc=33.33%
2025-02-02 17:23:53,658 - INFO - ####################Training epoch 276####################
2025-02-02 17:23:54,291 - INFO - Epoch 276: train_loss=0.8270
2025-02-02 17:23:54,448 - INFO - Epoch 276: train_loss=0.8884
2025-02-02 17:23:54,582 - INFO - Epoch 276: train_loss=0.8897
2025-02-02 17:23:55,229 - INFO - Epoch 276: val_loss=1.9929, val_acc=33.33%
2025-02-02 17:23:55,232 - INFO - ####################Training epoch 277####################
2025-02-02 17:23:55,899 - INFO - Epoch 277: train_loss=0.9867
2025-02-02 17:23:56,068 - INFO - Epoch 277: train_loss=0.7746
2025-02-02 17:23:56,202 - INFO - Epoch 277: train_loss=0.7778
2025-02-02 17:23:56,873 - INFO - Epoch 277: val_loss=2.0010, val_acc=33.33%
2025-02-02 17:23:56,877 - INFO - ####################Training epoch 278####################
2025-02-02 17:23:57,525 - INFO - Epoch 278: train_loss=0.8555
2025-02-02 17:23:57,682 - INFO - Epoch 278: train_loss=0.8399
2025-02-02 17:23:57,817 - INFO - Epoch 278: train_loss=0.9324
2025-02-02 17:23:58,483 - INFO - Epoch 278: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:23:58,487 - INFO - ####################Training epoch 279####################
2025-02-02 17:23:59,139 - INFO - Epoch 279: train_loss=0.8676
2025-02-02 17:23:59,298 - INFO - Epoch 279: train_loss=0.9365
2025-02-02 17:23:59,432 - INFO - Epoch 279: train_loss=0.6762
2025-02-02 17:24:00,115 - INFO - Epoch 279: val_loss=1.9997, val_acc=33.33%
2025-02-02 17:24:00,119 - INFO - ####################Training epoch 280####################
2025-02-02 17:24:00,750 - INFO - Epoch 280: train_loss=0.7415
2025-02-02 17:24:00,908 - INFO - Epoch 280: train_loss=0.9943
2025-02-02 17:24:01,042 - INFO - Epoch 280: train_loss=0.8273
2025-02-02 17:24:01,718 - INFO - Epoch 280: val_loss=2.0012, val_acc=33.33%
2025-02-02 17:24:01,722 - INFO - ####################Training epoch 281####################
2025-02-02 17:24:02,358 - INFO - Epoch 281: train_loss=0.7848
2025-02-02 17:24:02,516 - INFO - Epoch 281: train_loss=0.9681
2025-02-02 17:24:02,651 - INFO - Epoch 281: train_loss=0.7970
2025-02-02 17:24:03,299 - INFO - Epoch 281: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:24:03,303 - INFO - ####################Training epoch 282####################
2025-02-02 17:24:03,951 - INFO - Epoch 282: train_loss=0.7563
2025-02-02 17:24:04,108 - INFO - Epoch 282: train_loss=0.9781
2025-02-02 17:24:04,250 - INFO - Epoch 282: train_loss=0.8208
2025-02-02 17:24:04,939 - INFO - Epoch 282: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:24:04,943 - INFO - ####################Training epoch 283####################
2025-02-02 17:24:05,595 - INFO - Epoch 283: train_loss=0.8822
2025-02-02 17:24:05,753 - INFO - Epoch 283: train_loss=0.7650
2025-02-02 17:24:05,888 - INFO - Epoch 283: train_loss=1.0537
2025-02-02 17:24:06,552 - INFO - Epoch 283: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:24:06,556 - INFO - ####################Training epoch 284####################
2025-02-02 17:24:07,212 - INFO - Epoch 284: train_loss=0.7790
2025-02-02 17:24:07,370 - INFO - Epoch 284: train_loss=0.8835
2025-02-02 17:24:07,505 - INFO - Epoch 284: train_loss=1.0154
2025-02-02 17:24:08,145 - INFO - Epoch 284: val_loss=1.9912, val_acc=33.33%
2025-02-02 17:24:08,149 - INFO - ####################Training epoch 285####################
2025-02-02 17:24:08,804 - INFO - Epoch 285: train_loss=0.9162
2025-02-02 17:24:08,961 - INFO - Epoch 285: train_loss=0.7677
2025-02-02 17:24:09,095 - INFO - Epoch 285: train_loss=0.9706
2025-02-02 17:24:09,754 - INFO - Epoch 285: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:24:09,758 - INFO - ####################Training epoch 286####################
2025-02-02 17:24:10,403 - INFO - Epoch 286: train_loss=0.7690
2025-02-02 17:24:10,560 - INFO - Epoch 286: train_loss=1.0078
2025-02-02 17:24:10,695 - INFO - Epoch 286: train_loss=0.7085
2025-02-02 17:24:11,355 - INFO - Epoch 286: val_loss=2.0004, val_acc=33.33%
2025-02-02 17:24:11,359 - INFO - ####################Training epoch 287####################
2025-02-02 17:24:12,027 - INFO - Epoch 287: train_loss=0.8387
2025-02-02 17:24:12,186 - INFO - Epoch 287: train_loss=0.8467
2025-02-02 17:24:12,320 - INFO - Epoch 287: train_loss=0.9699
2025-02-02 17:24:13,037 - INFO - Epoch 287: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:24:13,041 - INFO - ####################Training epoch 288####################
2025-02-02 17:24:13,683 - INFO - Epoch 288: train_loss=0.9228
2025-02-02 17:24:13,840 - INFO - Epoch 288: train_loss=0.8008
2025-02-02 17:24:13,989 - INFO - Epoch 288: train_loss=0.8715
2025-02-02 17:24:14,631 - INFO - Epoch 288: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:24:14,635 - INFO - ####################Training epoch 289####################
2025-02-02 17:24:15,269 - INFO - Epoch 289: train_loss=0.8986
2025-02-02 17:24:15,426 - INFO - Epoch 289: train_loss=0.8698
2025-02-02 17:24:15,561 - INFO - Epoch 289: train_loss=0.7533
2025-02-02 17:24:16,233 - INFO - Epoch 289: val_loss=1.9954, val_acc=33.33%
2025-02-02 17:24:16,236 - INFO - ####################Training epoch 290####################
2025-02-02 17:24:16,894 - INFO - Epoch 290: train_loss=0.7612
2025-02-02 17:24:17,052 - INFO - Epoch 290: train_loss=0.9272
2025-02-02 17:24:17,187 - INFO - Epoch 290: train_loss=0.9438
2025-02-02 17:24:17,840 - INFO - Epoch 290: val_loss=1.9912, val_acc=33.33%
2025-02-02 17:24:17,844 - INFO - ####################Training epoch 291####################
2025-02-02 17:24:18,490 - INFO - Epoch 291: train_loss=0.9031
2025-02-02 17:24:18,648 - INFO - Epoch 291: train_loss=0.7940
2025-02-02 17:24:18,783 - INFO - Epoch 291: train_loss=0.9201
2025-02-02 17:24:19,444 - INFO - Epoch 291: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:24:19,447 - INFO - ####################Training epoch 292####################
2025-02-02 17:24:20,098 - INFO - Epoch 292: train_loss=0.8856
2025-02-02 17:24:20,255 - INFO - Epoch 292: train_loss=0.8553
2025-02-02 17:24:20,390 - INFO - Epoch 292: train_loss=0.8165
2025-02-02 17:24:21,053 - INFO - Epoch 292: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:24:21,056 - INFO - ####################Training epoch 293####################
2025-02-02 17:24:21,717 - INFO - Epoch 293: train_loss=0.9063
2025-02-02 17:24:21,886 - INFO - Epoch 293: train_loss=0.8634
2025-02-02 17:24:22,022 - INFO - Epoch 293: train_loss=0.7465
2025-02-02 17:24:22,680 - INFO - Epoch 293: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:24:22,684 - INFO - ####################Training epoch 294####################
2025-02-02 17:24:23,325 - INFO - Epoch 294: train_loss=0.9828
2025-02-02 17:24:23,484 - INFO - Epoch 294: train_loss=0.7716
2025-02-02 17:24:23,620 - INFO - Epoch 294: train_loss=0.7832
2025-02-02 17:24:24,306 - INFO - Epoch 294: val_loss=1.9941, val_acc=33.33%
2025-02-02 17:24:24,310 - INFO - ####################Training epoch 295####################
2025-02-02 17:24:24,951 - INFO - Epoch 295: train_loss=0.9118
2025-02-02 17:24:25,109 - INFO - Epoch 295: train_loss=0.7931
2025-02-02 17:24:25,244 - INFO - Epoch 295: train_loss=0.9114
2025-02-02 17:24:25,907 - INFO - Epoch 295: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:24:25,910 - INFO - ####################Training epoch 296####################
2025-02-02 17:24:26,568 - INFO - Epoch 296: train_loss=0.9060
2025-02-02 17:24:26,726 - INFO - Epoch 296: train_loss=0.9303
2025-02-02 17:24:26,861 - INFO - Epoch 296: train_loss=0.5854
2025-02-02 17:24:27,513 - INFO - Epoch 296: val_loss=1.9952, val_acc=33.33%
2025-02-02 17:24:27,517 - INFO - ####################Training epoch 297####################
2025-02-02 17:24:28,153 - INFO - Epoch 297: train_loss=0.8564
2025-02-02 17:24:28,311 - INFO - Epoch 297: train_loss=0.8936
2025-02-02 17:24:28,445 - INFO - Epoch 297: train_loss=0.8069
2025-02-02 17:24:29,121 - INFO - Epoch 297: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:24:29,125 - INFO - ####################Training epoch 298####################
2025-02-02 17:24:29,780 - INFO - Epoch 298: train_loss=0.9118
2025-02-02 17:24:29,938 - INFO - Epoch 298: train_loss=0.9206
2025-02-02 17:24:30,072 - INFO - Epoch 298: train_loss=0.5955
2025-02-02 17:24:30,762 - INFO - Epoch 298: val_loss=1.9889, val_acc=33.33%
2025-02-02 17:24:30,766 - INFO - ####################Training epoch 299####################
2025-02-02 17:24:31,391 - INFO - Epoch 299: train_loss=0.9828
2025-02-02 17:24:31,549 - INFO - Epoch 299: train_loss=0.8685
2025-02-02 17:24:31,684 - INFO - Epoch 299: train_loss=0.5462
2025-02-02 17:24:32,345 - INFO - Epoch 299: val_loss=1.9923, val_acc=33.33%
2025-02-02 17:24:32,348 - INFO - ####################Training epoch 300####################
2025-02-02 17:24:32,996 - INFO - Epoch 300: train_loss=0.8814
2025-02-02 17:24:33,153 - INFO - Epoch 300: train_loss=0.8379
2025-02-02 17:24:33,288 - INFO - Epoch 300: train_loss=0.8676
2025-02-02 17:24:33,959 - INFO - Epoch 300: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:24:33,963 - INFO - ####################Training epoch 301####################
2025-02-02 17:24:34,620 - INFO - Epoch 301: train_loss=0.9423
2025-02-02 17:24:34,777 - INFO - Epoch 301: train_loss=0.7732
2025-02-02 17:24:34,911 - INFO - Epoch 301: train_loss=0.8793
2025-02-02 17:24:35,571 - INFO - Epoch 301: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:24:35,575 - INFO - ####################Training epoch 302####################
2025-02-02 17:24:36,221 - INFO - Epoch 302: train_loss=0.6981
2025-02-02 17:24:36,379 - INFO - Epoch 302: train_loss=1.0049
2025-02-02 17:24:36,515 - INFO - Epoch 302: train_loss=0.9216
2025-02-02 17:24:37,190 - INFO - Epoch 302: val_loss=2.0007, val_acc=33.33%
2025-02-02 17:24:37,194 - INFO - ####################Training epoch 303####################
2025-02-02 17:24:37,836 - INFO - Epoch 303: train_loss=0.8591
2025-02-02 17:24:37,993 - INFO - Epoch 303: train_loss=0.8956
2025-02-02 17:24:38,128 - INFO - Epoch 303: train_loss=0.7871
2025-02-02 17:24:38,849 - INFO - Epoch 303: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:24:38,852 - INFO - ####################Training epoch 304####################
2025-02-02 17:24:39,505 - INFO - Epoch 304: train_loss=0.8950
2025-02-02 17:24:39,663 - INFO - Epoch 304: train_loss=0.8202
2025-02-02 17:24:39,798 - INFO - Epoch 304: train_loss=0.8851
2025-02-02 17:24:40,449 - INFO - Epoch 304: val_loss=2.0025, val_acc=33.33%
2025-02-02 17:24:40,453 - INFO - ####################Training epoch 305####################
2025-02-02 17:24:41,112 - INFO - Epoch 305: train_loss=0.9053
2025-02-02 17:24:41,269 - INFO - Epoch 305: train_loss=0.8508
2025-02-02 17:24:41,404 - INFO - Epoch 305: train_loss=0.7705
2025-02-02 17:24:42,048 - INFO - Epoch 305: val_loss=1.9930, val_acc=33.33%
2025-02-02 17:24:42,051 - INFO - ####################Training epoch 306####################
2025-02-02 17:24:42,691 - INFO - Epoch 306: train_loss=0.7028
2025-02-02 17:24:42,848 - INFO - Epoch 306: train_loss=0.9845
2025-02-02 17:24:42,983 - INFO - Epoch 306: train_loss=0.9589
2025-02-02 17:24:43,642 - INFO - Epoch 306: val_loss=1.9995, val_acc=33.33%
2025-02-02 17:24:43,646 - INFO - ####################Training epoch 307####################
2025-02-02 17:24:44,298 - INFO - Epoch 307: train_loss=0.7815
2025-02-02 17:24:44,456 - INFO - Epoch 307: train_loss=0.9367
2025-02-02 17:24:44,590 - INFO - Epoch 307: train_loss=0.8796
2025-02-02 17:24:45,247 - INFO - Epoch 307: val_loss=1.9946, val_acc=33.33%
2025-02-02 17:24:45,251 - INFO - ####################Training epoch 308####################
2025-02-02 17:24:45,903 - INFO - Epoch 308: train_loss=0.7693
2025-02-02 17:24:46,061 - INFO - Epoch 308: train_loss=0.9295
2025-02-02 17:24:46,195 - INFO - Epoch 308: train_loss=0.9159
2025-02-02 17:24:46,906 - INFO - Epoch 308: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:24:46,909 - INFO - ####################Training epoch 309####################
2025-02-02 17:24:47,558 - INFO - Epoch 309: train_loss=0.8776
2025-02-02 17:24:47,715 - INFO - Epoch 309: train_loss=0.8733
2025-02-02 17:24:47,849 - INFO - Epoch 309: train_loss=0.7964
2025-02-02 17:24:48,508 - INFO - Epoch 309: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:24:48,512 - INFO - ####################Training epoch 310####################
2025-02-02 17:24:49,172 - INFO - Epoch 310: train_loss=0.8720
2025-02-02 17:24:49,329 - INFO - Epoch 310: train_loss=0.8964
2025-02-02 17:24:49,463 - INFO - Epoch 310: train_loss=0.7626
2025-02-02 17:24:50,119 - INFO - Epoch 310: val_loss=2.0030, val_acc=33.33%
2025-02-02 17:24:50,123 - INFO - ####################Training epoch 311####################
2025-02-02 17:24:50,784 - INFO - Epoch 311: train_loss=0.8430
2025-02-02 17:24:50,942 - INFO - Epoch 311: train_loss=0.9310
2025-02-02 17:24:51,077 - INFO - Epoch 311: train_loss=0.7397
2025-02-02 17:24:51,739 - INFO - Epoch 311: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:24:51,743 - INFO - ####################Training epoch 312####################
2025-02-02 17:24:52,388 - INFO - Epoch 312: train_loss=0.8200
2025-02-02 17:24:52,546 - INFO - Epoch 312: train_loss=0.8372
2025-02-02 17:24:52,680 - INFO - Epoch 312: train_loss=1.0431
2025-02-02 17:24:53,340 - INFO - Epoch 312: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:24:53,343 - INFO - ####################Training epoch 313####################
2025-02-02 17:24:54,000 - INFO - Epoch 313: train_loss=0.9566
2025-02-02 17:24:54,158 - INFO - Epoch 313: train_loss=0.8638
2025-02-02 17:24:54,293 - INFO - Epoch 313: train_loss=0.6185
2025-02-02 17:24:54,966 - INFO - Epoch 313: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:24:54,969 - INFO - ####################Training epoch 314####################
2025-02-02 17:24:55,661 - INFO - Epoch 314: train_loss=0.8875
2025-02-02 17:24:55,819 - INFO - Epoch 314: train_loss=0.7881
2025-02-02 17:24:55,954 - INFO - Epoch 314: train_loss=0.9882
2025-02-02 17:24:56,619 - INFO - Epoch 314: val_loss=1.9976, val_acc=33.33%
2025-02-02 17:24:56,623 - INFO - ####################Training epoch 315####################
2025-02-02 17:24:57,301 - INFO - Epoch 315: train_loss=0.8941
2025-02-02 17:24:57,460 - INFO - Epoch 315: train_loss=0.7962
2025-02-02 17:24:57,595 - INFO - Epoch 315: train_loss=0.9472
2025-02-02 17:24:58,264 - INFO - Epoch 315: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:24:58,267 - INFO - ####################Training epoch 316####################
2025-02-02 17:24:58,922 - INFO - Epoch 316: train_loss=0.8521
2025-02-02 17:24:59,079 - INFO - Epoch 316: train_loss=0.8151
2025-02-02 17:24:59,215 - INFO - Epoch 316: train_loss=0.9983
2025-02-02 17:24:59,890 - INFO - Epoch 316: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:24:59,893 - INFO - ####################Training epoch 317####################
2025-02-02 17:25:00,553 - INFO - Epoch 317: train_loss=0.8385
2025-02-02 17:25:00,710 - INFO - Epoch 317: train_loss=0.8799
2025-02-02 17:25:00,844 - INFO - Epoch 317: train_loss=0.8826
2025-02-02 17:25:01,493 - INFO - Epoch 317: val_loss=2.0000, val_acc=33.33%
2025-02-02 17:25:01,497 - INFO - ####################Training epoch 318####################
2025-02-02 17:25:02,148 - INFO - Epoch 318: train_loss=0.8468
2025-02-02 17:25:02,305 - INFO - Epoch 318: train_loss=0.9369
2025-02-02 17:25:02,440 - INFO - Epoch 318: train_loss=0.7128
2025-02-02 17:25:03,119 - INFO - Epoch 318: val_loss=2.0001, val_acc=33.33%
2025-02-02 17:25:03,123 - INFO - ####################Training epoch 319####################
2025-02-02 17:25:03,787 - INFO - Epoch 319: train_loss=0.8735
2025-02-02 17:25:03,944 - INFO - Epoch 319: train_loss=0.8627
2025-02-02 17:25:04,079 - INFO - Epoch 319: train_loss=0.8380
2025-02-02 17:25:04,711 - INFO - Epoch 319: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:25:04,714 - INFO - ####################Training epoch 320####################
2025-02-02 17:25:05,378 - INFO - Epoch 320: train_loss=0.7489
2025-02-02 17:25:05,536 - INFO - Epoch 320: train_loss=0.8937
2025-02-02 17:25:05,670 - INFO - Epoch 320: train_loss=1.0708
2025-02-02 17:25:06,356 - INFO - Epoch 320: val_loss=1.9983, val_acc=33.33%
2025-02-02 17:25:06,360 - INFO - ####################Training epoch 321####################
2025-02-02 17:25:07,013 - INFO - Epoch 321: train_loss=0.9797
2025-02-02 17:25:07,170 - INFO - Epoch 321: train_loss=0.7848
2025-02-02 17:25:07,305 - INFO - Epoch 321: train_loss=0.7528
2025-02-02 17:25:07,964 - INFO - Epoch 321: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:25:07,967 - INFO - ####################Training epoch 322####################
2025-02-02 17:25:08,622 - INFO - Epoch 322: train_loss=0.8288
2025-02-02 17:25:08,779 - INFO - Epoch 322: train_loss=0.8973
2025-02-02 17:25:08,914 - INFO - Epoch 322: train_loss=0.8544
2025-02-02 17:25:09,572 - INFO - Epoch 322: val_loss=1.9928, val_acc=33.33%
2025-02-02 17:25:09,576 - INFO - ####################Training epoch 323####################
2025-02-02 17:25:10,199 - INFO - Epoch 323: train_loss=0.7304
2025-02-02 17:25:10,358 - INFO - Epoch 323: train_loss=1.0130
2025-02-02 17:25:10,492 - INFO - Epoch 323: train_loss=0.8156
2025-02-02 17:25:11,158 - INFO - Epoch 323: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:25:11,162 - INFO - ####################Training epoch 324####################
2025-02-02 17:25:11,820 - INFO - Epoch 324: train_loss=0.9592
2025-02-02 17:25:11,978 - INFO - Epoch 324: train_loss=0.7643
2025-02-02 17:25:12,113 - INFO - Epoch 324: train_loss=0.8642
2025-02-02 17:25:12,778 - INFO - Epoch 324: val_loss=1.9979, val_acc=33.33%
2025-02-02 17:25:12,781 - INFO - ####################Training epoch 325####################
2025-02-02 17:25:13,433 - INFO - Epoch 325: train_loss=0.9326
2025-02-02 17:25:13,591 - INFO - Epoch 325: train_loss=0.8215
2025-02-02 17:25:13,725 - INFO - Epoch 325: train_loss=0.7918
2025-02-02 17:25:14,389 - INFO - Epoch 325: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:25:14,393 - INFO - ####################Training epoch 326####################
2025-02-02 17:25:15,046 - INFO - Epoch 326: train_loss=0.7195
2025-02-02 17:25:15,203 - INFO - Epoch 326: train_loss=0.9671
2025-02-02 17:25:15,337 - INFO - Epoch 326: train_loss=0.9495
2025-02-02 17:25:15,987 - INFO - Epoch 326: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:25:15,991 - INFO - ####################Training epoch 327####################
2025-02-02 17:25:16,638 - INFO - Epoch 327: train_loss=0.7196
2025-02-02 17:25:16,796 - INFO - Epoch 327: train_loss=1.0004
2025-02-02 17:25:16,930 - INFO - Epoch 327: train_loss=0.8684
2025-02-02 17:25:17,592 - INFO - Epoch 327: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:25:17,595 - INFO - ####################Training epoch 328####################
2025-02-02 17:25:18,256 - INFO - Epoch 328: train_loss=0.8573
2025-02-02 17:25:18,414 - INFO - Epoch 328: train_loss=0.9749
2025-02-02 17:25:18,548 - INFO - Epoch 328: train_loss=0.5885
2025-02-02 17:25:19,222 - INFO - Epoch 328: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:25:19,226 - INFO - ####################Training epoch 329####################
2025-02-02 17:25:19,885 - INFO - Epoch 329: train_loss=0.7689
2025-02-02 17:25:20,042 - INFO - Epoch 329: train_loss=0.9119
2025-02-02 17:25:20,176 - INFO - Epoch 329: train_loss=0.9810
2025-02-02 17:25:20,900 - INFO - Epoch 329: val_loss=1.9963, val_acc=33.33%
2025-02-02 17:25:20,903 - INFO - ####################Training epoch 330####################
2025-02-02 17:25:21,562 - INFO - Epoch 330: train_loss=0.8947
2025-02-02 17:25:21,719 - INFO - Epoch 330: train_loss=0.9249
2025-02-02 17:25:21,853 - INFO - Epoch 330: train_loss=0.6252
2025-02-02 17:25:22,519 - INFO - Epoch 330: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:25:22,523 - INFO - ####################Training epoch 331####################
2025-02-02 17:25:23,162 - INFO - Epoch 331: train_loss=0.8565
2025-02-02 17:25:23,319 - INFO - Epoch 331: train_loss=0.8942
2025-02-02 17:25:23,453 - INFO - Epoch 331: train_loss=0.7924
2025-02-02 17:25:24,114 - INFO - Epoch 331: val_loss=2.0018, val_acc=33.33%
2025-02-02 17:25:24,118 - INFO - ####################Training epoch 332####################
2025-02-02 17:25:24,772 - INFO - Epoch 332: train_loss=1.0135
2025-02-02 17:25:24,930 - INFO - Epoch 332: train_loss=0.7595
2025-02-02 17:25:25,065 - INFO - Epoch 332: train_loss=0.7458
2025-02-02 17:25:25,728 - INFO - Epoch 332: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:25:25,731 - INFO - ####################Training epoch 333####################
2025-02-02 17:25:26,371 - INFO - Epoch 333: train_loss=0.9401
2025-02-02 17:25:26,529 - INFO - Epoch 333: train_loss=0.8737
2025-02-02 17:25:26,664 - INFO - Epoch 333: train_loss=0.6446
2025-02-02 17:25:27,327 - INFO - Epoch 333: val_loss=1.9896, val_acc=33.33%
2025-02-02 17:25:27,331 - INFO - ####################Training epoch 334####################
2025-02-02 17:25:27,991 - INFO - Epoch 334: train_loss=0.8633
2025-02-02 17:25:28,149 - INFO - Epoch 334: train_loss=0.7987
2025-02-02 17:25:28,283 - INFO - Epoch 334: train_loss=1.0239
2025-02-02 17:25:28,950 - INFO - Epoch 334: val_loss=1.9964, val_acc=33.33%
2025-02-02 17:25:28,954 - INFO - ####################Training epoch 335####################
2025-02-02 17:25:29,616 - INFO - Epoch 335: train_loss=0.8807
2025-02-02 17:25:29,774 - INFO - Epoch 335: train_loss=0.8773
2025-02-02 17:25:29,908 - INFO - Epoch 335: train_loss=0.7780
2025-02-02 17:25:30,564 - INFO - Epoch 335: val_loss=1.9953, val_acc=33.33%
2025-02-02 17:25:30,568 - INFO - ####################Training epoch 336####################
2025-02-02 17:25:31,226 - INFO - Epoch 336: train_loss=0.9387
2025-02-02 17:25:31,384 - INFO - Epoch 336: train_loss=0.7472
2025-02-02 17:25:31,519 - INFO - Epoch 336: train_loss=0.9505
2025-02-02 17:25:32,208 - INFO - Epoch 336: val_loss=2.0030, val_acc=33.33%
2025-02-02 17:25:32,211 - INFO - ####################Training epoch 337####################
2025-02-02 17:25:32,869 - INFO - Epoch 337: train_loss=0.9407
2025-02-02 17:25:33,027 - INFO - Epoch 337: train_loss=0.6939
2025-02-02 17:25:33,161 - INFO - Epoch 337: train_loss=1.0781
2025-02-02 17:25:33,829 - INFO - Epoch 337: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:25:33,832 - INFO - ####################Training epoch 338####################
2025-02-02 17:25:34,485 - INFO - Epoch 338: train_loss=0.9218
2025-02-02 17:25:34,642 - INFO - Epoch 338: train_loss=0.8854
2025-02-02 17:25:34,777 - INFO - Epoch 338: train_loss=0.6414
2025-02-02 17:25:35,433 - INFO - Epoch 338: val_loss=1.9992, val_acc=33.33%
2025-02-02 17:25:35,437 - INFO - ####################Training epoch 339####################
2025-02-02 17:25:36,072 - INFO - Epoch 339: train_loss=0.8904
2025-02-02 17:25:36,231 - INFO - Epoch 339: train_loss=0.8302
2025-02-02 17:25:36,365 - INFO - Epoch 339: train_loss=0.8717
2025-02-02 17:25:37,040 - INFO - Epoch 339: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:25:37,043 - INFO - ####################Training epoch 340####################
2025-02-02 17:25:37,745 - INFO - Epoch 340: train_loss=0.8321
2025-02-02 17:25:37,904 - INFO - Epoch 340: train_loss=0.9004
2025-02-02 17:25:38,038 - INFO - Epoch 340: train_loss=0.8528
2025-02-02 17:25:38,698 - INFO - Epoch 340: val_loss=1.9909, val_acc=33.33%
2025-02-02 17:25:38,701 - INFO - ####################Training epoch 341####################
2025-02-02 17:25:39,342 - INFO - Epoch 341: train_loss=0.8675
2025-02-02 17:25:39,500 - INFO - Epoch 341: train_loss=0.8789
2025-02-02 17:25:39,635 - INFO - Epoch 341: train_loss=0.8061
2025-02-02 17:25:40,314 - INFO - Epoch 341: val_loss=1.9931, val_acc=33.33%
2025-02-02 17:25:40,318 - INFO - ####################Training epoch 342####################
2025-02-02 17:25:40,968 - INFO - Epoch 342: train_loss=0.9130
2025-02-02 17:25:41,127 - INFO - Epoch 342: train_loss=0.8047
2025-02-02 17:25:41,263 - INFO - Epoch 342: train_loss=0.8791
2025-02-02 17:25:41,929 - INFO - Epoch 342: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:25:41,933 - INFO - ####################Training epoch 343####################
2025-02-02 17:25:42,595 - INFO - Epoch 343: train_loss=0.8994
2025-02-02 17:25:42,753 - INFO - Epoch 343: train_loss=0.8189
2025-02-02 17:25:42,888 - INFO - Epoch 343: train_loss=0.8711
2025-02-02 17:25:43,543 - INFO - Epoch 343: val_loss=1.9898, val_acc=33.33%
2025-02-02 17:25:43,547 - INFO - ####################Training epoch 344####################
2025-02-02 17:25:44,203 - INFO - Epoch 344: train_loss=0.8686
2025-02-02 17:25:44,362 - INFO - Epoch 344: train_loss=0.8656
2025-02-02 17:25:44,497 - INFO - Epoch 344: train_loss=0.8380
2025-02-02 17:25:45,165 - INFO - Epoch 344: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:25:45,168 - INFO - ####################Training epoch 345####################
2025-02-02 17:25:45,864 - INFO - Epoch 345: train_loss=0.9511
2025-02-02 17:25:46,023 - INFO - Epoch 345: train_loss=0.8644
2025-02-02 17:25:46,158 - INFO - Epoch 345: train_loss=0.6366
2025-02-02 17:25:46,819 - INFO - Epoch 345: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:25:46,823 - INFO - ####################Training epoch 346####################
2025-02-02 17:25:47,449 - INFO - Epoch 346: train_loss=0.9272
2025-02-02 17:25:47,608 - INFO - Epoch 346: train_loss=0.7890
2025-02-02 17:25:47,742 - INFO - Epoch 346: train_loss=0.8710
2025-02-02 17:25:48,412 - INFO - Epoch 346: val_loss=1.9948, val_acc=33.33%
2025-02-02 17:25:48,415 - INFO - ####################Training epoch 347####################
2025-02-02 17:25:49,059 - INFO - Epoch 347: train_loss=0.8918
2025-02-02 17:25:49,218 - INFO - Epoch 347: train_loss=0.7168
2025-02-02 17:25:49,352 - INFO - Epoch 347: train_loss=1.1545
2025-02-02 17:25:50,029 - INFO - Epoch 347: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:25:50,032 - INFO - ####################Training epoch 348####################
2025-02-02 17:25:50,680 - INFO - Epoch 348: train_loss=0.9598
2025-02-02 17:25:50,838 - INFO - Epoch 348: train_loss=0.7693
2025-02-02 17:25:50,972 - INFO - Epoch 348: train_loss=0.8539
2025-02-02 17:25:51,638 - INFO - Epoch 348: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:25:51,641 - INFO - ####################Training epoch 349####################
2025-02-02 17:25:52,298 - INFO - Epoch 349: train_loss=0.8536
2025-02-02 17:25:52,456 - INFO - Epoch 349: train_loss=0.8147
2025-02-02 17:25:52,591 - INFO - Epoch 349: train_loss=1.0018
2025-02-02 17:25:53,272 - INFO - Epoch 349: val_loss=1.9944, val_acc=33.33%
2025-02-02 17:25:53,275 - INFO - ####################Training epoch 350####################
2025-02-02 17:25:53,933 - INFO - Epoch 350: train_loss=0.8207
2025-02-02 17:25:54,100 - INFO - Epoch 350: train_loss=0.8880
2025-02-02 17:25:54,235 - INFO - Epoch 350: train_loss=0.9031
2025-02-02 17:25:54,906 - INFO - Epoch 350: val_loss=2.0017, val_acc=33.33%
2025-02-02 17:25:54,910 - INFO - ####################Training epoch 351####################
2025-02-02 17:25:55,565 - INFO - Epoch 351: train_loss=0.8784
2025-02-02 17:25:55,722 - INFO - Epoch 351: train_loss=0.8152
2025-02-02 17:25:55,857 - INFO - Epoch 351: train_loss=0.9403
2025-02-02 17:25:56,537 - INFO - Epoch 351: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:25:56,540 - INFO - ####################Training epoch 352####################
2025-02-02 17:25:57,185 - INFO - Epoch 352: train_loss=0.8986
2025-02-02 17:25:57,343 - INFO - Epoch 352: train_loss=0.8588
2025-02-02 17:25:57,478 - INFO - Epoch 352: train_loss=0.7843
2025-02-02 17:25:58,143 - INFO - Epoch 352: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:25:58,146 - INFO - ####################Training epoch 353####################
2025-02-02 17:25:58,798 - INFO - Epoch 353: train_loss=0.8227
2025-02-02 17:25:58,956 - INFO - Epoch 353: train_loss=0.9312
2025-02-02 17:25:59,091 - INFO - Epoch 353: train_loss=0.7982
2025-02-02 17:25:59,747 - INFO - Epoch 353: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:25:59,750 - INFO - ####################Training epoch 354####################
2025-02-02 17:26:00,392 - INFO - Epoch 354: train_loss=0.8343
2025-02-02 17:26:00,549 - INFO - Epoch 354: train_loss=0.9255
2025-02-02 17:26:00,683 - INFO - Epoch 354: train_loss=0.7749
2025-02-02 17:26:01,341 - INFO - Epoch 354: val_loss=2.0005, val_acc=33.33%
2025-02-02 17:26:01,345 - INFO - ####################Training epoch 355####################
2025-02-02 17:26:02,004 - INFO - Epoch 355: train_loss=0.8362
2025-02-02 17:26:02,161 - INFO - Epoch 355: train_loss=0.8819
2025-02-02 17:26:02,304 - INFO - Epoch 355: train_loss=0.8696
2025-02-02 17:26:03,003 - INFO - Epoch 355: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:26:03,007 - INFO - ####################Training epoch 356####################
2025-02-02 17:26:03,666 - INFO - Epoch 356: train_loss=0.9609
2025-02-02 17:26:03,823 - INFO - Epoch 356: train_loss=0.7180
2025-02-02 17:26:03,958 - INFO - Epoch 356: train_loss=0.9736
2025-02-02 17:26:04,627 - INFO - Epoch 356: val_loss=1.9915, val_acc=33.33%
2025-02-02 17:26:04,631 - INFO - ####################Training epoch 357####################
2025-02-02 17:26:05,300 - INFO - Epoch 357: train_loss=0.9334
2025-02-02 17:26:05,459 - INFO - Epoch 357: train_loss=0.8410
2025-02-02 17:26:05,594 - INFO - Epoch 357: train_loss=0.7389
2025-02-02 17:26:06,274 - INFO - Epoch 357: val_loss=1.9917, val_acc=33.33%
2025-02-02 17:26:06,277 - INFO - ####################Training epoch 358####################
2025-02-02 17:26:06,921 - INFO - Epoch 358: train_loss=0.9556
2025-02-02 17:26:07,079 - INFO - Epoch 358: train_loss=0.7647
2025-02-02 17:26:07,214 - INFO - Epoch 358: train_loss=0.8760
2025-02-02 17:26:07,858 - INFO - Epoch 358: val_loss=1.9935, val_acc=33.33%
2025-02-02 17:26:07,862 - INFO - ####################Training epoch 359####################
2025-02-02 17:26:08,520 - INFO - Epoch 359: train_loss=0.8624
2025-02-02 17:26:08,678 - INFO - Epoch 359: train_loss=0.8743
2025-02-02 17:26:08,813 - INFO - Epoch 359: train_loss=0.8485
2025-02-02 17:26:09,468 - INFO - Epoch 359: val_loss=1.9961, val_acc=33.33%
2025-02-02 17:26:09,472 - INFO - ####################Training epoch 360####################
2025-02-02 17:26:10,116 - INFO - Epoch 360: train_loss=0.8395
2025-02-02 17:26:10,274 - INFO - Epoch 360: train_loss=0.9162
2025-02-02 17:26:10,409 - INFO - Epoch 360: train_loss=0.7906
2025-02-02 17:26:11,111 - INFO - Epoch 360: val_loss=1.9954, val_acc=33.33%
2025-02-02 17:26:11,115 - INFO - ####################Training epoch 361####################
2025-02-02 17:26:11,779 - INFO - Epoch 361: train_loss=0.8441
2025-02-02 17:26:11,938 - INFO - Epoch 361: train_loss=0.9220
2025-02-02 17:26:12,073 - INFO - Epoch 361: train_loss=0.7493
2025-02-02 17:26:12,740 - INFO - Epoch 361: val_loss=2.0007, val_acc=33.33%
2025-02-02 17:26:12,744 - INFO - ####################Training epoch 362####################
2025-02-02 17:26:13,380 - INFO - Epoch 362: train_loss=0.8080
2025-02-02 17:26:13,538 - INFO - Epoch 362: train_loss=0.8729
2025-02-02 17:26:13,672 - INFO - Epoch 362: train_loss=0.9921
2025-02-02 17:26:14,324 - INFO - Epoch 362: val_loss=1.9928, val_acc=33.33%
2025-02-02 17:26:14,328 - INFO - ####################Training epoch 363####################
2025-02-02 17:26:14,983 - INFO - Epoch 363: train_loss=0.8926
2025-02-02 17:26:15,141 - INFO - Epoch 363: train_loss=0.8685
2025-02-02 17:26:15,276 - INFO - Epoch 363: train_loss=0.7781
2025-02-02 17:26:15,935 - INFO - Epoch 363: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:26:15,939 - INFO - ####################Training epoch 364####################
2025-02-02 17:26:16,603 - INFO - Epoch 364: train_loss=0.9833
2025-02-02 17:26:16,764 - INFO - Epoch 364: train_loss=0.7702
2025-02-02 17:26:16,899 - INFO - Epoch 364: train_loss=0.7886
2025-02-02 17:26:17,550 - INFO - Epoch 364: val_loss=1.9997, val_acc=33.33%
2025-02-02 17:26:17,554 - INFO - ####################Training epoch 365####################
2025-02-02 17:26:18,212 - INFO - Epoch 365: train_loss=0.9501
2025-02-02 17:26:18,370 - INFO - Epoch 365: train_loss=0.8705
2025-02-02 17:26:18,505 - INFO - Epoch 365: train_loss=0.6190
2025-02-02 17:26:19,167 - INFO - Epoch 365: val_loss=2.0019, val_acc=33.33%
2025-02-02 17:26:19,171 - INFO - ####################Training epoch 366####################
2025-02-02 17:26:19,816 - INFO - Epoch 366: train_loss=0.8467
2025-02-02 17:26:19,974 - INFO - Epoch 366: train_loss=0.8039
2025-02-02 17:26:20,108 - INFO - Epoch 366: train_loss=1.0521
2025-02-02 17:26:20,815 - INFO - Epoch 366: val_loss=2.0003, val_acc=33.33%
2025-02-02 17:26:20,819 - INFO - ####################Training epoch 367####################
2025-02-02 17:26:21,460 - INFO - Epoch 367: train_loss=0.7540
2025-02-02 17:26:21,618 - INFO - Epoch 367: train_loss=1.0158
2025-02-02 17:26:21,752 - INFO - Epoch 367: train_loss=0.7527
2025-02-02 17:26:22,428 - INFO - Epoch 367: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:26:22,432 - INFO - ####################Training epoch 368####################
2025-02-02 17:26:23,066 - INFO - Epoch 368: train_loss=0.8968
2025-02-02 17:26:23,223 - INFO - Epoch 368: train_loss=0.9057
2025-02-02 17:26:23,358 - INFO - Epoch 368: train_loss=0.6725
2025-02-02 17:26:24,021 - INFO - Epoch 368: val_loss=2.0002, val_acc=33.33%
2025-02-02 17:26:24,025 - INFO - ####################Training epoch 369####################
2025-02-02 17:26:24,658 - INFO - Epoch 369: train_loss=0.7908
2025-02-02 17:26:24,815 - INFO - Epoch 369: train_loss=0.9872
2025-02-02 17:26:24,950 - INFO - Epoch 369: train_loss=0.7355
2025-02-02 17:26:25,599 - INFO - Epoch 369: val_loss=1.9937, val_acc=33.33%
2025-02-02 17:26:25,603 - INFO - ####################Training epoch 370####################
2025-02-02 17:26:26,262 - INFO - Epoch 370: train_loss=0.8762
2025-02-02 17:26:26,420 - INFO - Epoch 370: train_loss=0.8425
2025-02-02 17:26:26,554 - INFO - Epoch 370: train_loss=0.8669
2025-02-02 17:26:27,213 - INFO - Epoch 370: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:26:27,218 - INFO - ####################Training epoch 371####################
2025-02-02 17:26:27,860 - INFO - Epoch 371: train_loss=0.9058
2025-02-02 17:26:28,017 - INFO - Epoch 371: train_loss=0.8691
2025-02-02 17:26:28,152 - INFO - Epoch 371: train_loss=0.7278
2025-02-02 17:26:28,841 - INFO - Epoch 371: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:26:28,845 - INFO - ####################Training epoch 372####################
2025-02-02 17:26:29,489 - INFO - Epoch 372: train_loss=0.6968
2025-02-02 17:26:29,647 - INFO - Epoch 372: train_loss=1.1000
2025-02-02 17:26:29,782 - INFO - Epoch 372: train_loss=0.6820
2025-02-02 17:26:30,449 - INFO - Epoch 372: val_loss=1.9925, val_acc=33.33%
2025-02-02 17:26:30,452 - INFO - ####################Training epoch 373####################
2025-02-02 17:26:31,101 - INFO - Epoch 373: train_loss=0.7907
2025-02-02 17:26:31,259 - INFO - Epoch 373: train_loss=0.9248
2025-02-02 17:26:31,393 - INFO - Epoch 373: train_loss=0.8862
2025-02-02 17:26:32,064 - INFO - Epoch 373: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:26:32,068 - INFO - ####################Training epoch 374####################
2025-02-02 17:26:32,732 - INFO - Epoch 374: train_loss=0.7604
2025-02-02 17:26:32,889 - INFO - Epoch 374: train_loss=0.9120
2025-02-02 17:26:33,024 - INFO - Epoch 374: train_loss=0.9908
2025-02-02 17:26:33,671 - INFO - Epoch 374: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:26:33,674 - INFO - ####################Training epoch 375####################
2025-02-02 17:26:34,315 - INFO - Epoch 375: train_loss=0.9693
2025-02-02 17:26:34,473 - INFO - Epoch 375: train_loss=0.8065
2025-02-02 17:26:34,608 - INFO - Epoch 375: train_loss=0.7421
2025-02-02 17:26:35,288 - INFO - Epoch 375: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:26:35,292 - INFO - ####################Training epoch 376####################
2025-02-02 17:26:35,949 - INFO - Epoch 376: train_loss=0.8457
2025-02-02 17:26:36,107 - INFO - Epoch 376: train_loss=0.8977
2025-02-02 17:26:36,241 - INFO - Epoch 376: train_loss=0.8229
2025-02-02 17:26:36,921 - INFO - Epoch 376: val_loss=1.9929, val_acc=33.33%
2025-02-02 17:26:36,933 - INFO - ####################Training epoch 377####################
2025-02-02 17:26:37,599 - INFO - Epoch 377: train_loss=0.8900
2025-02-02 17:26:37,756 - INFO - Epoch 377: train_loss=0.8019
2025-02-02 17:26:37,890 - INFO - Epoch 377: train_loss=0.9375
2025-02-02 17:26:38,574 - INFO - Epoch 377: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:26:38,578 - INFO - ####################Training epoch 378####################
2025-02-02 17:26:39,258 - INFO - Epoch 378: train_loss=0.8477
2025-02-02 17:26:39,415 - INFO - Epoch 378: train_loss=0.9153
2025-02-02 17:26:39,549 - INFO - Epoch 378: train_loss=0.7622
2025-02-02 17:26:40,227 - INFO - Epoch 378: val_loss=1.9991, val_acc=33.33%
2025-02-02 17:26:40,231 - INFO - ####################Training epoch 379####################
2025-02-02 17:26:40,880 - INFO - Epoch 379: train_loss=0.9041
2025-02-02 17:26:41,038 - INFO - Epoch 379: train_loss=0.8502
2025-02-02 17:26:41,172 - INFO - Epoch 379: train_loss=0.7718
2025-02-02 17:26:41,844 - INFO - Epoch 379: val_loss=1.9926, val_acc=33.33%
2025-02-02 17:26:41,847 - INFO - ####################Training epoch 380####################
2025-02-02 17:26:42,507 - INFO - Epoch 380: train_loss=0.7502
2025-02-02 17:26:42,665 - INFO - Epoch 380: train_loss=0.9346
2025-02-02 17:26:42,800 - INFO - Epoch 380: train_loss=0.9575
2025-02-02 17:26:43,478 - INFO - Epoch 380: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:26:43,482 - INFO - ####################Training epoch 381####################
2025-02-02 17:26:44,137 - INFO - Epoch 381: train_loss=0.7340
2025-02-02 17:26:44,294 - INFO - Epoch 381: train_loss=1.0144
2025-02-02 17:26:44,428 - INFO - Epoch 381: train_loss=0.7962
2025-02-02 17:26:45,102 - INFO - Epoch 381: val_loss=2.0009, val_acc=33.33%
2025-02-02 17:26:45,106 - INFO - ####################Training epoch 382####################
2025-02-02 17:26:45,790 - INFO - Epoch 382: train_loss=0.9435
2025-02-02 17:26:45,948 - INFO - Epoch 382: train_loss=0.8163
2025-02-02 17:26:46,083 - INFO - Epoch 382: train_loss=0.7797
2025-02-02 17:26:46,747 - INFO - Epoch 382: val_loss=1.9921, val_acc=33.33%
2025-02-02 17:26:46,751 - INFO - ####################Training epoch 383####################
2025-02-02 17:26:47,383 - INFO - Epoch 383: train_loss=0.8043
2025-02-02 17:26:47,541 - INFO - Epoch 383: train_loss=0.8792
2025-02-02 17:26:47,676 - INFO - Epoch 383: train_loss=0.9608
2025-02-02 17:26:48,360 - INFO - Epoch 383: val_loss=1.9909, val_acc=33.33%
2025-02-02 17:26:48,364 - INFO - ####################Training epoch 384####################
2025-02-02 17:26:48,990 - INFO - Epoch 384: train_loss=0.7577
2025-02-02 17:26:49,148 - INFO - Epoch 384: train_loss=0.8943
2025-02-02 17:26:49,283 - INFO - Epoch 384: train_loss=1.0458
2025-02-02 17:26:49,950 - INFO - Epoch 384: val_loss=1.9927, val_acc=33.33%
2025-02-02 17:26:49,953 - INFO - ####################Training epoch 385####################
2025-02-02 17:26:50,594 - INFO - Epoch 385: train_loss=0.8217
2025-02-02 17:26:50,751 - INFO - Epoch 385: train_loss=0.8443
2025-02-02 17:26:50,885 - INFO - Epoch 385: train_loss=1.0218
2025-02-02 17:26:51,568 - INFO - Epoch 385: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:26:51,571 - INFO - ####################Training epoch 386####################
2025-02-02 17:26:52,208 - INFO - Epoch 386: train_loss=0.8543
2025-02-02 17:26:52,366 - INFO - Epoch 386: train_loss=0.8669
2025-02-02 17:26:52,501 - INFO - Epoch 386: train_loss=0.8768
2025-02-02 17:26:53,158 - INFO - Epoch 386: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:26:53,162 - INFO - ####################Training epoch 387####################
2025-02-02 17:26:53,823 - INFO - Epoch 387: train_loss=0.8550
2025-02-02 17:26:53,984 - INFO - Epoch 387: train_loss=0.8480
2025-02-02 17:26:54,119 - INFO - Epoch 387: train_loss=0.9183
2025-02-02 17:26:54,788 - INFO - Epoch 387: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:26:54,791 - INFO - ####################Training epoch 388####################
2025-02-02 17:26:55,438 - INFO - Epoch 388: train_loss=0.7665
2025-02-02 17:26:55,595 - INFO - Epoch 388: train_loss=0.9612
2025-02-02 17:26:55,730 - INFO - Epoch 388: train_loss=0.8372
2025-02-02 17:26:56,393 - INFO - Epoch 388: val_loss=1.9929, val_acc=33.33%
2025-02-02 17:26:56,397 - INFO - ####################Training epoch 389####################
2025-02-02 17:26:57,038 - INFO - Epoch 389: train_loss=0.9186
2025-02-02 17:26:57,196 - INFO - Epoch 389: train_loss=0.6945
2025-02-02 17:26:57,330 - INFO - Epoch 389: train_loss=1.1383
2025-02-02 17:26:58,003 - INFO - Epoch 389: val_loss=1.9912, val_acc=33.33%
2025-02-02 17:26:58,007 - INFO - ####################Training epoch 390####################
2025-02-02 17:26:58,658 - INFO - Epoch 390: train_loss=0.9356
2025-02-02 17:26:58,815 - INFO - Epoch 390: train_loss=0.8834
2025-02-02 17:26:58,949 - INFO - Epoch 390: train_loss=0.6229
2025-02-02 17:26:59,606 - INFO - Epoch 390: val_loss=1.9948, val_acc=33.33%
2025-02-02 17:26:59,610 - INFO - ####################Training epoch 391####################
2025-02-02 17:27:00,270 - INFO - Epoch 391: train_loss=0.7936
2025-02-02 17:27:00,427 - INFO - Epoch 391: train_loss=0.9389
2025-02-02 17:27:00,562 - INFO - Epoch 391: train_loss=0.8430
2025-02-02 17:27:01,213 - INFO - Epoch 391: val_loss=1.9931, val_acc=33.33%
2025-02-02 17:27:01,217 - INFO - ####################Training epoch 392####################
2025-02-02 17:27:01,869 - INFO - Epoch 392: train_loss=0.8367
2025-02-02 17:27:02,027 - INFO - Epoch 392: train_loss=0.9702
2025-02-02 17:27:02,161 - INFO - Epoch 392: train_loss=0.6547
2025-02-02 17:27:02,895 - INFO - Epoch 392: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:27:02,899 - INFO - ####################Training epoch 393####################
2025-02-02 17:27:03,551 - INFO - Epoch 393: train_loss=0.7851
2025-02-02 17:27:03,708 - INFO - Epoch 393: train_loss=0.9586
2025-02-02 17:27:03,843 - INFO - Epoch 393: train_loss=0.8140
2025-02-02 17:27:04,496 - INFO - Epoch 393: val_loss=1.9922, val_acc=33.33%
2025-02-02 17:27:04,499 - INFO - ####################Training epoch 394####################
2025-02-02 17:27:05,147 - INFO - Epoch 394: train_loss=0.9578
2025-02-02 17:27:05,305 - INFO - Epoch 394: train_loss=0.7858
2025-02-02 17:27:05,439 - INFO - Epoch 394: train_loss=0.8115
2025-02-02 17:27:06,095 - INFO - Epoch 394: val_loss=1.9913, val_acc=33.33%
2025-02-02 17:27:06,099 - INFO - ####################Training epoch 395####################
2025-02-02 17:27:06,761 - INFO - Epoch 395: train_loss=0.7787
2025-02-02 17:27:06,919 - INFO - Epoch 395: train_loss=0.9517
2025-02-02 17:27:07,054 - INFO - Epoch 395: train_loss=0.8468
2025-02-02 17:27:07,722 - INFO - Epoch 395: val_loss=2.0029, val_acc=33.33%
2025-02-02 17:27:07,725 - INFO - ####################Training epoch 396####################
2025-02-02 17:27:08,356 - INFO - Epoch 396: train_loss=0.7996
2025-02-02 17:27:08,513 - INFO - Epoch 396: train_loss=0.8826
2025-02-02 17:27:08,648 - INFO - Epoch 396: train_loss=0.9834
2025-02-02 17:27:09,295 - INFO - Epoch 396: val_loss=1.9927, val_acc=33.33%
2025-02-02 17:27:09,299 - INFO - ####################Training epoch 397####################
2025-02-02 17:27:09,939 - INFO - Epoch 397: train_loss=0.9586
2025-02-02 17:27:10,098 - INFO - Epoch 397: train_loss=0.8202
2025-02-02 17:27:10,233 - INFO - Epoch 397: train_loss=0.7288
2025-02-02 17:27:10,941 - INFO - Epoch 397: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:27:10,945 - INFO - ####################Training epoch 398####################
2025-02-02 17:27:11,598 - INFO - Epoch 398: train_loss=0.8100
2025-02-02 17:27:11,756 - INFO - Epoch 398: train_loss=0.8962
2025-02-02 17:27:11,891 - INFO - Epoch 398: train_loss=0.9099
2025-02-02 17:27:12,583 - INFO - Epoch 398: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:27:12,586 - INFO - ####################Training epoch 399####################
2025-02-02 17:27:13,250 - INFO - Epoch 399: train_loss=0.8352
2025-02-02 17:27:13,408 - INFO - Epoch 399: train_loss=0.8940
2025-02-02 17:27:13,542 - INFO - Epoch 399: train_loss=0.8420
2025-02-02 17:27:14,212 - INFO - Epoch 399: val_loss=1.9915, val_acc=33.33%
2025-02-02 17:27:14,216 - INFO - ####################Training epoch 400####################
2025-02-02 17:27:14,879 - INFO - Epoch 400: train_loss=1.0509
2025-02-02 17:27:15,037 - INFO - Epoch 400: train_loss=0.7264
2025-02-02 17:27:15,171 - INFO - Epoch 400: train_loss=0.7257
2025-02-02 17:27:15,828 - INFO - Epoch 400: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:27:15,832 - INFO - ####################Training epoch 401####################
2025-02-02 17:27:16,499 - INFO - Epoch 401: train_loss=0.9093
2025-02-02 17:27:16,657 - INFO - Epoch 401: train_loss=0.8196
2025-02-02 17:27:16,791 - INFO - Epoch 401: train_loss=0.8433
2025-02-02 17:27:17,470 - INFO - Epoch 401: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:27:17,474 - INFO - ####################Training epoch 402####################
2025-02-02 17:27:18,122 - INFO - Epoch 402: train_loss=0.7788
2025-02-02 17:27:18,280 - INFO - Epoch 402: train_loss=0.9105
2025-02-02 17:27:18,415 - INFO - Epoch 402: train_loss=0.9466
2025-02-02 17:27:19,071 - INFO - Epoch 402: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:27:19,075 - INFO - ####################Training epoch 403####################
2025-02-02 17:27:19,774 - INFO - Epoch 403: train_loss=0.7851
2025-02-02 17:27:19,932 - INFO - Epoch 403: train_loss=0.9722
2025-02-02 17:27:20,066 - INFO - Epoch 403: train_loss=0.7820
2025-02-02 17:27:20,745 - INFO - Epoch 403: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:27:20,749 - INFO - ####################Training epoch 404####################
2025-02-02 17:27:21,406 - INFO - Epoch 404: train_loss=0.8367
2025-02-02 17:27:21,563 - INFO - Epoch 404: train_loss=0.8555
2025-02-02 17:27:21,698 - INFO - Epoch 404: train_loss=0.9473
2025-02-02 17:27:22,371 - INFO - Epoch 404: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:27:22,375 - INFO - ####################Training epoch 405####################
2025-02-02 17:27:23,034 - INFO - Epoch 405: train_loss=0.8935
2025-02-02 17:27:23,192 - INFO - Epoch 405: train_loss=0.8634
2025-02-02 17:27:23,327 - INFO - Epoch 405: train_loss=0.7856
2025-02-02 17:27:23,991 - INFO - Epoch 405: val_loss=1.9991, val_acc=33.33%
2025-02-02 17:27:23,994 - INFO - ####################Training epoch 406####################
2025-02-02 17:27:24,664 - INFO - Epoch 406: train_loss=0.8489
2025-02-02 17:27:24,821 - INFO - Epoch 406: train_loss=0.8944
2025-02-02 17:27:24,956 - INFO - Epoch 406: train_loss=0.8206
2025-02-02 17:27:25,598 - INFO - Epoch 406: val_loss=2.0016, val_acc=33.33%
2025-02-02 17:27:25,602 - INFO - ####################Training epoch 407####################
2025-02-02 17:27:26,251 - INFO - Epoch 407: train_loss=0.8533
2025-02-02 17:27:26,409 - INFO - Epoch 407: train_loss=0.8824
2025-02-02 17:27:26,543 - INFO - Epoch 407: train_loss=0.8510
2025-02-02 17:27:27,198 - INFO - Epoch 407: val_loss=1.9943, val_acc=33.33%
2025-02-02 17:27:27,202 - INFO - ####################Training epoch 408####################
2025-02-02 17:27:27,922 - INFO - Epoch 408: train_loss=0.8815
2025-02-02 17:27:28,080 - INFO - Epoch 408: train_loss=0.7989
2025-02-02 17:27:28,214 - INFO - Epoch 408: train_loss=0.9645
2025-02-02 17:27:28,890 - INFO - Epoch 408: val_loss=1.9914, val_acc=33.33%
2025-02-02 17:27:28,894 - INFO - ####################Training epoch 409####################
2025-02-02 17:27:29,540 - INFO - Epoch 409: train_loss=0.9356
2025-02-02 17:27:29,697 - INFO - Epoch 409: train_loss=0.7522
2025-02-02 17:27:29,832 - INFO - Epoch 409: train_loss=0.9506
2025-02-02 17:27:30,508 - INFO - Epoch 409: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:27:30,512 - INFO - ####################Training epoch 410####################
2025-02-02 17:27:31,143 - INFO - Epoch 410: train_loss=0.8443
2025-02-02 17:27:31,300 - INFO - Epoch 410: train_loss=0.9141
2025-02-02 17:27:31,435 - INFO - Epoch 410: train_loss=0.7780
2025-02-02 17:27:32,084 - INFO - Epoch 410: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:27:32,087 - INFO - ####################Training epoch 411####################
2025-02-02 17:27:32,745 - INFO - Epoch 411: train_loss=0.8576
2025-02-02 17:27:32,902 - INFO - Epoch 411: train_loss=0.9121
2025-02-02 17:27:33,037 - INFO - Epoch 411: train_loss=0.7578
2025-02-02 17:27:33,707 - INFO - Epoch 411: val_loss=1.9932, val_acc=33.33%
2025-02-02 17:27:33,710 - INFO - ####################Training epoch 412####################
2025-02-02 17:27:34,364 - INFO - Epoch 412: train_loss=0.8754
2025-02-02 17:27:34,522 - INFO - Epoch 412: train_loss=0.7600
2025-02-02 17:27:34,656 - INFO - Epoch 412: train_loss=1.0875
2025-02-02 17:27:35,327 - INFO - Epoch 412: val_loss=1.9944, val_acc=33.33%
2025-02-02 17:27:35,330 - INFO - ####################Training epoch 413####################
2025-02-02 17:27:35,997 - INFO - Epoch 413: train_loss=0.8442
2025-02-02 17:27:36,156 - INFO - Epoch 413: train_loss=0.8529
2025-02-02 17:27:36,290 - INFO - Epoch 413: train_loss=0.9360
2025-02-02 17:27:36,943 - INFO - Epoch 413: val_loss=1.9920, val_acc=33.33%
2025-02-02 17:27:36,950 - INFO - ####################Training epoch 414####################
2025-02-02 17:27:37,606 - INFO - Epoch 414: train_loss=0.7644
2025-02-02 17:27:37,764 - INFO - Epoch 414: train_loss=0.9196
2025-02-02 17:27:37,899 - INFO - Epoch 414: train_loss=0.9655
2025-02-02 17:27:38,544 - INFO - Epoch 414: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:27:38,548 - INFO - ####################Training epoch 415####################
2025-02-02 17:27:39,187 - INFO - Epoch 415: train_loss=0.8681
2025-02-02 17:27:39,344 - INFO - Epoch 415: train_loss=0.8810
2025-02-02 17:27:39,479 - INFO - Epoch 415: train_loss=0.8086
2025-02-02 17:27:40,139 - INFO - Epoch 415: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:27:40,143 - INFO - ####################Training epoch 416####################
2025-02-02 17:27:40,795 - INFO - Epoch 416: train_loss=0.9296
2025-02-02 17:27:40,953 - INFO - Epoch 416: train_loss=0.8256
2025-02-02 17:27:41,088 - INFO - Epoch 416: train_loss=0.7845
2025-02-02 17:27:41,740 - INFO - Epoch 416: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:27:41,743 - INFO - ####################Training epoch 417####################
2025-02-02 17:27:42,394 - INFO - Epoch 417: train_loss=0.8649
2025-02-02 17:27:42,552 - INFO - Epoch 417: train_loss=0.8569
2025-02-02 17:27:42,687 - INFO - Epoch 417: train_loss=0.8769
2025-02-02 17:27:43,353 - INFO - Epoch 417: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:27:43,357 - INFO - ####################Training epoch 418####################
2025-02-02 17:27:44,010 - INFO - Epoch 418: train_loss=0.8754
2025-02-02 17:27:44,188 - INFO - Epoch 418: train_loss=0.7600
2025-02-02 17:27:44,332 - INFO - Epoch 418: train_loss=1.0823
2025-02-02 17:27:45,010 - INFO - Epoch 418: val_loss=1.9948, val_acc=33.33%
2025-02-02 17:27:45,013 - INFO - ####################Training epoch 419####################
2025-02-02 17:27:45,667 - INFO - Epoch 419: train_loss=0.9099
2025-02-02 17:27:45,825 - INFO - Epoch 419: train_loss=0.8696
2025-02-02 17:27:45,961 - INFO - Epoch 419: train_loss=0.7292
2025-02-02 17:27:46,661 - INFO - Epoch 419: val_loss=1.9915, val_acc=33.33%
2025-02-02 17:27:46,665 - INFO - ####################Training epoch 420####################
2025-02-02 17:27:47,344 - INFO - Epoch 420: train_loss=0.9697
2025-02-02 17:27:47,501 - INFO - Epoch 420: train_loss=0.7007
2025-02-02 17:27:47,636 - INFO - Epoch 420: train_loss=1.0138
2025-02-02 17:27:48,308 - INFO - Epoch 420: val_loss=1.9964, val_acc=33.33%
2025-02-02 17:27:48,312 - INFO - ####################Training epoch 421####################
2025-02-02 17:27:48,950 - INFO - Epoch 421: train_loss=0.8119
2025-02-02 17:27:49,108 - INFO - Epoch 421: train_loss=0.8955
2025-02-02 17:27:49,242 - INFO - Epoch 421: train_loss=0.9038
2025-02-02 17:27:49,919 - INFO - Epoch 421: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:27:49,923 - INFO - ####################Training epoch 422####################
2025-02-02 17:27:50,579 - INFO - Epoch 422: train_loss=0.8271
2025-02-02 17:27:50,737 - INFO - Epoch 422: train_loss=0.8401
2025-02-02 17:27:50,871 - INFO - Epoch 422: train_loss=0.9911
2025-02-02 17:27:51,522 - INFO - Epoch 422: val_loss=1.9915, val_acc=33.33%
2025-02-02 17:27:51,526 - INFO - ####################Training epoch 423####################
2025-02-02 17:27:52,187 - INFO - Epoch 423: train_loss=0.9566
2025-02-02 17:27:52,345 - INFO - Epoch 423: train_loss=0.7648
2025-02-02 17:27:52,490 - INFO - Epoch 423: train_loss=0.8635
2025-02-02 17:27:53,172 - INFO - Epoch 423: val_loss=1.9926, val_acc=33.33%
2025-02-02 17:27:53,176 - INFO - ####################Training epoch 424####################
2025-02-02 17:27:53,814 - INFO - Epoch 424: train_loss=0.8587
2025-02-02 17:27:53,972 - INFO - Epoch 424: train_loss=0.8658
2025-02-02 17:27:54,106 - INFO - Epoch 424: train_loss=0.8574
2025-02-02 17:27:54,763 - INFO - Epoch 424: val_loss=1.9907, val_acc=33.33%
2025-02-02 17:27:54,767 - INFO - ####################Training epoch 425####################
2025-02-02 17:27:55,428 - INFO - Epoch 425: train_loss=0.8850
2025-02-02 17:27:55,587 - INFO - Epoch 425: train_loss=0.8878
2025-02-02 17:27:55,721 - INFO - Epoch 425: train_loss=0.7409
2025-02-02 17:27:56,382 - INFO - Epoch 425: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:27:56,386 - INFO - ####################Training epoch 426####################
2025-02-02 17:27:57,046 - INFO - Epoch 426: train_loss=0.9858
2025-02-02 17:27:57,204 - INFO - Epoch 426: train_loss=0.7689
2025-02-02 17:27:57,339 - INFO - Epoch 426: train_loss=0.7884
2025-02-02 17:27:57,986 - INFO - Epoch 426: val_loss=1.9943, val_acc=33.33%
2025-02-02 17:27:57,990 - INFO - ####################Training epoch 427####################
2025-02-02 17:27:58,651 - INFO - Epoch 427: train_loss=0.8729
2025-02-02 17:27:58,808 - INFO - Epoch 427: train_loss=0.8064
2025-02-02 17:27:58,943 - INFO - Epoch 427: train_loss=0.9716
2025-02-02 17:27:59,599 - INFO - Epoch 427: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:27:59,603 - INFO - ####################Training epoch 428####################
2025-02-02 17:28:00,244 - INFO - Epoch 428: train_loss=0.9344
2025-02-02 17:28:00,402 - INFO - Epoch 428: train_loss=0.7908
2025-02-02 17:28:00,537 - INFO - Epoch 428: train_loss=0.8824
2025-02-02 17:28:01,261 - INFO - Epoch 428: val_loss=1.9946, val_acc=33.33%
2025-02-02 17:28:01,264 - INFO - ####################Training epoch 429####################
2025-02-02 17:28:01,911 - INFO - Epoch 429: train_loss=0.9708
2025-02-02 17:28:02,069 - INFO - Epoch 429: train_loss=0.8161
2025-02-02 17:28:02,203 - INFO - Epoch 429: train_loss=0.7034
2025-02-02 17:28:02,859 - INFO - Epoch 429: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:28:02,863 - INFO - ####################Training epoch 430####################
2025-02-02 17:28:03,496 - INFO - Epoch 430: train_loss=0.9928
2025-02-02 17:28:03,654 - INFO - Epoch 430: train_loss=0.7570
2025-02-02 17:28:03,788 - INFO - Epoch 430: train_loss=0.7964
2025-02-02 17:28:04,454 - INFO - Epoch 430: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:28:04,458 - INFO - ####################Training epoch 431####################
2025-02-02 17:28:05,114 - INFO - Epoch 431: train_loss=0.7850
2025-02-02 17:28:05,272 - INFO - Epoch 431: train_loss=0.9269
2025-02-02 17:28:05,406 - INFO - Epoch 431: train_loss=0.8939
2025-02-02 17:28:06,050 - INFO - Epoch 431: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:28:06,053 - INFO - ####################Training epoch 432####################
2025-02-02 17:28:06,707 - INFO - Epoch 432: train_loss=0.8682
2025-02-02 17:28:06,865 - INFO - Epoch 432: train_loss=0.8741
2025-02-02 17:28:07,000 - INFO - Epoch 432: train_loss=0.8236
2025-02-02 17:28:07,665 - INFO - Epoch 432: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:28:07,669 - INFO - ####################Training epoch 433####################
2025-02-02 17:28:08,303 - INFO - Epoch 433: train_loss=0.7970
2025-02-02 17:28:08,461 - INFO - Epoch 433: train_loss=0.8749
2025-02-02 17:28:08,596 - INFO - Epoch 433: train_loss=0.9982
2025-02-02 17:28:09,255 - INFO - Epoch 433: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:28:09,259 - INFO - ####################Training epoch 434####################
2025-02-02 17:28:09,947 - INFO - Epoch 434: train_loss=0.8917
2025-02-02 17:28:10,105 - INFO - Epoch 434: train_loss=0.8389
2025-02-02 17:28:10,240 - INFO - Epoch 434: train_loss=0.8476
2025-02-02 17:28:10,895 - INFO - Epoch 434: val_loss=1.9909, val_acc=33.33%
2025-02-02 17:28:10,899 - INFO - ####################Training epoch 435####################
2025-02-02 17:28:11,555 - INFO - Epoch 435: train_loss=0.7702
2025-02-02 17:28:11,714 - INFO - Epoch 435: train_loss=0.8890
2025-02-02 17:28:11,849 - INFO - Epoch 435: train_loss=1.0098
2025-02-02 17:28:12,498 - INFO - Epoch 435: val_loss=1.9954, val_acc=33.33%
2025-02-02 17:28:12,502 - INFO - ####################Training epoch 436####################
2025-02-02 17:28:13,160 - INFO - Epoch 436: train_loss=0.7433
2025-02-02 17:28:13,320 - INFO - Epoch 436: train_loss=0.9955
2025-02-02 17:28:13,455 - INFO - Epoch 436: train_loss=0.8338
2025-02-02 17:28:14,114 - INFO - Epoch 436: val_loss=1.9967, val_acc=33.33%
2025-02-02 17:28:14,118 - INFO - ####################Training epoch 437####################
2025-02-02 17:28:14,748 - INFO - Epoch 437: train_loss=0.8216
2025-02-02 17:28:14,906 - INFO - Epoch 437: train_loss=0.9024
2025-02-02 17:28:15,040 - INFO - Epoch 437: train_loss=0.8579
2025-02-02 17:28:15,714 - INFO - Epoch 437: val_loss=1.9935, val_acc=33.33%
2025-02-02 17:28:15,718 - INFO - ####################Training epoch 438####################
2025-02-02 17:28:16,385 - INFO - Epoch 438: train_loss=0.7669
2025-02-02 17:28:16,544 - INFO - Epoch 438: train_loss=0.9136
2025-02-02 17:28:16,679 - INFO - Epoch 438: train_loss=0.9819
2025-02-02 17:28:17,340 - INFO - Epoch 438: val_loss=1.9924, val_acc=33.33%
2025-02-02 17:28:17,347 - INFO - ####################Training epoch 439####################
2025-02-02 17:28:18,063 - INFO - Epoch 439: train_loss=0.7862
2025-02-02 17:28:18,221 - INFO - Epoch 439: train_loss=0.8982
2025-02-02 17:28:18,356 - INFO - Epoch 439: train_loss=0.9630
2025-02-02 17:28:19,024 - INFO - Epoch 439: val_loss=1.9977, val_acc=33.33%
2025-02-02 17:28:19,028 - INFO - ####################Training epoch 440####################
2025-02-02 17:28:19,671 - INFO - Epoch 440: train_loss=0.7856
2025-02-02 17:28:19,829 - INFO - Epoch 440: train_loss=0.9373
2025-02-02 17:28:19,963 - INFO - Epoch 440: train_loss=0.8643
2025-02-02 17:28:20,646 - INFO - Epoch 440: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:28:20,650 - INFO - ####################Training epoch 441####################
2025-02-02 17:28:21,317 - INFO - Epoch 441: train_loss=0.7716
2025-02-02 17:28:21,475 - INFO - Epoch 441: train_loss=0.9620
2025-02-02 17:28:21,609 - INFO - Epoch 441: train_loss=0.8471
2025-02-02 17:28:22,265 - INFO - Epoch 441: val_loss=1.9954, val_acc=33.33%
2025-02-02 17:28:22,268 - INFO - ####################Training epoch 442####################
2025-02-02 17:28:22,914 - INFO - Epoch 442: train_loss=0.7671
2025-02-02 17:28:23,071 - INFO - Epoch 442: train_loss=0.9285
2025-02-02 17:28:23,206 - INFO - Epoch 442: train_loss=0.9277
2025-02-02 17:28:23,854 - INFO - Epoch 442: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:28:23,858 - INFO - ####################Training epoch 443####################
2025-02-02 17:28:24,515 - INFO - Epoch 443: train_loss=0.8427
2025-02-02 17:28:24,673 - INFO - Epoch 443: train_loss=0.8623
2025-02-02 17:28:24,807 - INFO - Epoch 443: train_loss=0.9054
2025-02-02 17:28:25,464 - INFO - Epoch 443: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:28:25,467 - INFO - ####################Training epoch 444####################
2025-02-02 17:28:26,129 - INFO - Epoch 444: train_loss=0.8875
2025-02-02 17:28:26,291 - INFO - Epoch 444: train_loss=0.8046
2025-02-02 17:28:26,426 - INFO - Epoch 444: train_loss=0.9415
2025-02-02 17:28:27,095 - INFO - Epoch 444: val_loss=1.9941, val_acc=33.33%
2025-02-02 17:28:27,099 - INFO - ####################Training epoch 445####################
2025-02-02 17:28:27,726 - INFO - Epoch 445: train_loss=0.9954
2025-02-02 17:28:27,883 - INFO - Epoch 445: train_loss=0.8049
2025-02-02 17:28:28,018 - INFO - Epoch 445: train_loss=0.6797
2025-02-02 17:28:28,698 - INFO - Epoch 445: val_loss=1.9978, val_acc=33.33%
2025-02-02 17:28:28,702 - INFO - ####################Training epoch 446####################
2025-02-02 17:28:29,344 - INFO - Epoch 446: train_loss=0.9475
2025-02-02 17:28:29,502 - INFO - Epoch 446: train_loss=0.8474
2025-02-02 17:28:29,637 - INFO - Epoch 446: train_loss=0.6841
2025-02-02 17:28:30,313 - INFO - Epoch 446: val_loss=1.9956, val_acc=33.33%
2025-02-02 17:28:30,316 - INFO - ####################Training epoch 447####################
2025-02-02 17:28:30,950 - INFO - Epoch 447: train_loss=0.8105
2025-02-02 17:28:31,108 - INFO - Epoch 447: train_loss=0.9004
2025-02-02 17:28:31,243 - INFO - Epoch 447: train_loss=0.8877
2025-02-02 17:28:31,919 - INFO - Epoch 447: val_loss=1.9937, val_acc=33.33%
2025-02-02 17:28:31,923 - INFO - ####################Training epoch 448####################
2025-02-02 17:28:32,558 - INFO - Epoch 448: train_loss=0.9170
2025-02-02 17:28:32,716 - INFO - Epoch 448: train_loss=0.9198
2025-02-02 17:28:32,850 - INFO - Epoch 448: train_loss=0.5697
2025-02-02 17:28:33,514 - INFO - Epoch 448: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:28:33,518 - INFO - ####################Training epoch 449####################
2025-02-02 17:28:34,151 - INFO - Epoch 449: train_loss=0.7268
2025-02-02 17:28:34,310 - INFO - Epoch 449: train_loss=0.9190
2025-02-02 17:28:34,445 - INFO - Epoch 449: train_loss=1.0605
2025-02-02 17:28:35,171 - INFO - Epoch 449: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:28:35,175 - INFO - ####################Training epoch 450####################
2025-02-02 17:28:35,821 - INFO - Epoch 450: train_loss=0.8423
2025-02-02 17:28:35,980 - INFO - Epoch 450: train_loss=0.9122
2025-02-02 17:28:36,114 - INFO - Epoch 450: train_loss=0.7876
2025-02-02 17:28:36,790 - INFO - Epoch 450: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:28:36,793 - INFO - ####################Training epoch 451####################
2025-02-02 17:28:37,434 - INFO - Epoch 451: train_loss=0.7871
2025-02-02 17:28:37,592 - INFO - Epoch 451: train_loss=0.9408
2025-02-02 17:28:37,727 - INFO - Epoch 451: train_loss=0.8439
2025-02-02 17:28:38,404 - INFO - Epoch 451: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:28:38,407 - INFO - ####################Training epoch 452####################
2025-02-02 17:28:39,044 - INFO - Epoch 452: train_loss=0.8950
2025-02-02 17:28:39,202 - INFO - Epoch 452: train_loss=0.8415
2025-02-02 17:28:39,336 - INFO - Epoch 452: train_loss=0.8265
2025-02-02 17:28:40,029 - INFO - Epoch 452: val_loss=1.9917, val_acc=33.33%
2025-02-02 17:28:40,033 - INFO - ####################Training epoch 453####################
2025-02-02 17:28:40,694 - INFO - Epoch 453: train_loss=0.8318
2025-02-02 17:28:40,853 - INFO - Epoch 453: train_loss=0.8719
2025-02-02 17:28:40,988 - INFO - Epoch 453: train_loss=0.9037
2025-02-02 17:28:41,640 - INFO - Epoch 453: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:28:41,644 - INFO - ####################Training epoch 454####################
2025-02-02 17:28:42,290 - INFO - Epoch 454: train_loss=0.9052
2025-02-02 17:28:42,449 - INFO - Epoch 454: train_loss=0.8654
2025-02-02 17:28:42,584 - INFO - Epoch 454: train_loss=0.7398
2025-02-02 17:28:43,269 - INFO - Epoch 454: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:28:43,273 - INFO - ####################Training epoch 455####################
2025-02-02 17:28:43,920 - INFO - Epoch 455: train_loss=0.7234
2025-02-02 17:28:44,079 - INFO - Epoch 455: train_loss=1.0058
2025-02-02 17:28:44,213 - INFO - Epoch 455: train_loss=0.8497
2025-02-02 17:28:44,881 - INFO - Epoch 455: val_loss=1.9932, val_acc=33.33%
2025-02-02 17:28:44,885 - INFO - ####################Training epoch 456####################
2025-02-02 17:28:45,541 - INFO - Epoch 456: train_loss=0.8279
2025-02-02 17:28:45,698 - INFO - Epoch 456: train_loss=0.9841
2025-02-02 17:28:45,834 - INFO - Epoch 456: train_loss=0.6520
2025-02-02 17:28:46,476 - INFO - Epoch 456: val_loss=1.9911, val_acc=33.33%
2025-02-02 17:28:46,480 - INFO - ####################Training epoch 457####################
2025-02-02 17:28:47,131 - INFO - Epoch 457: train_loss=0.7840
2025-02-02 17:28:47,289 - INFO - Epoch 457: train_loss=0.9708
2025-02-02 17:28:47,423 - INFO - Epoch 457: train_loss=0.7897
2025-02-02 17:28:48,082 - INFO - Epoch 457: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:28:48,086 - INFO - ####################Training epoch 458####################
2025-02-02 17:28:48,712 - INFO - Epoch 458: train_loss=0.8545
2025-02-02 17:28:48,870 - INFO - Epoch 458: train_loss=0.8992
2025-02-02 17:28:49,004 - INFO - Epoch 458: train_loss=0.7928
2025-02-02 17:28:49,655 - INFO - Epoch 458: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:28:49,659 - INFO - ####################Training epoch 459####################
2025-02-02 17:28:50,315 - INFO - Epoch 459: train_loss=0.9555
2025-02-02 17:28:50,473 - INFO - Epoch 459: train_loss=0.8298
2025-02-02 17:28:50,607 - INFO - Epoch 459: train_loss=0.7077
2025-02-02 17:28:51,281 - INFO - Epoch 459: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:28:51,285 - INFO - ####################Training epoch 460####################
2025-02-02 17:28:51,995 - INFO - Epoch 460: train_loss=0.8229
2025-02-02 17:28:52,153 - INFO - Epoch 460: train_loss=0.8147
2025-02-02 17:28:52,287 - INFO - Epoch 460: train_loss=1.0708
2025-02-02 17:28:52,943 - INFO - Epoch 460: val_loss=1.9940, val_acc=33.33%
2025-02-02 17:28:52,946 - INFO - ####################Training epoch 461####################
2025-02-02 17:28:53,580 - INFO - Epoch 461: train_loss=0.8421
2025-02-02 17:28:53,738 - INFO - Epoch 461: train_loss=0.8790
2025-02-02 17:28:53,873 - INFO - Epoch 461: train_loss=0.8664
2025-02-02 17:28:54,546 - INFO - Epoch 461: val_loss=1.9953, val_acc=33.33%
2025-02-02 17:28:54,550 - INFO - ####################Training epoch 462####################
2025-02-02 17:28:55,203 - INFO - Epoch 462: train_loss=0.8461
2025-02-02 17:28:55,361 - INFO - Epoch 462: train_loss=0.9067
2025-02-02 17:28:55,495 - INFO - Epoch 462: train_loss=0.7990
2025-02-02 17:28:56,165 - INFO - Epoch 462: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:28:56,169 - INFO - ####################Training epoch 463####################
2025-02-02 17:28:56,828 - INFO - Epoch 463: train_loss=0.8520
2025-02-02 17:28:56,986 - INFO - Epoch 463: train_loss=0.9524
2025-02-02 17:28:57,120 - INFO - Epoch 463: train_loss=0.6699
2025-02-02 17:28:57,770 - INFO - Epoch 463: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:28:57,777 - INFO - ####################Training epoch 464####################
2025-02-02 17:28:58,436 - INFO - Epoch 464: train_loss=0.8993
2025-02-02 17:28:58,593 - INFO - Epoch 464: train_loss=0.8148
2025-02-02 17:28:58,727 - INFO - Epoch 464: train_loss=0.8889
2025-02-02 17:28:59,395 - INFO - Epoch 464: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:28:59,399 - INFO - ####################Training epoch 465####################
2025-02-02 17:29:00,057 - INFO - Epoch 465: train_loss=0.7584
2025-02-02 17:29:00,214 - INFO - Epoch 465: train_loss=0.9732
2025-02-02 17:29:00,349 - INFO - Epoch 465: train_loss=0.8519
2025-02-02 17:29:01,002 - INFO - Epoch 465: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:29:01,005 - INFO - ####################Training epoch 466####################
2025-02-02 17:29:01,662 - INFO - Epoch 466: train_loss=0.8643
2025-02-02 17:29:01,820 - INFO - Epoch 466: train_loss=0.9342
2025-02-02 17:29:01,954 - INFO - Epoch 466: train_loss=0.6973
2025-02-02 17:29:02,632 - INFO - Epoch 466: val_loss=1.9923, val_acc=33.33%
2025-02-02 17:29:02,636 - INFO - ####################Training epoch 467####################
2025-02-02 17:29:03,299 - INFO - Epoch 467: train_loss=0.8690
2025-02-02 17:29:03,456 - INFO - Epoch 467: train_loss=0.8448
2025-02-02 17:29:03,591 - INFO - Epoch 467: train_loss=0.8868
2025-02-02 17:29:04,254 - INFO - Epoch 467: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:29:04,257 - INFO - ####################Training epoch 468####################
2025-02-02 17:29:04,910 - INFO - Epoch 468: train_loss=0.8522
2025-02-02 17:29:05,068 - INFO - Epoch 468: train_loss=0.8870
2025-02-02 17:29:05,202 - INFO - Epoch 468: train_loss=0.8079
2025-02-02 17:29:05,872 - INFO - Epoch 468: val_loss=1.9950, val_acc=33.33%
2025-02-02 17:29:05,875 - INFO - ####################Training epoch 469####################
2025-02-02 17:29:06,529 - INFO - Epoch 469: train_loss=0.8734
2025-02-02 17:29:06,687 - INFO - Epoch 469: train_loss=0.8051
2025-02-02 17:29:06,821 - INFO - Epoch 469: train_loss=0.9752
2025-02-02 17:29:07,476 - INFO - Epoch 469: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:29:07,480 - INFO - ####################Training epoch 470####################
2025-02-02 17:29:08,135 - INFO - Epoch 470: train_loss=0.8824
2025-02-02 17:29:08,292 - INFO - Epoch 470: train_loss=0.8363
2025-02-02 17:29:08,426 - INFO - Epoch 470: train_loss=0.8749
2025-02-02 17:29:09,154 - INFO - Epoch 470: val_loss=1.9976, val_acc=33.33%
2025-02-02 17:29:09,157 - INFO - ####################Training epoch 471####################
2025-02-02 17:29:09,814 - INFO - Epoch 471: train_loss=0.9648
2025-02-02 17:29:09,971 - INFO - Epoch 471: train_loss=0.7433
2025-02-02 17:29:10,105 - INFO - Epoch 471: train_loss=0.9099
2025-02-02 17:29:10,775 - INFO - Epoch 471: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:29:10,778 - INFO - ####################Training epoch 472####################
2025-02-02 17:29:11,443 - INFO - Epoch 472: train_loss=0.9127
2025-02-02 17:29:11,601 - INFO - Epoch 472: train_loss=0.8465
2025-02-02 17:29:11,735 - INFO - Epoch 472: train_loss=0.7774
2025-02-02 17:29:12,389 - INFO - Epoch 472: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:29:12,393 - INFO - ####################Training epoch 473####################
2025-02-02 17:29:13,049 - INFO - Epoch 473: train_loss=0.8740
2025-02-02 17:29:13,206 - INFO - Epoch 473: train_loss=0.9836
2025-02-02 17:29:13,341 - INFO - Epoch 473: train_loss=0.5247
2025-02-02 17:29:14,005 - INFO - Epoch 473: val_loss=1.9948, val_acc=33.33%
2025-02-02 17:29:14,009 - INFO - ####################Training epoch 474####################
2025-02-02 17:29:14,665 - INFO - Epoch 474: train_loss=0.7950
2025-02-02 17:29:14,822 - INFO - Epoch 474: train_loss=0.8770
2025-02-02 17:29:14,957 - INFO - Epoch 474: train_loss=0.9870
2025-02-02 17:29:15,635 - INFO - Epoch 474: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:29:15,639 - INFO - ####################Training epoch 475####################
2025-02-02 17:29:16,273 - INFO - Epoch 475: train_loss=0.8700
2025-02-02 17:29:16,430 - INFO - Epoch 475: train_loss=0.8406
2025-02-02 17:29:16,564 - INFO - Epoch 475: train_loss=0.9027
2025-02-02 17:29:17,256 - INFO - Epoch 475: val_loss=1.9925, val_acc=33.33%
2025-02-02 17:29:17,260 - INFO - ####################Training epoch 476####################
2025-02-02 17:29:17,905 - INFO - Epoch 476: train_loss=0.8386
2025-02-02 17:29:18,063 - INFO - Epoch 476: train_loss=0.8288
2025-02-02 17:29:18,198 - INFO - Epoch 476: train_loss=1.0099
2025-02-02 17:29:18,861 - INFO - Epoch 476: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:29:18,865 - INFO - ####################Training epoch 477####################
2025-02-02 17:29:19,518 - INFO - Epoch 477: train_loss=0.8444
2025-02-02 17:29:19,676 - INFO - Epoch 477: train_loss=0.8685
2025-02-02 17:29:19,810 - INFO - Epoch 477: train_loss=0.8878
2025-02-02 17:29:20,471 - INFO - Epoch 477: val_loss=1.9937, val_acc=33.33%
2025-02-02 17:29:20,475 - INFO - ####################Training epoch 478####################
2025-02-02 17:29:21,137 - INFO - Epoch 478: train_loss=0.8385
2025-02-02 17:29:21,295 - INFO - Epoch 478: train_loss=0.9281
2025-02-02 17:29:21,429 - INFO - Epoch 478: train_loss=0.7570
2025-02-02 17:29:22,103 - INFO - Epoch 478: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:29:22,106 - INFO - ####################Training epoch 479####################
2025-02-02 17:29:22,752 - INFO - Epoch 479: train_loss=0.8377
2025-02-02 17:29:22,909 - INFO - Epoch 479: train_loss=0.8748
2025-02-02 17:29:23,044 - INFO - Epoch 479: train_loss=0.8845
2025-02-02 17:29:23,694 - INFO - Epoch 479: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:29:23,698 - INFO - ####################Training epoch 480####################
2025-02-02 17:29:24,343 - INFO - Epoch 480: train_loss=0.8433
2025-02-02 17:29:24,501 - INFO - Epoch 480: train_loss=0.9270
2025-02-02 17:29:24,636 - INFO - Epoch 480: train_loss=0.7436
2025-02-02 17:29:25,310 - INFO - Epoch 480: val_loss=1.9921, val_acc=33.33%
2025-02-02 17:29:25,314 - INFO - ####################Training epoch 481####################
2025-02-02 17:29:25,996 - INFO - Epoch 481: train_loss=0.8971
2025-02-02 17:29:26,154 - INFO - Epoch 481: train_loss=0.8241
2025-02-02 17:29:26,288 - INFO - Epoch 481: train_loss=0.8734
2025-02-02 17:29:26,929 - INFO - Epoch 481: val_loss=1.9928, val_acc=33.33%
2025-02-02 17:29:26,933 - INFO - ####################Training epoch 482####################
2025-02-02 17:29:27,588 - INFO - Epoch 482: train_loss=0.9867
2025-02-02 17:29:27,745 - INFO - Epoch 482: train_loss=0.7668
2025-02-02 17:29:27,880 - INFO - Epoch 482: train_loss=0.7911
2025-02-02 17:29:28,583 - INFO - Epoch 482: val_loss=1.9977, val_acc=33.33%
2025-02-02 17:29:28,587 - INFO - ####################Training epoch 483####################
2025-02-02 17:29:29,235 - INFO - Epoch 483: train_loss=0.8952
2025-02-02 17:29:29,393 - INFO - Epoch 483: train_loss=0.7789
2025-02-02 17:29:29,527 - INFO - Epoch 483: train_loss=0.9832
2025-02-02 17:29:30,193 - INFO - Epoch 483: val_loss=1.9912, val_acc=33.33%
2025-02-02 17:29:30,197 - INFO - ####################Training epoch 484####################
2025-02-02 17:29:30,853 - INFO - Epoch 484: train_loss=0.8067
2025-02-02 17:29:31,011 - INFO - Epoch 484: train_loss=0.8359
2025-02-02 17:29:31,145 - INFO - Epoch 484: train_loss=1.0631
2025-02-02 17:29:31,819 - INFO - Epoch 484: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:29:31,823 - INFO - ####################Training epoch 485####################
2025-02-02 17:29:32,481 - INFO - Epoch 485: train_loss=0.8374
2025-02-02 17:29:32,639 - INFO - Epoch 485: train_loss=0.8757
2025-02-02 17:29:32,773 - INFO - Epoch 485: train_loss=0.8901
2025-02-02 17:29:33,419 - INFO - Epoch 485: val_loss=1.9900, val_acc=33.33%
2025-02-02 17:29:33,424 - INFO - ####################Training epoch 486####################
2025-02-02 17:29:34,081 - INFO - Epoch 486: train_loss=0.8855
2025-02-02 17:29:34,239 - INFO - Epoch 486: train_loss=0.7794
2025-02-02 17:29:34,373 - INFO - Epoch 486: train_loss=1.0039
2025-02-02 17:29:35,032 - INFO - Epoch 486: val_loss=1.9981, val_acc=33.33%
2025-02-02 17:29:35,036 - INFO - ####################Training epoch 487####################
2025-02-02 17:29:35,697 - INFO - Epoch 487: train_loss=0.7730
2025-02-02 17:29:35,855 - INFO - Epoch 487: train_loss=0.9130
2025-02-02 17:29:35,989 - INFO - Epoch 487: train_loss=0.9587
2025-02-02 17:29:36,660 - INFO - Epoch 487: val_loss=1.9950, val_acc=33.33%
2025-02-02 17:29:36,663 - INFO - ####################Training epoch 488####################
2025-02-02 17:29:37,319 - INFO - Epoch 488: train_loss=0.6513
2025-02-02 17:29:37,477 - INFO - Epoch 488: train_loss=0.9756
2025-02-02 17:29:37,612 - INFO - Epoch 488: train_loss=1.0994
2025-02-02 17:29:38,266 - INFO - Epoch 488: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:29:38,270 - INFO - ####################Training epoch 489####################
2025-02-02 17:29:38,927 - INFO - Epoch 489: train_loss=0.7942
2025-02-02 17:29:39,084 - INFO - Epoch 489: train_loss=0.9121
2025-02-02 17:29:39,219 - INFO - Epoch 489: train_loss=0.9071
2025-02-02 17:29:39,896 - INFO - Epoch 489: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:29:39,899 - INFO - ####################Training epoch 490####################
2025-02-02 17:29:40,530 - INFO - Epoch 490: train_loss=0.9174
2025-02-02 17:29:40,688 - INFO - Epoch 490: train_loss=0.9090
2025-02-02 17:29:40,822 - INFO - Epoch 490: train_loss=0.6022
2025-02-02 17:29:41,506 - INFO - Epoch 490: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:29:41,510 - INFO - ####################Training epoch 491####################
2025-02-02 17:29:42,150 - INFO - Epoch 491: train_loss=0.9430
2025-02-02 17:29:42,317 - INFO - Epoch 491: train_loss=0.7414
2025-02-02 17:29:42,454 - INFO - Epoch 491: train_loss=0.9751
2025-02-02 17:29:43,099 - INFO - Epoch 491: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:29:43,102 - INFO - ####################Training epoch 492####################
2025-02-02 17:29:43,728 - INFO - Epoch 492: train_loss=0.8182
2025-02-02 17:29:43,885 - INFO - Epoch 492: train_loss=0.9256
2025-02-02 17:29:44,020 - INFO - Epoch 492: train_loss=0.8132
2025-02-02 17:29:44,701 - INFO - Epoch 492: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:29:44,705 - INFO - ####################Training epoch 493####################
2025-02-02 17:29:45,346 - INFO - Epoch 493: train_loss=0.7971
2025-02-02 17:29:45,504 - INFO - Epoch 493: train_loss=0.8237
2025-02-02 17:29:45,639 - INFO - Epoch 493: train_loss=1.1195
2025-02-02 17:29:46,317 - INFO - Epoch 493: val_loss=1.9924, val_acc=33.33%
2025-02-02 17:29:46,321 - INFO - ####################Training epoch 494####################
2025-02-02 17:29:46,974 - INFO - Epoch 494: train_loss=0.8870
2025-02-02 17:29:47,132 - INFO - Epoch 494: train_loss=0.8181
2025-02-02 17:29:47,267 - INFO - Epoch 494: train_loss=0.9078
2025-02-02 17:29:47,928 - INFO - Epoch 494: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:29:47,932 - INFO - ####################Training epoch 495####################
2025-02-02 17:29:48,584 - INFO - Epoch 495: train_loss=1.0026
2025-02-02 17:29:48,741 - INFO - Epoch 495: train_loss=0.7347
2025-02-02 17:29:48,876 - INFO - Epoch 495: train_loss=0.8269
2025-02-02 17:29:49,545 - INFO - Epoch 495: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:29:49,549 - INFO - ####################Training epoch 496####################
2025-02-02 17:29:50,183 - INFO - Epoch 496: train_loss=0.8301
2025-02-02 17:29:50,340 - INFO - Epoch 496: train_loss=0.9523
2025-02-02 17:29:50,474 - INFO - Epoch 496: train_loss=0.7230
2025-02-02 17:29:51,181 - INFO - Epoch 496: val_loss=1.9940, val_acc=33.33%
2025-02-02 17:29:51,185 - INFO - ####################Training epoch 497####################
2025-02-02 17:29:51,815 - INFO - Epoch 497: train_loss=0.9235
2025-02-02 17:29:51,973 - INFO - Epoch 497: train_loss=0.7974
2025-02-02 17:29:52,107 - INFO - Epoch 497: train_loss=0.8731
2025-02-02 17:29:52,770 - INFO - Epoch 497: val_loss=2.0010, val_acc=33.33%
2025-02-02 17:29:52,774 - INFO - ####################Training epoch 498####################
2025-02-02 17:29:53,431 - INFO - Epoch 498: train_loss=0.7439
2025-02-02 17:29:53,589 - INFO - Epoch 498: train_loss=0.9027
2025-02-02 17:29:53,723 - INFO - Epoch 498: train_loss=1.0470
2025-02-02 17:29:54,395 - INFO - Epoch 498: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:29:54,399 - INFO - ####################Training epoch 499####################
2025-02-02 17:29:55,062 - INFO - Epoch 499: train_loss=0.9481
2025-02-02 17:29:55,219 - INFO - Epoch 499: train_loss=0.7498
2025-02-02 17:29:55,353 - INFO - Epoch 499: train_loss=0.9237
2025-02-02 17:29:56,034 - INFO - Epoch 499: val_loss=2.0022, val_acc=33.33%
2025-02-02 17:29:56,038 - INFO - ####################Training epoch 500####################
2025-02-02 17:29:56,692 - INFO - Epoch 500: train_loss=0.9396
2025-02-02 17:29:56,850 - INFO - Epoch 500: train_loss=0.8363
2025-02-02 17:29:56,985 - INFO - Epoch 500: train_loss=0.7322
2025-02-02 17:29:57,646 - INFO - Epoch 500: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:29:57,650 - INFO - ####################Training epoch 501####################
2025-02-02 17:29:58,315 - INFO - Epoch 501: train_loss=0.9132
2025-02-02 17:29:58,472 - INFO - Epoch 501: train_loss=0.8716
2025-02-02 17:29:58,607 - INFO - Epoch 501: train_loss=0.7111
2025-02-02 17:29:59,274 - INFO - Epoch 501: val_loss=1.9891, val_acc=33.33%
2025-02-02 17:29:59,292 - INFO - ####################Training epoch 502####################
2025-02-02 17:29:59,949 - INFO - Epoch 502: train_loss=0.9347
2025-02-02 17:30:00,107 - INFO - Epoch 502: train_loss=0.8284
2025-02-02 17:30:00,241 - INFO - Epoch 502: train_loss=0.7654
2025-02-02 17:30:00,904 - INFO - Epoch 502: val_loss=1.9964, val_acc=33.33%
2025-02-02 17:30:00,909 - INFO - ####################Training epoch 503####################
2025-02-02 17:30:01,585 - INFO - Epoch 503: train_loss=0.9200
2025-02-02 17:30:01,743 - INFO - Epoch 503: train_loss=0.7756
2025-02-02 17:30:01,878 - INFO - Epoch 503: train_loss=0.9474
2025-02-02 17:30:02,573 - INFO - Epoch 503: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:30:02,576 - INFO - ####################Training epoch 504####################
2025-02-02 17:30:03,235 - INFO - Epoch 504: train_loss=0.8114
2025-02-02 17:30:03,392 - INFO - Epoch 504: train_loss=0.8990
2025-02-02 17:30:03,527 - INFO - Epoch 504: train_loss=0.8969
2025-02-02 17:30:04,175 - INFO - Epoch 504: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:30:04,178 - INFO - ####################Training epoch 505####################
2025-02-02 17:30:04,826 - INFO - Epoch 505: train_loss=0.9544
2025-02-02 17:30:04,984 - INFO - Epoch 505: train_loss=0.8554
2025-02-02 17:30:05,119 - INFO - Epoch 505: train_loss=0.6543
2025-02-02 17:30:05,787 - INFO - Epoch 505: val_loss=1.9919, val_acc=33.33%
2025-02-02 17:30:05,791 - INFO - ####################Training epoch 506####################
2025-02-02 17:30:06,448 - INFO - Epoch 506: train_loss=0.8558
2025-02-02 17:30:06,605 - INFO - Epoch 506: train_loss=0.8678
2025-02-02 17:30:06,740 - INFO - Epoch 506: train_loss=0.8708
2025-02-02 17:30:07,421 - INFO - Epoch 506: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:30:07,425 - INFO - ####################Training epoch 507####################
2025-02-02 17:30:08,136 - INFO - Epoch 507: train_loss=0.8056
2025-02-02 17:30:08,293 - INFO - Epoch 507: train_loss=0.9175
2025-02-02 17:30:08,427 - INFO - Epoch 507: train_loss=0.8770
2025-02-02 17:30:09,099 - INFO - Epoch 507: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:30:09,103 - INFO - ####################Training epoch 508####################
2025-02-02 17:30:09,766 - INFO - Epoch 508: train_loss=0.8605
2025-02-02 17:30:09,924 - INFO - Epoch 508: train_loss=0.9112
2025-02-02 17:30:10,059 - INFO - Epoch 508: train_loss=0.7454
2025-02-02 17:30:10,698 - INFO - Epoch 508: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:30:10,702 - INFO - ####################Training epoch 509####################
2025-02-02 17:30:11,346 - INFO - Epoch 509: train_loss=0.8292
2025-02-02 17:30:11,504 - INFO - Epoch 509: train_loss=0.9247
2025-02-02 17:30:11,639 - INFO - Epoch 509: train_loss=0.7884
2025-02-02 17:30:12,313 - INFO - Epoch 509: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:30:12,317 - INFO - ####################Training epoch 510####################
2025-02-02 17:30:12,974 - INFO - Epoch 510: train_loss=0.7818
2025-02-02 17:30:13,131 - INFO - Epoch 510: train_loss=1.0179
2025-02-02 17:30:13,266 - INFO - Epoch 510: train_loss=0.6774
2025-02-02 17:30:13,926 - INFO - Epoch 510: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:30:13,929 - INFO - ####################Training epoch 511####################
2025-02-02 17:30:14,591 - INFO - Epoch 511: train_loss=1.0004
2025-02-02 17:30:14,748 - INFO - Epoch 511: train_loss=0.7297
2025-02-02 17:30:14,883 - INFO - Epoch 511: train_loss=0.8494
2025-02-02 17:30:15,546 - INFO - Epoch 511: val_loss=1.9917, val_acc=33.33%
2025-02-02 17:30:15,552 - INFO - ####################Training epoch 512####################
2025-02-02 17:30:16,262 - INFO - Epoch 512: train_loss=0.9276
2025-02-02 17:30:16,420 - INFO - Epoch 512: train_loss=0.7439
2025-02-02 17:30:16,554 - INFO - Epoch 512: train_loss=0.9945
2025-02-02 17:30:17,228 - INFO - Epoch 512: val_loss=1.9979, val_acc=33.33%
2025-02-02 17:30:17,232 - INFO - ####################Training epoch 513####################
2025-02-02 17:30:17,892 - INFO - Epoch 513: train_loss=1.0285
2025-02-02 17:30:18,049 - INFO - Epoch 513: train_loss=0.7449
2025-02-02 17:30:18,184 - INFO - Epoch 513: train_loss=0.7398
2025-02-02 17:30:18,868 - INFO - Epoch 513: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:30:18,872 - INFO - ####################Training epoch 514####################
2025-02-02 17:30:19,496 - INFO - Epoch 514: train_loss=0.8119
2025-02-02 17:30:19,653 - INFO - Epoch 514: train_loss=1.0065
2025-02-02 17:30:19,787 - INFO - Epoch 514: train_loss=0.6223
2025-02-02 17:30:20,448 - INFO - Epoch 514: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:30:20,452 - INFO - ####################Training epoch 515####################
2025-02-02 17:30:21,103 - INFO - Epoch 515: train_loss=0.7993
2025-02-02 17:30:21,261 - INFO - Epoch 515: train_loss=0.8844
2025-02-02 17:30:21,396 - INFO - Epoch 515: train_loss=0.9677
2025-02-02 17:30:22,059 - INFO - Epoch 515: val_loss=1.9961, val_acc=33.33%
2025-02-02 17:30:22,063 - INFO - ####################Training epoch 516####################
2025-02-02 17:30:22,708 - INFO - Epoch 516: train_loss=0.7075
2025-02-02 17:30:22,865 - INFO - Epoch 516: train_loss=0.9766
2025-02-02 17:30:23,000 - INFO - Epoch 516: train_loss=0.9638
2025-02-02 17:30:23,678 - INFO - Epoch 516: val_loss=1.9930, val_acc=33.33%
2025-02-02 17:30:23,681 - INFO - ####################Training epoch 517####################
2025-02-02 17:30:24,322 - INFO - Epoch 517: train_loss=0.7380
2025-02-02 17:30:24,481 - INFO - Epoch 517: train_loss=0.9093
2025-02-02 17:30:24,616 - INFO - Epoch 517: train_loss=1.0519
2025-02-02 17:30:25,272 - INFO - Epoch 517: val_loss=1.9998, val_acc=33.33%
2025-02-02 17:30:25,276 - INFO - ####################Training epoch 518####################
2025-02-02 17:30:25,934 - INFO - Epoch 518: train_loss=0.8213
2025-02-02 17:30:26,091 - INFO - Epoch 518: train_loss=0.8571
2025-02-02 17:30:26,225 - INFO - Epoch 518: train_loss=0.9712
2025-02-02 17:30:26,893 - INFO - Epoch 518: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:30:26,897 - INFO - ####################Training epoch 519####################
2025-02-02 17:30:27,561 - INFO - Epoch 519: train_loss=0.8651
2025-02-02 17:30:27,719 - INFO - Epoch 519: train_loss=0.7942
2025-02-02 17:30:27,853 - INFO - Epoch 519: train_loss=1.0240
2025-02-02 17:30:28,529 - INFO - Epoch 519: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:30:28,533 - INFO - ####################Training epoch 520####################
2025-02-02 17:30:29,180 - INFO - Epoch 520: train_loss=0.9260
2025-02-02 17:30:29,338 - INFO - Epoch 520: train_loss=0.8208
2025-02-02 17:30:29,473 - INFO - Epoch 520: train_loss=0.7951
2025-02-02 17:30:30,138 - INFO - Epoch 520: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:30:30,142 - INFO - ####################Training epoch 521####################
2025-02-02 17:30:30,776 - INFO - Epoch 521: train_loss=0.7754
2025-02-02 17:30:30,934 - INFO - Epoch 521: train_loss=0.9412
2025-02-02 17:30:31,069 - INFO - Epoch 521: train_loss=0.8890
2025-02-02 17:30:31,729 - INFO - Epoch 521: val_loss=1.9925, val_acc=33.33%
2025-02-02 17:30:31,732 - INFO - ####################Training epoch 522####################
2025-02-02 17:30:32,353 - INFO - Epoch 522: train_loss=1.0125
2025-02-02 17:30:32,511 - INFO - Epoch 522: train_loss=0.7687
2025-02-02 17:30:32,645 - INFO - Epoch 522: train_loss=0.7262
2025-02-02 17:30:33,344 - INFO - Epoch 522: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:30:33,347 - INFO - ####################Training epoch 523####################
2025-02-02 17:30:33,995 - INFO - Epoch 523: train_loss=0.7802
2025-02-02 17:30:34,153 - INFO - Epoch 523: train_loss=1.0023
2025-02-02 17:30:34,288 - INFO - Epoch 523: train_loss=0.7216
2025-02-02 17:30:34,955 - INFO - Epoch 523: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:30:34,959 - INFO - ####################Training epoch 524####################
2025-02-02 17:30:35,637 - INFO - Epoch 524: train_loss=0.9381
2025-02-02 17:30:35,795 - INFO - Epoch 524: train_loss=0.7338
2025-02-02 17:30:35,930 - INFO - Epoch 524: train_loss=0.9903
2025-02-02 17:30:36,599 - INFO - Epoch 524: val_loss=1.9925, val_acc=33.33%
2025-02-02 17:30:36,603 - INFO - ####################Training epoch 525####################
2025-02-02 17:30:37,254 - INFO - Epoch 525: train_loss=0.7569
2025-02-02 17:30:37,412 - INFO - Epoch 525: train_loss=0.9394
2025-02-02 17:30:37,547 - INFO - Epoch 525: train_loss=0.9347
2025-02-02 17:30:38,201 - INFO - Epoch 525: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:30:38,204 - INFO - ####################Training epoch 526####################
2025-02-02 17:30:38,853 - INFO - Epoch 526: train_loss=0.8919
2025-02-02 17:30:39,011 - INFO - Epoch 526: train_loss=0.8757
2025-02-02 17:30:39,145 - INFO - Epoch 526: train_loss=0.7645
2025-02-02 17:30:39,815 - INFO - Epoch 526: val_loss=1.9943, val_acc=33.33%
2025-02-02 17:30:39,818 - INFO - ####################Training epoch 527####################
2025-02-02 17:30:40,472 - INFO - Epoch 527: train_loss=0.9175
2025-02-02 17:30:40,630 - INFO - Epoch 527: train_loss=0.7979
2025-02-02 17:30:40,764 - INFO - Epoch 527: train_loss=0.8902
2025-02-02 17:30:41,444 - INFO - Epoch 527: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:30:41,447 - INFO - ####################Training epoch 528####################
2025-02-02 17:30:42,109 - INFO - Epoch 528: train_loss=0.9236
2025-02-02 17:30:42,267 - INFO - Epoch 528: train_loss=0.7644
2025-02-02 17:30:42,402 - INFO - Epoch 528: train_loss=0.9453
2025-02-02 17:30:43,078 - INFO - Epoch 528: val_loss=2.0014, val_acc=33.33%
2025-02-02 17:30:43,082 - INFO - ####################Training epoch 529####################
2025-02-02 17:30:43,702 - INFO - Epoch 529: train_loss=0.8429
2025-02-02 17:30:43,859 - INFO - Epoch 529: train_loss=0.8637
2025-02-02 17:30:43,994 - INFO - Epoch 529: train_loss=0.9101
2025-02-02 17:30:44,656 - INFO - Epoch 529: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:30:44,660 - INFO - ####################Training epoch 530####################
2025-02-02 17:30:45,325 - INFO - Epoch 530: train_loss=0.8262
2025-02-02 17:30:45,483 - INFO - Epoch 530: train_loss=0.8827
2025-02-02 17:30:45,617 - INFO - Epoch 530: train_loss=0.8978
2025-02-02 17:30:46,294 - INFO - Epoch 530: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:30:46,298 - INFO - ####################Training epoch 531####################
2025-02-02 17:30:46,942 - INFO - Epoch 531: train_loss=0.7018
2025-02-02 17:30:47,099 - INFO - Epoch 531: train_loss=0.9779
2025-02-02 17:30:47,234 - INFO - Epoch 531: train_loss=0.9699
2025-02-02 17:30:47,875 - INFO - Epoch 531: val_loss=1.9903, val_acc=33.33%
2025-02-02 17:30:47,879 - INFO - ####################Training epoch 532####################
2025-02-02 17:30:48,518 - INFO - Epoch 532: train_loss=0.7890
2025-02-02 17:30:48,676 - INFO - Epoch 532: train_loss=0.8679
2025-02-02 17:30:48,810 - INFO - Epoch 532: train_loss=1.0296
2025-02-02 17:30:49,463 - INFO - Epoch 532: val_loss=2.0028, val_acc=33.33%
2025-02-02 17:30:49,466 - INFO - ####################Training epoch 533####################
2025-02-02 17:30:50,174 - INFO - Epoch 533: train_loss=0.8743
2025-02-02 17:30:50,332 - INFO - Epoch 533: train_loss=0.7806
2025-02-02 17:30:50,467 - INFO - Epoch 533: train_loss=1.0417
2025-02-02 17:30:51,149 - INFO - Epoch 533: val_loss=1.9950, val_acc=33.33%
2025-02-02 17:30:51,153 - INFO - ####################Training epoch 534####################
2025-02-02 17:30:51,792 - INFO - Epoch 534: train_loss=0.9147
2025-02-02 17:30:51,951 - INFO - Epoch 534: train_loss=0.7788
2025-02-02 17:30:52,085 - INFO - Epoch 534: train_loss=0.9498
2025-02-02 17:30:52,741 - INFO - Epoch 534: val_loss=1.9944, val_acc=33.33%
2025-02-02 17:30:52,745 - INFO - ####################Training epoch 535####################
2025-02-02 17:30:53,386 - INFO - Epoch 535: train_loss=0.8565
2025-02-02 17:30:53,543 - INFO - Epoch 535: train_loss=0.8579
2025-02-02 17:30:53,678 - INFO - Epoch 535: train_loss=0.8910
2025-02-02 17:30:54,351 - INFO - Epoch 535: val_loss=1.9931, val_acc=33.33%
2025-02-02 17:30:54,355 - INFO - ####################Training epoch 536####################
2025-02-02 17:30:55,011 - INFO - Epoch 536: train_loss=0.8767
2025-02-02 17:30:55,169 - INFO - Epoch 536: train_loss=0.8327
2025-02-02 17:30:55,304 - INFO - Epoch 536: train_loss=0.9001
2025-02-02 17:30:55,968 - INFO - Epoch 536: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:30:55,972 - INFO - ####################Training epoch 537####################
2025-02-02 17:30:56,625 - INFO - Epoch 537: train_loss=0.9123
2025-02-02 17:30:56,783 - INFO - Epoch 537: train_loss=0.8538
2025-02-02 17:30:56,918 - INFO - Epoch 537: train_loss=0.7547
2025-02-02 17:30:57,582 - INFO - Epoch 537: val_loss=1.9905, val_acc=33.33%
2025-02-02 17:30:57,586 - INFO - ####################Training epoch 538####################
2025-02-02 17:30:58,276 - INFO - Epoch 538: train_loss=0.9083
2025-02-02 17:30:58,435 - INFO - Epoch 538: train_loss=0.7944
2025-02-02 17:30:58,569 - INFO - Epoch 538: train_loss=0.9171
2025-02-02 17:30:59,247 - INFO - Epoch 538: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:30:59,251 - INFO - ####################Training epoch 539####################
2025-02-02 17:30:59,911 - INFO - Epoch 539: train_loss=0.9047
2025-02-02 17:31:00,069 - INFO - Epoch 539: train_loss=0.7799
2025-02-02 17:31:00,203 - INFO - Epoch 539: train_loss=0.9607
2025-02-02 17:31:00,850 - INFO - Epoch 539: val_loss=1.9921, val_acc=33.33%
2025-02-02 17:31:00,854 - INFO - ####################Training epoch 540####################
2025-02-02 17:31:01,486 - INFO - Epoch 540: train_loss=0.9095
2025-02-02 17:31:01,644 - INFO - Epoch 540: train_loss=0.8383
2025-02-02 17:31:01,779 - INFO - Epoch 540: train_loss=0.8002
2025-02-02 17:31:02,446 - INFO - Epoch 540: val_loss=2.0016, val_acc=33.33%
2025-02-02 17:31:02,449 - INFO - ####################Training epoch 541####################
2025-02-02 17:31:03,092 - INFO - Epoch 541: train_loss=0.9225
2025-02-02 17:31:03,250 - INFO - Epoch 541: train_loss=0.7769
2025-02-02 17:31:03,385 - INFO - Epoch 541: train_loss=0.9111
2025-02-02 17:31:04,057 - INFO - Epoch 541: val_loss=2.0004, val_acc=33.33%
2025-02-02 17:31:04,060 - INFO - ####################Training epoch 542####################
2025-02-02 17:31:04,718 - INFO - Epoch 542: train_loss=0.8903
2025-02-02 17:31:04,875 - INFO - Epoch 542: train_loss=0.8544
2025-02-02 17:31:05,010 - INFO - Epoch 542: train_loss=0.8151
2025-02-02 17:31:05,675 - INFO - Epoch 542: val_loss=1.9956, val_acc=33.33%
2025-02-02 17:31:05,678 - INFO - ####################Training epoch 543####################
2025-02-02 17:31:06,340 - INFO - Epoch 543: train_loss=0.8542
2025-02-02 17:31:06,500 - INFO - Epoch 543: train_loss=0.7971
2025-02-02 17:31:06,635 - INFO - Epoch 543: train_loss=1.0403
2025-02-02 17:31:07,298 - INFO - Epoch 543: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:31:07,301 - INFO - ####################Training epoch 544####################
2025-02-02 17:31:07,957 - INFO - Epoch 544: train_loss=0.8376
2025-02-02 17:31:08,115 - INFO - Epoch 544: train_loss=0.9477
2025-02-02 17:31:08,249 - INFO - Epoch 544: train_loss=0.6982
2025-02-02 17:31:08,946 - INFO - Epoch 544: val_loss=1.9967, val_acc=33.33%
2025-02-02 17:31:08,950 - INFO - ####################Training epoch 545####################
2025-02-02 17:31:09,626 - INFO - Epoch 545: train_loss=0.8959
2025-02-02 17:31:09,785 - INFO - Epoch 545: train_loss=0.8215
2025-02-02 17:31:09,920 - INFO - Epoch 545: train_loss=0.8910
2025-02-02 17:31:10,607 - INFO - Epoch 545: val_loss=1.9956, val_acc=33.33%
2025-02-02 17:31:10,611 - INFO - ####################Training epoch 546####################
2025-02-02 17:31:11,271 - INFO - Epoch 546: train_loss=0.9029
2025-02-02 17:31:11,429 - INFO - Epoch 546: train_loss=0.8675
2025-02-02 17:31:11,564 - INFO - Epoch 546: train_loss=0.7461
2025-02-02 17:31:12,244 - INFO - Epoch 546: val_loss=1.9894, val_acc=33.33%
2025-02-02 17:31:12,247 - INFO - ####################Training epoch 547####################
2025-02-02 17:31:12,902 - INFO - Epoch 547: train_loss=0.8275
2025-02-02 17:31:13,061 - INFO - Epoch 547: train_loss=0.8324
2025-02-02 17:31:13,196 - INFO - Epoch 547: train_loss=1.0306
2025-02-02 17:31:13,856 - INFO - Epoch 547: val_loss=1.9917, val_acc=33.33%
2025-02-02 17:31:13,860 - INFO - ####################Training epoch 548####################
2025-02-02 17:31:14,518 - INFO - Epoch 548: train_loss=0.7676
2025-02-02 17:31:14,685 - INFO - Epoch 548: train_loss=0.9219
2025-02-02 17:31:14,821 - INFO - Epoch 548: train_loss=0.9493
2025-02-02 17:31:15,482 - INFO - Epoch 548: val_loss=1.9935, val_acc=33.33%
2025-02-02 17:31:15,485 - INFO - ####################Training epoch 549####################
2025-02-02 17:31:16,133 - INFO - Epoch 549: train_loss=0.8187
2025-02-02 17:31:16,291 - INFO - Epoch 549: train_loss=0.8653
2025-02-02 17:31:16,425 - INFO - Epoch 549: train_loss=0.9613
2025-02-02 17:31:17,105 - INFO - Epoch 549: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:31:17,108 - INFO - ####################Training epoch 550####################
2025-02-02 17:31:17,762 - INFO - Epoch 550: train_loss=0.8670
2025-02-02 17:31:17,921 - INFO - Epoch 550: train_loss=0.8532
2025-02-02 17:31:18,056 - INFO - Epoch 550: train_loss=0.8733
2025-02-02 17:31:18,716 - INFO - Epoch 550: val_loss=1.9920, val_acc=33.33%
2025-02-02 17:31:18,720 - INFO - ####################Training epoch 551####################
2025-02-02 17:31:19,366 - INFO - Epoch 551: train_loss=0.8943
2025-02-02 17:31:19,524 - INFO - Epoch 551: train_loss=0.8300
2025-02-02 17:31:19,659 - INFO - Epoch 551: train_loss=0.8674
2025-02-02 17:31:20,323 - INFO - Epoch 551: val_loss=2.0010, val_acc=33.33%
2025-02-02 17:31:20,327 - INFO - ####################Training epoch 552####################
2025-02-02 17:31:20,961 - INFO - Epoch 552: train_loss=0.7244
2025-02-02 17:31:21,119 - INFO - Epoch 552: train_loss=0.9272
2025-02-02 17:31:21,254 - INFO - Epoch 552: train_loss=1.0450
2025-02-02 17:31:21,926 - INFO - Epoch 552: val_loss=1.9946, val_acc=33.33%
2025-02-02 17:31:21,930 - INFO - ####################Training epoch 553####################
2025-02-02 17:31:22,577 - INFO - Epoch 553: train_loss=0.7968
2025-02-02 17:31:22,735 - INFO - Epoch 553: train_loss=0.8628
2025-02-02 17:31:22,870 - INFO - Epoch 553: train_loss=1.0342
2025-02-02 17:31:23,585 - INFO - Epoch 553: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:31:23,588 - INFO - ####################Training epoch 554####################
2025-02-02 17:31:24,239 - INFO - Epoch 554: train_loss=0.8294
2025-02-02 17:31:24,398 - INFO - Epoch 554: train_loss=0.9319
2025-02-02 17:31:24,533 - INFO - Epoch 554: train_loss=0.7756
2025-02-02 17:31:25,209 - INFO - Epoch 554: val_loss=1.9913, val_acc=33.33%
2025-02-02 17:31:25,213 - INFO - ####################Training epoch 555####################
2025-02-02 17:31:25,858 - INFO - Epoch 555: train_loss=0.9513
2025-02-02 17:31:26,016 - INFO - Epoch 555: train_loss=0.7165
2025-02-02 17:31:26,151 - INFO - Epoch 555: train_loss=0.9982
2025-02-02 17:31:26,824 - INFO - Epoch 555: val_loss=1.9979, val_acc=33.33%
2025-02-02 17:31:26,828 - INFO - ####################Training epoch 556####################
2025-02-02 17:31:27,482 - INFO - Epoch 556: train_loss=0.9442
2025-02-02 17:31:27,641 - INFO - Epoch 556: train_loss=0.8404
2025-02-02 17:31:27,776 - INFO - Epoch 556: train_loss=0.7144
2025-02-02 17:31:28,460 - INFO - Epoch 556: val_loss=1.9994, val_acc=33.33%
2025-02-02 17:31:28,464 - INFO - ####################Training epoch 557####################
2025-02-02 17:31:29,118 - INFO - Epoch 557: train_loss=0.9761
2025-02-02 17:31:29,277 - INFO - Epoch 557: train_loss=0.7081
2025-02-02 17:31:29,411 - INFO - Epoch 557: train_loss=0.9526
2025-02-02 17:31:30,094 - INFO - Epoch 557: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:31:30,098 - INFO - ####################Training epoch 558####################
2025-02-02 17:31:30,750 - INFO - Epoch 558: train_loss=0.8095
2025-02-02 17:31:30,907 - INFO - Epoch 558: train_loss=0.9035
2025-02-02 17:31:31,042 - INFO - Epoch 558: train_loss=0.8808
2025-02-02 17:31:31,753 - INFO - Epoch 558: val_loss=1.9996, val_acc=33.33%
2025-02-02 17:31:31,757 - INFO - ####################Training epoch 559####################
2025-02-02 17:31:32,390 - INFO - Epoch 559: train_loss=0.8731
2025-02-02 17:31:32,547 - INFO - Epoch 559: train_loss=0.8796
2025-02-02 17:31:32,681 - INFO - Epoch 559: train_loss=0.7906
2025-02-02 17:31:33,341 - INFO - Epoch 559: val_loss=1.9968, val_acc=33.33%
2025-02-02 17:31:33,345 - INFO - ####################Training epoch 560####################
2025-02-02 17:31:33,976 - INFO - Epoch 560: train_loss=0.7744
2025-02-02 17:31:34,134 - INFO - Epoch 560: train_loss=0.9079
2025-02-02 17:31:34,268 - INFO - Epoch 560: train_loss=0.9696
2025-02-02 17:31:34,940 - INFO - Epoch 560: val_loss=1.9968, val_acc=33.33%
2025-02-02 17:31:34,944 - INFO - ####################Training epoch 561####################
2025-02-02 17:31:35,597 - INFO - Epoch 561: train_loss=0.8508
2025-02-02 17:31:35,755 - INFO - Epoch 561: train_loss=0.9218
2025-02-02 17:31:35,890 - INFO - Epoch 561: train_loss=0.7362
2025-02-02 17:31:36,544 - INFO - Epoch 561: val_loss=1.9979, val_acc=33.33%
2025-02-02 17:31:36,548 - INFO - ####################Training epoch 562####################
2025-02-02 17:31:37,185 - INFO - Epoch 562: train_loss=0.8867
2025-02-02 17:31:37,342 - INFO - Epoch 562: train_loss=0.8850
2025-02-02 17:31:37,477 - INFO - Epoch 562: train_loss=0.7399
2025-02-02 17:31:38,150 - INFO - Epoch 562: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:31:38,154 - INFO - ####################Training epoch 563####################
2025-02-02 17:31:38,780 - INFO - Epoch 563: train_loss=0.8580
2025-02-02 17:31:38,939 - INFO - Epoch 563: train_loss=0.7796
2025-02-02 17:31:39,073 - INFO - Epoch 563: train_loss=1.0680
2025-02-02 17:31:39,739 - INFO - Epoch 563: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:31:39,742 - INFO - ####################Training epoch 564####################
2025-02-02 17:31:40,446 - INFO - Epoch 564: train_loss=0.7975
2025-02-02 17:31:40,604 - INFO - Epoch 564: train_loss=0.9526
2025-02-02 17:31:40,738 - INFO - Epoch 564: train_loss=0.8028
2025-02-02 17:31:41,415 - INFO - Epoch 564: val_loss=1.9916, val_acc=33.33%
2025-02-02 17:31:41,419 - INFO - ####################Training epoch 565####################
2025-02-02 17:31:42,080 - INFO - Epoch 565: train_loss=0.8992
2025-02-02 17:31:42,238 - INFO - Epoch 565: train_loss=0.8048
2025-02-02 17:31:42,373 - INFO - Epoch 565: train_loss=0.9186
2025-02-02 17:31:43,049 - INFO - Epoch 565: val_loss=2.0024, val_acc=33.33%
2025-02-02 17:31:43,053 - INFO - ####################Training epoch 566####################
2025-02-02 17:31:43,740 - INFO - Epoch 566: train_loss=0.7788
2025-02-02 17:31:43,898 - INFO - Epoch 566: train_loss=1.0135
2025-02-02 17:31:44,033 - INFO - Epoch 566: train_loss=0.6915
2025-02-02 17:31:44,710 - INFO - Epoch 566: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:31:44,714 - INFO - ####################Training epoch 567####################
2025-02-02 17:31:45,351 - INFO - Epoch 567: train_loss=0.9819
2025-02-02 17:31:45,509 - INFO - Epoch 567: train_loss=0.7831
2025-02-02 17:31:45,643 - INFO - Epoch 567: train_loss=0.7694
2025-02-02 17:31:46,324 - INFO - Epoch 567: val_loss=1.9882, val_acc=33.33%
2025-02-02 17:31:46,328 - INFO - ####################Training epoch 568####################
2025-02-02 17:31:46,972 - INFO - Epoch 568: train_loss=0.8360
2025-02-02 17:31:47,130 - INFO - Epoch 568: train_loss=0.8841
2025-02-02 17:31:47,264 - INFO - Epoch 568: train_loss=0.8632
2025-02-02 17:31:47,940 - INFO - Epoch 568: val_loss=1.9911, val_acc=33.33%
2025-02-02 17:31:47,943 - INFO - ####################Training epoch 569####################
2025-02-02 17:31:48,654 - INFO - Epoch 569: train_loss=0.7764
2025-02-02 17:31:48,812 - INFO - Epoch 569: train_loss=0.9498
2025-02-02 17:31:48,946 - INFO - Epoch 569: train_loss=0.8585
2025-02-02 17:31:49,598 - INFO - Epoch 569: val_loss=2.0025, val_acc=33.33%
2025-02-02 17:31:49,601 - INFO - ####################Training epoch 570####################
2025-02-02 17:31:50,247 - INFO - Epoch 570: train_loss=0.9058
2025-02-02 17:31:50,405 - INFO - Epoch 570: train_loss=0.8317
2025-02-02 17:31:50,539 - INFO - Epoch 570: train_loss=0.8236
2025-02-02 17:31:51,198 - INFO - Epoch 570: val_loss=1.9983, val_acc=33.33%
2025-02-02 17:31:51,202 - INFO - ####################Training epoch 571####################
2025-02-02 17:31:51,837 - INFO - Epoch 571: train_loss=0.9620
2025-02-02 17:31:51,995 - INFO - Epoch 571: train_loss=0.7934
2025-02-02 17:31:52,130 - INFO - Epoch 571: train_loss=0.7789
2025-02-02 17:31:52,787 - INFO - Epoch 571: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:31:52,791 - INFO - ####################Training epoch 572####################
2025-02-02 17:31:53,447 - INFO - Epoch 572: train_loss=0.7674
2025-02-02 17:31:53,605 - INFO - Epoch 572: train_loss=0.9076
2025-02-02 17:31:53,740 - INFO - Epoch 572: train_loss=0.9821
2025-02-02 17:31:54,398 - INFO - Epoch 572: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:31:54,401 - INFO - ####################Training epoch 573####################
2025-02-02 17:31:55,053 - INFO - Epoch 573: train_loss=0.9242
2025-02-02 17:31:55,211 - INFO - Epoch 573: train_loss=0.8465
2025-02-02 17:31:55,347 - INFO - Epoch 573: train_loss=0.7497
2025-02-02 17:31:56,008 - INFO - Epoch 573: val_loss=2.0013, val_acc=33.33%
2025-02-02 17:31:56,011 - INFO - ####################Training epoch 574####################
2025-02-02 17:31:56,672 - INFO - Epoch 574: train_loss=0.7568
2025-02-02 17:31:56,833 - INFO - Epoch 574: train_loss=0.8966
2025-02-02 17:31:56,968 - INFO - Epoch 574: train_loss=1.0416
2025-02-02 17:31:57,611 - INFO - Epoch 574: val_loss=2.0012, val_acc=33.33%
2025-02-02 17:31:57,615 - INFO - ####################Training epoch 575####################
2025-02-02 17:31:58,272 - INFO - Epoch 575: train_loss=0.9121
2025-02-02 17:31:58,430 - INFO - Epoch 575: train_loss=0.8123
2025-02-02 17:31:58,565 - INFO - Epoch 575: train_loss=0.8510
2025-02-02 17:31:59,224 - INFO - Epoch 575: val_loss=1.9941, val_acc=33.33%
2025-02-02 17:31:59,227 - INFO - ####################Training epoch 576####################
2025-02-02 17:31:59,879 - INFO - Epoch 576: train_loss=0.9143
2025-02-02 17:32:00,036 - INFO - Epoch 576: train_loss=0.7406
2025-02-02 17:32:00,170 - INFO - Epoch 576: train_loss=1.0392
2025-02-02 17:32:00,853 - INFO - Epoch 576: val_loss=1.9953, val_acc=33.33%
2025-02-02 17:32:00,857 - INFO - ####################Training epoch 577####################
2025-02-02 17:32:01,501 - INFO - Epoch 577: train_loss=0.9069
2025-02-02 17:32:01,658 - INFO - Epoch 577: train_loss=0.9062
2025-02-02 17:32:01,793 - INFO - Epoch 577: train_loss=0.6433
2025-02-02 17:32:02,442 - INFO - Epoch 577: val_loss=1.9928, val_acc=33.33%
2025-02-02 17:32:02,446 - INFO - ####################Training epoch 578####################
2025-02-02 17:32:03,088 - INFO - Epoch 578: train_loss=0.8162
2025-02-02 17:32:03,246 - INFO - Epoch 578: train_loss=0.8734
2025-02-02 17:32:03,380 - INFO - Epoch 578: train_loss=0.9432
2025-02-02 17:32:04,039 - INFO - Epoch 578: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:32:04,042 - INFO - ####################Training epoch 579####################
2025-02-02 17:32:04,693 - INFO - Epoch 579: train_loss=0.8341
2025-02-02 17:32:04,850 - INFO - Epoch 579: train_loss=0.8432
2025-02-02 17:32:04,985 - INFO - Epoch 579: train_loss=0.9855
2025-02-02 17:32:05,696 - INFO - Epoch 579: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:32:05,699 - INFO - ####################Training epoch 580####################
2025-02-02 17:32:06,359 - INFO - Epoch 580: train_loss=0.9831
2025-02-02 17:32:06,517 - INFO - Epoch 580: train_loss=0.7462
2025-02-02 17:32:06,651 - INFO - Epoch 580: train_loss=0.8489
2025-02-02 17:32:07,300 - INFO - Epoch 580: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:32:07,304 - INFO - ####################Training epoch 581####################
2025-02-02 17:32:07,934 - INFO - Epoch 581: train_loss=0.9736
2025-02-02 17:32:08,091 - INFO - Epoch 581: train_loss=0.7569
2025-02-02 17:32:08,226 - INFO - Epoch 581: train_loss=0.8466
2025-02-02 17:32:08,876 - INFO - Epoch 581: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:32:08,880 - INFO - ####################Training epoch 582####################
2025-02-02 17:32:09,513 - INFO - Epoch 582: train_loss=0.9265
2025-02-02 17:32:09,671 - INFO - Epoch 582: train_loss=0.7410
2025-02-02 17:32:09,805 - INFO - Epoch 582: train_loss=1.0030
2025-02-02 17:32:10,469 - INFO - Epoch 582: val_loss=2.0006, val_acc=33.33%
2025-02-02 17:32:10,472 - INFO - ####################Training epoch 583####################
2025-02-02 17:32:11,128 - INFO - Epoch 583: train_loss=0.8037
2025-02-02 17:32:11,286 - INFO - Epoch 583: train_loss=0.8538
2025-02-02 17:32:11,421 - INFO - Epoch 583: train_loss=1.0236
2025-02-02 17:32:12,085 - INFO - Epoch 583: val_loss=1.9954, val_acc=33.33%
2025-02-02 17:32:12,088 - INFO - ####################Training epoch 584####################
2025-02-02 17:32:12,742 - INFO - Epoch 584: train_loss=0.8879
2025-02-02 17:32:12,900 - INFO - Epoch 584: train_loss=0.8336
2025-02-02 17:32:13,034 - INFO - Epoch 584: train_loss=0.8614
2025-02-02 17:32:13,740 - INFO - Epoch 584: val_loss=1.9900, val_acc=33.33%
2025-02-02 17:32:13,744 - INFO - ####################Training epoch 585####################
2025-02-02 17:32:14,379 - INFO - Epoch 585: train_loss=0.8041
2025-02-02 17:32:14,536 - INFO - Epoch 585: train_loss=0.8791
2025-02-02 17:32:14,670 - INFO - Epoch 585: train_loss=0.9590
2025-02-02 17:32:15,343 - INFO - Epoch 585: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:32:15,347 - INFO - ####################Training epoch 586####################
2025-02-02 17:32:15,974 - INFO - Epoch 586: train_loss=0.9350
2025-02-02 17:32:16,132 - INFO - Epoch 586: train_loss=0.8943
2025-02-02 17:32:16,268 - INFO - Epoch 586: train_loss=0.6017
2025-02-02 17:32:16,950 - INFO - Epoch 586: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:32:16,954 - INFO - ####################Training epoch 587####################
2025-02-02 17:32:17,628 - INFO - Epoch 587: train_loss=0.8763
2025-02-02 17:32:17,786 - INFO - Epoch 587: train_loss=0.8679
2025-02-02 17:32:17,920 - INFO - Epoch 587: train_loss=0.8007
2025-02-02 17:32:18,571 - INFO - Epoch 587: val_loss=1.9937, val_acc=33.33%
2025-02-02 17:32:18,575 - INFO - ####################Training epoch 588####################
2025-02-02 17:32:19,228 - INFO - Epoch 588: train_loss=0.8268
2025-02-02 17:32:19,385 - INFO - Epoch 588: train_loss=0.8513
2025-02-02 17:32:19,523 - INFO - Epoch 588: train_loss=0.9678
2025-02-02 17:32:20,181 - INFO - Epoch 588: val_loss=1.9949, val_acc=33.33%
2025-02-02 17:32:20,184 - INFO - ####################Training epoch 589####################
2025-02-02 17:32:20,822 - INFO - Epoch 589: train_loss=0.7215
2025-02-02 17:32:20,980 - INFO - Epoch 589: train_loss=0.9812
2025-02-02 17:32:21,114 - INFO - Epoch 589: train_loss=0.9149
2025-02-02 17:32:21,767 - INFO - Epoch 589: val_loss=1.9932, val_acc=33.33%
2025-02-02 17:32:21,770 - INFO - ####################Training epoch 590####################
2025-02-02 17:32:22,465 - INFO - Epoch 590: train_loss=0.9415
2025-02-02 17:32:22,624 - INFO - Epoch 590: train_loss=0.7706
2025-02-02 17:32:22,759 - INFO - Epoch 590: train_loss=0.9034
2025-02-02 17:32:23,443 - INFO - Epoch 590: val_loss=1.9948, val_acc=33.33%
2025-02-02 17:32:23,447 - INFO - ####################Training epoch 591####################
2025-02-02 17:32:24,097 - INFO - Epoch 591: train_loss=0.7882
2025-02-02 17:32:24,254 - INFO - Epoch 591: train_loss=0.9068
2025-02-02 17:32:24,388 - INFO - Epoch 591: train_loss=0.9326
2025-02-02 17:32:25,059 - INFO - Epoch 591: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:32:25,063 - INFO - ####################Training epoch 592####################
2025-02-02 17:32:25,698 - INFO - Epoch 592: train_loss=0.8237
2025-02-02 17:32:25,855 - INFO - Epoch 592: train_loss=0.9024
2025-02-02 17:32:25,990 - INFO - Epoch 592: train_loss=0.8486
2025-02-02 17:32:26,651 - INFO - Epoch 592: val_loss=1.9944, val_acc=33.33%
2025-02-02 17:32:26,655 - INFO - ####################Training epoch 593####################
2025-02-02 17:32:27,314 - INFO - Epoch 593: train_loss=0.8049
2025-02-02 17:32:27,472 - INFO - Epoch 593: train_loss=0.9011
2025-02-02 17:32:27,606 - INFO - Epoch 593: train_loss=0.9125
2025-02-02 17:32:28,277 - INFO - Epoch 593: val_loss=1.9926, val_acc=33.33%
2025-02-02 17:32:28,280 - INFO - ####################Training epoch 594####################
2025-02-02 17:32:28,908 - INFO - Epoch 594: train_loss=0.7746
2025-02-02 17:32:29,066 - INFO - Epoch 594: train_loss=0.9034
2025-02-02 17:32:29,200 - INFO - Epoch 594: train_loss=0.9770
2025-02-02 17:32:29,885 - INFO - Epoch 594: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:32:29,889 - INFO - ####################Training epoch 595####################
2025-02-02 17:32:30,574 - INFO - Epoch 595: train_loss=0.8557
2025-02-02 17:32:30,732 - INFO - Epoch 595: train_loss=0.7976
2025-02-02 17:32:30,867 - INFO - Epoch 595: train_loss=1.0337
2025-02-02 17:32:31,553 - INFO - Epoch 595: val_loss=1.9977, val_acc=33.33%
2025-02-02 17:32:31,556 - INFO - ####################Training epoch 596####################
2025-02-02 17:32:32,189 - INFO - Epoch 596: train_loss=0.7578
2025-02-02 17:32:32,346 - INFO - Epoch 596: train_loss=0.8987
2025-02-02 17:32:32,481 - INFO - Epoch 596: train_loss=1.0189
2025-02-02 17:32:33,140 - INFO - Epoch 596: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:32:33,144 - INFO - ####################Training epoch 597####################
2025-02-02 17:32:33,789 - INFO - Epoch 597: train_loss=0.8143
2025-02-02 17:32:33,946 - INFO - Epoch 597: train_loss=0.9569
2025-02-02 17:32:34,080 - INFO - Epoch 597: train_loss=0.7454
2025-02-02 17:32:34,747 - INFO - Epoch 597: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:32:34,751 - INFO - ####################Training epoch 598####################
2025-02-02 17:32:35,418 - INFO - Epoch 598: train_loss=0.9780
2025-02-02 17:32:35,576 - INFO - Epoch 598: train_loss=0.7594
2025-02-02 17:32:35,712 - INFO - Epoch 598: train_loss=0.8274
2025-02-02 17:32:36,393 - INFO - Epoch 598: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:32:36,397 - INFO - ####################Training epoch 599####################
2025-02-02 17:32:37,063 - INFO - Epoch 599: train_loss=0.8125
2025-02-02 17:32:37,221 - INFO - Epoch 599: train_loss=0.8569
2025-02-02 17:32:37,357 - INFO - Epoch 599: train_loss=0.9815
2025-02-02 17:32:38,008 - INFO - Epoch 599: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:32:38,011 - INFO - ####################Training epoch 600####################
2025-02-02 17:32:38,704 - INFO - Epoch 600: train_loss=0.8525
2025-02-02 17:32:38,862 - INFO - Epoch 600: train_loss=0.9210
2025-02-02 17:32:38,997 - INFO - Epoch 600: train_loss=0.7257
2025-02-02 17:32:39,655 - INFO - Epoch 600: val_loss=1.9928, val_acc=33.33%
2025-02-02 17:32:39,658 - INFO - ####################Training epoch 601####################
2025-02-02 17:32:40,327 - INFO - Epoch 601: train_loss=0.7820
2025-02-02 17:32:40,484 - INFO - Epoch 601: train_loss=0.9159
2025-02-02 17:32:40,618 - INFO - Epoch 601: train_loss=0.9223
2025-02-02 17:32:41,277 - INFO - Epoch 601: val_loss=2.0002, val_acc=33.33%
2025-02-02 17:32:41,281 - INFO - ####################Training epoch 602####################
2025-02-02 17:32:41,937 - INFO - Epoch 602: train_loss=0.8946
2025-02-02 17:32:42,095 - INFO - Epoch 602: train_loss=0.8336
2025-02-02 17:32:42,230 - INFO - Epoch 602: train_loss=0.8449
2025-02-02 17:32:42,905 - INFO - Epoch 602: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:32:42,909 - INFO - ####################Training epoch 603####################
2025-02-02 17:32:43,569 - INFO - Epoch 603: train_loss=0.8485
2025-02-02 17:32:43,727 - INFO - Epoch 603: train_loss=0.8193
2025-02-02 17:32:43,861 - INFO - Epoch 603: train_loss=0.9999
2025-02-02 17:32:44,514 - INFO - Epoch 603: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:32:44,518 - INFO - ####################Training epoch 604####################
2025-02-02 17:32:45,177 - INFO - Epoch 604: train_loss=0.8308
2025-02-02 17:32:45,335 - INFO - Epoch 604: train_loss=0.8825
2025-02-02 17:32:45,470 - INFO - Epoch 604: train_loss=0.8883
2025-02-02 17:32:46,131 - INFO - Epoch 604: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:32:46,135 - INFO - ####################Training epoch 605####################
2025-02-02 17:32:46,785 - INFO - Epoch 605: train_loss=0.9479
2025-02-02 17:32:46,943 - INFO - Epoch 605: train_loss=0.7498
2025-02-02 17:32:47,078 - INFO - Epoch 605: train_loss=0.9385
2025-02-02 17:32:47,771 - INFO - Epoch 605: val_loss=1.9926, val_acc=33.33%
2025-02-02 17:32:47,775 - INFO - ####################Training epoch 606####################
2025-02-02 17:32:48,437 - INFO - Epoch 606: train_loss=0.7430
2025-02-02 17:32:48,595 - INFO - Epoch 606: train_loss=0.9595
2025-02-02 17:32:48,730 - INFO - Epoch 606: train_loss=0.9108
2025-02-02 17:32:49,405 - INFO - Epoch 606: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:32:49,409 - INFO - ####################Training epoch 607####################
2025-02-02 17:32:50,061 - INFO - Epoch 607: train_loss=0.9052
2025-02-02 17:32:50,219 - INFO - Epoch 607: train_loss=0.7758
2025-02-02 17:32:50,354 - INFO - Epoch 607: train_loss=0.9702
2025-02-02 17:32:51,032 - INFO - Epoch 607: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:32:51,036 - INFO - ####################Training epoch 608####################
2025-02-02 17:32:51,702 - INFO - Epoch 608: train_loss=0.8306
2025-02-02 17:32:51,859 - INFO - Epoch 608: train_loss=0.9374
2025-02-02 17:32:51,993 - INFO - Epoch 608: train_loss=0.7481
2025-02-02 17:32:52,682 - INFO - Epoch 608: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:32:52,687 - INFO - ####################Training epoch 609####################
2025-02-02 17:32:53,354 - INFO - Epoch 609: train_loss=0.7016
2025-02-02 17:32:53,513 - INFO - Epoch 609: train_loss=0.9138
2025-02-02 17:32:53,648 - INFO - Epoch 609: train_loss=1.1268
2025-02-02 17:32:54,337 - INFO - Epoch 609: val_loss=1.9906, val_acc=33.33%
2025-02-02 17:32:54,341 - INFO - ####################Training epoch 610####################
2025-02-02 17:32:54,980 - INFO - Epoch 610: train_loss=0.9194
2025-02-02 17:32:55,138 - INFO - Epoch 610: train_loss=0.8029
2025-02-02 17:32:55,273 - INFO - Epoch 610: train_loss=0.8734
2025-02-02 17:32:56,006 - INFO - Epoch 610: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:32:56,010 - INFO - ####################Training epoch 611####################
2025-02-02 17:32:56,666 - INFO - Epoch 611: train_loss=0.9764
2025-02-02 17:32:56,823 - INFO - Epoch 611: train_loss=0.7807
2025-02-02 17:32:56,958 - INFO - Epoch 611: train_loss=0.7797
2025-02-02 17:32:57,630 - INFO - Epoch 611: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:32:57,634 - INFO - ####################Training epoch 612####################
2025-02-02 17:32:58,284 - INFO - Epoch 612: train_loss=0.8741
2025-02-02 17:32:58,441 - INFO - Epoch 612: train_loss=0.8858
2025-02-02 17:32:58,575 - INFO - Epoch 612: train_loss=0.7706
2025-02-02 17:32:59,254 - INFO - Epoch 612: val_loss=1.9910, val_acc=33.33%
2025-02-02 17:32:59,257 - INFO - ####################Training epoch 613####################
2025-02-02 17:32:59,902 - INFO - Epoch 613: train_loss=0.8303
2025-02-02 17:33:00,060 - INFO - Epoch 613: train_loss=0.8902
2025-02-02 17:33:00,195 - INFO - Epoch 613: train_loss=0.8576
2025-02-02 17:33:00,869 - INFO - Epoch 613: val_loss=1.9946, val_acc=33.33%
2025-02-02 17:33:00,873 - INFO - ####################Training epoch 614####################
2025-02-02 17:33:01,532 - INFO - Epoch 614: train_loss=0.8309
2025-02-02 17:33:01,691 - INFO - Epoch 614: train_loss=0.8148
2025-02-02 17:33:01,825 - INFO - Epoch 614: train_loss=1.0698
2025-02-02 17:33:02,484 - INFO - Epoch 614: val_loss=1.9903, val_acc=33.33%
2025-02-02 17:33:02,488 - INFO - ####################Training epoch 615####################
2025-02-02 17:33:03,135 - INFO - Epoch 615: train_loss=0.8856
2025-02-02 17:33:03,292 - INFO - Epoch 615: train_loss=0.7511
2025-02-02 17:33:03,427 - INFO - Epoch 615: train_loss=1.0683
2025-02-02 17:33:04,127 - INFO - Epoch 615: val_loss=1.9954, val_acc=33.33%
2025-02-02 17:33:04,131 - INFO - ####################Training epoch 616####################
2025-02-02 17:33:04,768 - INFO - Epoch 616: train_loss=0.7813
2025-02-02 17:33:04,926 - INFO - Epoch 616: train_loss=0.8264
2025-02-02 17:33:05,061 - INFO - Epoch 616: train_loss=1.1602
2025-02-02 17:33:05,738 - INFO - Epoch 616: val_loss=1.9907, val_acc=33.33%
2025-02-02 17:33:05,741 - INFO - ####################Training epoch 617####################
2025-02-02 17:33:06,394 - INFO - Epoch 617: train_loss=1.0008
2025-02-02 17:33:06,552 - INFO - Epoch 617: train_loss=0.8615
2025-02-02 17:33:06,687 - INFO - Epoch 617: train_loss=0.5121
2025-02-02 17:33:07,343 - INFO - Epoch 617: val_loss=2.0007, val_acc=33.33%
2025-02-02 17:33:07,347 - INFO - ####################Training epoch 618####################
2025-02-02 17:33:07,984 - INFO - Epoch 618: train_loss=0.8169
2025-02-02 17:33:08,141 - INFO - Epoch 618: train_loss=0.9456
2025-02-02 17:33:08,276 - INFO - Epoch 618: train_loss=0.7686
2025-02-02 17:33:08,946 - INFO - Epoch 618: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:33:08,950 - INFO - ####################Training epoch 619####################
2025-02-02 17:33:09,618 - INFO - Epoch 619: train_loss=0.8600
2025-02-02 17:33:09,775 - INFO - Epoch 619: train_loss=0.8762
2025-02-02 17:33:09,910 - INFO - Epoch 619: train_loss=0.8255
2025-02-02 17:33:10,595 - INFO - Epoch 619: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:33:10,598 - INFO - ####################Training epoch 620####################
2025-02-02 17:33:11,246 - INFO - Epoch 620: train_loss=0.9196
2025-02-02 17:33:11,404 - INFO - Epoch 620: train_loss=0.8229
2025-02-02 17:33:11,539 - INFO - Epoch 620: train_loss=0.8054
2025-02-02 17:33:12,201 - INFO - Epoch 620: val_loss=1.9920, val_acc=33.33%
2025-02-02 17:33:12,204 - INFO - ####################Training epoch 621####################
2025-02-02 17:33:12,896 - INFO - Epoch 621: train_loss=0.9774
2025-02-02 17:33:13,053 - INFO - Epoch 621: train_loss=0.7867
2025-02-02 17:33:13,188 - INFO - Epoch 621: train_loss=0.7686
2025-02-02 17:33:13,857 - INFO - Epoch 621: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:33:13,860 - INFO - ####################Training epoch 622####################
2025-02-02 17:33:14,525 - INFO - Epoch 622: train_loss=0.9986
2025-02-02 17:33:14,683 - INFO - Epoch 622: train_loss=0.7415
2025-02-02 17:33:14,817 - INFO - Epoch 622: train_loss=0.8224
2025-02-02 17:33:15,493 - INFO - Epoch 622: val_loss=1.9930, val_acc=33.33%
2025-02-02 17:33:15,497 - INFO - ####################Training epoch 623####################
2025-02-02 17:33:16,158 - INFO - Epoch 623: train_loss=0.8214
2025-02-02 17:33:16,315 - INFO - Epoch 623: train_loss=0.8920
2025-02-02 17:33:16,449 - INFO - Epoch 623: train_loss=0.9056
2025-02-02 17:33:17,127 - INFO - Epoch 623: val_loss=1.9950, val_acc=33.33%
2025-02-02 17:33:17,131 - INFO - ####################Training epoch 624####################
2025-02-02 17:33:17,772 - INFO - Epoch 624: train_loss=0.9381
2025-02-02 17:33:17,930 - INFO - Epoch 624: train_loss=0.8291
2025-02-02 17:33:18,064 - INFO - Epoch 624: train_loss=0.7577
2025-02-02 17:33:18,752 - INFO - Epoch 624: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:33:18,756 - INFO - ####################Training epoch 625####################
2025-02-02 17:33:19,425 - INFO - Epoch 625: train_loss=0.8104
2025-02-02 17:33:19,583 - INFO - Epoch 625: train_loss=0.9219
2025-02-02 17:33:19,718 - INFO - Epoch 625: train_loss=0.8364
2025-02-02 17:33:20,380 - INFO - Epoch 625: val_loss=1.9909, val_acc=33.33%
2025-02-02 17:33:20,384 - INFO - ####################Training epoch 626####################
2025-02-02 17:33:21,077 - INFO - Epoch 626: train_loss=0.9242
2025-02-02 17:33:21,235 - INFO - Epoch 626: train_loss=0.8197
2025-02-02 17:33:21,369 - INFO - Epoch 626: train_loss=0.8087
2025-02-02 17:33:22,040 - INFO - Epoch 626: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:33:22,044 - INFO - ####################Training epoch 627####################
2025-02-02 17:33:22,712 - INFO - Epoch 627: train_loss=0.7251
2025-02-02 17:33:22,869 - INFO - Epoch 627: train_loss=0.9064
2025-02-02 17:33:23,004 - INFO - Epoch 627: train_loss=1.0910
2025-02-02 17:33:23,694 - INFO - Epoch 627: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:33:23,698 - INFO - ####################Training epoch 628####################
2025-02-02 17:33:24,346 - INFO - Epoch 628: train_loss=0.8270
2025-02-02 17:33:24,504 - INFO - Epoch 628: train_loss=0.9468
2025-02-02 17:33:24,639 - INFO - Epoch 628: train_loss=0.7399
2025-02-02 17:33:25,320 - INFO - Epoch 628: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:33:25,324 - INFO - ####################Training epoch 629####################
2025-02-02 17:33:25,982 - INFO - Epoch 629: train_loss=0.8114
2025-02-02 17:33:26,140 - INFO - Epoch 629: train_loss=0.8596
2025-02-02 17:33:26,275 - INFO - Epoch 629: train_loss=0.9921
2025-02-02 17:33:26,930 - INFO - Epoch 629: val_loss=1.9977, val_acc=33.33%
2025-02-02 17:33:26,933 - INFO - ####################Training epoch 630####################
2025-02-02 17:33:27,577 - INFO - Epoch 630: train_loss=0.8076
2025-02-02 17:33:27,735 - INFO - Epoch 630: train_loss=0.8536
2025-02-02 17:33:27,869 - INFO - Epoch 630: train_loss=1.0205
2025-02-02 17:33:28,528 - INFO - Epoch 630: val_loss=1.9977, val_acc=33.33%
2025-02-02 17:33:28,532 - INFO - ####################Training epoch 631####################
2025-02-02 17:33:29,180 - INFO - Epoch 631: train_loss=0.8660
2025-02-02 17:33:29,350 - INFO - Epoch 631: train_loss=0.7739
2025-02-02 17:33:29,497 - INFO - Epoch 631: train_loss=1.0800
2025-02-02 17:33:30,154 - INFO - Epoch 631: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:33:30,158 - INFO - ####################Training epoch 632####################
2025-02-02 17:33:30,816 - INFO - Epoch 632: train_loss=0.9491
2025-02-02 17:33:30,973 - INFO - Epoch 632: train_loss=0.7886
2025-02-02 17:33:31,108 - INFO - Epoch 632: train_loss=0.8248
2025-02-02 17:33:31,777 - INFO - Epoch 632: val_loss=1.9909, val_acc=33.33%
2025-02-02 17:33:31,780 - INFO - ####################Training epoch 633####################
2025-02-02 17:33:32,411 - INFO - Epoch 633: train_loss=0.9049
2025-02-02 17:33:32,568 - INFO - Epoch 633: train_loss=0.7801
2025-02-02 17:33:32,702 - INFO - Epoch 633: train_loss=0.9647
2025-02-02 17:33:33,358 - INFO - Epoch 633: val_loss=2.0012, val_acc=33.33%
2025-02-02 17:33:33,362 - INFO - ####################Training epoch 634####################
2025-02-02 17:33:34,018 - INFO - Epoch 634: train_loss=0.8415
2025-02-02 17:33:34,175 - INFO - Epoch 634: train_loss=0.8811
2025-02-02 17:33:34,310 - INFO - Epoch 634: train_loss=0.8609
2025-02-02 17:33:34,967 - INFO - Epoch 634: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:33:34,971 - INFO - ####################Training epoch 635####################
2025-02-02 17:33:35,616 - INFO - Epoch 635: train_loss=0.8677
2025-02-02 17:33:35,774 - INFO - Epoch 635: train_loss=0.7708
2025-02-02 17:33:35,909 - INFO - Epoch 635: train_loss=1.0708
2025-02-02 17:33:36,578 - INFO - Epoch 635: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:33:36,582 - INFO - ####################Training epoch 636####################
2025-02-02 17:33:37,214 - INFO - Epoch 636: train_loss=0.8004
2025-02-02 17:33:37,372 - INFO - Epoch 636: train_loss=0.9097
2025-02-02 17:33:37,506 - INFO - Epoch 636: train_loss=0.9051
2025-02-02 17:33:38,214 - INFO - Epoch 636: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:33:38,218 - INFO - ####################Training epoch 637####################
2025-02-02 17:33:38,880 - INFO - Epoch 637: train_loss=0.8630
2025-02-02 17:33:39,038 - INFO - Epoch 637: train_loss=0.8939
2025-02-02 17:33:39,173 - INFO - Epoch 637: train_loss=0.7858
2025-02-02 17:33:39,831 - INFO - Epoch 637: val_loss=1.9953, val_acc=33.33%
2025-02-02 17:33:39,835 - INFO - ####################Training epoch 638####################
2025-02-02 17:33:40,498 - INFO - Epoch 638: train_loss=0.9145
2025-02-02 17:33:40,660 - INFO - Epoch 638: train_loss=0.7569
2025-02-02 17:33:40,795 - INFO - Epoch 638: train_loss=0.9880
2025-02-02 17:33:41,475 - INFO - Epoch 638: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:33:41,479 - INFO - ####################Training epoch 639####################
2025-02-02 17:33:42,131 - INFO - Epoch 639: train_loss=0.7731
2025-02-02 17:33:42,289 - INFO - Epoch 639: train_loss=0.9811
2025-02-02 17:33:42,423 - INFO - Epoch 639: train_loss=0.7852
2025-02-02 17:33:43,099 - INFO - Epoch 639: val_loss=1.9964, val_acc=33.33%
2025-02-02 17:33:43,103 - INFO - ####################Training epoch 640####################
2025-02-02 17:33:43,735 - INFO - Epoch 640: train_loss=0.9763
2025-02-02 17:33:43,893 - INFO - Epoch 640: train_loss=0.8476
2025-02-02 17:33:44,028 - INFO - Epoch 640: train_loss=0.6204
2025-02-02 17:33:44,700 - INFO - Epoch 640: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:33:44,703 - INFO - ####################Training epoch 641####################
2025-02-02 17:33:45,357 - INFO - Epoch 641: train_loss=0.8117
2025-02-02 17:33:45,516 - INFO - Epoch 641: train_loss=0.8943
2025-02-02 17:33:45,650 - INFO - Epoch 641: train_loss=0.8989
2025-02-02 17:33:46,375 - INFO - Epoch 641: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:33:46,378 - INFO - ####################Training epoch 642####################
2025-02-02 17:33:47,047 - INFO - Epoch 642: train_loss=0.7590
2025-02-02 17:33:47,204 - INFO - Epoch 642: train_loss=0.9320
2025-02-02 17:33:47,339 - INFO - Epoch 642: train_loss=0.9458
2025-02-02 17:33:47,993 - INFO - Epoch 642: val_loss=1.9963, val_acc=33.33%
2025-02-02 17:33:47,997 - INFO - ####################Training epoch 643####################
2025-02-02 17:33:48,654 - INFO - Epoch 643: train_loss=0.9997
2025-02-02 17:33:48,812 - INFO - Epoch 643: train_loss=0.7338
2025-02-02 17:33:48,948 - INFO - Epoch 643: train_loss=0.8366
2025-02-02 17:33:49,619 - INFO - Epoch 643: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:33:49,622 - INFO - ####################Training epoch 644####################
2025-02-02 17:33:50,285 - INFO - Epoch 644: train_loss=0.8218
2025-02-02 17:33:50,442 - INFO - Epoch 644: train_loss=0.8943
2025-02-02 17:33:50,578 - INFO - Epoch 644: train_loss=0.8817
2025-02-02 17:33:51,239 - INFO - Epoch 644: val_loss=1.9952, val_acc=33.33%
2025-02-02 17:33:51,243 - INFO - ####################Training epoch 645####################
2025-02-02 17:33:51,914 - INFO - Epoch 645: train_loss=0.7894
2025-02-02 17:33:52,075 - INFO - Epoch 645: train_loss=0.9464
2025-02-02 17:33:52,210 - INFO - Epoch 645: train_loss=0.8342
2025-02-02 17:33:52,899 - INFO - Epoch 645: val_loss=1.9979, val_acc=33.33%
2025-02-02 17:33:52,903 - INFO - ####################Training epoch 646####################
2025-02-02 17:33:53,559 - INFO - Epoch 646: train_loss=0.9091
2025-02-02 17:33:53,717 - INFO - Epoch 646: train_loss=0.7450
2025-02-02 17:33:53,853 - INFO - Epoch 646: train_loss=1.0311
2025-02-02 17:33:54,541 - INFO - Epoch 646: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:33:54,545 - INFO - ####################Training epoch 647####################
2025-02-02 17:33:55,193 - INFO - Epoch 647: train_loss=0.8513
2025-02-02 17:33:55,351 - INFO - Epoch 647: train_loss=0.8651
2025-02-02 17:33:55,487 - INFO - Epoch 647: train_loss=0.8804
2025-02-02 17:33:56,163 - INFO - Epoch 647: val_loss=1.9949, val_acc=33.33%
2025-02-02 17:33:56,167 - INFO - ####################Training epoch 648####################
2025-02-02 17:33:56,808 - INFO - Epoch 648: train_loss=0.8413
2025-02-02 17:33:56,966 - INFO - Epoch 648: train_loss=0.8918
2025-02-02 17:33:57,100 - INFO - Epoch 648: train_loss=0.8379
2025-02-02 17:33:57,770 - INFO - Epoch 648: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:33:57,774 - INFO - ####################Training epoch 649####################
2025-02-02 17:33:58,453 - INFO - Epoch 649: train_loss=0.9218
2025-02-02 17:33:58,612 - INFO - Epoch 649: train_loss=0.8234
2025-02-02 17:33:58,747 - INFO - Epoch 649: train_loss=0.7992
2025-02-02 17:33:59,448 - INFO - Epoch 649: val_loss=1.9923, val_acc=33.33%
2025-02-02 17:33:59,452 - INFO - ####################Training epoch 650####################
2025-02-02 17:34:00,130 - INFO - Epoch 650: train_loss=0.8709
2025-02-02 17:34:00,288 - INFO - Epoch 650: train_loss=0.8264
2025-02-02 17:34:00,423 - INFO - Epoch 650: train_loss=0.9236
2025-02-02 17:34:01,079 - INFO - Epoch 650: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:34:01,083 - INFO - ####################Training epoch 651####################
2025-02-02 17:34:01,749 - INFO - Epoch 651: train_loss=0.8502
2025-02-02 17:34:01,906 - INFO - Epoch 651: train_loss=0.8796
2025-02-02 17:34:02,041 - INFO - Epoch 651: train_loss=0.8480
2025-02-02 17:34:02,731 - INFO - Epoch 651: val_loss=1.9954, val_acc=33.33%
2025-02-02 17:34:02,734 - INFO - ####################Training epoch 652####################
2025-02-02 17:34:03,437 - INFO - Epoch 652: train_loss=0.7257
2025-02-02 17:34:03,595 - INFO - Epoch 652: train_loss=0.9665
2025-02-02 17:34:03,730 - INFO - Epoch 652: train_loss=0.9351
2025-02-02 17:34:04,388 - INFO - Epoch 652: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:34:04,392 - INFO - ####################Training epoch 653####################
2025-02-02 17:34:05,043 - INFO - Epoch 653: train_loss=0.8150
2025-02-02 17:34:05,200 - INFO - Epoch 653: train_loss=0.9394
2025-02-02 17:34:05,334 - INFO - Epoch 653: train_loss=0.7807
2025-02-02 17:34:05,990 - INFO - Epoch 653: val_loss=1.9920, val_acc=33.33%
2025-02-02 17:34:05,993 - INFO - ####################Training epoch 654####################
2025-02-02 17:34:06,662 - INFO - Epoch 654: train_loss=0.8955
2025-02-02 17:34:06,819 - INFO - Epoch 654: train_loss=0.7149
2025-02-02 17:34:06,954 - INFO - Epoch 654: train_loss=1.1355
2025-02-02 17:34:07,626 - INFO - Epoch 654: val_loss=1.9981, val_acc=33.33%
2025-02-02 17:34:07,630 - INFO - ####################Training epoch 655####################
2025-02-02 17:34:08,291 - INFO - Epoch 655: train_loss=0.8944
2025-02-02 17:34:08,450 - INFO - Epoch 655: train_loss=0.9235
2025-02-02 17:34:08,584 - INFO - Epoch 655: train_loss=0.6258
2025-02-02 17:34:09,247 - INFO - Epoch 655: val_loss=1.9944, val_acc=33.33%
2025-02-02 17:34:09,251 - INFO - ####################Training epoch 656####################
2025-02-02 17:34:09,886 - INFO - Epoch 656: train_loss=0.9150
2025-02-02 17:34:10,044 - INFO - Epoch 656: train_loss=0.8133
2025-02-02 17:34:10,179 - INFO - Epoch 656: train_loss=0.8499
2025-02-02 17:34:10,840 - INFO - Epoch 656: val_loss=1.9964, val_acc=33.33%
2025-02-02 17:34:10,844 - INFO - ####################Training epoch 657####################
2025-02-02 17:34:11,534 - INFO - Epoch 657: train_loss=1.0323
2025-02-02 17:34:11,692 - INFO - Epoch 657: train_loss=0.7595
2025-02-02 17:34:11,827 - INFO - Epoch 657: train_loss=0.6930
2025-02-02 17:34:12,504 - INFO - Epoch 657: val_loss=1.9915, val_acc=33.33%
2025-02-02 17:34:12,508 - INFO - ####################Training epoch 658####################
2025-02-02 17:34:13,141 - INFO - Epoch 658: train_loss=0.8664
2025-02-02 17:34:13,299 - INFO - Epoch 658: train_loss=0.8328
2025-02-02 17:34:13,433 - INFO - Epoch 658: train_loss=0.9353
2025-02-02 17:34:14,102 - INFO - Epoch 658: val_loss=1.9909, val_acc=33.33%
2025-02-02 17:34:14,106 - INFO - ####################Training epoch 659####################
2025-02-02 17:34:14,748 - INFO - Epoch 659: train_loss=0.9322
2025-02-02 17:34:14,906 - INFO - Epoch 659: train_loss=0.8217
2025-02-02 17:34:15,041 - INFO - Epoch 659: train_loss=0.7918
2025-02-02 17:34:15,707 - INFO - Epoch 659: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:34:15,710 - INFO - ####################Training epoch 660####################
2025-02-02 17:34:16,383 - INFO - Epoch 660: train_loss=0.7695
2025-02-02 17:34:16,541 - INFO - Epoch 660: train_loss=0.9530
2025-02-02 17:34:16,676 - INFO - Epoch 660: train_loss=0.8546
2025-02-02 17:34:17,353 - INFO - Epoch 660: val_loss=1.9920, val_acc=33.33%
2025-02-02 17:34:17,356 - INFO - ####################Training epoch 661####################
2025-02-02 17:34:18,001 - INFO - Epoch 661: train_loss=0.8290
2025-02-02 17:34:18,158 - INFO - Epoch 661: train_loss=0.8856
2025-02-02 17:34:18,293 - INFO - Epoch 661: train_loss=0.8841
2025-02-02 17:34:18,967 - INFO - Epoch 661: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:34:18,971 - INFO - ####################Training epoch 662####################
2025-02-02 17:34:19,646 - INFO - Epoch 662: train_loss=0.7916
2025-02-02 17:34:19,808 - INFO - Epoch 662: train_loss=0.9009
2025-02-02 17:34:19,945 - INFO - Epoch 662: train_loss=0.9495
2025-02-02 17:34:20,617 - INFO - Epoch 662: val_loss=1.9948, val_acc=33.33%
2025-02-02 17:34:20,621 - INFO - ####################Training epoch 663####################
2025-02-02 17:34:21,296 - INFO - Epoch 663: train_loss=0.9716
2025-02-02 17:34:21,454 - INFO - Epoch 663: train_loss=0.8145
2025-02-02 17:34:21,589 - INFO - Epoch 663: train_loss=0.7063
2025-02-02 17:34:22,272 - INFO - Epoch 663: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:34:22,276 - INFO - ####################Training epoch 664####################
2025-02-02 17:34:22,937 - INFO - Epoch 664: train_loss=0.8268
2025-02-02 17:34:23,094 - INFO - Epoch 664: train_loss=0.9693
2025-02-02 17:34:23,229 - INFO - Epoch 664: train_loss=0.6838
2025-02-02 17:34:23,886 - INFO - Epoch 664: val_loss=1.9996, val_acc=33.33%
2025-02-02 17:34:23,890 - INFO - ####################Training epoch 665####################
2025-02-02 17:34:24,553 - INFO - Epoch 665: train_loss=0.8290
2025-02-02 17:34:24,711 - INFO - Epoch 665: train_loss=0.8516
2025-02-02 17:34:24,846 - INFO - Epoch 665: train_loss=0.9624
2025-02-02 17:34:25,493 - INFO - Epoch 665: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:34:25,497 - INFO - ####################Training epoch 666####################
2025-02-02 17:34:26,146 - INFO - Epoch 666: train_loss=0.8256
2025-02-02 17:34:26,305 - INFO - Epoch 666: train_loss=0.9400
2025-02-02 17:34:26,440 - INFO - Epoch 666: train_loss=0.7522
2025-02-02 17:34:27,116 - INFO - Epoch 666: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:34:27,120 - INFO - ####################Training epoch 667####################
2025-02-02 17:34:27,778 - INFO - Epoch 667: train_loss=0.8264
2025-02-02 17:34:27,936 - INFO - Epoch 667: train_loss=0.8550
2025-02-02 17:34:28,072 - INFO - Epoch 667: train_loss=0.9724
2025-02-02 17:34:28,764 - INFO - Epoch 667: val_loss=1.9923, val_acc=33.33%
2025-02-02 17:34:28,768 - INFO - ####################Training epoch 668####################
2025-02-02 17:34:29,428 - INFO - Epoch 668: train_loss=0.9432
2025-02-02 17:34:29,586 - INFO - Epoch 668: train_loss=0.8263
2025-02-02 17:34:29,721 - INFO - Epoch 668: train_loss=0.7394
2025-02-02 17:34:30,389 - INFO - Epoch 668: val_loss=1.9961, val_acc=33.33%
2025-02-02 17:34:30,393 - INFO - ####################Training epoch 669####################
2025-02-02 17:34:31,030 - INFO - Epoch 669: train_loss=0.7846
2025-02-02 17:34:31,188 - INFO - Epoch 669: train_loss=0.9293
2025-02-02 17:34:31,323 - INFO - Epoch 669: train_loss=0.8820
2025-02-02 17:34:31,999 - INFO - Epoch 669: val_loss=1.9925, val_acc=33.33%
2025-02-02 17:34:32,003 - INFO - ####################Training epoch 670####################
2025-02-02 17:34:32,687 - INFO - Epoch 670: train_loss=0.9653
2025-02-02 17:34:32,846 - INFO - Epoch 670: train_loss=0.7201
2025-02-02 17:34:32,981 - INFO - Epoch 670: train_loss=0.9524
2025-02-02 17:34:33,656 - INFO - Epoch 670: val_loss=1.9944, val_acc=33.33%
2025-02-02 17:34:33,660 - INFO - ####################Training epoch 671####################
2025-02-02 17:34:34,316 - INFO - Epoch 671: train_loss=0.8862
2025-02-02 17:34:34,474 - INFO - Epoch 671: train_loss=0.9113
2025-02-02 17:34:34,609 - INFO - Epoch 671: train_loss=0.6738
2025-02-02 17:34:35,265 - INFO - Epoch 671: val_loss=1.9991, val_acc=33.33%
2025-02-02 17:34:35,269 - INFO - ####################Training epoch 672####################
2025-02-02 17:34:35,933 - INFO - Epoch 672: train_loss=0.7697
2025-02-02 17:34:36,090 - INFO - Epoch 672: train_loss=0.9034
2025-02-02 17:34:36,225 - INFO - Epoch 672: train_loss=0.9974
2025-02-02 17:34:36,948 - INFO - Epoch 672: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:34:36,952 - INFO - ####################Training epoch 673####################
2025-02-02 17:34:37,622 - INFO - Epoch 673: train_loss=0.7886
2025-02-02 17:34:37,781 - INFO - Epoch 673: train_loss=0.9001
2025-02-02 17:34:37,915 - INFO - Epoch 673: train_loss=0.9508
2025-02-02 17:34:38,580 - INFO - Epoch 673: val_loss=1.9956, val_acc=33.33%
2025-02-02 17:34:38,584 - INFO - ####################Training epoch 674####################
2025-02-02 17:34:39,242 - INFO - Epoch 674: train_loss=0.9452
2025-02-02 17:34:39,401 - INFO - Epoch 674: train_loss=0.7872
2025-02-02 17:34:39,535 - INFO - Epoch 674: train_loss=0.8292
2025-02-02 17:34:40,197 - INFO - Epoch 674: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:34:40,200 - INFO - ####################Training epoch 675####################
2025-02-02 17:34:40,871 - INFO - Epoch 675: train_loss=0.9275
2025-02-02 17:34:41,029 - INFO - Epoch 675: train_loss=0.8507
2025-02-02 17:34:41,164 - INFO - Epoch 675: train_loss=0.7260
2025-02-02 17:34:41,830 - INFO - Epoch 675: val_loss=1.9924, val_acc=33.33%
2025-02-02 17:34:41,834 - INFO - ####################Training epoch 676####################
2025-02-02 17:34:42,495 - INFO - Epoch 676: train_loss=0.8918
2025-02-02 17:34:42,654 - INFO - Epoch 676: train_loss=0.9361
2025-02-02 17:34:42,790 - INFO - Epoch 676: train_loss=0.6041
2025-02-02 17:34:43,474 - INFO - Epoch 676: val_loss=1.9963, val_acc=33.33%
2025-02-02 17:34:43,478 - INFO - ####################Training epoch 677####################
2025-02-02 17:34:44,131 - INFO - Epoch 677: train_loss=0.8847
2025-02-02 17:34:44,289 - INFO - Epoch 677: train_loss=0.8863
2025-02-02 17:34:44,424 - INFO - Epoch 677: train_loss=0.7467
2025-02-02 17:34:45,108 - INFO - Epoch 677: val_loss=1.9997, val_acc=33.33%
2025-02-02 17:34:45,112 - INFO - ####################Training epoch 678####################
2025-02-02 17:34:45,770 - INFO - Epoch 678: train_loss=0.8359
2025-02-02 17:34:45,934 - INFO - Epoch 678: train_loss=0.8744
2025-02-02 17:34:46,070 - INFO - Epoch 678: train_loss=0.9018
2025-02-02 17:34:46,741 - INFO - Epoch 678: val_loss=1.9930, val_acc=33.33%
2025-02-02 17:34:46,745 - INFO - ####################Training epoch 679####################
2025-02-02 17:34:47,379 - INFO - Epoch 679: train_loss=0.8292
2025-02-02 17:34:47,539 - INFO - Epoch 679: train_loss=0.9615
2025-02-02 17:34:47,674 - INFO - Epoch 679: train_loss=0.6866
2025-02-02 17:34:48,356 - INFO - Epoch 679: val_loss=1.9935, val_acc=33.33%
2025-02-02 17:34:48,360 - INFO - ####################Training epoch 680####################
2025-02-02 17:34:49,012 - INFO - Epoch 680: train_loss=1.0320
2025-02-02 17:34:49,170 - INFO - Epoch 680: train_loss=0.8141
2025-02-02 17:34:49,306 - INFO - Epoch 680: train_loss=0.5585
2025-02-02 17:34:49,987 - INFO - Epoch 680: val_loss=1.9992, val_acc=33.33%
2025-02-02 17:34:49,991 - INFO - ####################Training epoch 681####################
2025-02-02 17:34:50,655 - INFO - Epoch 681: train_loss=0.8121
2025-02-02 17:34:50,812 - INFO - Epoch 681: train_loss=0.9377
2025-02-02 17:34:50,947 - INFO - Epoch 681: train_loss=0.7936
2025-02-02 17:34:51,598 - INFO - Epoch 681: val_loss=1.9937, val_acc=33.33%
2025-02-02 17:34:51,602 - INFO - ####################Training epoch 682####################
2025-02-02 17:34:52,257 - INFO - Epoch 682: train_loss=0.8947
2025-02-02 17:34:52,415 - INFO - Epoch 682: train_loss=0.7575
2025-02-02 17:34:52,550 - INFO - Epoch 682: train_loss=1.0501
2025-02-02 17:34:53,211 - INFO - Epoch 682: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:34:53,214 - INFO - ####################Training epoch 683####################
2025-02-02 17:34:53,870 - INFO - Epoch 683: train_loss=0.8219
2025-02-02 17:34:54,027 - INFO - Epoch 683: train_loss=0.8137
2025-02-02 17:34:54,171 - INFO - Epoch 683: train_loss=1.0753
2025-02-02 17:34:54,863 - INFO - Epoch 683: val_loss=1.9928, val_acc=33.33%
2025-02-02 17:34:54,867 - INFO - ####################Training epoch 684####################
2025-02-02 17:34:55,500 - INFO - Epoch 684: train_loss=0.8549
2025-02-02 17:34:55,658 - INFO - Epoch 684: train_loss=0.8806
2025-02-02 17:34:55,793 - INFO - Epoch 684: train_loss=0.8265
2025-02-02 17:34:56,460 - INFO - Epoch 684: val_loss=1.9987, val_acc=33.33%
2025-02-02 17:34:56,464 - INFO - ####################Training epoch 685####################
2025-02-02 17:34:57,120 - INFO - Epoch 685: train_loss=0.9581
2025-02-02 17:34:57,277 - INFO - Epoch 685: train_loss=0.7885
2025-02-02 17:34:57,412 - INFO - Epoch 685: train_loss=0.8093
2025-02-02 17:34:58,066 - INFO - Epoch 685: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:34:58,070 - INFO - ####################Training epoch 686####################
2025-02-02 17:34:58,718 - INFO - Epoch 686: train_loss=0.8948
2025-02-02 17:34:58,875 - INFO - Epoch 686: train_loss=0.8040
2025-02-02 17:34:59,009 - INFO - Epoch 686: train_loss=0.9207
2025-02-02 17:34:59,692 - INFO - Epoch 686: val_loss=1.9992, val_acc=33.33%
2025-02-02 17:34:59,695 - INFO - ####################Training epoch 687####################
2025-02-02 17:35:00,351 - INFO - Epoch 687: train_loss=0.7721
2025-02-02 17:35:00,508 - INFO - Epoch 687: train_loss=0.8594
2025-02-02 17:35:00,643 - INFO - Epoch 687: train_loss=1.0875
2025-02-02 17:35:01,327 - INFO - Epoch 687: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:35:01,334 - INFO - ####################Training epoch 688####################
2025-02-02 17:35:01,983 - INFO - Epoch 688: train_loss=0.8010
2025-02-02 17:35:02,140 - INFO - Epoch 688: train_loss=0.9484
2025-02-02 17:35:02,274 - INFO - Epoch 688: train_loss=0.8112
2025-02-02 17:35:02,979 - INFO - Epoch 688: val_loss=1.9930, val_acc=33.33%
2025-02-02 17:35:02,983 - INFO - ####################Training epoch 689####################
2025-02-02 17:35:03,633 - INFO - Epoch 689: train_loss=0.8428
2025-02-02 17:35:03,791 - INFO - Epoch 689: train_loss=0.9226
2025-02-02 17:35:03,925 - INFO - Epoch 689: train_loss=0.7650
2025-02-02 17:35:04,590 - INFO - Epoch 689: val_loss=1.9919, val_acc=33.33%
2025-02-02 17:35:04,594 - INFO - ####################Training epoch 690####################
2025-02-02 17:35:05,244 - INFO - Epoch 690: train_loss=0.9418
2025-02-02 17:35:05,401 - INFO - Epoch 690: train_loss=0.8346
2025-02-02 17:35:05,536 - INFO - Epoch 690: train_loss=0.7250
2025-02-02 17:35:06,225 - INFO - Epoch 690: val_loss=1.9950, val_acc=33.33%
2025-02-02 17:35:06,229 - INFO - ####################Training epoch 691####################
2025-02-02 17:35:06,917 - INFO - Epoch 691: train_loss=0.9260
2025-02-02 17:35:07,075 - INFO - Epoch 691: train_loss=0.8862
2025-02-02 17:35:07,209 - INFO - Epoch 691: train_loss=0.6305
2025-02-02 17:35:07,867 - INFO - Epoch 691: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:35:07,870 - INFO - ####################Training epoch 692####################
2025-02-02 17:35:08,503 - INFO - Epoch 692: train_loss=0.8724
2025-02-02 17:35:08,660 - INFO - Epoch 692: train_loss=0.8301
2025-02-02 17:35:08,794 - INFO - Epoch 692: train_loss=0.9148
2025-02-02 17:35:09,438 - INFO - Epoch 692: val_loss=1.9904, val_acc=33.33%
2025-02-02 17:35:09,442 - INFO - ####################Training epoch 693####################
2025-02-02 17:35:10,075 - INFO - Epoch 693: train_loss=0.7724
2025-02-02 17:35:10,233 - INFO - Epoch 693: train_loss=0.9411
2025-02-02 17:35:10,367 - INFO - Epoch 693: train_loss=0.8825
2025-02-02 17:35:11,051 - INFO - Epoch 693: val_loss=1.9998, val_acc=33.33%
2025-02-02 17:35:11,055 - INFO - ####################Training epoch 694####################
2025-02-02 17:35:11,708 - INFO - Epoch 694: train_loss=0.9972
2025-02-02 17:35:11,866 - INFO - Epoch 694: train_loss=0.7102
2025-02-02 17:35:12,001 - INFO - Epoch 694: train_loss=0.8915
2025-02-02 17:35:12,645 - INFO - Epoch 694: val_loss=1.9956, val_acc=33.33%
2025-02-02 17:35:12,649 - INFO - ####################Training epoch 695####################
2025-02-02 17:35:13,312 - INFO - Epoch 695: train_loss=0.7277
2025-02-02 17:35:13,470 - INFO - Epoch 695: train_loss=1.0190
2025-02-02 17:35:13,605 - INFO - Epoch 695: train_loss=0.8112
2025-02-02 17:35:14,260 - INFO - Epoch 695: val_loss=2.0013, val_acc=33.33%
2025-02-02 17:35:14,264 - INFO - ####################Training epoch 696####################
2025-02-02 17:35:14,896 - INFO - Epoch 696: train_loss=0.8456
2025-02-02 17:35:15,053 - INFO - Epoch 696: train_loss=0.8323
2025-02-02 17:35:15,188 - INFO - Epoch 696: train_loss=0.9736
2025-02-02 17:35:15,854 - INFO - Epoch 696: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:35:15,858 - INFO - ####################Training epoch 697####################
2025-02-02 17:35:16,515 - INFO - Epoch 697: train_loss=0.7516
2025-02-02 17:35:16,672 - INFO - Epoch 697: train_loss=0.8919
2025-02-02 17:35:16,807 - INFO - Epoch 697: train_loss=1.0485
2025-02-02 17:35:17,473 - INFO - Epoch 697: val_loss=2.0045, val_acc=33.33%
2025-02-02 17:35:17,476 - INFO - ####################Training epoch 698####################
2025-02-02 17:35:18,123 - INFO - Epoch 698: train_loss=0.9092
2025-02-02 17:35:18,281 - INFO - Epoch 698: train_loss=0.7863
2025-02-02 17:35:18,415 - INFO - Epoch 698: train_loss=0.9311
2025-02-02 17:35:19,079 - INFO - Epoch 698: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:35:19,083 - INFO - ####################Training epoch 699####################
2025-02-02 17:35:19,799 - INFO - Epoch 699: train_loss=0.8338
2025-02-02 17:35:19,956 - INFO - Epoch 699: train_loss=0.8280
2025-02-02 17:35:20,091 - INFO - Epoch 699: train_loss=1.0154
2025-02-02 17:35:20,761 - INFO - Epoch 699: val_loss=1.9931, val_acc=33.33%
2025-02-02 17:35:20,765 - INFO - ####################Training epoch 700####################
2025-02-02 17:35:21,428 - INFO - Epoch 700: train_loss=0.7850
2025-02-02 17:35:21,586 - INFO - Epoch 700: train_loss=0.8866
2025-02-02 17:35:21,720 - INFO - Epoch 700: train_loss=0.9896
2025-02-02 17:35:22,404 - INFO - Epoch 700: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:35:22,408 - INFO - ####################Training epoch 701####################
2025-02-02 17:35:23,036 - INFO - Epoch 701: train_loss=0.8909
2025-02-02 17:35:23,193 - INFO - Epoch 701: train_loss=0.8283
2025-02-02 17:35:23,327 - INFO - Epoch 701: train_loss=0.8707
2025-02-02 17:35:23,987 - INFO - Epoch 701: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:35:23,991 - INFO - ####################Training epoch 702####################
2025-02-02 17:35:24,637 - INFO - Epoch 702: train_loss=0.8131
2025-02-02 17:35:24,794 - INFO - Epoch 702: train_loss=1.0061
2025-02-02 17:35:24,928 - INFO - Epoch 702: train_loss=0.6213
2025-02-02 17:35:25,606 - INFO - Epoch 702: val_loss=1.9949, val_acc=33.33%
2025-02-02 17:35:25,610 - INFO - ####################Training epoch 703####################
2025-02-02 17:35:26,279 - INFO - Epoch 703: train_loss=0.7923
2025-02-02 17:35:26,437 - INFO - Epoch 703: train_loss=0.8406
2025-02-02 17:35:26,571 - INFO - Epoch 703: train_loss=1.0839
2025-02-02 17:35:27,225 - INFO - Epoch 703: val_loss=1.9891, val_acc=33.33%
2025-02-02 17:35:27,228 - INFO - ####################Training epoch 704####################
2025-02-02 17:35:27,899 - INFO - Epoch 704: train_loss=0.7739
2025-02-02 17:35:28,057 - INFO - Epoch 704: train_loss=0.9644
2025-02-02 17:35:28,192 - INFO - Epoch 704: train_loss=0.8195
2025-02-02 17:35:28,864 - INFO - Epoch 704: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:35:28,869 - INFO - ####################Training epoch 705####################
2025-02-02 17:35:29,525 - INFO - Epoch 705: train_loss=0.8958
2025-02-02 17:35:29,684 - INFO - Epoch 705: train_loss=0.8124
2025-02-02 17:35:29,818 - INFO - Epoch 705: train_loss=0.8965
2025-02-02 17:35:30,475 - INFO - Epoch 705: val_loss=1.9899, val_acc=33.33%
2025-02-02 17:35:30,479 - INFO - ####################Training epoch 706####################
2025-02-02 17:35:31,111 - INFO - Epoch 706: train_loss=0.8618
2025-02-02 17:35:31,269 - INFO - Epoch 706: train_loss=0.8836
2025-02-02 17:35:31,404 - INFO - Epoch 706: train_loss=0.8050
2025-02-02 17:35:32,067 - INFO - Epoch 706: val_loss=1.9927, val_acc=33.33%
2025-02-02 17:35:32,071 - INFO - ####################Training epoch 707####################
2025-02-02 17:35:32,731 - INFO - Epoch 707: train_loss=0.9831
2025-02-02 17:35:32,889 - INFO - Epoch 707: train_loss=0.7319
2025-02-02 17:35:33,023 - INFO - Epoch 707: train_loss=0.8822
2025-02-02 17:35:33,690 - INFO - Epoch 707: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:35:33,694 - INFO - ####################Training epoch 708####################
2025-02-02 17:35:34,341 - INFO - Epoch 708: train_loss=0.8105
2025-02-02 17:35:34,499 - INFO - Epoch 708: train_loss=0.8081
2025-02-02 17:35:34,634 - INFO - Epoch 708: train_loss=1.1037
2025-02-02 17:35:35,307 - INFO - Epoch 708: val_loss=2.0001, val_acc=33.33%
2025-02-02 17:35:35,310 - INFO - ####################Training epoch 709####################
2025-02-02 17:35:35,973 - INFO - Epoch 709: train_loss=0.9886
2025-02-02 17:35:36,135 - INFO - Epoch 709: train_loss=0.7325
2025-02-02 17:35:36,279 - INFO - Epoch 709: train_loss=0.8576
2025-02-02 17:35:36,945 - INFO - Epoch 709: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:35:36,949 - INFO - ####################Training epoch 710####################
2025-02-02 17:35:37,612 - INFO - Epoch 710: train_loss=0.8471
2025-02-02 17:35:37,769 - INFO - Epoch 710: train_loss=0.8602
2025-02-02 17:35:37,904 - INFO - Epoch 710: train_loss=0.9076
2025-02-02 17:35:38,570 - INFO - Epoch 710: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:35:38,573 - INFO - ####################Training epoch 711####################
2025-02-02 17:35:39,212 - INFO - Epoch 711: train_loss=0.8347
2025-02-02 17:35:39,370 - INFO - Epoch 711: train_loss=0.8193
2025-02-02 17:35:39,505 - INFO - Epoch 711: train_loss=1.0181
2025-02-02 17:35:40,189 - INFO - Epoch 711: val_loss=2.0000, val_acc=33.33%
2025-02-02 17:35:40,193 - INFO - ####################Training epoch 712####################
2025-02-02 17:35:40,874 - INFO - Epoch 712: train_loss=0.8760
2025-02-02 17:35:41,032 - INFO - Epoch 712: train_loss=0.8391
2025-02-02 17:35:41,165 - INFO - Epoch 712: train_loss=0.8859
2025-02-02 17:35:41,844 - INFO - Epoch 712: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:35:41,851 - INFO - ####################Training epoch 713####################
2025-02-02 17:35:42,501 - INFO - Epoch 713: train_loss=0.9810
2025-02-02 17:35:42,659 - INFO - Epoch 713: train_loss=0.7861
2025-02-02 17:35:42,794 - INFO - Epoch 713: train_loss=0.7558
2025-02-02 17:35:43,480 - INFO - Epoch 713: val_loss=1.9973, val_acc=33.33%
2025-02-02 17:35:43,484 - INFO - ####################Training epoch 714####################
2025-02-02 17:35:44,132 - INFO - Epoch 714: train_loss=0.7793
2025-02-02 17:35:44,289 - INFO - Epoch 714: train_loss=0.8559
2025-02-02 17:35:44,435 - INFO - Epoch 714: train_loss=1.0819
2025-02-02 17:35:45,113 - INFO - Epoch 714: val_loss=1.9977, val_acc=33.33%
2025-02-02 17:35:45,117 - INFO - ####################Training epoch 715####################
2025-02-02 17:35:45,766 - INFO - Epoch 715: train_loss=0.9315
2025-02-02 17:35:45,924 - INFO - Epoch 715: train_loss=0.7199
2025-02-02 17:35:46,059 - INFO - Epoch 715: train_loss=1.0361
2025-02-02 17:35:46,719 - INFO - Epoch 715: val_loss=1.9983, val_acc=33.33%
2025-02-02 17:35:46,723 - INFO - ####################Training epoch 716####################
2025-02-02 17:35:47,379 - INFO - Epoch 716: train_loss=0.9142
2025-02-02 17:35:47,537 - INFO - Epoch 716: train_loss=0.8327
2025-02-02 17:35:47,672 - INFO - Epoch 716: train_loss=0.7861
2025-02-02 17:35:48,329 - INFO - Epoch 716: val_loss=1.9919, val_acc=33.33%
2025-02-02 17:35:48,333 - INFO - ####################Training epoch 717####################
2025-02-02 17:35:48,984 - INFO - Epoch 717: train_loss=0.8345
2025-02-02 17:35:49,142 - INFO - Epoch 717: train_loss=0.9878
2025-02-02 17:35:49,277 - INFO - Epoch 717: train_loss=0.6227
2025-02-02 17:35:49,935 - INFO - Epoch 717: val_loss=2.0005, val_acc=33.33%
2025-02-02 17:35:49,938 - INFO - ####################Training epoch 718####################
2025-02-02 17:35:50,598 - INFO - Epoch 718: train_loss=0.7960
2025-02-02 17:35:50,756 - INFO - Epoch 718: train_loss=0.9277
2025-02-02 17:35:50,891 - INFO - Epoch 718: train_loss=0.8686
2025-02-02 17:35:51,549 - INFO - Epoch 718: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:35:51,552 - INFO - ####################Training epoch 719####################
2025-02-02 17:35:52,199 - INFO - Epoch 719: train_loss=0.8619
2025-02-02 17:35:52,357 - INFO - Epoch 719: train_loss=0.8432
2025-02-02 17:35:52,492 - INFO - Epoch 719: train_loss=0.9036
2025-02-02 17:35:53,189 - INFO - Epoch 719: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:35:53,193 - INFO - ####################Training epoch 720####################
2025-02-02 17:35:53,856 - INFO - Epoch 720: train_loss=0.9348
2025-02-02 17:35:54,014 - INFO - Epoch 720: train_loss=0.8404
2025-02-02 17:35:54,149 - INFO - Epoch 720: train_loss=0.7225
2025-02-02 17:35:54,831 - INFO - Epoch 720: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:35:54,835 - INFO - ####################Training epoch 721####################
2025-02-02 17:35:55,488 - INFO - Epoch 721: train_loss=0.8711
2025-02-02 17:35:55,645 - INFO - Epoch 721: train_loss=0.8722
2025-02-02 17:35:55,780 - INFO - Epoch 721: train_loss=0.8083
2025-02-02 17:35:56,434 - INFO - Epoch 721: val_loss=1.9976, val_acc=33.33%
2025-02-02 17:35:56,438 - INFO - ####################Training epoch 722####################
2025-02-02 17:35:57,081 - INFO - Epoch 722: train_loss=0.8263
2025-02-02 17:35:57,238 - INFO - Epoch 722: train_loss=0.9383
2025-02-02 17:35:57,373 - INFO - Epoch 722: train_loss=0.7564
2025-02-02 17:35:58,051 - INFO - Epoch 722: val_loss=1.9994, val_acc=33.33%
2025-02-02 17:35:58,054 - INFO - ####################Training epoch 723####################
2025-02-02 17:35:58,701 - INFO - Epoch 723: train_loss=0.9789
2025-02-02 17:35:58,859 - INFO - Epoch 723: train_loss=0.7289
2025-02-02 17:35:58,994 - INFO - Epoch 723: train_loss=0.9069
2025-02-02 17:35:59,669 - INFO - Epoch 723: val_loss=2.0016, val_acc=33.33%
2025-02-02 17:35:59,673 - INFO - ####################Training epoch 724####################
2025-02-02 17:36:00,338 - INFO - Epoch 724: train_loss=0.8604
2025-02-02 17:36:00,496 - INFO - Epoch 724: train_loss=0.8084
2025-02-02 17:36:00,635 - INFO - Epoch 724: train_loss=0.9946
2025-02-02 17:36:01,335 - INFO - Epoch 724: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:36:01,338 - INFO - ####################Training epoch 725####################
2025-02-02 17:36:02,015 - INFO - Epoch 725: train_loss=0.8600
2025-02-02 17:36:02,173 - INFO - Epoch 725: train_loss=0.8365
2025-02-02 17:36:02,308 - INFO - Epoch 725: train_loss=0.9253
2025-02-02 17:36:02,986 - INFO - Epoch 725: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:36:02,989 - INFO - ####################Training epoch 726####################
2025-02-02 17:36:03,650 - INFO - Epoch 726: train_loss=0.7960
2025-02-02 17:36:03,808 - INFO - Epoch 726: train_loss=0.9499
2025-02-02 17:36:03,942 - INFO - Epoch 726: train_loss=0.8042
2025-02-02 17:36:04,597 - INFO - Epoch 726: val_loss=1.9927, val_acc=33.33%
2025-02-02 17:36:04,600 - INFO - ####################Training epoch 727####################
2025-02-02 17:36:05,236 - INFO - Epoch 727: train_loss=0.8122
2025-02-02 17:36:05,395 - INFO - Epoch 727: train_loss=0.8637
2025-02-02 17:36:05,529 - INFO - Epoch 727: train_loss=0.9723
2025-02-02 17:36:06,179 - INFO - Epoch 727: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:36:06,182 - INFO - ####################Training epoch 728####################
2025-02-02 17:36:06,835 - INFO - Epoch 728: train_loss=0.8104
2025-02-02 17:36:06,993 - INFO - Epoch 728: train_loss=0.8639
2025-02-02 17:36:07,128 - INFO - Epoch 728: train_loss=0.9752
2025-02-02 17:36:07,792 - INFO - Epoch 728: val_loss=1.9978, val_acc=33.33%
2025-02-02 17:36:07,795 - INFO - ####################Training epoch 729####################
2025-02-02 17:36:08,461 - INFO - Epoch 729: train_loss=0.8404
2025-02-02 17:36:08,619 - INFO - Epoch 729: train_loss=0.8761
2025-02-02 17:36:08,753 - INFO - Epoch 729: train_loss=0.8839
2025-02-02 17:36:09,403 - INFO - Epoch 729: val_loss=1.9979, val_acc=33.33%
2025-02-02 17:36:09,407 - INFO - ####################Training epoch 730####################
2025-02-02 17:36:10,124 - INFO - Epoch 730: train_loss=0.7620
2025-02-02 17:36:10,281 - INFO - Epoch 730: train_loss=0.9340
2025-02-02 17:36:10,415 - INFO - Epoch 730: train_loss=0.9188
2025-02-02 17:36:11,074 - INFO - Epoch 730: val_loss=1.9998, val_acc=33.33%
2025-02-02 17:36:11,078 - INFO - ####################Training epoch 731####################
2025-02-02 17:36:11,748 - INFO - Epoch 731: train_loss=0.8222
2025-02-02 17:36:11,905 - INFO - Epoch 731: train_loss=0.9309
2025-02-02 17:36:12,040 - INFO - Epoch 731: train_loss=0.7903
2025-02-02 17:36:12,713 - INFO - Epoch 731: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:36:12,717 - INFO - ####################Training epoch 732####################
2025-02-02 17:36:13,384 - INFO - Epoch 732: train_loss=0.9163
2025-02-02 17:36:13,541 - INFO - Epoch 732: train_loss=0.9124
2025-02-02 17:36:13,676 - INFO - Epoch 732: train_loss=0.5889
2025-02-02 17:36:14,352 - INFO - Epoch 732: val_loss=1.9946, val_acc=33.33%
2025-02-02 17:36:14,356 - INFO - ####################Training epoch 733####################
2025-02-02 17:36:14,999 - INFO - Epoch 733: train_loss=0.8382
2025-02-02 17:36:15,156 - INFO - Epoch 733: train_loss=0.8788
2025-02-02 17:36:15,291 - INFO - Epoch 733: train_loss=0.8832
2025-02-02 17:36:15,973 - INFO - Epoch 733: val_loss=1.9956, val_acc=33.33%
2025-02-02 17:36:15,976 - INFO - ####################Training epoch 734####################
2025-02-02 17:36:16,639 - INFO - Epoch 734: train_loss=0.9852
2025-02-02 17:36:16,796 - INFO - Epoch 734: train_loss=0.7047
2025-02-02 17:36:16,931 - INFO - Epoch 734: train_loss=0.9471
2025-02-02 17:36:17,590 - INFO - Epoch 734: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:36:17,594 - INFO - ####################Training epoch 735####################
2025-02-02 17:36:18,262 - INFO - Epoch 735: train_loss=0.8512
2025-02-02 17:36:18,419 - INFO - Epoch 735: train_loss=0.9365
2025-02-02 17:36:18,554 - INFO - Epoch 735: train_loss=0.7069
2025-02-02 17:36:19,208 - INFO - Epoch 735: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:36:19,212 - INFO - ####################Training epoch 736####################
2025-02-02 17:36:19,853 - INFO - Epoch 736: train_loss=0.8546
2025-02-02 17:36:20,011 - INFO - Epoch 736: train_loss=0.8449
2025-02-02 17:36:20,146 - INFO - Epoch 736: train_loss=0.9182
2025-02-02 17:36:20,795 - INFO - Epoch 736: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:36:20,799 - INFO - ####################Training epoch 737####################
2025-02-02 17:36:21,433 - INFO - Epoch 737: train_loss=0.9284
2025-02-02 17:36:21,591 - INFO - Epoch 737: train_loss=0.8697
2025-02-02 17:36:21,725 - INFO - Epoch 737: train_loss=0.6636
2025-02-02 17:36:22,399 - INFO - Epoch 737: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:36:22,407 - INFO - ####################Training epoch 738####################
2025-02-02 17:36:23,066 - INFO - Epoch 738: train_loss=0.7216
2025-02-02 17:36:23,224 - INFO - Epoch 738: train_loss=0.9291
2025-02-02 17:36:23,359 - INFO - Epoch 738: train_loss=1.0356
2025-02-02 17:36:24,005 - INFO - Epoch 738: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:36:24,008 - INFO - ####################Training epoch 739####################
2025-02-02 17:36:24,656 - INFO - Epoch 739: train_loss=0.8299
2025-02-02 17:36:24,813 - INFO - Epoch 739: train_loss=0.9106
2025-02-02 17:36:24,948 - INFO - Epoch 739: train_loss=0.8141
2025-02-02 17:36:25,604 - INFO - Epoch 739: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:36:25,608 - INFO - ####################Training epoch 740####################
2025-02-02 17:36:26,270 - INFO - Epoch 740: train_loss=0.7087
2025-02-02 17:36:26,428 - INFO - Epoch 740: train_loss=0.9352
2025-02-02 17:36:26,565 - INFO - Epoch 740: train_loss=1.0596
2025-02-02 17:36:27,252 - INFO - Epoch 740: val_loss=1.9892, val_acc=33.33%
2025-02-02 17:36:27,256 - INFO - ####################Training epoch 741####################
2025-02-02 17:36:27,901 - INFO - Epoch 741: train_loss=0.8846
2025-02-02 17:36:28,058 - INFO - Epoch 741: train_loss=0.8615
2025-02-02 17:36:28,192 - INFO - Epoch 741: train_loss=0.8104
2025-02-02 17:36:28,833 - INFO - Epoch 741: val_loss=2.0001, val_acc=33.33%
2025-02-02 17:36:28,837 - INFO - ####################Training epoch 742####################
2025-02-02 17:36:29,502 - INFO - Epoch 742: train_loss=0.7637
2025-02-02 17:36:29,660 - INFO - Epoch 742: train_loss=0.9099
2025-02-02 17:36:29,795 - INFO - Epoch 742: train_loss=0.9867
2025-02-02 17:36:30,474 - INFO - Epoch 742: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:36:30,478 - INFO - ####################Training epoch 743####################
2025-02-02 17:36:31,143 - INFO - Epoch 743: train_loss=0.9353
2025-02-02 17:36:31,301 - INFO - Epoch 743: train_loss=0.8358
2025-02-02 17:36:31,436 - INFO - Epoch 743: train_loss=0.7375
2025-02-02 17:36:32,087 - INFO - Epoch 743: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:36:32,091 - INFO - ####################Training epoch 744####################
2025-02-02 17:36:32,755 - INFO - Epoch 744: train_loss=0.9312
2025-02-02 17:36:32,912 - INFO - Epoch 744: train_loss=0.8842
2025-02-02 17:36:33,047 - INFO - Epoch 744: train_loss=0.6275
2025-02-02 17:36:33,737 - INFO - Epoch 744: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:36:33,741 - INFO - ####################Training epoch 745####################
2025-02-02 17:36:34,399 - INFO - Epoch 745: train_loss=0.7494
2025-02-02 17:36:34,557 - INFO - Epoch 745: train_loss=0.9905
2025-02-02 17:36:34,692 - INFO - Epoch 745: train_loss=0.8153
2025-02-02 17:36:35,424 - INFO - Epoch 745: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:36:35,429 - INFO - ####################Training epoch 746####################
2025-02-02 17:36:36,104 - INFO - Epoch 746: train_loss=0.9050
2025-02-02 17:36:36,262 - INFO - Epoch 746: train_loss=0.8206
2025-02-02 17:36:36,397 - INFO - Epoch 746: train_loss=0.8511
2025-02-02 17:36:37,072 - INFO - Epoch 746: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:36:37,076 - INFO - ####################Training epoch 747####################
2025-02-02 17:36:37,740 - INFO - Epoch 747: train_loss=0.8507
2025-02-02 17:36:37,897 - INFO - Epoch 747: train_loss=0.9365
2025-02-02 17:36:38,032 - INFO - Epoch 747: train_loss=0.6994
2025-02-02 17:36:38,685 - INFO - Epoch 747: val_loss=1.9907, val_acc=33.33%
2025-02-02 17:36:38,689 - INFO - ####################Training epoch 748####################
2025-02-02 17:36:39,346 - INFO - Epoch 748: train_loss=0.7857
2025-02-02 17:36:39,504 - INFO - Epoch 748: train_loss=0.8487
2025-02-02 17:36:39,638 - INFO - Epoch 748: train_loss=1.0871
2025-02-02 17:36:40,309 - INFO - Epoch 748: val_loss=1.9926, val_acc=33.33%
2025-02-02 17:36:40,312 - INFO - ####################Training epoch 749####################
2025-02-02 17:36:40,952 - INFO - Epoch 749: train_loss=0.9036
2025-02-02 17:36:41,109 - INFO - Epoch 749: train_loss=0.8534
2025-02-02 17:36:41,244 - INFO - Epoch 749: train_loss=0.7795
2025-02-02 17:36:41,890 - INFO - Epoch 749: val_loss=2.0010, val_acc=33.33%
2025-02-02 17:36:41,893 - INFO - ####################Training epoch 750####################
2025-02-02 17:36:42,545 - INFO - Epoch 750: train_loss=0.9759
2025-02-02 17:36:42,703 - INFO - Epoch 750: train_loss=0.7460
2025-02-02 17:36:42,838 - INFO - Epoch 750: train_loss=0.8647
2025-02-02 17:36:43,487 - INFO - Epoch 750: val_loss=1.9949, val_acc=33.33%
2025-02-02 17:36:43,491 - INFO - ####################Training epoch 751####################
2025-02-02 17:36:44,197 - INFO - Epoch 751: train_loss=0.9589
2025-02-02 17:36:44,354 - INFO - Epoch 751: train_loss=0.7713
2025-02-02 17:36:44,489 - INFO - Epoch 751: train_loss=0.8289
2025-02-02 17:36:45,146 - INFO - Epoch 751: val_loss=1.9922, val_acc=33.33%
2025-02-02 17:36:45,150 - INFO - ####################Training epoch 752####################
2025-02-02 17:36:45,809 - INFO - Epoch 752: train_loss=0.8107
2025-02-02 17:36:45,966 - INFO - Epoch 752: train_loss=0.8760
2025-02-02 17:36:46,101 - INFO - Epoch 752: train_loss=0.9682
2025-02-02 17:36:46,767 - INFO - Epoch 752: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:36:46,771 - INFO - ####################Training epoch 753####################
2025-02-02 17:36:47,450 - INFO - Epoch 753: train_loss=0.8656
2025-02-02 17:36:47,608 - INFO - Epoch 753: train_loss=0.8970
2025-02-02 17:36:47,743 - INFO - Epoch 753: train_loss=0.7729
2025-02-02 17:36:48,437 - INFO - Epoch 753: val_loss=2.0007, val_acc=33.33%
2025-02-02 17:36:48,441 - INFO - ####################Training epoch 754####################
2025-02-02 17:36:49,099 - INFO - Epoch 754: train_loss=0.9520
2025-02-02 17:36:49,257 - INFO - Epoch 754: train_loss=0.8132
2025-02-02 17:36:49,392 - INFO - Epoch 754: train_loss=0.7619
2025-02-02 17:36:50,058 - INFO - Epoch 754: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:36:50,062 - INFO - ####################Training epoch 755####################
2025-02-02 17:36:50,730 - INFO - Epoch 755: train_loss=0.7861
2025-02-02 17:36:50,888 - INFO - Epoch 755: train_loss=0.9149
2025-02-02 17:36:51,022 - INFO - Epoch 755: train_loss=0.9110
2025-02-02 17:36:51,711 - INFO - Epoch 755: val_loss=1.9984, val_acc=33.33%
2025-02-02 17:36:51,715 - INFO - ####################Training epoch 756####################
2025-02-02 17:36:52,401 - INFO - Epoch 756: train_loss=0.7654
2025-02-02 17:36:52,558 - INFO - Epoch 756: train_loss=0.9561
2025-02-02 17:36:52,693 - INFO - Epoch 756: train_loss=0.8495
2025-02-02 17:36:53,343 - INFO - Epoch 756: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:36:53,347 - INFO - ####################Training epoch 757####################
2025-02-02 17:36:54,000 - INFO - Epoch 757: train_loss=0.7532
2025-02-02 17:36:54,158 - INFO - Epoch 757: train_loss=0.9127
2025-02-02 17:36:54,293 - INFO - Epoch 757: train_loss=1.0100
2025-02-02 17:36:54,943 - INFO - Epoch 757: val_loss=2.0003, val_acc=33.33%
2025-02-02 17:36:54,947 - INFO - ####################Training epoch 758####################
2025-02-02 17:36:55,609 - INFO - Epoch 758: train_loss=0.7813
2025-02-02 17:36:55,766 - INFO - Epoch 758: train_loss=0.9760
2025-02-02 17:36:55,901 - INFO - Epoch 758: train_loss=0.7758
2025-02-02 17:36:56,584 - INFO - Epoch 758: val_loss=2.0002, val_acc=33.33%
2025-02-02 17:36:56,587 - INFO - ####################Training epoch 759####################
2025-02-02 17:36:57,224 - INFO - Epoch 759: train_loss=0.9289
2025-02-02 17:36:57,382 - INFO - Epoch 759: train_loss=0.7394
2025-02-02 17:36:57,517 - INFO - Epoch 759: train_loss=0.9801
2025-02-02 17:36:58,184 - INFO - Epoch 759: val_loss=1.9968, val_acc=33.33%
2025-02-02 17:36:58,187 - INFO - ####################Training epoch 760####################
2025-02-02 17:36:58,834 - INFO - Epoch 760: train_loss=0.8479
2025-02-02 17:36:58,991 - INFO - Epoch 760: train_loss=0.8354
2025-02-02 17:36:59,126 - INFO - Epoch 760: train_loss=0.9546
2025-02-02 17:36:59,786 - INFO - Epoch 760: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:36:59,789 - INFO - ####################Training epoch 761####################
2025-02-02 17:37:00,436 - INFO - Epoch 761: train_loss=0.7934
2025-02-02 17:37:00,595 - INFO - Epoch 761: train_loss=0.9476
2025-02-02 17:37:00,729 - INFO - Epoch 761: train_loss=0.8030
2025-02-02 17:37:01,400 - INFO - Epoch 761: val_loss=1.9993, val_acc=33.33%
2025-02-02 17:37:01,403 - INFO - ####################Training epoch 762####################
2025-02-02 17:37:02,057 - INFO - Epoch 762: train_loss=0.7859
2025-02-02 17:37:02,215 - INFO - Epoch 762: train_loss=0.9653
2025-02-02 17:37:02,350 - INFO - Epoch 762: train_loss=0.7758
2025-02-02 17:37:03,003 - INFO - Epoch 762: val_loss=1.9905, val_acc=33.33%
2025-02-02 17:37:03,010 - INFO - ####################Training epoch 763####################
2025-02-02 17:37:03,663 - INFO - Epoch 763: train_loss=0.7146
2025-02-02 17:37:03,820 - INFO - Epoch 763: train_loss=0.9390
2025-02-02 17:37:03,955 - INFO - Epoch 763: train_loss=1.0253
2025-02-02 17:37:04,616 - INFO - Epoch 763: val_loss=1.9968, val_acc=33.33%
2025-02-02 17:37:04,619 - INFO - ####################Training epoch 764####################
2025-02-02 17:37:05,271 - INFO - Epoch 764: train_loss=0.8534
2025-02-02 17:37:05,429 - INFO - Epoch 764: train_loss=0.8718
2025-02-02 17:37:05,563 - INFO - Epoch 764: train_loss=0.8481
2025-02-02 17:37:06,227 - INFO - Epoch 764: val_loss=1.9956, val_acc=33.33%
2025-02-02 17:37:06,231 - INFO - ####################Training epoch 765####################
2025-02-02 17:37:06,882 - INFO - Epoch 765: train_loss=0.9461
2025-02-02 17:37:07,039 - INFO - Epoch 765: train_loss=0.8129
2025-02-02 17:37:07,174 - INFO - Epoch 765: train_loss=0.7721
2025-02-02 17:37:07,862 - INFO - Epoch 765: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:37:07,865 - INFO - ####################Training epoch 766####################
2025-02-02 17:37:08,493 - INFO - Epoch 766: train_loss=0.7981
2025-02-02 17:37:08,662 - INFO - Epoch 766: train_loss=0.8754
2025-02-02 17:37:08,801 - INFO - Epoch 766: train_loss=0.9827
2025-02-02 17:37:09,463 - INFO - Epoch 766: val_loss=2.0019, val_acc=33.33%
2025-02-02 17:37:09,467 - INFO - ####################Training epoch 767####################
2025-02-02 17:37:10,131 - INFO - Epoch 767: train_loss=0.7387
2025-02-02 17:37:10,289 - INFO - Epoch 767: train_loss=0.9407
2025-02-02 17:37:10,424 - INFO - Epoch 767: train_loss=0.9757
2025-02-02 17:37:11,102 - INFO - Epoch 767: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:37:11,106 - INFO - ####################Training epoch 768####################
2025-02-02 17:37:11,773 - INFO - Epoch 768: train_loss=0.8379
2025-02-02 17:37:11,931 - INFO - Epoch 768: train_loss=0.9066
2025-02-02 17:37:12,065 - INFO - Epoch 768: train_loss=0.7954
2025-02-02 17:37:12,726 - INFO - Epoch 768: val_loss=1.9915, val_acc=33.33%
2025-02-02 17:37:12,729 - INFO - ####################Training epoch 769####################
2025-02-02 17:37:13,386 - INFO - Epoch 769: train_loss=0.9379
2025-02-02 17:37:13,544 - INFO - Epoch 769: train_loss=0.6876
2025-02-02 17:37:13,678 - INFO - Epoch 769: train_loss=1.0992
2025-02-02 17:37:14,351 - INFO - Epoch 769: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:37:14,355 - INFO - ####################Training epoch 770####################
2025-02-02 17:37:14,992 - INFO - Epoch 770: train_loss=0.8888
2025-02-02 17:37:15,150 - INFO - Epoch 770: train_loss=0.7931
2025-02-02 17:37:15,285 - INFO - Epoch 770: train_loss=0.9396
2025-02-02 17:37:15,970 - INFO - Epoch 770: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:37:15,974 - INFO - ####################Training epoch 771####################
2025-02-02 17:37:16,629 - INFO - Epoch 771: train_loss=0.8311
2025-02-02 17:37:16,786 - INFO - Epoch 771: train_loss=0.8662
2025-02-02 17:37:16,921 - INFO - Epoch 771: train_loss=0.9201
2025-02-02 17:37:17,638 - INFO - Epoch 771: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:37:17,642 - INFO - ####################Training epoch 772####################
2025-02-02 17:37:18,291 - INFO - Epoch 772: train_loss=0.8724
2025-02-02 17:37:18,449 - INFO - Epoch 772: train_loss=0.8899
2025-02-02 17:37:18,583 - INFO - Epoch 772: train_loss=0.7680
2025-02-02 17:37:19,238 - INFO - Epoch 772: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:37:19,242 - INFO - ####################Training epoch 773####################
2025-02-02 17:37:19,888 - INFO - Epoch 773: train_loss=1.0267
2025-02-02 17:37:20,046 - INFO - Epoch 773: train_loss=0.7426
2025-02-02 17:37:20,181 - INFO - Epoch 773: train_loss=0.7319
2025-02-02 17:37:20,861 - INFO - Epoch 773: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:37:20,865 - INFO - ####################Training epoch 774####################
2025-02-02 17:37:21,549 - INFO - Epoch 774: train_loss=1.0024
2025-02-02 17:37:21,707 - INFO - Epoch 774: train_loss=0.7801
2025-02-02 17:37:21,842 - INFO - Epoch 774: train_loss=0.7157
2025-02-02 17:37:22,528 - INFO - Epoch 774: val_loss=1.9963, val_acc=33.33%
2025-02-02 17:37:22,532 - INFO - ####################Training epoch 775####################
2025-02-02 17:37:23,192 - INFO - Epoch 775: train_loss=0.7476
2025-02-02 17:37:23,350 - INFO - Epoch 775: train_loss=0.9550
2025-02-02 17:37:23,484 - INFO - Epoch 775: train_loss=0.9157
2025-02-02 17:37:24,141 - INFO - Epoch 775: val_loss=1.9961, val_acc=33.33%
2025-02-02 17:37:24,144 - INFO - ####################Training epoch 776####################
2025-02-02 17:37:24,807 - INFO - Epoch 776: train_loss=0.7359
2025-02-02 17:37:24,965 - INFO - Epoch 776: train_loss=0.9872
2025-02-02 17:37:25,099 - INFO - Epoch 776: train_loss=0.8557
2025-02-02 17:37:25,796 - INFO - Epoch 776: val_loss=1.9952, val_acc=33.33%
2025-02-02 17:37:25,800 - INFO - ####################Training epoch 777####################
2025-02-02 17:37:26,471 - INFO - Epoch 777: train_loss=0.9584
2025-02-02 17:37:26,629 - INFO - Epoch 777: train_loss=0.6810
2025-02-02 17:37:26,764 - INFO - Epoch 777: train_loss=1.0626
2025-02-02 17:37:27,437 - INFO - Epoch 777: val_loss=1.9952, val_acc=33.33%
2025-02-02 17:37:27,441 - INFO - ####################Training epoch 778####################
2025-02-02 17:37:28,104 - INFO - Epoch 778: train_loss=0.7911
2025-02-02 17:37:28,261 - INFO - Epoch 778: train_loss=0.9949
2025-02-02 17:37:28,395 - INFO - Epoch 778: train_loss=0.7046
2025-02-02 17:37:29,072 - INFO - Epoch 778: val_loss=1.9913, val_acc=33.33%
2025-02-02 17:37:29,076 - INFO - ####################Training epoch 779####################
2025-02-02 17:37:29,718 - INFO - Epoch 779: train_loss=0.8624
2025-02-02 17:37:29,875 - INFO - Epoch 779: train_loss=0.8164
2025-02-02 17:37:30,009 - INFO - Epoch 779: train_loss=0.9660
2025-02-02 17:37:30,660 - INFO - Epoch 779: val_loss=2.0003, val_acc=33.33%
2025-02-02 17:37:30,664 - INFO - ####################Training epoch 780####################
2025-02-02 17:37:31,319 - INFO - Epoch 780: train_loss=0.9288
2025-02-02 17:37:31,476 - INFO - Epoch 780: train_loss=0.8154
2025-02-02 17:37:31,611 - INFO - Epoch 780: train_loss=0.8079
2025-02-02 17:37:32,255 - INFO - Epoch 780: val_loss=1.9953, val_acc=33.33%
2025-02-02 17:37:32,259 - INFO - ####################Training epoch 781####################
2025-02-02 17:37:32,903 - INFO - Epoch 781: train_loss=0.8217
2025-02-02 17:37:33,061 - INFO - Epoch 781: train_loss=0.8699
2025-02-02 17:37:33,197 - INFO - Epoch 781: train_loss=0.9357
2025-02-02 17:37:33,860 - INFO - Epoch 781: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:37:33,864 - INFO - ####################Training epoch 782####################
2025-02-02 17:37:34,527 - INFO - Epoch 782: train_loss=0.8464
2025-02-02 17:37:34,685 - INFO - Epoch 782: train_loss=0.9782
2025-02-02 17:37:34,820 - INFO - Epoch 782: train_loss=0.6110
2025-02-02 17:37:35,502 - INFO - Epoch 782: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:37:35,506 - INFO - ####################Training epoch 783####################
2025-02-02 17:37:36,234 - INFO - Epoch 783: train_loss=1.0002
2025-02-02 17:37:36,393 - INFO - Epoch 783: train_loss=0.6601
2025-02-02 17:37:36,528 - INFO - Epoch 783: train_loss=1.0198
2025-02-02 17:37:37,210 - INFO - Epoch 783: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:37:37,213 - INFO - ####################Training epoch 784####################
2025-02-02 17:37:37,873 - INFO - Epoch 784: train_loss=0.8941
2025-02-02 17:37:38,031 - INFO - Epoch 784: train_loss=0.8381
2025-02-02 17:37:38,166 - INFO - Epoch 784: train_loss=0.8346
2025-02-02 17:37:38,820 - INFO - Epoch 784: val_loss=1.9915, val_acc=33.33%
2025-02-02 17:37:38,824 - INFO - ####################Training epoch 785####################
2025-02-02 17:37:39,537 - INFO - Epoch 785: train_loss=0.9301
2025-02-02 17:37:39,695 - INFO - Epoch 785: train_loss=0.8097
2025-02-02 17:37:39,829 - INFO - Epoch 785: train_loss=0.8282
2025-02-02 17:37:40,476 - INFO - Epoch 785: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:37:40,480 - INFO - ####################Training epoch 786####################
2025-02-02 17:37:41,128 - INFO - Epoch 786: train_loss=0.8659
2025-02-02 17:37:41,286 - INFO - Epoch 786: train_loss=0.8467
2025-02-02 17:37:41,421 - INFO - Epoch 786: train_loss=0.8799
2025-02-02 17:37:42,104 - INFO - Epoch 786: val_loss=1.9925, val_acc=33.33%
2025-02-02 17:37:42,108 - INFO - ####################Training epoch 787####################
2025-02-02 17:37:42,816 - INFO - Epoch 787: train_loss=0.9084
2025-02-02 17:37:42,973 - INFO - Epoch 787: train_loss=0.7782
2025-02-02 17:37:43,108 - INFO - Epoch 787: train_loss=0.9517
2025-02-02 17:37:43,762 - INFO - Epoch 787: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:37:43,766 - INFO - ####################Training epoch 788####################
2025-02-02 17:37:44,422 - INFO - Epoch 788: train_loss=0.8197
2025-02-02 17:37:44,580 - INFO - Epoch 788: train_loss=0.8589
2025-02-02 17:37:44,715 - INFO - Epoch 788: train_loss=0.9801
2025-02-02 17:37:45,390 - INFO - Epoch 788: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:37:45,394 - INFO - ####################Training epoch 789####################
2025-02-02 17:37:46,109 - INFO - Epoch 789: train_loss=0.9380
2025-02-02 17:37:46,266 - INFO - Epoch 789: train_loss=0.8234
2025-02-02 17:37:46,401 - INFO - Epoch 789: train_loss=0.7656
2025-02-02 17:37:47,056 - INFO - Epoch 789: val_loss=1.9992, val_acc=33.33%
2025-02-02 17:37:47,060 - INFO - ####################Training epoch 790####################
2025-02-02 17:37:47,717 - INFO - Epoch 790: train_loss=0.8431
2025-02-02 17:37:47,875 - INFO - Epoch 790: train_loss=0.8686
2025-02-02 17:37:48,010 - INFO - Epoch 790: train_loss=0.8863
2025-02-02 17:37:48,655 - INFO - Epoch 790: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:37:48,659 - INFO - ####################Training epoch 791####################
2025-02-02 17:37:49,361 - INFO - Epoch 791: train_loss=0.9289
2025-02-02 17:37:49,519 - INFO - Epoch 791: train_loss=0.8664
2025-02-02 17:37:49,654 - INFO - Epoch 791: train_loss=0.6752
2025-02-02 17:37:50,300 - INFO - Epoch 791: val_loss=1.9953, val_acc=33.33%
2025-02-02 17:37:50,304 - INFO - ####################Training epoch 792####################
2025-02-02 17:37:50,948 - INFO - Epoch 792: train_loss=0.8924
2025-02-02 17:37:51,106 - INFO - Epoch 792: train_loss=0.8801
2025-02-02 17:37:51,241 - INFO - Epoch 792: train_loss=0.7450
2025-02-02 17:37:51,968 - INFO - Epoch 792: val_loss=1.9946, val_acc=33.33%
2025-02-02 17:37:51,973 - INFO - ####################Training epoch 793####################
2025-02-02 17:37:52,646 - INFO - Epoch 793: train_loss=0.8803
2025-02-02 17:37:52,804 - INFO - Epoch 793: train_loss=0.8588
2025-02-02 17:37:52,939 - INFO - Epoch 793: train_loss=0.8236
2025-02-02 17:37:53,589 - INFO - Epoch 793: val_loss=1.9932, val_acc=33.33%
2025-02-02 17:37:53,593 - INFO - ####################Training epoch 794####################
2025-02-02 17:37:54,238 - INFO - Epoch 794: train_loss=0.9355
2025-02-02 17:37:54,396 - INFO - Epoch 794: train_loss=0.7472
2025-02-02 17:37:54,531 - INFO - Epoch 794: train_loss=0.9622
2025-02-02 17:37:55,266 - INFO - Epoch 794: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:37:55,271 - INFO - ####################Training epoch 795####################
2025-02-02 17:37:55,969 - INFO - Epoch 795: train_loss=0.8080
2025-02-02 17:37:56,126 - INFO - Epoch 795: train_loss=0.8490
2025-02-02 17:37:56,261 - INFO - Epoch 795: train_loss=1.0320
2025-02-02 17:37:56,927 - INFO - Epoch 795: val_loss=1.9979, val_acc=33.33%
2025-02-02 17:37:56,931 - INFO - ####################Training epoch 796####################
2025-02-02 17:37:57,563 - INFO - Epoch 796: train_loss=0.8972
2025-02-02 17:37:57,721 - INFO - Epoch 796: train_loss=0.9305
2025-02-02 17:37:57,855 - INFO - Epoch 796: train_loss=0.5936
2025-02-02 17:37:58,535 - INFO - Epoch 796: val_loss=2.0006, val_acc=33.33%
2025-02-02 17:37:58,539 - INFO - ####################Training epoch 797####################
2025-02-02 17:37:59,199 - INFO - Epoch 797: train_loss=0.8449
2025-02-02 17:37:59,357 - INFO - Epoch 797: train_loss=0.8529
2025-02-02 17:37:59,492 - INFO - Epoch 797: train_loss=0.9282
2025-02-02 17:38:00,182 - INFO - Epoch 797: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:38:00,185 - INFO - ####################Training epoch 798####################
2025-02-02 17:38:00,851 - INFO - Epoch 798: train_loss=0.8491
2025-02-02 17:38:01,008 - INFO - Epoch 798: train_loss=0.8930
2025-02-02 17:38:01,142 - INFO - Epoch 798: train_loss=0.8092
2025-02-02 17:38:01,826 - INFO - Epoch 798: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:38:01,829 - INFO - ####################Training epoch 799####################
2025-02-02 17:38:02,481 - INFO - Epoch 799: train_loss=0.7995
2025-02-02 17:38:02,640 - INFO - Epoch 799: train_loss=0.8721
2025-02-02 17:38:02,775 - INFO - Epoch 799: train_loss=0.9870
2025-02-02 17:38:03,439 - INFO - Epoch 799: val_loss=1.9981, val_acc=33.33%
2025-02-02 17:38:03,443 - INFO - ####################Training epoch 800####################
2025-02-02 17:38:04,116 - INFO - Epoch 800: train_loss=0.8651
2025-02-02 17:38:04,275 - INFO - Epoch 800: train_loss=0.8137
2025-02-02 17:38:04,409 - INFO - Epoch 800: train_loss=0.9685
2025-02-02 17:38:05,104 - INFO - Epoch 800: val_loss=2.0001, val_acc=33.33%
2025-02-02 17:38:05,108 - INFO - ####################Training epoch 801####################
2025-02-02 17:38:05,770 - INFO - Epoch 801: train_loss=0.8267
2025-02-02 17:38:05,928 - INFO - Epoch 801: train_loss=0.8561
2025-02-02 17:38:06,062 - INFO - Epoch 801: train_loss=0.9530
2025-02-02 17:38:06,744 - INFO - Epoch 801: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:38:06,748 - INFO - ####################Training epoch 802####################
2025-02-02 17:38:07,416 - INFO - Epoch 802: train_loss=0.7719
2025-02-02 17:38:07,574 - INFO - Epoch 802: train_loss=0.9118
2025-02-02 17:38:07,709 - INFO - Epoch 802: train_loss=0.9586
2025-02-02 17:38:08,421 - INFO - Epoch 802: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:38:08,425 - INFO - ####################Training epoch 803####################
2025-02-02 17:38:09,065 - INFO - Epoch 803: train_loss=0.9350
2025-02-02 17:38:09,222 - INFO - Epoch 803: train_loss=0.8236
2025-02-02 17:38:09,356 - INFO - Epoch 803: train_loss=0.7773
2025-02-02 17:38:10,053 - INFO - Epoch 803: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:38:10,056 - INFO - ####################Training epoch 804####################
2025-02-02 17:38:10,715 - INFO - Epoch 804: train_loss=0.8822
2025-02-02 17:38:10,873 - INFO - Epoch 804: train_loss=0.8250
2025-02-02 17:38:11,008 - INFO - Epoch 804: train_loss=0.9020
2025-02-02 17:38:11,756 - INFO - Epoch 804: val_loss=2.0017, val_acc=33.33%
2025-02-02 17:38:11,760 - INFO - ####################Training epoch 805####################
2025-02-02 17:38:12,429 - INFO - Epoch 805: train_loss=0.8706
2025-02-02 17:38:12,587 - INFO - Epoch 805: train_loss=0.8994
2025-02-02 17:38:12,721 - INFO - Epoch 805: train_loss=0.7413
2025-02-02 17:38:13,390 - INFO - Epoch 805: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:38:13,393 - INFO - ####################Training epoch 806####################
2025-02-02 17:38:14,056 - INFO - Epoch 806: train_loss=0.9378
2025-02-02 17:38:14,214 - INFO - Epoch 806: train_loss=0.8109
2025-02-02 17:38:14,348 - INFO - Epoch 806: train_loss=0.7881
2025-02-02 17:38:15,090 - INFO - Epoch 806: val_loss=1.9950, val_acc=33.33%
2025-02-02 17:38:15,094 - INFO - ####################Training epoch 807####################
2025-02-02 17:38:15,752 - INFO - Epoch 807: train_loss=0.7713
2025-02-02 17:38:15,910 - INFO - Epoch 807: train_loss=1.0243
2025-02-02 17:38:16,045 - INFO - Epoch 807: train_loss=0.6837
2025-02-02 17:38:16,722 - INFO - Epoch 807: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:38:16,726 - INFO - ####################Training epoch 808####################
2025-02-02 17:38:17,385 - INFO - Epoch 808: train_loss=0.8503
2025-02-02 17:38:17,543 - INFO - Epoch 808: train_loss=0.7735
2025-02-02 17:38:17,677 - INFO - Epoch 808: train_loss=1.1067
2025-02-02 17:38:18,401 - INFO - Epoch 808: val_loss=2.0002, val_acc=33.33%
2025-02-02 17:38:18,405 - INFO - ####################Training epoch 809####################
2025-02-02 17:38:19,076 - INFO - Epoch 809: train_loss=0.8416
2025-02-02 17:38:19,234 - INFO - Epoch 809: train_loss=0.8381
2025-02-02 17:38:19,368 - INFO - Epoch 809: train_loss=0.9692
2025-02-02 17:38:20,053 - INFO - Epoch 809: val_loss=1.9927, val_acc=33.33%
2025-02-02 17:38:20,057 - INFO - ####################Training epoch 810####################
2025-02-02 17:38:20,709 - INFO - Epoch 810: train_loss=0.8320
2025-02-02 17:38:20,866 - INFO - Epoch 810: train_loss=0.8997
2025-02-02 17:38:21,001 - INFO - Epoch 810: train_loss=0.8379
2025-02-02 17:38:21,722 - INFO - Epoch 810: val_loss=2.0021, val_acc=33.33%
2025-02-02 17:38:21,725 - INFO - ####################Training epoch 811####################
2025-02-02 17:38:22,362 - INFO - Epoch 811: train_loss=0.9980
2025-02-02 17:38:22,519 - INFO - Epoch 811: train_loss=0.7443
2025-02-02 17:38:22,653 - INFO - Epoch 811: train_loss=0.8028
2025-02-02 17:38:23,315 - INFO - Epoch 811: val_loss=1.9929, val_acc=33.33%
2025-02-02 17:38:23,319 - INFO - ####################Training epoch 812####################
2025-02-02 17:38:23,981 - INFO - Epoch 812: train_loss=0.8795
2025-02-02 17:38:24,138 - INFO - Epoch 812: train_loss=0.8451
2025-02-02 17:38:24,273 - INFO - Epoch 812: train_loss=0.8584
2025-02-02 17:38:25,005 - INFO - Epoch 812: val_loss=2.0018, val_acc=33.33%
2025-02-02 17:38:25,008 - INFO - ####################Training epoch 813####################
2025-02-02 17:38:25,666 - INFO - Epoch 813: train_loss=0.7195
2025-02-02 17:38:25,824 - INFO - Epoch 813: train_loss=0.9945
2025-02-02 17:38:25,959 - INFO - Epoch 813: train_loss=0.8822
2025-02-02 17:38:26,609 - INFO - Epoch 813: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:38:26,613 - INFO - ####################Training epoch 814####################
2025-02-02 17:38:27,280 - INFO - Epoch 814: train_loss=0.8804
2025-02-02 17:38:27,438 - INFO - Epoch 814: train_loss=0.8380
2025-02-02 17:38:27,572 - INFO - Epoch 814: train_loss=0.8659
2025-02-02 17:38:28,285 - INFO - Epoch 814: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:38:28,289 - INFO - ####################Training epoch 815####################
2025-02-02 17:38:28,953 - INFO - Epoch 815: train_loss=1.0082
2025-02-02 17:38:29,112 - INFO - Epoch 815: train_loss=0.7565
2025-02-02 17:38:29,250 - INFO - Epoch 815: train_loss=0.7579
2025-02-02 17:38:29,959 - INFO - Epoch 815: val_loss=1.9997, val_acc=33.33%
2025-02-02 17:38:29,963 - INFO - ####################Training epoch 816####################
2025-02-02 17:38:30,610 - INFO - Epoch 816: train_loss=0.8675
2025-02-02 17:38:30,768 - INFO - Epoch 816: train_loss=0.7954
2025-02-02 17:38:30,919 - INFO - Epoch 816: train_loss=1.0086
2025-02-02 17:38:31,614 - INFO - Epoch 816: val_loss=1.9979, val_acc=33.33%
2025-02-02 17:38:31,618 - INFO - ####################Training epoch 817####################
2025-02-02 17:38:32,296 - INFO - Epoch 817: train_loss=1.0131
2025-02-02 17:38:32,454 - INFO - Epoch 817: train_loss=0.7055
2025-02-02 17:38:32,590 - INFO - Epoch 817: train_loss=0.8829
2025-02-02 17:38:33,286 - INFO - Epoch 817: val_loss=1.9946, val_acc=33.33%
2025-02-02 17:38:33,289 - INFO - ####################Training epoch 818####################
2025-02-02 17:38:33,942 - INFO - Epoch 818: train_loss=0.8603
2025-02-02 17:38:34,109 - INFO - Epoch 818: train_loss=0.8548
2025-02-02 17:38:34,247 - INFO - Epoch 818: train_loss=0.8744
2025-02-02 17:38:34,923 - INFO - Epoch 818: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:38:34,927 - INFO - ####################Training epoch 819####################
2025-02-02 17:38:35,586 - INFO - Epoch 819: train_loss=0.8167
2025-02-02 17:38:35,744 - INFO - Epoch 819: train_loss=0.9737
2025-02-02 17:38:35,879 - INFO - Epoch 819: train_loss=0.6892
2025-02-02 17:38:36,526 - INFO - Epoch 819: val_loss=1.9992, val_acc=33.33%
2025-02-02 17:38:36,530 - INFO - ####################Training epoch 820####################
2025-02-02 17:38:37,183 - INFO - Epoch 820: train_loss=0.8551
2025-02-02 17:38:37,353 - INFO - Epoch 820: train_loss=0.9151
2025-02-02 17:38:37,495 - INFO - Epoch 820: train_loss=0.7488
2025-02-02 17:38:38,180 - INFO - Epoch 820: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:38:38,183 - INFO - ####################Training epoch 821####################
2025-02-02 17:38:38,839 - INFO - Epoch 821: train_loss=0.9411
2025-02-02 17:38:38,996 - INFO - Epoch 821: train_loss=0.7691
2025-02-02 17:38:39,131 - INFO - Epoch 821: train_loss=0.8901
2025-02-02 17:38:39,785 - INFO - Epoch 821: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:38:39,789 - INFO - ####################Training epoch 822####################
2025-02-02 17:38:40,425 - INFO - Epoch 822: train_loss=0.7548
2025-02-02 17:38:40,585 - INFO - Epoch 822: train_loss=0.9665
2025-02-02 17:38:40,720 - INFO - Epoch 822: train_loss=0.8665
2025-02-02 17:38:41,392 - INFO - Epoch 822: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:38:41,396 - INFO - ####################Training epoch 823####################
2025-02-02 17:38:42,133 - INFO - Epoch 823: train_loss=0.8960
2025-02-02 17:38:42,290 - INFO - Epoch 823: train_loss=0.7994
2025-02-02 17:38:42,425 - INFO - Epoch 823: train_loss=0.9353
2025-02-02 17:38:43,110 - INFO - Epoch 823: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:38:43,113 - INFO - ####################Training epoch 824####################
2025-02-02 17:38:43,780 - INFO - Epoch 824: train_loss=0.8829
2025-02-02 17:38:43,937 - INFO - Epoch 824: train_loss=0.8742
2025-02-02 17:38:44,072 - INFO - Epoch 824: train_loss=0.7736
2025-02-02 17:38:44,741 - INFO - Epoch 824: val_loss=1.9981, val_acc=33.33%
2025-02-02 17:38:44,745 - INFO - ####################Training epoch 825####################
2025-02-02 17:38:45,411 - INFO - Epoch 825: train_loss=0.9105
2025-02-02 17:38:45,569 - INFO - Epoch 825: train_loss=0.7692
2025-02-02 17:38:45,703 - INFO - Epoch 825: train_loss=0.9651
2025-02-02 17:38:46,350 - INFO - Epoch 825: val_loss=1.9995, val_acc=33.33%
2025-02-02 17:38:46,354 - INFO - ####################Training epoch 826####################
2025-02-02 17:38:47,013 - INFO - Epoch 826: train_loss=0.9772
2025-02-02 17:38:47,170 - INFO - Epoch 826: train_loss=0.8087
2025-02-02 17:38:47,305 - INFO - Epoch 826: train_loss=0.6971
2025-02-02 17:38:47,960 - INFO - Epoch 826: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:38:47,964 - INFO - ####################Training epoch 827####################
2025-02-02 17:38:48,609 - INFO - Epoch 827: train_loss=0.8814
2025-02-02 17:38:48,766 - INFO - Epoch 827: train_loss=0.8808
2025-02-02 17:38:48,901 - INFO - Epoch 827: train_loss=0.7625
2025-02-02 17:38:49,569 - INFO - Epoch 827: val_loss=1.9976, val_acc=33.33%
2025-02-02 17:38:49,572 - INFO - ####################Training epoch 828####################
2025-02-02 17:38:50,263 - INFO - Epoch 828: train_loss=0.8175
2025-02-02 17:38:50,421 - INFO - Epoch 828: train_loss=0.8708
2025-02-02 17:38:50,555 - INFO - Epoch 828: train_loss=0.9526
2025-02-02 17:38:51,226 - INFO - Epoch 828: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:38:51,230 - INFO - ####################Training epoch 829####################
2025-02-02 17:38:51,894 - INFO - Epoch 829: train_loss=0.8692
2025-02-02 17:38:52,051 - INFO - Epoch 829: train_loss=0.8531
2025-02-02 17:38:52,186 - INFO - Epoch 829: train_loss=0.8570
2025-02-02 17:38:52,853 - INFO - Epoch 829: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:38:52,857 - INFO - ####################Training epoch 830####################
2025-02-02 17:38:53,523 - INFO - Epoch 830: train_loss=0.8474
2025-02-02 17:38:53,681 - INFO - Epoch 830: train_loss=0.7976
2025-02-02 17:38:53,816 - INFO - Epoch 830: train_loss=1.0581
2025-02-02 17:38:54,474 - INFO - Epoch 830: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:38:54,478 - INFO - ####################Training epoch 831####################
2025-02-02 17:38:55,139 - INFO - Epoch 831: train_loss=0.8667
2025-02-02 17:38:55,296 - INFO - Epoch 831: train_loss=0.9992
2025-02-02 17:38:55,431 - INFO - Epoch 831: train_loss=0.5021
2025-02-02 17:38:56,096 - INFO - Epoch 831: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:38:56,100 - INFO - ####################Training epoch 832####################
2025-02-02 17:38:56,759 - INFO - Epoch 832: train_loss=0.8757
2025-02-02 17:38:56,917 - INFO - Epoch 832: train_loss=0.7990
2025-02-02 17:38:57,052 - INFO - Epoch 832: train_loss=0.9741
2025-02-02 17:38:57,724 - INFO - Epoch 832: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:38:57,728 - INFO - ####################Training epoch 833####################
2025-02-02 17:38:58,435 - INFO - Epoch 833: train_loss=0.8934
2025-02-02 17:38:58,593 - INFO - Epoch 833: train_loss=0.7738
2025-02-02 17:38:58,727 - INFO - Epoch 833: train_loss=1.0022
2025-02-02 17:38:59,404 - INFO - Epoch 833: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:38:59,408 - INFO - ####################Training epoch 834####################
2025-02-02 17:39:00,054 - INFO - Epoch 834: train_loss=0.7947
2025-02-02 17:39:00,211 - INFO - Epoch 834: train_loss=0.8850
2025-02-02 17:39:00,345 - INFO - Epoch 834: train_loss=0.9673
2025-02-02 17:39:01,015 - INFO - Epoch 834: val_loss=1.9956, val_acc=33.33%
2025-02-02 17:39:01,019 - INFO - ####################Training epoch 835####################
2025-02-02 17:39:01,665 - INFO - Epoch 835: train_loss=0.7884
2025-02-02 17:39:01,824 - INFO - Epoch 835: train_loss=0.9604
2025-02-02 17:39:01,959 - INFO - Epoch 835: train_loss=0.7905
2025-02-02 17:39:02,653 - INFO - Epoch 835: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:39:02,656 - INFO - ####################Training epoch 836####################
2025-02-02 17:39:03,347 - INFO - Epoch 836: train_loss=0.8419
2025-02-02 17:39:03,504 - INFO - Epoch 836: train_loss=0.8237
2025-02-02 17:39:03,638 - INFO - Epoch 836: train_loss=1.0106
2025-02-02 17:39:04,311 - INFO - Epoch 836: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:39:04,314 - INFO - ####################Training epoch 837####################
2025-02-02 17:39:04,975 - INFO - Epoch 837: train_loss=0.8887
2025-02-02 17:39:05,132 - INFO - Epoch 837: train_loss=0.8420
2025-02-02 17:39:05,267 - INFO - Epoch 837: train_loss=0.8482
2025-02-02 17:39:05,949 - INFO - Epoch 837: val_loss=1.9897, val_acc=33.33%
2025-02-02 17:39:05,952 - INFO - ####################Training epoch 838####################
2025-02-02 17:39:06,642 - INFO - Epoch 838: train_loss=0.9398
2025-02-02 17:39:06,800 - INFO - Epoch 838: train_loss=0.8102
2025-02-02 17:39:06,935 - INFO - Epoch 838: train_loss=0.7889
2025-02-02 17:39:07,588 - INFO - Epoch 838: val_loss=1.9967, val_acc=33.33%
2025-02-02 17:39:07,592 - INFO - ####################Training epoch 839####################
2025-02-02 17:39:08,261 - INFO - Epoch 839: train_loss=0.8712
2025-02-02 17:39:08,420 - INFO - Epoch 839: train_loss=0.8119
2025-02-02 17:39:08,555 - INFO - Epoch 839: train_loss=0.9745
2025-02-02 17:39:09,215 - INFO - Epoch 839: val_loss=1.9997, val_acc=33.33%
2025-02-02 17:39:09,219 - INFO - ####################Training epoch 840####################
2025-02-02 17:39:09,869 - INFO - Epoch 840: train_loss=0.8332
2025-02-02 17:39:10,027 - INFO - Epoch 840: train_loss=0.8487
2025-02-02 17:39:10,162 - INFO - Epoch 840: train_loss=0.9605
2025-02-02 17:39:10,848 - INFO - Epoch 840: val_loss=1.9978, val_acc=33.33%
2025-02-02 17:39:10,852 - INFO - ####################Training epoch 841####################
2025-02-02 17:39:11,517 - INFO - Epoch 841: train_loss=0.9695
2025-02-02 17:39:11,675 - INFO - Epoch 841: train_loss=0.7630
2025-02-02 17:39:11,809 - INFO - Epoch 841: train_loss=0.8341
2025-02-02 17:39:12,474 - INFO - Epoch 841: val_loss=1.9973, val_acc=33.33%
2025-02-02 17:39:12,477 - INFO - ####################Training epoch 842####################
2025-02-02 17:39:13,141 - INFO - Epoch 842: train_loss=0.8078
2025-02-02 17:39:13,298 - INFO - Epoch 842: train_loss=0.9842
2025-02-02 17:39:13,433 - INFO - Epoch 842: train_loss=0.6866
2025-02-02 17:39:14,118 - INFO - Epoch 842: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:39:14,122 - INFO - ####################Training epoch 843####################
2025-02-02 17:39:14,782 - INFO - Epoch 843: train_loss=0.8497
2025-02-02 17:39:14,941 - INFO - Epoch 843: train_loss=0.8850
2025-02-02 17:39:15,076 - INFO - Epoch 843: train_loss=0.8222
2025-02-02 17:39:15,726 - INFO - Epoch 843: val_loss=1.9984, val_acc=33.33%
2025-02-02 17:39:15,729 - INFO - ####################Training epoch 844####################
2025-02-02 17:39:16,388 - INFO - Epoch 844: train_loss=0.8470
2025-02-02 17:39:16,545 - INFO - Epoch 844: train_loss=0.7900
2025-02-02 17:39:16,679 - INFO - Epoch 844: train_loss=1.0746
2025-02-02 17:39:17,356 - INFO - Epoch 844: val_loss=2.0001, val_acc=33.33%
2025-02-02 17:39:17,360 - INFO - ####################Training epoch 845####################
2025-02-02 17:39:18,017 - INFO - Epoch 845: train_loss=0.8254
2025-02-02 17:39:18,175 - INFO - Epoch 845: train_loss=0.9768
2025-02-02 17:39:18,310 - INFO - Epoch 845: train_loss=0.6706
2025-02-02 17:39:18,976 - INFO - Epoch 845: val_loss=2.0025, val_acc=33.33%
2025-02-02 17:39:18,979 - INFO - ####################Training epoch 846####################
2025-02-02 17:39:19,636 - INFO - Epoch 846: train_loss=0.9011
2025-02-02 17:39:19,794 - INFO - Epoch 846: train_loss=0.7911
2025-02-02 17:39:19,928 - INFO - Epoch 846: train_loss=0.9496
2025-02-02 17:39:20,582 - INFO - Epoch 846: val_loss=1.9886, val_acc=33.33%
2025-02-02 17:39:20,586 - INFO - ####################Training epoch 847####################
2025-02-02 17:39:21,254 - INFO - Epoch 847: train_loss=0.9051
2025-02-02 17:39:21,412 - INFO - Epoch 847: train_loss=0.7927
2025-02-02 17:39:21,547 - INFO - Epoch 847: train_loss=0.9379
2025-02-02 17:39:22,199 - INFO - Epoch 847: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:39:22,203 - INFO - ####################Training epoch 848####################
2025-02-02 17:39:22,860 - INFO - Epoch 848: train_loss=0.8367
2025-02-02 17:39:23,018 - INFO - Epoch 848: train_loss=0.9244
2025-02-02 17:39:23,152 - INFO - Epoch 848: train_loss=0.7705
2025-02-02 17:39:23,886 - INFO - Epoch 848: val_loss=1.9949, val_acc=33.33%
2025-02-02 17:39:23,890 - INFO - ####################Training epoch 849####################
2025-02-02 17:39:24,542 - INFO - Epoch 849: train_loss=0.7917
2025-02-02 17:39:24,699 - INFO - Epoch 849: train_loss=0.8765
2025-02-02 17:39:24,833 - INFO - Epoch 849: train_loss=1.0057
2025-02-02 17:39:25,483 - INFO - Epoch 849: val_loss=2.0000, val_acc=33.33%
2025-02-02 17:39:25,487 - INFO - ####################Training epoch 850####################
2025-02-02 17:39:26,147 - INFO - Epoch 850: train_loss=0.8235
2025-02-02 17:39:26,304 - INFO - Epoch 850: train_loss=0.9373
2025-02-02 17:39:26,438 - INFO - Epoch 850: train_loss=0.7785
2025-02-02 17:39:27,105 - INFO - Epoch 850: val_loss=1.9898, val_acc=33.33%
2025-02-02 17:39:27,108 - INFO - ####################Training epoch 851####################
2025-02-02 17:39:27,764 - INFO - Epoch 851: train_loss=0.9269
2025-02-02 17:39:27,921 - INFO - Epoch 851: train_loss=0.8501
2025-02-02 17:39:28,055 - INFO - Epoch 851: train_loss=0.7234
2025-02-02 17:39:28,720 - INFO - Epoch 851: val_loss=1.9972, val_acc=33.33%
2025-02-02 17:39:28,724 - INFO - ####################Training epoch 852####################
2025-02-02 17:39:29,367 - INFO - Epoch 852: train_loss=0.7534
2025-02-02 17:39:29,525 - INFO - Epoch 852: train_loss=0.9103
2025-02-02 17:39:29,659 - INFO - Epoch 852: train_loss=0.9945
2025-02-02 17:39:30,314 - INFO - Epoch 852: val_loss=1.9977, val_acc=33.33%
2025-02-02 17:39:30,318 - INFO - ####################Training epoch 853####################
2025-02-02 17:39:30,985 - INFO - Epoch 853: train_loss=0.8371
2025-02-02 17:39:31,142 - INFO - Epoch 853: train_loss=0.9414
2025-02-02 17:39:31,277 - INFO - Epoch 853: train_loss=0.7273
2025-02-02 17:39:31,994 - INFO - Epoch 853: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:39:31,997 - INFO - ####################Training epoch 854####################
2025-02-02 17:39:32,655 - INFO - Epoch 854: train_loss=0.9286
2025-02-02 17:39:32,813 - INFO - Epoch 854: train_loss=0.8034
2025-02-02 17:39:32,947 - INFO - Epoch 854: train_loss=0.8410
2025-02-02 17:39:33,618 - INFO - Epoch 854: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:39:33,622 - INFO - ####################Training epoch 855####################
2025-02-02 17:39:34,289 - INFO - Epoch 855: train_loss=0.8691
2025-02-02 17:39:34,447 - INFO - Epoch 855: train_loss=0.8531
2025-02-02 17:39:34,581 - INFO - Epoch 855: train_loss=0.8539
2025-02-02 17:39:35,269 - INFO - Epoch 855: val_loss=2.0011, val_acc=33.33%
2025-02-02 17:39:35,273 - INFO - ####################Training epoch 856####################
2025-02-02 17:39:35,921 - INFO - Epoch 856: train_loss=0.8495
2025-02-02 17:39:36,080 - INFO - Epoch 856: train_loss=0.9295
2025-02-02 17:39:36,215 - INFO - Epoch 856: train_loss=0.7181
2025-02-02 17:39:36,896 - INFO - Epoch 856: val_loss=1.9968, val_acc=33.33%
2025-02-02 17:39:36,901 - INFO - ####################Training epoch 857####################
2025-02-02 17:39:37,584 - INFO - Epoch 857: train_loss=0.9286
2025-02-02 17:39:37,743 - INFO - Epoch 857: train_loss=0.7722
2025-02-02 17:39:37,878 - INFO - Epoch 857: train_loss=0.9161
2025-02-02 17:39:38,545 - INFO - Epoch 857: val_loss=1.9944, val_acc=33.33%
2025-02-02 17:39:38,549 - INFO - ####################Training epoch 858####################
2025-02-02 17:39:39,183 - INFO - Epoch 858: train_loss=0.7991
2025-02-02 17:39:39,342 - INFO - Epoch 858: train_loss=0.9354
2025-02-02 17:39:39,477 - INFO - Epoch 858: train_loss=0.8088
2025-02-02 17:39:40,182 - INFO - Epoch 858: val_loss=2.0011, val_acc=33.33%
2025-02-02 17:39:40,185 - INFO - ####################Training epoch 859####################
2025-02-02 17:39:40,869 - INFO - Epoch 859: train_loss=0.6749
2025-02-02 17:39:41,028 - INFO - Epoch 859: train_loss=0.9681
2025-02-02 17:39:41,163 - INFO - Epoch 859: train_loss=1.0577
2025-02-02 17:39:41,825 - INFO - Epoch 859: val_loss=1.9922, val_acc=33.33%
2025-02-02 17:39:41,829 - INFO - ####################Training epoch 860####################
2025-02-02 17:39:42,480 - INFO - Epoch 860: train_loss=0.9451
2025-02-02 17:39:42,638 - INFO - Epoch 860: train_loss=0.6863
2025-02-02 17:39:42,774 - INFO - Epoch 860: train_loss=1.0786
2025-02-02 17:39:43,452 - INFO - Epoch 860: val_loss=1.9964, val_acc=33.33%
2025-02-02 17:39:43,455 - INFO - ####################Training epoch 861####################
2025-02-02 17:39:44,090 - INFO - Epoch 861: train_loss=0.8927
2025-02-02 17:39:44,248 - INFO - Epoch 861: train_loss=0.9260
2025-02-02 17:39:44,382 - INFO - Epoch 861: train_loss=0.6007
2025-02-02 17:39:45,062 - INFO - Epoch 861: val_loss=1.9973, val_acc=33.33%
2025-02-02 17:39:45,066 - INFO - ####################Training epoch 862####################
2025-02-02 17:39:45,734 - INFO - Epoch 862: train_loss=0.9724
2025-02-02 17:39:45,892 - INFO - Epoch 862: train_loss=0.8146
2025-02-02 17:39:46,030 - INFO - Epoch 862: train_loss=0.6965
2025-02-02 17:39:46,699 - INFO - Epoch 862: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:39:46,703 - INFO - ####################Training epoch 863####################
2025-02-02 17:39:47,346 - INFO - Epoch 863: train_loss=0.8195
2025-02-02 17:39:47,504 - INFO - Epoch 863: train_loss=0.8837
2025-02-02 17:39:47,638 - INFO - Epoch 863: train_loss=0.9229
2025-02-02 17:39:48,290 - INFO - Epoch 863: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:39:48,294 - INFO - ####################Training epoch 864####################
2025-02-02 17:39:48,994 - INFO - Epoch 864: train_loss=0.8443
2025-02-02 17:39:49,151 - INFO - Epoch 864: train_loss=0.8989
2025-02-02 17:39:49,286 - INFO - Epoch 864: train_loss=0.7995
2025-02-02 17:39:49,940 - INFO - Epoch 864: val_loss=1.9996, val_acc=33.33%
2025-02-02 17:39:49,944 - INFO - ####################Training epoch 865####################
2025-02-02 17:39:50,605 - INFO - Epoch 865: train_loss=0.7792
2025-02-02 17:39:50,763 - INFO - Epoch 865: train_loss=0.9948
2025-02-02 17:39:50,898 - INFO - Epoch 865: train_loss=0.7295
2025-02-02 17:39:51,571 - INFO - Epoch 865: val_loss=1.9973, val_acc=33.33%
2025-02-02 17:39:51,575 - INFO - ####################Training epoch 866####################
2025-02-02 17:39:52,231 - INFO - Epoch 866: train_loss=0.9225
2025-02-02 17:39:52,388 - INFO - Epoch 866: train_loss=0.8056
2025-02-02 17:39:52,523 - INFO - Epoch 866: train_loss=0.8518
2025-02-02 17:39:53,200 - INFO - Epoch 866: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:39:53,204 - INFO - ####################Training epoch 867####################
2025-02-02 17:39:53,870 - INFO - Epoch 867: train_loss=0.8497
2025-02-02 17:39:54,028 - INFO - Epoch 867: train_loss=0.8421
2025-02-02 17:39:54,163 - INFO - Epoch 867: train_loss=0.9582
2025-02-02 17:39:54,848 - INFO - Epoch 867: val_loss=1.9963, val_acc=33.33%
2025-02-02 17:39:54,851 - INFO - ####################Training epoch 868####################
2025-02-02 17:39:55,502 - INFO - Epoch 868: train_loss=0.8300
2025-02-02 17:39:55,661 - INFO - Epoch 868: train_loss=1.0131
2025-02-02 17:39:55,795 - INFO - Epoch 868: train_loss=0.5594
2025-02-02 17:39:56,478 - INFO - Epoch 868: val_loss=1.9953, val_acc=33.33%
2025-02-02 17:39:56,482 - INFO - ####################Training epoch 869####################
2025-02-02 17:39:57,149 - INFO - Epoch 869: train_loss=0.7672
2025-02-02 17:39:57,308 - INFO - Epoch 869: train_loss=0.8708
2025-02-02 17:39:57,442 - INFO - Epoch 869: train_loss=1.0692
2025-02-02 17:39:58,102 - INFO - Epoch 869: val_loss=1.9978, val_acc=33.33%
2025-02-02 17:39:58,106 - INFO - ####################Training epoch 870####################
2025-02-02 17:39:58,738 - INFO - Epoch 870: train_loss=0.8957
2025-02-02 17:39:58,895 - INFO - Epoch 870: train_loss=0.9631
2025-02-02 17:39:59,030 - INFO - Epoch 870: train_loss=0.5134
2025-02-02 17:39:59,685 - INFO - Epoch 870: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:39:59,689 - INFO - ####################Training epoch 871####################
2025-02-02 17:40:00,352 - INFO - Epoch 871: train_loss=0.8290
2025-02-02 17:40:00,510 - INFO - Epoch 871: train_loss=0.8758
2025-02-02 17:40:00,644 - INFO - Epoch 871: train_loss=0.8987
2025-02-02 17:40:01,326 - INFO - Epoch 871: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:40:01,329 - INFO - ####################Training epoch 872####################
2025-02-02 17:40:01,992 - INFO - Epoch 872: train_loss=0.9191
2025-02-02 17:40:02,150 - INFO - Epoch 872: train_loss=0.8029
2025-02-02 17:40:02,284 - INFO - Epoch 872: train_loss=0.8717
2025-02-02 17:40:02,956 - INFO - Epoch 872: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:40:02,959 - INFO - ####################Training epoch 873####################
2025-02-02 17:40:03,617 - INFO - Epoch 873: train_loss=0.9542
2025-02-02 17:40:03,775 - INFO - Epoch 873: train_loss=0.7297
2025-02-02 17:40:03,910 - INFO - Epoch 873: train_loss=0.9616
2025-02-02 17:40:04,583 - INFO - Epoch 873: val_loss=2.0034, val_acc=33.33%
2025-02-02 17:40:04,587 - INFO - ####################Training epoch 874####################
2025-02-02 17:40:05,253 - INFO - Epoch 874: train_loss=0.8011
2025-02-02 17:40:05,410 - INFO - Epoch 874: train_loss=1.0272
2025-02-02 17:40:05,555 - INFO - Epoch 874: train_loss=0.5952
2025-02-02 17:40:06,226 - INFO - Epoch 874: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:40:06,230 - INFO - ####################Training epoch 875####################
2025-02-02 17:40:06,863 - INFO - Epoch 875: train_loss=0.8838
2025-02-02 17:40:07,021 - INFO - Epoch 875: train_loss=0.8628
2025-02-02 17:40:07,155 - INFO - Epoch 875: train_loss=0.7952
2025-02-02 17:40:07,824 - INFO - Epoch 875: val_loss=1.9924, val_acc=33.33%
2025-02-02 17:40:07,828 - INFO - ####################Training epoch 876####################
2025-02-02 17:40:08,491 - INFO - Epoch 876: train_loss=0.9569
2025-02-02 17:40:08,649 - INFO - Epoch 876: train_loss=0.7601
2025-02-02 17:40:08,783 - INFO - Epoch 876: train_loss=0.8740
2025-02-02 17:40:09,467 - INFO - Epoch 876: val_loss=1.9942, val_acc=33.33%
2025-02-02 17:40:09,471 - INFO - ####################Training epoch 877####################
2025-02-02 17:40:10,135 - INFO - Epoch 877: train_loss=0.7780
2025-02-02 17:40:10,293 - INFO - Epoch 877: train_loss=0.8907
2025-02-02 17:40:10,428 - INFO - Epoch 877: train_loss=0.9959
2025-02-02 17:40:11,117 - INFO - Epoch 877: val_loss=1.9998, val_acc=33.33%
2025-02-02 17:40:11,121 - INFO - ####################Training epoch 878####################
2025-02-02 17:40:11,751 - INFO - Epoch 878: train_loss=0.8332
2025-02-02 17:40:11,908 - INFO - Epoch 878: train_loss=0.9500
2025-02-02 17:40:12,042 - INFO - Epoch 878: train_loss=0.7069
2025-02-02 17:40:12,711 - INFO - Epoch 878: val_loss=1.9963, val_acc=33.33%
2025-02-02 17:40:12,715 - INFO - ####################Training epoch 879####################
2025-02-02 17:40:13,379 - INFO - Epoch 879: train_loss=0.9235
2025-02-02 17:40:13,537 - INFO - Epoch 879: train_loss=0.8456
2025-02-02 17:40:13,672 - INFO - Epoch 879: train_loss=0.7416
2025-02-02 17:40:14,389 - INFO - Epoch 879: val_loss=1.9952, val_acc=33.33%
2025-02-02 17:40:14,393 - INFO - ####################Training epoch 880####################
2025-02-02 17:40:15,040 - INFO - Epoch 880: train_loss=0.8494
2025-02-02 17:40:15,199 - INFO - Epoch 880: train_loss=0.8476
2025-02-02 17:40:15,334 - INFO - Epoch 880: train_loss=0.9323
2025-02-02 17:40:15,988 - INFO - Epoch 880: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:40:15,992 - INFO - ####################Training epoch 881####################
2025-02-02 17:40:16,640 - INFO - Epoch 881: train_loss=0.9157
2025-02-02 17:40:16,798 - INFO - Epoch 881: train_loss=0.7996
2025-02-02 17:40:16,933 - INFO - Epoch 881: train_loss=0.8849
2025-02-02 17:40:17,606 - INFO - Epoch 881: val_loss=1.9981, val_acc=33.33%
2025-02-02 17:40:17,610 - INFO - ####################Training epoch 882####################
2025-02-02 17:40:18,264 - INFO - Epoch 882: train_loss=0.9145
2025-02-02 17:40:18,422 - INFO - Epoch 882: train_loss=0.8246
2025-02-02 17:40:18,557 - INFO - Epoch 882: train_loss=0.8207
2025-02-02 17:40:19,214 - INFO - Epoch 882: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:40:19,217 - INFO - ####################Training epoch 883####################
2025-02-02 17:40:19,881 - INFO - Epoch 883: train_loss=0.8537
2025-02-02 17:40:20,039 - INFO - Epoch 883: train_loss=0.8899
2025-02-02 17:40:20,173 - INFO - Epoch 883: train_loss=0.7993
2025-02-02 17:40:20,832 - INFO - Epoch 883: val_loss=1.9984, val_acc=33.33%
2025-02-02 17:40:20,836 - INFO - ####################Training epoch 884####################
2025-02-02 17:40:21,495 - INFO - Epoch 884: train_loss=0.7783
2025-02-02 17:40:21,653 - INFO - Epoch 884: train_loss=0.8885
2025-02-02 17:40:21,788 - INFO - Epoch 884: train_loss=0.9942
2025-02-02 17:40:22,439 - INFO - Epoch 884: val_loss=1.9940, val_acc=33.33%
2025-02-02 17:40:22,443 - INFO - ####################Training epoch 885####################
2025-02-02 17:40:23,151 - INFO - Epoch 885: train_loss=0.7430
2025-02-02 17:40:23,309 - INFO - Epoch 885: train_loss=0.9338
2025-02-02 17:40:23,444 - INFO - Epoch 885: train_loss=0.9800
2025-02-02 17:40:24,097 - INFO - Epoch 885: val_loss=2.0026, val_acc=33.33%
2025-02-02 17:40:24,101 - INFO - ####################Training epoch 886####################
2025-02-02 17:40:24,765 - INFO - Epoch 886: train_loss=0.8074
2025-02-02 17:40:24,925 - INFO - Epoch 886: train_loss=0.8726
2025-02-02 17:40:25,060 - INFO - Epoch 886: train_loss=0.9871
2025-02-02 17:40:25,731 - INFO - Epoch 886: val_loss=2.0016, val_acc=33.33%
2025-02-02 17:40:25,735 - INFO - ####################Training epoch 887####################
2025-02-02 17:40:26,387 - INFO - Epoch 887: train_loss=0.8271
2025-02-02 17:40:26,546 - INFO - Epoch 887: train_loss=0.9066
2025-02-02 17:40:26,681 - INFO - Epoch 887: train_loss=0.8244
2025-02-02 17:40:27,364 - INFO - Epoch 887: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:40:27,368 - INFO - ####################Training epoch 888####################
2025-02-02 17:40:28,024 - INFO - Epoch 888: train_loss=0.7864
2025-02-02 17:40:28,182 - INFO - Epoch 888: train_loss=0.8794
2025-02-02 17:40:28,317 - INFO - Epoch 888: train_loss=1.0081
2025-02-02 17:40:28,995 - INFO - Epoch 888: val_loss=1.9996, val_acc=33.33%
2025-02-02 17:40:28,999 - INFO - ####################Training epoch 889####################
2025-02-02 17:40:29,634 - INFO - Epoch 889: train_loss=0.8571
2025-02-02 17:40:29,793 - INFO - Epoch 889: train_loss=0.7742
2025-02-02 17:40:29,927 - INFO - Epoch 889: train_loss=1.0797
2025-02-02 17:40:30,612 - INFO - Epoch 889: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:40:30,616 - INFO - ####################Training epoch 890####################
2025-02-02 17:40:31,309 - INFO - Epoch 890: train_loss=0.7736
2025-02-02 17:40:31,466 - INFO - Epoch 890: train_loss=0.8966
2025-02-02 17:40:31,602 - INFO - Epoch 890: train_loss=1.0030
2025-02-02 17:40:32,266 - INFO - Epoch 890: val_loss=1.9948, val_acc=33.33%
2025-02-02 17:40:32,269 - INFO - ####################Training epoch 891####################
2025-02-02 17:40:32,923 - INFO - Epoch 891: train_loss=0.9219
2025-02-02 17:40:33,081 - INFO - Epoch 891: train_loss=0.7277
2025-02-02 17:40:33,216 - INFO - Epoch 891: train_loss=1.0486
2025-02-02 17:40:33,884 - INFO - Epoch 891: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:40:33,888 - INFO - ####################Training epoch 892####################
2025-02-02 17:40:34,529 - INFO - Epoch 892: train_loss=0.8129
2025-02-02 17:40:34,687 - INFO - Epoch 892: train_loss=1.0156
2025-02-02 17:40:34,823 - INFO - Epoch 892: train_loss=0.5961
2025-02-02 17:40:35,484 - INFO - Epoch 892: val_loss=1.9943, val_acc=33.33%
2025-02-02 17:40:35,488 - INFO - ####################Training epoch 893####################
2025-02-02 17:40:36,152 - INFO - Epoch 893: train_loss=0.9602
2025-02-02 17:40:36,311 - INFO - Epoch 893: train_loss=0.7982
2025-02-02 17:40:36,446 - INFO - Epoch 893: train_loss=0.7708
2025-02-02 17:40:37,115 - INFO - Epoch 893: val_loss=1.9979, val_acc=33.33%
2025-02-02 17:40:37,119 - INFO - ####################Training epoch 894####################
2025-02-02 17:40:37,772 - INFO - Epoch 894: train_loss=0.8966
2025-02-02 17:40:37,931 - INFO - Epoch 894: train_loss=0.8499
2025-02-02 17:40:38,066 - INFO - Epoch 894: train_loss=0.7904
2025-02-02 17:40:38,735 - INFO - Epoch 894: val_loss=1.9971, val_acc=33.33%
2025-02-02 17:40:38,739 - INFO - ####################Training epoch 895####################
2025-02-02 17:40:39,390 - INFO - Epoch 895: train_loss=0.7673
2025-02-02 17:40:39,555 - INFO - Epoch 895: train_loss=0.9100
2025-02-02 17:40:39,691 - INFO - Epoch 895: train_loss=0.9663
2025-02-02 17:40:40,361 - INFO - Epoch 895: val_loss=1.9939, val_acc=33.33%
2025-02-02 17:40:40,365 - INFO - ####################Training epoch 896####################
2025-02-02 17:40:41,014 - INFO - Epoch 896: train_loss=0.8791
2025-02-02 17:40:41,173 - INFO - Epoch 896: train_loss=0.8356
2025-02-02 17:40:41,308 - INFO - Epoch 896: train_loss=0.8810
2025-02-02 17:40:41,990 - INFO - Epoch 896: val_loss=1.9949, val_acc=33.33%
2025-02-02 17:40:41,994 - INFO - ####################Training epoch 897####################
2025-02-02 17:40:42,655 - INFO - Epoch 897: train_loss=0.7685
2025-02-02 17:40:42,812 - INFO - Epoch 897: train_loss=0.8878
2025-02-02 17:40:42,948 - INFO - Epoch 897: train_loss=1.0236
2025-02-02 17:40:43,633 - INFO - Epoch 897: val_loss=1.9960, val_acc=33.33%
2025-02-02 17:40:43,637 - INFO - ####################Training epoch 898####################
2025-02-02 17:40:44,326 - INFO - Epoch 898: train_loss=1.0382
2025-02-02 17:40:44,485 - INFO - Epoch 898: train_loss=0.8016
2025-02-02 17:40:44,621 - INFO - Epoch 898: train_loss=0.5738
2025-02-02 17:40:45,300 - INFO - Epoch 898: val_loss=2.0008, val_acc=33.33%
2025-02-02 17:40:45,304 - INFO - ####################Training epoch 899####################
2025-02-02 17:40:45,962 - INFO - Epoch 899: train_loss=0.8581
2025-02-02 17:40:46,120 - INFO - Epoch 899: train_loss=0.7647
2025-02-02 17:40:46,254 - INFO - Epoch 899: train_loss=1.1128
2025-02-02 17:40:46,935 - INFO - Epoch 899: val_loss=1.9952, val_acc=33.33%
2025-02-02 17:40:46,938 - INFO - ####################Training epoch 900####################
2025-02-02 17:40:47,607 - INFO - Epoch 900: train_loss=0.8756
2025-02-02 17:40:47,766 - INFO - Epoch 900: train_loss=0.8242
2025-02-02 17:40:47,901 - INFO - Epoch 900: train_loss=0.9235
2025-02-02 17:40:48,619 - INFO - Epoch 900: val_loss=1.9928, val_acc=33.33%
2025-02-02 17:40:48,622 - INFO - ####################Training epoch 901####################
2025-02-02 17:40:49,281 - INFO - Epoch 901: train_loss=0.8925
2025-02-02 17:40:49,438 - INFO - Epoch 901: train_loss=0.7903
2025-02-02 17:40:49,573 - INFO - Epoch 901: train_loss=0.9629
2025-02-02 17:40:50,254 - INFO - Epoch 901: val_loss=1.9978, val_acc=33.33%
2025-02-02 17:40:50,258 - INFO - ####################Training epoch 902####################
2025-02-02 17:40:50,927 - INFO - Epoch 902: train_loss=0.9400
2025-02-02 17:40:51,085 - INFO - Epoch 902: train_loss=0.7417
2025-02-02 17:40:51,220 - INFO - Epoch 902: train_loss=0.9566
2025-02-02 17:40:51,901 - INFO - Epoch 902: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:40:51,905 - INFO - ####################Training epoch 903####################
2025-02-02 17:40:52,556 - INFO - Epoch 903: train_loss=0.8468
2025-02-02 17:40:52,714 - INFO - Epoch 903: train_loss=0.8826
2025-02-02 17:40:52,849 - INFO - Epoch 903: train_loss=0.8307
2025-02-02 17:40:53,521 - INFO - Epoch 903: val_loss=1.9940, val_acc=33.33%
2025-02-02 17:40:53,525 - INFO - ####################Training epoch 904####################
2025-02-02 17:40:54,163 - INFO - Epoch 904: train_loss=0.9596
2025-02-02 17:40:54,322 - INFO - Epoch 904: train_loss=0.7547
2025-02-02 17:40:54,456 - INFO - Epoch 904: train_loss=0.8738
2025-02-02 17:40:55,112 - INFO - Epoch 904: val_loss=1.9926, val_acc=33.33%
2025-02-02 17:40:55,116 - INFO - ####################Training epoch 905####################
2025-02-02 17:40:55,767 - INFO - Epoch 905: train_loss=0.8096
2025-02-02 17:40:55,926 - INFO - Epoch 905: train_loss=0.9033
2025-02-02 17:40:56,061 - INFO - Epoch 905: train_loss=0.8780
2025-02-02 17:40:56,781 - INFO - Epoch 905: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:40:56,785 - INFO - ####################Training epoch 906####################
2025-02-02 17:40:57,447 - INFO - Epoch 906: train_loss=0.8629
2025-02-02 17:40:57,605 - INFO - Epoch 906: train_loss=0.9247
2025-02-02 17:40:57,741 - INFO - Epoch 906: train_loss=0.6874
2025-02-02 17:40:58,410 - INFO - Epoch 906: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:40:58,414 - INFO - ####################Training epoch 907####################
2025-02-02 17:40:59,085 - INFO - Epoch 907: train_loss=0.8814
2025-02-02 17:40:59,243 - INFO - Epoch 907: train_loss=0.9005
2025-02-02 17:40:59,379 - INFO - Epoch 907: train_loss=0.7183
2025-02-02 17:41:00,048 - INFO - Epoch 907: val_loss=1.9949, val_acc=33.33%
2025-02-02 17:41:00,052 - INFO - ####################Training epoch 908####################
2025-02-02 17:41:00,721 - INFO - Epoch 908: train_loss=0.9403
2025-02-02 17:41:00,880 - INFO - Epoch 908: train_loss=0.9019
2025-02-02 17:41:01,015 - INFO - Epoch 908: train_loss=0.5586
2025-02-02 17:41:01,682 - INFO - Epoch 908: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:41:01,686 - INFO - ####################Training epoch 909####################
2025-02-02 17:41:02,347 - INFO - Epoch 909: train_loss=0.8889
2025-02-02 17:41:02,506 - INFO - Epoch 909: train_loss=0.8124
2025-02-02 17:41:02,641 - INFO - Epoch 909: train_loss=0.9258
2025-02-02 17:41:03,300 - INFO - Epoch 909: val_loss=2.0006, val_acc=33.33%
2025-02-02 17:41:03,304 - INFO - ####################Training epoch 910####################
2025-02-02 17:41:03,961 - INFO - Epoch 910: train_loss=0.8359
2025-02-02 17:41:04,120 - INFO - Epoch 910: train_loss=0.9103
2025-02-02 17:41:04,254 - INFO - Epoch 910: train_loss=0.8024
2025-02-02 17:41:04,943 - INFO - Epoch 910: val_loss=1.9987, val_acc=33.33%
2025-02-02 17:41:04,947 - INFO - ####################Training epoch 911####################
2025-02-02 17:41:05,631 - INFO - Epoch 911: train_loss=0.8328
2025-02-02 17:41:05,788 - INFO - Epoch 911: train_loss=0.7582
2025-02-02 17:41:05,923 - INFO - Epoch 911: train_loss=1.1928
2025-02-02 17:41:06,574 - INFO - Epoch 911: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:41:06,577 - INFO - ####################Training epoch 912####################
2025-02-02 17:41:07,219 - INFO - Epoch 912: train_loss=0.8898
2025-02-02 17:41:07,381 - INFO - Epoch 912: train_loss=0.8705
2025-02-02 17:41:07,515 - INFO - Epoch 912: train_loss=0.7702
2025-02-02 17:41:08,181 - INFO - Epoch 912: val_loss=1.9948, val_acc=33.33%
2025-02-02 17:41:08,185 - INFO - ####################Training epoch 913####################
2025-02-02 17:41:08,848 - INFO - Epoch 913: train_loss=0.9533
2025-02-02 17:41:09,005 - INFO - Epoch 913: train_loss=0.8503
2025-02-02 17:41:09,140 - INFO - Epoch 913: train_loss=0.6613
2025-02-02 17:41:09,814 - INFO - Epoch 913: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:41:09,818 - INFO - ####################Training epoch 914####################
2025-02-02 17:41:10,474 - INFO - Epoch 914: train_loss=0.8037
2025-02-02 17:41:10,632 - INFO - Epoch 914: train_loss=1.0093
2025-02-02 17:41:10,766 - INFO - Epoch 914: train_loss=0.6342
2025-02-02 17:41:11,424 - INFO - Epoch 914: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:41:11,428 - INFO - ####################Training epoch 915####################
2025-02-02 17:41:12,096 - INFO - Epoch 915: train_loss=0.8051
2025-02-02 17:41:12,253 - INFO - Epoch 915: train_loss=0.8457
2025-02-02 17:41:12,388 - INFO - Epoch 915: train_loss=1.0455
2025-02-02 17:41:13,071 - INFO - Epoch 915: val_loss=1.9946, val_acc=33.33%
2025-02-02 17:41:13,074 - INFO - ####################Training epoch 916####################
2025-02-02 17:41:13,782 - INFO - Epoch 916: train_loss=0.6930
2025-02-02 17:41:13,940 - INFO - Epoch 916: train_loss=0.9700
2025-02-02 17:41:14,075 - INFO - Epoch 916: train_loss=1.0072
2025-02-02 17:41:14,737 - INFO - Epoch 916: val_loss=1.9973, val_acc=33.33%
2025-02-02 17:41:14,741 - INFO - ####################Training epoch 917####################
2025-02-02 17:41:15,391 - INFO - Epoch 917: train_loss=0.8692
2025-02-02 17:41:15,548 - INFO - Epoch 917: train_loss=0.8692
2025-02-02 17:41:15,683 - INFO - Epoch 917: train_loss=0.8288
2025-02-02 17:41:16,353 - INFO - Epoch 917: val_loss=1.9998, val_acc=33.33%
2025-02-02 17:41:16,357 - INFO - ####################Training epoch 918####################
2025-02-02 17:41:17,022 - INFO - Epoch 918: train_loss=0.8839
2025-02-02 17:41:17,180 - INFO - Epoch 918: train_loss=0.8025
2025-02-02 17:41:17,316 - INFO - Epoch 918: train_loss=0.9440
2025-02-02 17:41:18,028 - INFO - Epoch 918: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:41:18,032 - INFO - ####################Training epoch 919####################
2025-02-02 17:41:18,721 - INFO - Epoch 919: train_loss=0.7902
2025-02-02 17:41:18,879 - INFO - Epoch 919: train_loss=0.9726
2025-02-02 17:41:19,014 - INFO - Epoch 919: train_loss=0.7676
2025-02-02 17:41:19,676 - INFO - Epoch 919: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:41:19,679 - INFO - ####################Training epoch 920####################
2025-02-02 17:41:20,340 - INFO - Epoch 920: train_loss=0.8960
2025-02-02 17:41:20,498 - INFO - Epoch 920: train_loss=0.7508
2025-02-02 17:41:20,633 - INFO - Epoch 920: train_loss=1.0443
2025-02-02 17:41:21,321 - INFO - Epoch 920: val_loss=2.0002, val_acc=33.33%
2025-02-02 17:41:21,324 - INFO - ####################Training epoch 921####################
2025-02-02 17:41:21,999 - INFO - Epoch 921: train_loss=0.8718
2025-02-02 17:41:22,157 - INFO - Epoch 921: train_loss=0.7526
2025-02-02 17:41:22,292 - INFO - Epoch 921: train_loss=1.1104
2025-02-02 17:41:22,943 - INFO - Epoch 921: val_loss=1.9958, val_acc=33.33%
2025-02-02 17:41:22,948 - INFO - ####################Training epoch 922####################
2025-02-02 17:41:23,613 - INFO - Epoch 922: train_loss=0.8133
2025-02-02 17:41:23,772 - INFO - Epoch 922: train_loss=1.0078
2025-02-02 17:41:23,907 - INFO - Epoch 922: train_loss=0.6225
2025-02-02 17:41:24,590 - INFO - Epoch 922: val_loss=1.9974, val_acc=33.33%
2025-02-02 17:41:24,593 - INFO - ####################Training epoch 923####################
2025-02-02 17:41:25,244 - INFO - Epoch 923: train_loss=0.8391
2025-02-02 17:41:25,401 - INFO - Epoch 923: train_loss=0.8591
2025-02-02 17:41:25,536 - INFO - Epoch 923: train_loss=0.9157
2025-02-02 17:41:26,205 - INFO - Epoch 923: val_loss=1.9980, val_acc=33.33%
2025-02-02 17:41:26,209 - INFO - ####################Training epoch 924####################
2025-02-02 17:41:26,877 - INFO - Epoch 924: train_loss=0.9175
2025-02-02 17:41:27,035 - INFO - Epoch 924: train_loss=0.8438
2025-02-02 17:41:27,170 - INFO - Epoch 924: train_loss=0.7726
2025-02-02 17:41:27,843 - INFO - Epoch 924: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:41:27,846 - INFO - ####################Training epoch 925####################
2025-02-02 17:41:28,513 - INFO - Epoch 925: train_loss=0.8638
2025-02-02 17:41:28,671 - INFO - Epoch 925: train_loss=0.7997
2025-02-02 17:41:28,806 - INFO - Epoch 925: train_loss=1.0065
2025-02-02 17:41:29,477 - INFO - Epoch 925: val_loss=1.9965, val_acc=33.33%
2025-02-02 17:41:29,480 - INFO - ####################Training epoch 926####################
2025-02-02 17:41:30,127 - INFO - Epoch 926: train_loss=0.9589
2025-02-02 17:41:30,285 - INFO - Epoch 926: train_loss=0.8232
2025-02-02 17:41:30,430 - INFO - Epoch 926: train_loss=0.7086
2025-02-02 17:41:31,138 - INFO - Epoch 926: val_loss=1.9984, val_acc=33.33%
2025-02-02 17:41:31,142 - INFO - ####################Training epoch 927####################
2025-02-02 17:41:31,783 - INFO - Epoch 927: train_loss=0.7782
2025-02-02 17:41:31,940 - INFO - Epoch 927: train_loss=0.9226
2025-02-02 17:41:32,075 - INFO - Epoch 927: train_loss=0.9188
2025-02-02 17:41:32,747 - INFO - Epoch 927: val_loss=1.9964, val_acc=33.33%
2025-02-02 17:41:32,750 - INFO - ####################Training epoch 928####################
2025-02-02 17:41:33,416 - INFO - Epoch 928: train_loss=0.8689
2025-02-02 17:41:33,574 - INFO - Epoch 928: train_loss=0.8736
2025-02-02 17:41:33,709 - INFO - Epoch 928: train_loss=0.8085
2025-02-02 17:41:34,378 - INFO - Epoch 928: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:41:34,382 - INFO - ####################Training epoch 929####################
2025-02-02 17:41:35,021 - INFO - Epoch 929: train_loss=0.9061
2025-02-02 17:41:35,179 - INFO - Epoch 929: train_loss=0.8911
2025-02-02 17:41:35,314 - INFO - Epoch 929: train_loss=0.6752
2025-02-02 17:41:35,995 - INFO - Epoch 929: val_loss=1.9897, val_acc=33.33%
2025-02-02 17:41:35,999 - INFO - ####################Training epoch 930####################
2025-02-02 17:41:36,638 - INFO - Epoch 930: train_loss=0.8273
2025-02-02 17:41:36,796 - INFO - Epoch 930: train_loss=0.8921
2025-02-02 17:41:36,931 - INFO - Epoch 930: train_loss=0.8717
2025-02-02 17:41:37,602 - INFO - Epoch 930: val_loss=1.9945, val_acc=33.33%
2025-02-02 17:41:37,606 - INFO - ####################Training epoch 931####################
2025-02-02 17:41:38,280 - INFO - Epoch 931: train_loss=0.7626
2025-02-02 17:41:38,437 - INFO - Epoch 931: train_loss=0.9467
2025-02-02 17:41:38,572 - INFO - Epoch 931: train_loss=0.8771
2025-02-02 17:41:39,265 - INFO - Epoch 931: val_loss=1.9926, val_acc=33.33%
2025-02-02 17:41:39,269 - INFO - ####################Training epoch 932####################
2025-02-02 17:41:39,922 - INFO - Epoch 932: train_loss=0.7814
2025-02-02 17:41:40,079 - INFO - Epoch 932: train_loss=0.9000
2025-02-02 17:41:40,213 - INFO - Epoch 932: train_loss=0.9546
2025-02-02 17:41:40,873 - INFO - Epoch 932: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:41:40,877 - INFO - ####################Training epoch 933####################
2025-02-02 17:41:41,515 - INFO - Epoch 933: train_loss=0.8971
2025-02-02 17:41:41,673 - INFO - Epoch 933: train_loss=0.8144
2025-02-02 17:41:41,808 - INFO - Epoch 933: train_loss=0.9025
2025-02-02 17:41:42,483 - INFO - Epoch 933: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:41:42,487 - INFO - ####################Training epoch 934####################
2025-02-02 17:41:43,122 - INFO - Epoch 934: train_loss=0.8130
2025-02-02 17:41:43,280 - INFO - Epoch 934: train_loss=0.7599
2025-02-02 17:41:43,414 - INFO - Epoch 934: train_loss=1.2288
2025-02-02 17:41:44,091 - INFO - Epoch 934: val_loss=1.9989, val_acc=33.33%
2025-02-02 17:41:44,095 - INFO - ####################Training epoch 935####################
2025-02-02 17:41:44,750 - INFO - Epoch 935: train_loss=0.8497
2025-02-02 17:41:44,909 - INFO - Epoch 935: train_loss=0.7739
2025-02-02 17:41:45,043 - INFO - Epoch 935: train_loss=1.1061
2025-02-02 17:41:45,700 - INFO - Epoch 935: val_loss=1.9936, val_acc=33.33%
2025-02-02 17:41:45,703 - INFO - ####################Training epoch 936####################
2025-02-02 17:41:46,360 - INFO - Epoch 936: train_loss=0.9046
2025-02-02 17:41:46,517 - INFO - Epoch 936: train_loss=0.7982
2025-02-02 17:41:46,651 - INFO - Epoch 936: train_loss=0.9108
2025-02-02 17:41:47,366 - INFO - Epoch 936: val_loss=1.9944, val_acc=33.33%
2025-02-02 17:41:47,370 - INFO - ####################Training epoch 937####################
2025-02-02 17:41:48,017 - INFO - Epoch 937: train_loss=0.8523
2025-02-02 17:41:48,175 - INFO - Epoch 937: train_loss=0.8269
2025-02-02 17:41:48,310 - INFO - Epoch 937: train_loss=0.9625
2025-02-02 17:41:48,975 - INFO - Epoch 937: val_loss=1.9987, val_acc=33.33%
2025-02-02 17:41:48,978 - INFO - ####################Training epoch 938####################
2025-02-02 17:41:49,607 - INFO - Epoch 938: train_loss=0.8441
2025-02-02 17:41:49,766 - INFO - Epoch 938: train_loss=0.8222
2025-02-02 17:41:49,901 - INFO - Epoch 938: train_loss=1.0133
2025-02-02 17:41:50,582 - INFO - Epoch 938: val_loss=2.0002, val_acc=33.33%
2025-02-02 17:41:50,586 - INFO - ####################Training epoch 939####################
2025-02-02 17:41:51,251 - INFO - Epoch 939: train_loss=0.9322
2025-02-02 17:41:51,409 - INFO - Epoch 939: train_loss=0.7789
2025-02-02 17:41:51,544 - INFO - Epoch 939: train_loss=0.8853
2025-02-02 17:41:52,234 - INFO - Epoch 939: val_loss=1.9918, val_acc=33.33%
2025-02-02 17:41:52,238 - INFO - ####################Training epoch 940####################
2025-02-02 17:41:52,911 - INFO - Epoch 940: train_loss=0.6972
2025-02-02 17:41:53,069 - INFO - Epoch 940: train_loss=0.9734
2025-02-02 17:41:53,204 - INFO - Epoch 940: train_loss=0.9935
2025-02-02 17:41:53,889 - INFO - Epoch 940: val_loss=1.9981, val_acc=33.33%
2025-02-02 17:41:53,892 - INFO - ####################Training epoch 941####################
2025-02-02 17:41:54,553 - INFO - Epoch 941: train_loss=0.7771
2025-02-02 17:41:54,711 - INFO - Epoch 941: train_loss=0.8974
2025-02-02 17:41:54,846 - INFO - Epoch 941: train_loss=0.9855
2025-02-02 17:41:55,528 - INFO - Epoch 941: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:41:55,532 - INFO - ####################Training epoch 942####################
2025-02-02 17:41:56,184 - INFO - Epoch 942: train_loss=0.8525
2025-02-02 17:41:56,343 - INFO - Epoch 942: train_loss=0.8443
2025-02-02 17:41:56,478 - INFO - Epoch 942: train_loss=0.9306
2025-02-02 17:41:57,151 - INFO - Epoch 942: val_loss=1.9996, val_acc=33.33%
2025-02-02 17:41:57,155 - INFO - ####################Training epoch 943####################
2025-02-02 17:41:57,814 - INFO - Epoch 943: train_loss=0.7507
2025-02-02 17:41:57,971 - INFO - Epoch 943: train_loss=1.0086
2025-02-02 17:41:58,106 - INFO - Epoch 943: train_loss=0.7729
2025-02-02 17:41:58,772 - INFO - Epoch 943: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:41:58,776 - INFO - ####################Training epoch 944####################
2025-02-02 17:41:59,415 - INFO - Epoch 944: train_loss=0.7888
2025-02-02 17:41:59,573 - INFO - Epoch 944: train_loss=0.9157
2025-02-02 17:41:59,707 - INFO - Epoch 944: train_loss=0.8989
2025-02-02 17:42:00,365 - INFO - Epoch 944: val_loss=1.9961, val_acc=33.33%
2025-02-02 17:42:00,369 - INFO - ####################Training epoch 945####################
2025-02-02 17:42:00,999 - INFO - Epoch 945: train_loss=0.7985
2025-02-02 17:42:01,157 - INFO - Epoch 945: train_loss=0.7692
2025-02-02 17:42:01,291 - INFO - Epoch 945: train_loss=1.2438
2025-02-02 17:42:01,952 - INFO - Epoch 945: val_loss=1.9991, val_acc=33.33%
2025-02-02 17:42:01,956 - INFO - ####################Training epoch 946####################
2025-02-02 17:42:02,598 - INFO - Epoch 946: train_loss=0.7774
2025-02-02 17:42:02,756 - INFO - Epoch 946: train_loss=0.8465
2025-02-02 17:42:02,891 - INFO - Epoch 946: train_loss=1.1045
2025-02-02 17:42:03,565 - INFO - Epoch 946: val_loss=1.9976, val_acc=33.33%
2025-02-02 17:42:03,569 - INFO - ####################Training epoch 947####################
2025-02-02 17:42:04,284 - INFO - Epoch 947: train_loss=0.8515
2025-02-02 17:42:04,444 - INFO - Epoch 947: train_loss=0.8637
2025-02-02 17:42:04,579 - INFO - Epoch 947: train_loss=0.8737
2025-02-02 17:42:05,248 - INFO - Epoch 947: val_loss=1.9988, val_acc=33.33%
2025-02-02 17:42:05,252 - INFO - ####################Training epoch 948####################
2025-02-02 17:42:05,922 - INFO - Epoch 948: train_loss=0.7918
2025-02-02 17:42:06,080 - INFO - Epoch 948: train_loss=0.9954
2025-02-02 17:42:06,216 - INFO - Epoch 948: train_loss=0.7052
2025-02-02 17:42:06,882 - INFO - Epoch 948: val_loss=2.0008, val_acc=33.33%
2025-02-02 17:42:06,886 - INFO - ####################Training epoch 949####################
2025-02-02 17:42:07,548 - INFO - Epoch 949: train_loss=0.8170
2025-02-02 17:42:07,706 - INFO - Epoch 949: train_loss=1.0015
2025-02-02 17:42:07,842 - INFO - Epoch 949: train_loss=0.6123
2025-02-02 17:42:08,533 - INFO - Epoch 949: val_loss=1.9944, val_acc=33.33%
2025-02-02 17:42:08,537 - INFO - ####################Training epoch 950####################
2025-02-02 17:42:09,205 - INFO - Epoch 950: train_loss=0.8420
2025-02-02 17:42:09,364 - INFO - Epoch 950: train_loss=0.8764
2025-02-02 17:42:09,500 - INFO - Epoch 950: train_loss=0.8805
2025-02-02 17:42:10,165 - INFO - Epoch 950: val_loss=1.9908, val_acc=33.33%
2025-02-02 17:42:10,169 - INFO - ####################Training epoch 951####################
2025-02-02 17:42:10,826 - INFO - Epoch 951: train_loss=0.8490
2025-02-02 17:42:10,985 - INFO - Epoch 951: train_loss=0.7449
2025-02-02 17:42:11,121 - INFO - Epoch 951: train_loss=1.1822
2025-02-02 17:42:11,797 - INFO - Epoch 951: val_loss=1.9990, val_acc=33.33%
2025-02-02 17:42:11,801 - INFO - ####################Training epoch 952####################
2025-02-02 17:42:12,504 - INFO - Epoch 952: train_loss=0.8404
2025-02-02 17:42:12,662 - INFO - Epoch 952: train_loss=0.9229
2025-02-02 17:42:12,797 - INFO - Epoch 952: train_loss=0.7747
2025-02-02 17:42:13,483 - INFO - Epoch 952: val_loss=1.9931, val_acc=33.33%
2025-02-02 17:42:13,486 - INFO - ####################Training epoch 953####################
2025-02-02 17:42:14,126 - INFO - Epoch 953: train_loss=0.8525
2025-02-02 17:42:14,284 - INFO - Epoch 953: train_loss=0.8189
2025-02-02 17:42:14,419 - INFO - Epoch 953: train_loss=0.9882
2025-02-02 17:42:15,088 - INFO - Epoch 953: val_loss=2.0020, val_acc=33.33%
2025-02-02 17:42:15,091 - INFO - ####################Training epoch 954####################
2025-02-02 17:42:15,725 - INFO - Epoch 954: train_loss=0.7891
2025-02-02 17:42:15,884 - INFO - Epoch 954: train_loss=0.9023
2025-02-02 17:42:16,018 - INFO - Epoch 954: train_loss=0.9376
2025-02-02 17:42:16,687 - INFO - Epoch 954: val_loss=1.9991, val_acc=33.33%
2025-02-02 17:42:16,691 - INFO - ####################Training epoch 955####################
2025-02-02 17:42:17,343 - INFO - Epoch 955: train_loss=0.9143
2025-02-02 17:42:17,501 - INFO - Epoch 955: train_loss=0.7993
2025-02-02 17:42:17,635 - INFO - Epoch 955: train_loss=0.8740
2025-02-02 17:42:18,296 - INFO - Epoch 955: val_loss=1.9929, val_acc=33.33%
2025-02-02 17:42:18,300 - INFO - ####################Training epoch 956####################
2025-02-02 17:42:18,966 - INFO - Epoch 956: train_loss=0.7936
2025-02-02 17:42:19,123 - INFO - Epoch 956: train_loss=0.9042
2025-02-02 17:42:19,258 - INFO - Epoch 956: train_loss=0.9205
2025-02-02 17:42:19,910 - INFO - Epoch 956: val_loss=1.9970, val_acc=33.33%
2025-02-02 17:42:19,914 - INFO - ####################Training epoch 957####################
2025-02-02 17:42:20,559 - INFO - Epoch 957: train_loss=0.7618
2025-02-02 17:42:20,718 - INFO - Epoch 957: train_loss=0.9652
2025-02-02 17:42:20,854 - INFO - Epoch 957: train_loss=0.8435
2025-02-02 17:42:21,509 - INFO - Epoch 957: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:42:21,513 - INFO - ####################Training epoch 958####################
2025-02-02 17:42:22,176 - INFO - Epoch 958: train_loss=0.8987
2025-02-02 17:42:22,334 - INFO - Epoch 958: train_loss=0.8228
2025-02-02 17:42:22,469 - INFO - Epoch 958: train_loss=0.8746
2025-02-02 17:42:23,119 - INFO - Epoch 958: val_loss=1.9976, val_acc=33.33%
2025-02-02 17:42:23,123 - INFO - ####################Training epoch 959####################
2025-02-02 17:42:23,779 - INFO - Epoch 959: train_loss=0.8593
2025-02-02 17:42:23,937 - INFO - Epoch 959: train_loss=0.8615
2025-02-02 17:42:24,071 - INFO - Epoch 959: train_loss=0.8707
2025-02-02 17:42:24,760 - INFO - Epoch 959: val_loss=1.9975, val_acc=33.33%
2025-02-02 17:42:24,764 - INFO - ####################Training epoch 960####################
2025-02-02 17:42:25,440 - INFO - Epoch 960: train_loss=0.8747
2025-02-02 17:42:25,598 - INFO - Epoch 960: train_loss=0.8387
2025-02-02 17:42:25,733 - INFO - Epoch 960: train_loss=0.8794
2025-02-02 17:42:26,428 - INFO - Epoch 960: val_loss=1.9984, val_acc=33.33%
2025-02-02 17:42:26,432 - INFO - ####################Training epoch 961####################
2025-02-02 17:42:27,088 - INFO - Epoch 961: train_loss=0.7989
2025-02-02 17:42:27,246 - INFO - Epoch 961: train_loss=0.9079
2025-02-02 17:42:27,381 - INFO - Epoch 961: train_loss=0.9014
2025-02-02 17:42:28,046 - INFO - Epoch 961: val_loss=2.0005, val_acc=33.33%
2025-02-02 17:42:28,053 - INFO - ####################Training epoch 962####################
2025-02-02 17:42:28,710 - INFO - Epoch 962: train_loss=0.8205
2025-02-02 17:42:28,868 - INFO - Epoch 962: train_loss=0.8790
2025-02-02 17:42:29,003 - INFO - Epoch 962: train_loss=0.9202
2025-02-02 17:42:29,714 - INFO - Epoch 962: val_loss=1.9947, val_acc=33.33%
2025-02-02 17:42:29,718 - INFO - ####################Training epoch 963####################
2025-02-02 17:42:30,373 - INFO - Epoch 963: train_loss=0.7948
2025-02-02 17:42:30,531 - INFO - Epoch 963: train_loss=0.8865
2025-02-02 17:42:30,666 - INFO - Epoch 963: train_loss=0.9507
2025-02-02 17:42:31,329 - INFO - Epoch 963: val_loss=1.9992, val_acc=33.33%
2025-02-02 17:42:31,333 - INFO - ####################Training epoch 964####################
2025-02-02 17:42:31,970 - INFO - Epoch 964: train_loss=0.8083
2025-02-02 17:42:32,127 - INFO - Epoch 964: train_loss=0.9195
2025-02-02 17:42:32,262 - INFO - Epoch 964: train_loss=0.8478
2025-02-02 17:42:32,948 - INFO - Epoch 964: val_loss=2.0000, val_acc=33.33%
2025-02-02 17:42:32,952 - INFO - ####################Training epoch 965####################
2025-02-02 17:42:33,614 - INFO - Epoch 965: train_loss=0.9394
2025-02-02 17:42:33,772 - INFO - Epoch 965: train_loss=0.8148
2025-02-02 17:42:33,907 - INFO - Epoch 965: train_loss=0.7758
2025-02-02 17:42:34,582 - INFO - Epoch 965: val_loss=1.9982, val_acc=33.33%
2025-02-02 17:42:34,586 - INFO - ####################Training epoch 966####################
2025-02-02 17:42:35,254 - INFO - Epoch 966: train_loss=0.9072
2025-02-02 17:42:35,412 - INFO - Epoch 966: train_loss=0.8102
2025-02-02 17:42:35,546 - INFO - Epoch 966: train_loss=0.8701
2025-02-02 17:42:36,232 - INFO - Epoch 966: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:42:36,236 - INFO - ####################Training epoch 967####################
2025-02-02 17:42:36,908 - INFO - Epoch 967: train_loss=0.9347
2025-02-02 17:42:37,066 - INFO - Epoch 967: train_loss=0.7645
2025-02-02 17:42:37,200 - INFO - Epoch 967: train_loss=0.9213
2025-02-02 17:42:37,927 - INFO - Epoch 967: val_loss=1.9994, val_acc=33.33%
2025-02-02 17:42:37,931 - INFO - ####################Training epoch 968####################
2025-02-02 17:42:38,561 - INFO - Epoch 968: train_loss=0.8846
2025-02-02 17:42:38,718 - INFO - Epoch 968: train_loss=0.8486
2025-02-02 17:42:38,853 - INFO - Epoch 968: train_loss=0.8321
2025-02-02 17:42:39,525 - INFO - Epoch 968: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:42:39,528 - INFO - ####################Training epoch 969####################
2025-02-02 17:42:40,168 - INFO - Epoch 969: train_loss=0.8140
2025-02-02 17:42:40,325 - INFO - Epoch 969: train_loss=0.8668
2025-02-02 17:42:40,460 - INFO - Epoch 969: train_loss=0.9730
2025-02-02 17:42:41,135 - INFO - Epoch 969: val_loss=2.0016, val_acc=33.33%
2025-02-02 17:42:41,139 - INFO - ####################Training epoch 970####################
2025-02-02 17:42:41,793 - INFO - Epoch 970: train_loss=0.8395
2025-02-02 17:42:41,951 - INFO - Epoch 970: train_loss=0.8925
2025-02-02 17:42:42,085 - INFO - Epoch 970: train_loss=0.8319
2025-02-02 17:42:42,768 - INFO - Epoch 970: val_loss=2.0000, val_acc=33.33%
2025-02-02 17:42:42,771 - INFO - ####################Training epoch 971####################
2025-02-02 17:42:43,439 - INFO - Epoch 971: train_loss=0.8908
2025-02-02 17:42:43,596 - INFO - Epoch 971: train_loss=0.8774
2025-02-02 17:42:43,731 - INFO - Epoch 971: train_loss=0.7385
2025-02-02 17:42:44,401 - INFO - Epoch 971: val_loss=1.9985, val_acc=33.33%
2025-02-02 17:42:44,405 - INFO - ####################Training epoch 972####################
2025-02-02 17:42:45,035 - INFO - Epoch 972: train_loss=0.8136
2025-02-02 17:42:45,193 - INFO - Epoch 972: train_loss=0.9570
2025-02-02 17:42:45,328 - INFO - Epoch 972: train_loss=0.7478
2025-02-02 17:42:46,007 - INFO - Epoch 972: val_loss=1.9950, val_acc=33.33%
2025-02-02 17:42:46,011 - INFO - ####################Training epoch 973####################
2025-02-02 17:42:46,670 - INFO - Epoch 973: train_loss=0.9087
2025-02-02 17:42:46,828 - INFO - Epoch 973: train_loss=0.7941
2025-02-02 17:42:46,963 - INFO - Epoch 973: train_loss=0.9137
2025-02-02 17:42:47,638 - INFO - Epoch 973: val_loss=1.9948, val_acc=33.33%
2025-02-02 17:42:47,641 - INFO - ####################Training epoch 974####################
2025-02-02 17:42:48,286 - INFO - Epoch 974: train_loss=0.8904
2025-02-02 17:42:48,443 - INFO - Epoch 974: train_loss=0.8352
2025-02-02 17:42:48,578 - INFO - Epoch 974: train_loss=0.8583
2025-02-02 17:42:49,237 - INFO - Epoch 974: val_loss=1.9984, val_acc=33.33%
2025-02-02 17:42:49,241 - INFO - ####################Training epoch 975####################
2025-02-02 17:42:49,897 - INFO - Epoch 975: train_loss=0.8936
2025-02-02 17:42:50,055 - INFO - Epoch 975: train_loss=0.8347
2025-02-02 17:42:50,189 - INFO - Epoch 975: train_loss=0.8412
2025-02-02 17:42:50,857 - INFO - Epoch 975: val_loss=1.9984, val_acc=33.33%
2025-02-02 17:42:50,861 - INFO - ####################Training epoch 976####################
2025-02-02 17:42:51,496 - INFO - Epoch 976: train_loss=0.7150
2025-02-02 17:42:51,653 - INFO - Epoch 976: train_loss=0.9375
2025-02-02 17:42:51,788 - INFO - Epoch 976: train_loss=1.0524
2025-02-02 17:42:52,463 - INFO - Epoch 976: val_loss=1.9951, val_acc=33.33%
2025-02-02 17:42:52,467 - INFO - ####################Training epoch 977####################
2025-02-02 17:42:53,135 - INFO - Epoch 977: train_loss=0.8661
2025-02-02 17:42:53,293 - INFO - Epoch 977: train_loss=0.9288
2025-02-02 17:42:53,428 - INFO - Epoch 977: train_loss=0.6805
2025-02-02 17:42:54,102 - INFO - Epoch 977: val_loss=1.9966, val_acc=33.33%
2025-02-02 17:42:54,105 - INFO - ####################Training epoch 978####################
2025-02-02 17:42:54,809 - INFO - Epoch 978: train_loss=0.8714
2025-02-02 17:42:54,967 - INFO - Epoch 978: train_loss=0.9732
2025-02-02 17:42:55,102 - INFO - Epoch 978: train_loss=0.5465
2025-02-02 17:42:55,767 - INFO - Epoch 978: val_loss=1.9961, val_acc=33.33%
2025-02-02 17:42:55,771 - INFO - ####################Training epoch 979####################
2025-02-02 17:42:56,444 - INFO - Epoch 979: train_loss=0.8017
2025-02-02 17:42:56,602 - INFO - Epoch 979: train_loss=0.8631
2025-02-02 17:42:56,737 - INFO - Epoch 979: train_loss=1.0145
2025-02-02 17:42:57,414 - INFO - Epoch 979: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:42:57,417 - INFO - ####################Training epoch 980####################
2025-02-02 17:42:58,089 - INFO - Epoch 980: train_loss=0.9158
2025-02-02 17:42:58,248 - INFO - Epoch 980: train_loss=0.7554
2025-02-02 17:42:58,383 - INFO - Epoch 980: train_loss=0.9883
2025-02-02 17:42:59,094 - INFO - Epoch 980: val_loss=1.9959, val_acc=33.33%
2025-02-02 17:42:59,099 - INFO - ####################Training epoch 981####################
2025-02-02 17:42:59,790 - INFO - Epoch 981: train_loss=0.8018
2025-02-02 17:42:59,949 - INFO - Epoch 981: train_loss=0.8933
2025-02-02 17:43:00,084 - INFO - Epoch 981: train_loss=0.9323
2025-02-02 17:43:00,771 - INFO - Epoch 981: val_loss=1.9962, val_acc=33.33%
2025-02-02 17:43:00,774 - INFO - ####################Training epoch 982####################
2025-02-02 17:43:01,430 - INFO - Epoch 982: train_loss=0.8756
2025-02-02 17:43:01,588 - INFO - Epoch 982: train_loss=0.8227
2025-02-02 17:43:01,724 - INFO - Epoch 982: train_loss=0.9166
2025-02-02 17:43:02,381 - INFO - Epoch 982: val_loss=1.9934, val_acc=33.33%
2025-02-02 17:43:02,385 - INFO - ####################Training epoch 983####################
2025-02-02 17:43:03,080 - INFO - Epoch 983: train_loss=0.8735
2025-02-02 17:43:03,238 - INFO - Epoch 983: train_loss=0.8232
2025-02-02 17:43:03,373 - INFO - Epoch 983: train_loss=0.9320
2025-02-02 17:43:04,035 - INFO - Epoch 983: val_loss=1.9918, val_acc=33.33%
2025-02-02 17:43:04,039 - INFO - ####################Training epoch 984####################
2025-02-02 17:43:04,691 - INFO - Epoch 984: train_loss=0.7944
2025-02-02 17:43:04,849 - INFO - Epoch 984: train_loss=0.8455
2025-02-02 17:43:04,985 - INFO - Epoch 984: train_loss=1.0609
2025-02-02 17:43:05,660 - INFO - Epoch 984: val_loss=1.9964, val_acc=33.33%
2025-02-02 17:43:05,665 - INFO - ####################Training epoch 985####################
2025-02-02 17:43:06,336 - INFO - Epoch 985: train_loss=0.7709
2025-02-02 17:43:06,494 - INFO - Epoch 985: train_loss=0.8558
2025-02-02 17:43:06,630 - INFO - Epoch 985: train_loss=1.1146
2025-02-02 17:43:07,314 - INFO - Epoch 985: val_loss=1.9943, val_acc=33.33%
2025-02-02 17:43:07,318 - INFO - ####################Training epoch 986####################
2025-02-02 17:43:07,973 - INFO - Epoch 986: train_loss=1.0509
2025-02-02 17:43:08,131 - INFO - Epoch 986: train_loss=0.6860
2025-02-02 17:43:08,266 - INFO - Epoch 986: train_loss=0.8197
2025-02-02 17:43:08,936 - INFO - Epoch 986: val_loss=1.9933, val_acc=33.33%
2025-02-02 17:43:08,943 - INFO - ####################Training epoch 987####################
2025-02-02 17:43:09,592 - INFO - Epoch 987: train_loss=0.9267
2025-02-02 17:43:09,750 - INFO - Epoch 987: train_loss=0.8168
2025-02-02 17:43:09,885 - INFO - Epoch 987: train_loss=0.8091
2025-02-02 17:43:10,547 - INFO - Epoch 987: val_loss=1.9995, val_acc=33.33%
2025-02-02 17:43:10,551 - INFO - ####################Training epoch 988####################
2025-02-02 17:43:11,234 - INFO - Epoch 988: train_loss=0.8827
2025-02-02 17:43:11,397 - INFO - Epoch 988: train_loss=0.8309
2025-02-02 17:43:11,531 - INFO - Epoch 988: train_loss=0.8951
2025-02-02 17:43:12,212 - INFO - Epoch 988: val_loss=1.9967, val_acc=33.33%
2025-02-02 17:43:12,215 - INFO - ####################Training epoch 989####################
2025-02-02 17:43:12,861 - INFO - Epoch 989: train_loss=0.7764
2025-02-02 17:43:13,019 - INFO - Epoch 989: train_loss=0.9746
2025-02-02 17:43:13,154 - INFO - Epoch 989: train_loss=0.7791
2025-02-02 17:43:13,832 - INFO - Epoch 989: val_loss=2.0015, val_acc=33.33%
2025-02-02 17:43:13,836 - INFO - ####################Training epoch 990####################
2025-02-02 17:43:14,502 - INFO - Epoch 990: train_loss=0.8910
2025-02-02 17:43:14,660 - INFO - Epoch 990: train_loss=0.8470
2025-02-02 17:43:14,795 - INFO - Epoch 990: train_loss=0.8239
2025-02-02 17:43:15,476 - INFO - Epoch 990: val_loss=1.9938, val_acc=33.33%
2025-02-02 17:43:15,480 - INFO - ####################Training epoch 991####################
2025-02-02 17:43:16,120 - INFO - Epoch 991: train_loss=0.9477
2025-02-02 17:43:16,278 - INFO - Epoch 991: train_loss=0.7363
2025-02-02 17:43:16,412 - INFO - Epoch 991: train_loss=0.9665
2025-02-02 17:43:17,090 - INFO - Epoch 991: val_loss=2.0000, val_acc=33.33%
2025-02-02 17:43:17,093 - INFO - ####################Training epoch 992####################
2025-02-02 17:43:17,752 - INFO - Epoch 992: train_loss=0.8757
2025-02-02 17:43:17,909 - INFO - Epoch 992: train_loss=0.8507
2025-02-02 17:43:18,043 - INFO - Epoch 992: train_loss=0.8583
2025-02-02 17:43:18,714 - INFO - Epoch 992: val_loss=1.9976, val_acc=33.33%
2025-02-02 17:43:18,718 - INFO - ####################Training epoch 993####################
2025-02-02 17:43:19,376 - INFO - Epoch 993: train_loss=0.7955
2025-02-02 17:43:19,534 - INFO - Epoch 993: train_loss=0.9628
2025-02-02 17:43:19,676 - INFO - Epoch 993: train_loss=0.7893
2025-02-02 17:43:20,374 - INFO - Epoch 993: val_loss=2.0014, val_acc=33.33%
2025-02-02 17:43:20,378 - INFO - ####################Training epoch 994####################
2025-02-02 17:43:21,038 - INFO - Epoch 994: train_loss=0.8436
2025-02-02 17:43:21,196 - INFO - Epoch 994: train_loss=0.9093
2025-02-02 17:43:21,331 - INFO - Epoch 994: train_loss=0.7928
2025-02-02 17:43:21,987 - INFO - Epoch 994: val_loss=1.9986, val_acc=33.33%
2025-02-02 17:43:21,990 - INFO - ####################Training epoch 995####################
2025-02-02 17:43:22,654 - INFO - Epoch 995: train_loss=0.8799
2025-02-02 17:43:22,812 - INFO - Epoch 995: train_loss=0.7638
2025-02-02 17:43:22,946 - INFO - Epoch 995: train_loss=1.0616
2025-02-02 17:43:23,629 - INFO - Epoch 995: val_loss=1.9955, val_acc=33.33%
2025-02-02 17:43:23,632 - INFO - ####################Training epoch 996####################
2025-02-02 17:43:24,287 - INFO - Epoch 996: train_loss=0.8872
2025-02-02 17:43:24,444 - INFO - Epoch 996: train_loss=0.9374
2025-02-02 17:43:24,579 - INFO - Epoch 996: train_loss=0.6046
2025-02-02 17:43:25,269 - INFO - Epoch 996: val_loss=1.9969, val_acc=33.33%
2025-02-02 17:43:25,273 - INFO - ####################Training epoch 997####################
2025-02-02 17:43:25,928 - INFO - Epoch 997: train_loss=0.9616
2025-02-02 17:43:26,085 - INFO - Epoch 997: train_loss=0.7614
2025-02-02 17:43:26,219 - INFO - Epoch 997: train_loss=0.8548
2025-02-02 17:43:26,883 - INFO - Epoch 997: val_loss=1.9973, val_acc=33.33%
2025-02-02 17:43:26,887 - INFO - ####################Training epoch 998####################
2025-02-02 17:43:27,542 - INFO - Epoch 998: train_loss=0.9782
2025-02-02 17:43:27,700 - INFO - Epoch 998: train_loss=0.7343
2025-02-02 17:43:27,834 - INFO - Epoch 998: train_loss=0.8857
2025-02-02 17:43:28,563 - INFO - Epoch 998: val_loss=1.9992, val_acc=33.33%
2025-02-02 17:43:28,567 - INFO - ####################Training epoch 999####################
2025-02-02 17:43:29,229 - INFO - Epoch 999: train_loss=0.7370
2025-02-02 17:43:29,386 - INFO - Epoch 999: train_loss=0.9092
2025-02-02 17:43:29,520 - INFO - Epoch 999: train_loss=1.0589
2025-02-02 17:43:30,202 - INFO - Epoch 999: val_loss=1.9957, val_acc=33.33%
2025-02-02 17:43:30,592 - INFO - Model saved.
