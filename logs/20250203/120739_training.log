2025-02-03 12:07:43,535 - INFO - Starting training with the following parameters:
2025-02-03 12:07:43,535 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product |
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.005          |
| epochs          | 100            |

2025-02-03 12:07:45,333 - INFO - Epoch 0: val_loss=1.1002, val_acc=33.33%
2025-02-03 12:07:46,483 - INFO - ####################Training epoch 0####################
2025-02-03 12:07:46,611 - INFO - Epoch 0: train_loss=1.2233
2025-02-03 12:07:47,004 - INFO - Epoch 0: train_loss=3.7255
2025-02-03 12:07:47,247 - INFO - Epoch 0: train_loss=2.5019
2025-02-03 12:07:48,923 - INFO - Epoch 0: val_loss=1.5538, val_acc=33.33%
2025-02-03 12:07:48,958 - INFO - ####################Training epoch 1####################
2025-02-03 12:07:50,656 - INFO - Epoch 1: train_loss=1.0326
2025-02-03 12:07:50,937 - INFO - Epoch 1: train_loss=1.6118
2025-02-03 12:07:51,180 - INFO - Epoch 1: train_loss=2.0088
2025-02-03 12:07:52,876 - INFO - Epoch 1: val_loss=1.4668, val_acc=0.00%
2025-02-03 12:07:52,906 - INFO - ####################Training epoch 2####################
2025-02-03 12:07:54,590 - INFO - Epoch 2: train_loss=1.3088
2025-02-03 12:07:54,874 - INFO - Epoch 2: train_loss=1.0327
2025-02-03 12:07:55,103 - INFO - Epoch 2: train_loss=2.4182
2025-02-03 12:07:56,787 - INFO - Epoch 2: val_loss=0.7958, val_acc=66.67%
2025-02-03 12:07:56,828 - INFO - ####################Training epoch 3####################
2025-02-03 12:07:58,514 - INFO - Epoch 3: train_loss=1.6069
2025-02-03 12:07:58,851 - INFO - Epoch 3: train_loss=1.3448
2025-02-03 12:07:59,201 - INFO - Epoch 3: train_loss=1.0971
2025-02-03 12:08:01,007 - INFO - Epoch 3: val_loss=0.9646, val_acc=33.33%
2025-02-03 12:08:01,046 - INFO - ####################Training epoch 4####################
2025-02-03 12:08:02,860 - INFO - Epoch 4: train_loss=1.0710
2025-02-03 12:08:03,266 - INFO - Epoch 4: train_loss=1.1047
2025-02-03 12:08:03,558 - INFO - Epoch 4: train_loss=1.1249
2025-02-03 12:08:05,266 - INFO - Epoch 4: val_loss=1.8114, val_acc=0.00%
2025-02-03 12:08:05,272 - INFO - ####################Training epoch 5####################
2025-02-03 12:08:07,062 - INFO - Epoch 5: train_loss=1.3339
2025-02-03 12:08:07,352 - INFO - Epoch 5: train_loss=1.4202
2025-02-03 12:08:07,596 - INFO - Epoch 5: train_loss=1.0270
2025-02-03 12:08:09,412 - INFO - Epoch 5: val_loss=2.6981, val_acc=0.00%
2025-02-03 12:08:09,417 - INFO - ####################Training epoch 6####################
2025-02-03 12:08:11,173 - INFO - Epoch 6: train_loss=1.6980
2025-02-03 12:08:11,456 - INFO - Epoch 6: train_loss=1.9195
2025-02-03 12:08:11,702 - INFO - Epoch 6: train_loss=1.1387
2025-02-03 12:08:13,481 - INFO - Epoch 6: val_loss=3.2351, val_acc=0.00%
2025-02-03 12:08:13,486 - INFO - ####################Training epoch 7####################
2025-02-03 12:08:15,178 - INFO - Epoch 7: train_loss=2.2251
2025-02-03 12:08:15,460 - INFO - Epoch 7: train_loss=1.2854
2025-02-03 12:08:15,689 - INFO - Epoch 7: train_loss=2.9015
2025-02-03 12:08:17,421 - INFO - Epoch 7: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:17,440 - INFO - ####################Training epoch 8####################
2025-02-03 12:08:19,132 - INFO - Epoch 8: train_loss=nan
2025-02-03 12:08:19,419 - INFO - Epoch 8: train_loss=nan
2025-02-03 12:08:19,659 - INFO - Epoch 8: train_loss=nan
2025-02-03 12:08:21,422 - INFO - Epoch 8: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:21,434 - INFO - ####################Training epoch 9####################
2025-02-03 12:08:23,188 - INFO - Epoch 9: train_loss=nan
2025-02-03 12:08:23,466 - INFO - Epoch 9: train_loss=nan
2025-02-03 12:08:23,705 - INFO - Epoch 9: train_loss=nan
2025-02-03 12:08:25,476 - INFO - Epoch 9: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:25,482 - INFO - ####################Training epoch 10####################
2025-02-03 12:08:27,146 - INFO - Epoch 10: train_loss=nan
2025-02-03 12:08:27,426 - INFO - Epoch 10: train_loss=nan
2025-02-03 12:08:27,659 - INFO - Epoch 10: train_loss=nan
2025-02-03 12:08:29,443 - INFO - Epoch 10: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:29,449 - INFO - ####################Training epoch 11####################
2025-02-03 12:08:31,187 - INFO - Epoch 11: train_loss=nan
2025-02-03 12:08:31,466 - INFO - Epoch 11: train_loss=nan
2025-02-03 12:08:31,705 - INFO - Epoch 11: train_loss=nan
2025-02-03 12:08:33,488 - INFO - Epoch 11: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:33,495 - INFO - ####################Training epoch 12####################
2025-02-03 12:08:35,223 - INFO - Epoch 12: train_loss=nan
2025-02-03 12:08:35,501 - INFO - Epoch 12: train_loss=nan
2025-02-03 12:08:35,772 - INFO - Epoch 12: train_loss=nan
2025-02-03 12:08:37,572 - INFO - Epoch 12: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:37,578 - INFO - ####################Training epoch 13####################
2025-02-03 12:08:39,342 - INFO - Epoch 13: train_loss=nan
2025-02-03 12:08:39,794 - INFO - Epoch 13: train_loss=nan
2025-02-03 12:08:40,178 - INFO - Epoch 13: train_loss=nan
2025-02-03 12:08:41,884 - INFO - Epoch 13: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:41,889 - INFO - ####################Training epoch 14####################
2025-02-03 12:08:43,733 - INFO - Epoch 14: train_loss=nan
2025-02-03 12:08:44,176 - INFO - Epoch 14: train_loss=nan
2025-02-03 12:08:44,446 - INFO - Epoch 14: train_loss=nan
2025-02-03 12:08:46,167 - INFO - Epoch 14: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:46,173 - INFO - ####################Training epoch 15####################
2025-02-03 12:08:47,899 - INFO - Epoch 15: train_loss=nan
2025-02-03 12:08:48,173 - INFO - Epoch 15: train_loss=nan
2025-02-03 12:08:48,418 - INFO - Epoch 15: train_loss=nan
2025-02-03 12:08:50,108 - INFO - Epoch 15: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:50,114 - INFO - ####################Training epoch 16####################
2025-02-03 12:08:51,766 - INFO - Epoch 16: train_loss=nan
2025-02-03 12:08:52,045 - INFO - Epoch 16: train_loss=nan
2025-02-03 12:08:52,292 - INFO - Epoch 16: train_loss=nan
2025-02-03 12:08:54,023 - INFO - Epoch 16: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:54,028 - INFO - ####################Training epoch 17####################
2025-02-03 12:08:55,735 - INFO - Epoch 17: train_loss=nan
2025-02-03 12:08:56,017 - INFO - Epoch 17: train_loss=nan
2025-02-03 12:08:56,245 - INFO - Epoch 17: train_loss=nan
2025-02-03 12:08:57,997 - INFO - Epoch 17: val_loss=nan, val_acc=66.67%
2025-02-03 12:08:58,003 - INFO - ####################Training epoch 18####################
2025-02-03 12:08:59,708 - INFO - Epoch 18: train_loss=nan
2025-02-03 12:08:59,988 - INFO - Epoch 18: train_loss=nan
2025-02-03 12:09:00,231 - INFO - Epoch 18: train_loss=nan
2025-02-03 12:09:01,996 - INFO - Epoch 18: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:02,007 - INFO - ####################Training epoch 19####################
2025-02-03 12:09:03,722 - INFO - Epoch 19: train_loss=nan
2025-02-03 12:09:04,020 - INFO - Epoch 19: train_loss=nan
2025-02-03 12:09:04,260 - INFO - Epoch 19: train_loss=nan
2025-02-03 12:09:06,064 - INFO - Epoch 19: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:06,069 - INFO - ####################Training epoch 20####################
2025-02-03 12:09:07,780 - INFO - Epoch 20: train_loss=nan
2025-02-03 12:09:08,059 - INFO - Epoch 20: train_loss=nan
2025-02-03 12:09:08,303 - INFO - Epoch 20: train_loss=nan
2025-02-03 12:09:10,063 - INFO - Epoch 20: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:10,068 - INFO - ####################Training epoch 21####################
2025-02-03 12:09:11,798 - INFO - Epoch 21: train_loss=nan
2025-02-03 12:09:12,078 - INFO - Epoch 21: train_loss=nan
2025-02-03 12:09:12,318 - INFO - Epoch 21: train_loss=nan
2025-02-03 12:09:13,972 - INFO - Epoch 21: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:13,978 - INFO - ####################Training epoch 22####################
2025-02-03 12:09:15,730 - INFO - Epoch 22: train_loss=nan
2025-02-03 12:09:16,000 - INFO - Epoch 22: train_loss=nan
2025-02-03 12:09:16,229 - INFO - Epoch 22: train_loss=nan
2025-02-03 12:09:17,955 - INFO - Epoch 22: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:17,960 - INFO - ####################Training epoch 23####################
2025-02-03 12:09:19,668 - INFO - Epoch 23: train_loss=nan
2025-02-03 12:09:19,925 - INFO - Epoch 23: train_loss=nan
2025-02-03 12:09:20,217 - INFO - Epoch 23: train_loss=nan
2025-02-03 12:09:21,964 - INFO - Epoch 23: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:22,127 - INFO - ####################Training epoch 24####################
2025-02-03 12:09:23,380 - INFO - Epoch 24: train_loss=nan
2025-02-03 12:09:23,662 - INFO - Epoch 24: train_loss=nan
2025-02-03 12:09:23,963 - INFO - Epoch 24: train_loss=nan
2025-02-03 12:09:25,623 - INFO - Epoch 24: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:25,630 - INFO - ####################Training epoch 25####################
2025-02-03 12:09:26,732 - INFO - Epoch 25: train_loss=nan
2025-02-03 12:09:27,009 - INFO - Epoch 25: train_loss=nan
2025-02-03 12:09:27,251 - INFO - Epoch 25: train_loss=nan
2025-02-03 12:09:28,345 - INFO - Epoch 25: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:28,351 - INFO - ####################Training epoch 26####################
2025-02-03 12:09:29,407 - INFO - Epoch 26: train_loss=nan
2025-02-03 12:09:29,705 - INFO - Epoch 26: train_loss=nan
2025-02-03 12:09:29,949 - INFO - Epoch 26: train_loss=nan
2025-02-03 12:09:31,061 - INFO - Epoch 26: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:31,069 - INFO - ####################Training epoch 27####################
2025-02-03 12:09:32,116 - INFO - Epoch 27: train_loss=nan
2025-02-03 12:09:32,392 - INFO - Epoch 27: train_loss=nan
2025-02-03 12:09:32,633 - INFO - Epoch 27: train_loss=nan
2025-02-03 12:09:33,737 - INFO - Epoch 27: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:33,775 - INFO - ####################Training epoch 28####################
2025-02-03 12:09:34,814 - INFO - Epoch 28: train_loss=nan
2025-02-03 12:09:35,094 - INFO - Epoch 28: train_loss=nan
2025-02-03 12:09:35,341 - INFO - Epoch 28: train_loss=nan
2025-02-03 12:09:36,428 - INFO - Epoch 28: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:36,433 - INFO - ####################Training epoch 29####################
2025-02-03 12:09:37,494 - INFO - Epoch 29: train_loss=nan
2025-02-03 12:09:37,774 - INFO - Epoch 29: train_loss=nan
2025-02-03 12:09:38,021 - INFO - Epoch 29: train_loss=nan
2025-02-03 12:09:39,198 - INFO - Epoch 29: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:39,204 - INFO - ####################Training epoch 30####################
2025-02-03 12:09:40,313 - INFO - Epoch 30: train_loss=nan
2025-02-03 12:09:40,595 - INFO - Epoch 30: train_loss=nan
2025-02-03 12:09:40,924 - INFO - Epoch 30: train_loss=nan
2025-02-03 12:09:42,088 - INFO - Epoch 30: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:42,093 - INFO - ####################Training epoch 31####################
2025-02-03 12:09:43,206 - INFO - Epoch 31: train_loss=nan
2025-02-03 12:09:43,576 - INFO - Epoch 31: train_loss=nan
2025-02-03 12:09:43,974 - INFO - Epoch 31: train_loss=nan
2025-02-03 12:09:45,129 - INFO - Epoch 31: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:45,136 - INFO - ####################Training epoch 32####################
2025-02-03 12:09:46,258 - INFO - Epoch 32: train_loss=nan
2025-02-03 12:09:46,708 - INFO - Epoch 32: train_loss=nan
2025-02-03 12:09:47,069 - INFO - Epoch 32: train_loss=nan
2025-02-03 12:09:48,205 - INFO - Epoch 32: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:48,215 - INFO - ####################Training epoch 33####################
2025-02-03 12:09:49,426 - INFO - Epoch 33: train_loss=nan
2025-02-03 12:09:49,869 - INFO - Epoch 33: train_loss=nan
2025-02-03 12:09:50,171 - INFO - Epoch 33: train_loss=nan
2025-02-03 12:09:51,321 - INFO - Epoch 33: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:51,327 - INFO - ####################Training epoch 34####################
2025-02-03 12:09:52,512 - INFO - Epoch 34: train_loss=nan
2025-02-03 12:09:52,849 - INFO - Epoch 34: train_loss=nan
2025-02-03 12:09:53,093 - INFO - Epoch 34: train_loss=nan
2025-02-03 12:09:54,195 - INFO - Epoch 34: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:54,199 - INFO - ####################Training epoch 35####################
2025-02-03 12:09:55,336 - INFO - Epoch 35: train_loss=nan
2025-02-03 12:09:55,614 - INFO - Epoch 35: train_loss=nan
2025-02-03 12:09:55,838 - INFO - Epoch 35: train_loss=nan
2025-02-03 12:09:56,975 - INFO - Epoch 35: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:56,980 - INFO - ####################Training epoch 36####################
2025-02-03 12:09:58,073 - INFO - Epoch 36: train_loss=nan
2025-02-03 12:09:58,356 - INFO - Epoch 36: train_loss=nan
2025-02-03 12:09:58,581 - INFO - Epoch 36: train_loss=nan
2025-02-03 12:09:59,720 - INFO - Epoch 36: val_loss=nan, val_acc=66.67%
2025-02-03 12:09:59,731 - INFO - ####################Training epoch 37####################
2025-02-03 12:10:00,784 - INFO - Epoch 37: train_loss=nan
2025-02-03 12:10:01,062 - INFO - Epoch 37: train_loss=nan
2025-02-03 12:10:01,302 - INFO - Epoch 37: train_loss=nan
2025-02-03 12:10:02,509 - INFO - Epoch 37: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:02,520 - INFO - ####################Training epoch 38####################
2025-02-03 12:10:03,632 - INFO - Epoch 38: train_loss=nan
2025-02-03 12:10:03,929 - INFO - Epoch 38: train_loss=nan
2025-02-03 12:10:04,173 - INFO - Epoch 38: train_loss=nan
2025-02-03 12:10:05,344 - INFO - Epoch 38: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:05,351 - INFO - ####################Training epoch 39####################
2025-02-03 12:10:06,442 - INFO - Epoch 39: train_loss=nan
2025-02-03 12:10:06,698 - INFO - Epoch 39: train_loss=nan
2025-02-03 12:10:06,942 - INFO - Epoch 39: train_loss=nan
2025-02-03 12:10:08,084 - INFO - Epoch 39: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:08,090 - INFO - ####################Training epoch 40####################
2025-02-03 12:10:09,151 - INFO - Epoch 40: train_loss=nan
2025-02-03 12:10:09,433 - INFO - Epoch 40: train_loss=nan
2025-02-03 12:10:09,659 - INFO - Epoch 40: train_loss=nan
2025-02-03 12:10:10,733 - INFO - Epoch 40: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:10,744 - INFO - ####################Training epoch 41####################
2025-02-03 12:10:11,844 - INFO - Epoch 41: train_loss=nan
2025-02-03 12:10:12,126 - INFO - Epoch 41: train_loss=nan
2025-02-03 12:10:12,345 - INFO - Epoch 41: train_loss=nan
2025-02-03 12:10:13,416 - INFO - Epoch 41: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:13,421 - INFO - ####################Training epoch 42####################
2025-02-03 12:10:14,484 - INFO - Epoch 42: train_loss=nan
2025-02-03 12:10:14,761 - INFO - Epoch 42: train_loss=nan
2025-02-03 12:10:15,047 - INFO - Epoch 42: train_loss=nan
2025-02-03 12:10:16,249 - INFO - Epoch 42: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:16,255 - INFO - ####################Training epoch 43####################
2025-02-03 12:10:17,350 - INFO - Epoch 43: train_loss=nan
2025-02-03 12:10:17,689 - INFO - Epoch 43: train_loss=nan
2025-02-03 12:10:18,076 - INFO - Epoch 43: train_loss=nan
2025-02-03 12:10:19,216 - INFO - Epoch 43: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:19,221 - INFO - ####################Training epoch 44####################
2025-02-03 12:10:20,386 - INFO - Epoch 44: train_loss=nan
2025-02-03 12:10:20,832 - INFO - Epoch 44: train_loss=nan
2025-02-03 12:10:21,214 - INFO - Epoch 44: train_loss=nan
2025-02-03 12:10:22,288 - INFO - Epoch 44: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:22,297 - INFO - ####################Training epoch 45####################
2025-02-03 12:10:23,478 - INFO - Epoch 45: train_loss=nan
2025-02-03 12:10:23,904 - INFO - Epoch 45: train_loss=nan
2025-02-03 12:10:24,204 - INFO - Epoch 45: train_loss=nan
2025-02-03 12:10:25,307 - INFO - Epoch 45: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:25,313 - INFO - ####################Training epoch 46####################
2025-02-03 12:10:26,496 - INFO - Epoch 46: train_loss=nan
2025-02-03 12:10:26,852 - INFO - Epoch 46: train_loss=nan
2025-02-03 12:10:27,093 - INFO - Epoch 46: train_loss=nan
2025-02-03 12:10:28,265 - INFO - Epoch 46: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:28,270 - INFO - ####################Training epoch 47####################
2025-02-03 12:10:29,402 - INFO - Epoch 47: train_loss=nan
2025-02-03 12:10:29,685 - INFO - Epoch 47: train_loss=nan
2025-02-03 12:10:29,929 - INFO - Epoch 47: train_loss=nan
2025-02-03 12:10:31,030 - INFO - Epoch 47: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:31,035 - INFO - ####################Training epoch 48####################
2025-02-03 12:10:32,110 - INFO - Epoch 48: train_loss=nan
2025-02-03 12:10:32,379 - INFO - Epoch 48: train_loss=nan
2025-02-03 12:10:32,624 - INFO - Epoch 48: train_loss=nan
2025-02-03 12:10:33,729 - INFO - Epoch 48: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:33,734 - INFO - ####################Training epoch 49####################
2025-02-03 12:10:34,779 - INFO - Epoch 49: train_loss=nan
2025-02-03 12:10:35,058 - INFO - Epoch 49: train_loss=nan
2025-02-03 12:10:35,304 - INFO - Epoch 49: train_loss=nan
2025-02-03 12:10:36,426 - INFO - Epoch 49: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:36,444 - INFO - ####################Training epoch 50####################
2025-02-03 12:10:37,516 - INFO - Epoch 50: train_loss=nan
2025-02-03 12:10:37,798 - INFO - Epoch 50: train_loss=nan
2025-02-03 12:10:38,041 - INFO - Epoch 50: train_loss=nan
2025-02-03 12:10:39,236 - INFO - Epoch 50: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:39,252 - INFO - ####################Training epoch 51####################
2025-02-03 12:10:40,387 - INFO - Epoch 51: train_loss=nan
2025-02-03 12:10:40,685 - INFO - Epoch 51: train_loss=nan
2025-02-03 12:10:40,924 - INFO - Epoch 51: train_loss=nan
2025-02-03 12:10:42,104 - INFO - Epoch 51: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:42,112 - INFO - ####################Training epoch 52####################
2025-02-03 12:10:43,158 - INFO - Epoch 52: train_loss=nan
2025-02-03 12:10:43,437 - INFO - Epoch 52: train_loss=nan
2025-02-03 12:10:43,683 - INFO - Epoch 52: train_loss=nan
2025-02-03 12:10:44,833 - INFO - Epoch 52: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:44,838 - INFO - ####################Training epoch 53####################
2025-02-03 12:10:45,948 - INFO - Epoch 53: train_loss=nan
2025-02-03 12:10:46,205 - INFO - Epoch 53: train_loss=nan
2025-02-03 12:10:46,450 - INFO - Epoch 53: train_loss=nan
2025-02-03 12:10:47,547 - INFO - Epoch 53: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:47,557 - INFO - ####################Training epoch 54####################
2025-02-03 12:10:48,664 - INFO - Epoch 54: train_loss=nan
2025-02-03 12:10:48,945 - INFO - Epoch 54: train_loss=nan
2025-02-03 12:10:49,172 - INFO - Epoch 54: train_loss=nan
2025-02-03 12:10:50,273 - INFO - Epoch 54: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:50,277 - INFO - ####################Training epoch 55####################
2025-02-03 12:10:51,375 - INFO - Epoch 55: train_loss=nan
2025-02-03 12:10:51,658 - INFO - Epoch 55: train_loss=nan
2025-02-03 12:10:51,903 - INFO - Epoch 55: train_loss=nan
2025-02-03 12:10:53,075 - INFO - Epoch 55: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:53,080 - INFO - ####################Training epoch 56####################
2025-02-03 12:10:54,222 - INFO - Epoch 56: train_loss=nan
2025-02-03 12:10:54,501 - INFO - Epoch 56: train_loss=nan
2025-02-03 12:10:54,850 - INFO - Epoch 56: train_loss=nan
2025-02-03 12:10:56,025 - INFO - Epoch 56: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:56,031 - INFO - ####################Training epoch 57####################
2025-02-03 12:10:57,173 - INFO - Epoch 57: train_loss=nan
2025-02-03 12:10:57,511 - INFO - Epoch 57: train_loss=nan
2025-02-03 12:10:57,917 - INFO - Epoch 57: train_loss=nan
2025-02-03 12:10:59,085 - INFO - Epoch 57: val_loss=nan, val_acc=66.67%
2025-02-03 12:10:59,095 - INFO - ####################Training epoch 58####################
2025-02-03 12:11:00,209 - INFO - Epoch 58: train_loss=nan
2025-02-03 12:11:00,656 - INFO - Epoch 58: train_loss=nan
2025-02-03 12:11:01,047 - INFO - Epoch 58: train_loss=nan
2025-02-03 12:11:02,181 - INFO - Epoch 58: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:02,191 - INFO - ####################Training epoch 59####################
2025-02-03 12:11:03,318 - INFO - Epoch 59: train_loss=nan
2025-02-03 12:11:03,762 - INFO - Epoch 59: train_loss=nan
2025-02-03 12:11:04,137 - INFO - Epoch 59: train_loss=nan
2025-02-03 12:11:05,368 - INFO - Epoch 59: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:05,373 - INFO - ####################Training epoch 60####################
2025-02-03 12:11:06,618 - INFO - Epoch 60: train_loss=nan
2025-02-03 12:11:07,028 - INFO - Epoch 60: train_loss=nan
2025-02-03 12:11:07,322 - INFO - Epoch 60: train_loss=nan
2025-02-03 12:11:08,484 - INFO - Epoch 60: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:08,489 - INFO - ####################Training epoch 61####################
2025-02-03 12:11:09,714 - INFO - Epoch 61: train_loss=nan
2025-02-03 12:11:10,088 - INFO - Epoch 61: train_loss=nan
2025-02-03 12:11:10,315 - INFO - Epoch 61: train_loss=nan
2025-02-03 12:11:11,465 - INFO - Epoch 61: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:11,471 - INFO - ####################Training epoch 62####################
2025-02-03 12:11:12,648 - INFO - Epoch 62: train_loss=nan
2025-02-03 12:11:12,925 - INFO - Epoch 62: train_loss=nan
2025-02-03 12:11:13,152 - INFO - Epoch 62: train_loss=nan
2025-02-03 12:11:14,308 - INFO - Epoch 62: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:14,313 - INFO - ####################Training epoch 63####################
2025-02-03 12:11:15,405 - INFO - Epoch 63: train_loss=nan
2025-02-03 12:11:15,687 - INFO - Epoch 63: train_loss=nan
2025-02-03 12:11:15,913 - INFO - Epoch 63: train_loss=nan
2025-02-03 12:11:17,146 - INFO - Epoch 63: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:17,160 - INFO - ####################Training epoch 64####################
2025-02-03 12:11:18,209 - INFO - Epoch 64: train_loss=nan
2025-02-03 12:11:18,487 - INFO - Epoch 64: train_loss=nan
2025-02-03 12:11:18,726 - INFO - Epoch 64: train_loss=nan
2025-02-03 12:11:19,961 - INFO - Epoch 64: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:19,967 - INFO - ####################Training epoch 65####################
2025-02-03 12:11:21,025 - INFO - Epoch 65: train_loss=nan
2025-02-03 12:11:21,308 - INFO - Epoch 65: train_loss=nan
2025-02-03 12:11:21,563 - INFO - Epoch 65: train_loss=nan
2025-02-03 12:11:22,740 - INFO - Epoch 65: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:22,751 - INFO - ####################Training epoch 66####################
2025-02-03 12:11:23,835 - INFO - Epoch 66: train_loss=nan
2025-02-03 12:11:24,132 - INFO - Epoch 66: train_loss=nan
2025-02-03 12:11:24,372 - INFO - Epoch 66: train_loss=nan
2025-02-03 12:11:25,607 - INFO - Epoch 66: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:25,612 - INFO - ####################Training epoch 67####################
2025-02-03 12:11:26,731 - INFO - Epoch 67: train_loss=nan
2025-02-03 12:11:27,011 - INFO - Epoch 67: train_loss=nan
2025-02-03 12:11:27,253 - INFO - Epoch 67: train_loss=nan
2025-02-03 12:11:28,362 - INFO - Epoch 67: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:28,372 - INFO - ####################Training epoch 68####################
2025-02-03 12:11:29,523 - INFO - Epoch 68: train_loss=nan
2025-02-03 12:11:29,804 - INFO - Epoch 68: train_loss=nan
2025-02-03 12:11:30,048 - INFO - Epoch 68: train_loss=nan
2025-02-03 12:11:31,184 - INFO - Epoch 68: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:31,188 - INFO - ####################Training epoch 69####################
2025-02-03 12:11:32,277 - INFO - Epoch 69: train_loss=nan
2025-02-03 12:11:32,557 - INFO - Epoch 69: train_loss=nan
2025-02-03 12:11:32,802 - INFO - Epoch 69: train_loss=nan
2025-02-03 12:11:33,945 - INFO - Epoch 69: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:33,949 - INFO - ####################Training epoch 70####################
2025-02-03 12:11:35,079 - INFO - Epoch 70: train_loss=nan
2025-02-03 12:11:35,336 - INFO - Epoch 70: train_loss=nan
2025-02-03 12:11:35,650 - INFO - Epoch 70: train_loss=nan
2025-02-03 12:11:36,779 - INFO - Epoch 70: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:36,787 - INFO - ####################Training epoch 71####################
2025-02-03 12:11:37,873 - INFO - Epoch 71: train_loss=nan
2025-02-03 12:11:38,169 - INFO - Epoch 71: train_loss=nan
2025-02-03 12:11:38,585 - INFO - Epoch 71: train_loss=nan
2025-02-03 12:11:39,737 - INFO - Epoch 71: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:39,741 - INFO - ####################Training epoch 72####################
2025-02-03 12:11:40,911 - INFO - Epoch 72: train_loss=nan
2025-02-03 12:11:41,336 - INFO - Epoch 72: train_loss=nan
2025-02-03 12:11:41,708 - INFO - Epoch 72: train_loss=nan
2025-02-03 12:11:42,891 - INFO - Epoch 72: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:42,897 - INFO - ####################Training epoch 73####################
2025-02-03 12:11:44,093 - INFO - Epoch 73: train_loss=nan
2025-02-03 12:11:44,540 - INFO - Epoch 73: train_loss=nan
2025-02-03 12:11:44,853 - INFO - Epoch 73: train_loss=nan
2025-02-03 12:11:45,994 - INFO - Epoch 73: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:45,999 - INFO - ####################Training epoch 74####################
2025-02-03 12:11:47,152 - INFO - Epoch 74: train_loss=nan
2025-02-03 12:11:47,575 - INFO - Epoch 74: train_loss=nan
2025-02-03 12:11:47,809 - INFO - Epoch 74: train_loss=nan
2025-02-03 12:11:48,912 - INFO - Epoch 74: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:48,918 - INFO - ####################Training epoch 75####################
2025-02-03 12:11:50,077 - INFO - Epoch 75: train_loss=nan
2025-02-03 12:11:50,381 - INFO - Epoch 75: train_loss=nan
2025-02-03 12:11:50,625 - INFO - Epoch 75: train_loss=nan
2025-02-03 12:11:51,743 - INFO - Epoch 75: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:51,753 - INFO - ####################Training epoch 76####################
2025-02-03 12:11:52,847 - INFO - Epoch 76: train_loss=nan
2025-02-03 12:11:53,125 - INFO - Epoch 76: train_loss=nan
2025-02-03 12:11:53,369 - INFO - Epoch 76: train_loss=nan
2025-02-03 12:11:54,485 - INFO - Epoch 76: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:54,491 - INFO - ####################Training epoch 77####################
2025-02-03 12:11:55,582 - INFO - Epoch 77: train_loss=nan
2025-02-03 12:11:55,839 - INFO - Epoch 77: train_loss=nan
2025-02-03 12:11:56,082 - INFO - Epoch 77: train_loss=nan
2025-02-03 12:11:57,240 - INFO - Epoch 77: val_loss=nan, val_acc=66.67%
2025-02-03 12:11:57,245 - INFO - ####################Training epoch 78####################
2025-02-03 12:11:58,301 - INFO - Epoch 78: train_loss=nan
2025-02-03 12:11:58,579 - INFO - Epoch 78: train_loss=nan
2025-02-03 12:11:58,818 - INFO - Epoch 78: train_loss=nan
2025-02-03 12:12:00,051 - INFO - Epoch 78: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:00,058 - INFO - ####################Training epoch 79####################
2025-02-03 12:12:01,117 - INFO - Epoch 79: train_loss=nan
2025-02-03 12:12:01,400 - INFO - Epoch 79: train_loss=nan
2025-02-03 12:12:01,655 - INFO - Epoch 79: train_loss=nan
2025-02-03 12:12:02,817 - INFO - Epoch 79: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:02,837 - INFO - ####################Training epoch 80####################
2025-02-03 12:12:03,919 - INFO - Epoch 80: train_loss=nan
2025-02-03 12:12:04,219 - INFO - Epoch 80: train_loss=nan
2025-02-03 12:12:04,445 - INFO - Epoch 80: train_loss=nan
2025-02-03 12:12:05,720 - INFO - Epoch 80: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:05,729 - INFO - ####################Training epoch 81####################
2025-02-03 12:12:06,858 - INFO - Epoch 81: train_loss=nan
2025-02-03 12:12:07,140 - INFO - Epoch 81: train_loss=nan
2025-02-03 12:12:07,368 - INFO - Epoch 81: train_loss=nan
2025-02-03 12:12:08,477 - INFO - Epoch 81: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:08,481 - INFO - ####################Training epoch 82####################
2025-02-03 12:12:09,592 - INFO - Epoch 82: train_loss=nan
2025-02-03 12:12:09,863 - INFO - Epoch 82: train_loss=nan
2025-02-03 12:12:10,107 - INFO - Epoch 82: train_loss=nan
2025-02-03 12:12:11,242 - INFO - Epoch 82: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:11,247 - INFO - ####################Training epoch 83####################
2025-02-03 12:12:12,373 - INFO - Epoch 83: train_loss=nan
2025-02-03 12:12:12,630 - INFO - Epoch 83: train_loss=nan
2025-02-03 12:12:12,889 - INFO - Epoch 83: train_loss=nan
2025-02-03 12:12:14,021 - INFO - Epoch 83: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:14,027 - INFO - ####################Training epoch 84####################
2025-02-03 12:12:15,143 - INFO - Epoch 84: train_loss=nan
2025-02-03 12:12:15,425 - INFO - Epoch 84: train_loss=nan
2025-02-03 12:12:15,743 - INFO - Epoch 84: train_loss=nan
2025-02-03 12:12:16,859 - INFO - Epoch 84: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:16,865 - INFO - ####################Training epoch 85####################
2025-02-03 12:12:18,019 - INFO - Epoch 85: train_loss=nan
2025-02-03 12:12:18,333 - INFO - Epoch 85: train_loss=nan
2025-02-03 12:12:18,737 - INFO - Epoch 85: train_loss=nan
2025-02-03 12:12:19,848 - INFO - Epoch 85: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:19,855 - INFO - ####################Training epoch 86####################
2025-02-03 12:12:20,985 - INFO - Epoch 86: train_loss=nan
2025-02-03 12:12:21,406 - INFO - Epoch 86: train_loss=nan
2025-02-03 12:12:21,795 - INFO - Epoch 86: train_loss=nan
2025-02-03 12:12:22,943 - INFO - Epoch 86: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:22,948 - INFO - ####################Training epoch 87####################
2025-02-03 12:12:24,085 - INFO - Epoch 87: train_loss=nan
2025-02-03 12:12:24,520 - INFO - Epoch 87: train_loss=nan
2025-02-03 12:12:24,910 - INFO - Epoch 87: train_loss=nan
2025-02-03 12:12:26,060 - INFO - Epoch 87: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:26,066 - INFO - ####################Training epoch 88####################
2025-02-03 12:12:27,261 - INFO - Epoch 88: train_loss=nan
2025-02-03 12:12:27,709 - INFO - Epoch 88: train_loss=nan
2025-02-03 12:12:27,976 - INFO - Epoch 88: train_loss=nan
2025-02-03 12:12:29,112 - INFO - Epoch 88: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:29,119 - INFO - ####################Training epoch 89####################
2025-02-03 12:12:30,310 - INFO - Epoch 89: train_loss=nan
2025-02-03 12:12:30,638 - INFO - Epoch 89: train_loss=nan
2025-02-03 12:12:30,877 - INFO - Epoch 89: train_loss=nan
2025-02-03 12:12:32,005 - INFO - Epoch 89: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:32,015 - INFO - ####################Training epoch 90####################
2025-02-03 12:12:33,157 - INFO - Epoch 90: train_loss=nan
2025-02-03 12:12:33,414 - INFO - Epoch 90: train_loss=nan
2025-02-03 12:12:33,657 - INFO - Epoch 90: train_loss=nan
2025-02-03 12:12:34,767 - INFO - Epoch 90: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:34,773 - INFO - ####################Training epoch 91####################
2025-02-03 12:12:35,864 - INFO - Epoch 91: train_loss=nan
2025-02-03 12:12:36,119 - INFO - Epoch 91: train_loss=nan
2025-02-03 12:12:36,364 - INFO - Epoch 91: train_loss=nan
2025-02-03 12:12:37,478 - INFO - Epoch 91: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:37,483 - INFO - ####################Training epoch 92####################
2025-02-03 12:12:38,571 - INFO - Epoch 92: train_loss=nan
2025-02-03 12:12:38,827 - INFO - Epoch 92: train_loss=nan
2025-02-03 12:12:39,071 - INFO - Epoch 92: train_loss=nan
2025-02-03 12:12:40,282 - INFO - Epoch 92: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:40,293 - INFO - ####################Training epoch 93####################
2025-02-03 12:12:41,435 - INFO - Epoch 93: train_loss=nan
2025-02-03 12:12:41,691 - INFO - Epoch 93: train_loss=nan
2025-02-03 12:12:41,954 - INFO - Epoch 93: train_loss=nan
2025-02-03 12:12:43,167 - INFO - Epoch 93: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:43,179 - INFO - ####################Training epoch 94####################
2025-02-03 12:12:44,267 - INFO - Epoch 94: train_loss=nan
2025-02-03 12:12:44,543 - INFO - Epoch 94: train_loss=nan
2025-02-03 12:12:44,785 - INFO - Epoch 94: train_loss=nan
2025-02-03 12:12:46,012 - INFO - Epoch 94: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:46,017 - INFO - ####################Training epoch 95####################
2025-02-03 12:12:47,145 - INFO - Epoch 95: train_loss=nan
2025-02-03 12:12:47,423 - INFO - Epoch 95: train_loss=nan
2025-02-03 12:12:47,666 - INFO - Epoch 95: train_loss=nan
2025-02-03 12:12:48,762 - INFO - Epoch 95: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:48,768 - INFO - ####################Training epoch 96####################
2025-02-03 12:12:49,897 - INFO - Epoch 96: train_loss=nan
2025-02-03 12:12:50,180 - INFO - Epoch 96: train_loss=nan
2025-02-03 12:12:50,407 - INFO - Epoch 96: train_loss=nan
2025-02-03 12:12:51,534 - INFO - Epoch 96: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:51,539 - INFO - ####################Training epoch 97####################
2025-02-03 12:12:52,626 - INFO - Epoch 97: train_loss=nan
2025-02-03 12:12:52,890 - INFO - Epoch 97: train_loss=nan
2025-02-03 12:12:53,132 - INFO - Epoch 97: train_loss=nan
2025-02-03 12:12:54,237 - INFO - Epoch 97: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:54,241 - INFO - ####################Training epoch 98####################
2025-02-03 12:12:55,330 - INFO - Epoch 98: train_loss=nan
2025-02-03 12:12:55,587 - INFO - Epoch 98: train_loss=nan
2025-02-03 12:12:55,828 - INFO - Epoch 98: train_loss=nan
2025-02-03 12:12:56,904 - INFO - Epoch 98: val_loss=nan, val_acc=66.67%
2025-02-03 12:12:56,910 - INFO - ####################Training epoch 99####################
2025-02-03 12:12:58,009 - INFO - Epoch 99: train_loss=nan
2025-02-03 12:12:58,291 - INFO - Epoch 99: train_loss=nan
2025-02-03 12:12:58,531 - INFO - Epoch 99: train_loss=nan
2025-02-03 12:12:59,633 - INFO - Epoch 99: val_loss=nan, val_acc=66.67%
2025-02-03 12:13:00,206 - INFO - Model saved.
