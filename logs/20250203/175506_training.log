2025-02-03 17:55:13,221 - INFO - Starting training with the following parameters:
2025-02-03 17:55:13,222 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product|
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.001          |
| epochs          | 1000           |
| batch_size      | 32             |

2025-02-03 17:55:13,837 - INFO - Epoch 0: val_loss=1.4502, val_acc=0.00%
2025-02-03 17:55:13,975 - INFO - ####################Training epoch 0####################
2025-02-03 17:55:14,122 - INFO - Epoch 0: train_loss=1.1148
2025-02-03 17:55:14,656 - INFO - Epoch 0: val_loss=2.1839, val_acc=33.33%
2025-02-03 17:55:14,659 - INFO - Epoch 0: EPOCH_AVG_TRAIN_LOSS=1.1148
2025-02-03 17:55:14,689 - INFO - ####################Training epoch 1####################
2025-02-03 17:55:14,972 - INFO - Epoch 1: train_loss=1.7333
2025-02-03 17:55:15,443 - INFO - Epoch 1: val_loss=1.9073, val_acc=0.00%
2025-02-03 17:55:15,446 - INFO - Epoch 1: EPOCH_AVG_TRAIN_LOSS=1.7333
2025-02-03 17:55:15,471 - INFO - ####################Training epoch 2####################
2025-02-03 17:55:15,758 - INFO - Epoch 2: train_loss=1.0509
2025-02-03 17:55:16,232 - INFO - Epoch 2: val_loss=2.0069, val_acc=33.33%
2025-02-03 17:55:16,235 - INFO - Epoch 2: EPOCH_AVG_TRAIN_LOSS=1.0509
2025-02-03 17:55:16,261 - INFO - ####################Training epoch 3####################
2025-02-03 17:55:16,547 - INFO - Epoch 3: train_loss=1.3366
2025-02-03 17:55:17,020 - INFO - Epoch 3: val_loss=2.1606, val_acc=33.33%
2025-02-03 17:55:17,024 - INFO - Epoch 3: EPOCH_AVG_TRAIN_LOSS=1.3366
2025-02-03 17:55:17,051 - INFO - ####################Training epoch 4####################
2025-02-03 17:55:17,343 - INFO - Epoch 4: train_loss=1.4589
2025-02-03 17:55:17,820 - INFO - Epoch 4: val_loss=2.0495, val_acc=33.33%
2025-02-03 17:55:17,824 - INFO - Epoch 4: EPOCH_AVG_TRAIN_LOSS=1.4589
2025-02-03 17:55:17,852 - INFO - ####################Training epoch 5####################
2025-02-03 17:55:18,141 - INFO - Epoch 5: train_loss=1.1627
2025-02-03 17:55:18,615 - INFO - Epoch 5: val_loss=2.0512, val_acc=0.00%
2025-02-03 17:55:18,619 - INFO - Epoch 5: EPOCH_AVG_TRAIN_LOSS=1.1627
2025-02-03 17:55:18,621 - INFO - ####################Training epoch 6####################
2025-02-03 17:55:18,908 - INFO - Epoch 6: train_loss=1.0053
2025-02-03 17:55:19,378 - INFO - Epoch 6: val_loss=2.1154, val_acc=33.33%
2025-02-03 17:55:19,382 - INFO - Epoch 6: EPOCH_AVG_TRAIN_LOSS=1.0053
2025-02-03 17:55:19,384 - INFO - ####################Training epoch 7####################
2025-02-03 17:55:19,672 - INFO - Epoch 7: train_loss=1.0587
2025-02-03 17:55:20,145 - INFO - Epoch 7: val_loss=2.1988, val_acc=33.33%
2025-02-03 17:55:20,149 - INFO - Epoch 7: EPOCH_AVG_TRAIN_LOSS=1.0587
2025-02-03 17:55:20,151 - INFO - ####################Training epoch 8####################
2025-02-03 17:55:20,441 - INFO - Epoch 8: train_loss=1.0984
2025-02-03 17:55:20,914 - INFO - Epoch 8: val_loss=2.2082, val_acc=33.33%
2025-02-03 17:55:20,918 - INFO - Epoch 8: EPOCH_AVG_TRAIN_LOSS=1.0984
2025-02-03 17:55:20,920 - INFO - ####################Training epoch 9####################
2025-02-03 17:55:21,210 - INFO - Epoch 9: train_loss=1.0720
2025-02-03 17:55:21,684 - INFO - Epoch 9: val_loss=2.2074, val_acc=33.33%
2025-02-03 17:55:21,688 - INFO - Epoch 9: EPOCH_AVG_TRAIN_LOSS=1.0720
2025-02-03 17:55:21,690 - INFO - ####################Training epoch 10####################
2025-02-03 17:55:21,982 - INFO - Epoch 10: train_loss=1.0255
2025-02-03 17:55:22,456 - INFO - Epoch 10: val_loss=2.2146, val_acc=33.33%
2025-02-03 17:55:22,460 - INFO - Epoch 10: EPOCH_AVG_TRAIN_LOSS=1.0255
2025-02-03 17:55:22,462 - INFO - ####################Training epoch 11####################
2025-02-03 17:55:22,780 - INFO - Epoch 11: train_loss=0.9830
2025-02-03 17:55:23,248 - INFO - Epoch 11: val_loss=2.2247, val_acc=33.33%
2025-02-03 17:55:23,251 - INFO - Epoch 11: EPOCH_AVG_TRAIN_LOSS=0.9830
2025-02-03 17:55:23,254 - INFO - ####################Training epoch 12####################
2025-02-03 17:55:23,544 - INFO - Epoch 12: train_loss=0.9601
2025-02-03 17:55:24,017 - INFO - Epoch 12: val_loss=2.2398, val_acc=33.33%
2025-02-03 17:55:24,020 - INFO - Epoch 12: EPOCH_AVG_TRAIN_LOSS=0.9601
2025-02-03 17:55:24,023 - INFO - ####################Training epoch 13####################
2025-02-03 17:55:24,313 - INFO - Epoch 13: train_loss=0.9644
2025-02-03 17:55:24,787 - INFO - Epoch 13: val_loss=2.2621, val_acc=33.33%
2025-02-03 17:55:24,791 - INFO - Epoch 13: EPOCH_AVG_TRAIN_LOSS=0.9644
2025-02-03 17:55:24,794 - INFO - ####################Training epoch 14####################
2025-02-03 17:55:25,085 - INFO - Epoch 14: train_loss=0.9735
2025-02-03 17:55:25,557 - INFO - Epoch 14: val_loss=2.2796, val_acc=33.33%
2025-02-03 17:55:25,561 - INFO - Epoch 14: EPOCH_AVG_TRAIN_LOSS=0.9735
2025-02-03 17:55:25,563 - INFO - ####################Training epoch 15####################
2025-02-03 17:55:25,855 - INFO - Epoch 15: train_loss=0.9726
2025-02-03 17:55:26,330 - INFO - Epoch 15: val_loss=2.2941, val_acc=33.33%
2025-02-03 17:55:26,333 - INFO - Epoch 15: EPOCH_AVG_TRAIN_LOSS=0.9726
2025-02-03 17:55:26,336 - INFO - ####################Training epoch 16####################
2025-02-03 17:55:26,626 - INFO - Epoch 16: train_loss=0.9621
2025-02-03 17:55:27,103 - INFO - Epoch 16: val_loss=2.3087, val_acc=33.33%
2025-02-03 17:55:27,106 - INFO - Epoch 16: EPOCH_AVG_TRAIN_LOSS=0.9621
2025-02-03 17:55:27,108 - INFO - ####################Training epoch 17####################
2025-02-03 17:55:27,400 - INFO - Epoch 17: train_loss=0.9461
2025-02-03 17:55:27,876 - INFO - Epoch 17: val_loss=2.3317, val_acc=0.00%
2025-02-03 17:55:27,879 - INFO - Epoch 17: EPOCH_AVG_TRAIN_LOSS=0.9461
2025-02-03 17:55:27,882 - INFO - ####################Training epoch 18####################
2025-02-03 17:55:28,171 - INFO - Epoch 18: train_loss=0.9265
2025-02-03 17:55:28,766 - INFO - Epoch 18: val_loss=2.3678, val_acc=33.33%
2025-02-03 17:55:28,769 - INFO - Epoch 18: EPOCH_AVG_TRAIN_LOSS=0.9265
2025-02-03 17:55:28,771 - INFO - ####################Training epoch 19####################
2025-02-03 17:55:29,059 - INFO - Epoch 19: train_loss=0.9116
2025-02-03 17:55:29,537 - INFO - Epoch 19: val_loss=2.4157, val_acc=33.33%
2025-02-03 17:55:29,541 - INFO - Epoch 19: EPOCH_AVG_TRAIN_LOSS=0.9116
2025-02-03 17:55:29,544 - INFO - ####################Training epoch 20####################
2025-02-03 17:55:29,839 - INFO - Epoch 20: train_loss=0.9040
2025-02-03 17:55:30,314 - INFO - Epoch 20: val_loss=2.4446, val_acc=33.33%
2025-02-03 17:55:30,318 - INFO - Epoch 20: EPOCH_AVG_TRAIN_LOSS=0.9040
2025-02-03 17:55:30,320 - INFO - ####################Training epoch 21####################
2025-02-03 17:55:30,617 - INFO - Epoch 21: train_loss=0.8861
2025-02-03 17:55:31,128 - INFO - Epoch 21: val_loss=2.5519, val_acc=33.33%
2025-02-03 17:55:31,131 - INFO - Epoch 21: EPOCH_AVG_TRAIN_LOSS=0.8861
2025-02-03 17:55:31,134 - INFO - ####################Training epoch 22####################
2025-02-03 17:55:31,425 - INFO - Epoch 22: train_loss=0.9026
2025-02-03 17:55:31,899 - INFO - Epoch 22: val_loss=2.4870, val_acc=33.33%
2025-02-03 17:55:31,903 - INFO - Epoch 22: EPOCH_AVG_TRAIN_LOSS=0.9026
2025-02-03 17:55:31,905 - INFO - ####################Training epoch 23####################
2025-02-03 17:55:32,198 - INFO - Epoch 23: train_loss=0.8784
2025-02-03 17:55:32,674 - INFO - Epoch 23: val_loss=2.4809, val_acc=33.33%
2025-02-03 17:55:32,677 - INFO - Epoch 23: EPOCH_AVG_TRAIN_LOSS=0.8784
2025-02-03 17:55:32,679 - INFO - ####################Training epoch 24####################
2025-02-03 17:55:32,968 - INFO - Epoch 24: train_loss=0.8948
2025-02-03 17:55:33,441 - INFO - Epoch 24: val_loss=2.4977, val_acc=33.33%
2025-02-03 17:55:33,445 - INFO - Epoch 24: EPOCH_AVG_TRAIN_LOSS=0.8948
2025-02-03 17:55:33,447 - INFO - ####################Training epoch 25####################
2025-02-03 17:55:33,739 - INFO - Epoch 25: train_loss=0.8935
2025-02-03 17:55:34,209 - INFO - Epoch 25: val_loss=2.5093, val_acc=33.33%
2025-02-03 17:55:34,213 - INFO - Epoch 25: EPOCH_AVG_TRAIN_LOSS=0.8935
2025-02-03 17:55:34,215 - INFO - ####################Training epoch 26####################
2025-02-03 17:55:34,503 - INFO - Epoch 26: train_loss=0.8905
2025-02-03 17:55:34,974 - INFO - Epoch 26: val_loss=2.5126, val_acc=33.33%
2025-02-03 17:55:34,978 - INFO - Epoch 26: EPOCH_AVG_TRAIN_LOSS=0.8905
2025-02-03 17:55:34,980 - INFO - ####################Training epoch 27####################
2025-02-03 17:55:35,272 - INFO - Epoch 27: train_loss=0.8792
2025-02-03 17:55:35,748 - INFO - Epoch 27: val_loss=2.5328, val_acc=33.33%
2025-02-03 17:55:35,751 - INFO - Epoch 27: EPOCH_AVG_TRAIN_LOSS=0.8792
2025-02-03 17:55:35,754 - INFO - ####################Training epoch 28####################
2025-02-03 17:55:36,048 - INFO - Epoch 28: train_loss=0.8645
2025-02-03 17:55:36,527 - INFO - Epoch 28: val_loss=2.6216, val_acc=33.33%
2025-02-03 17:55:36,530 - INFO - Epoch 28: EPOCH_AVG_TRAIN_LOSS=0.8645
2025-02-03 17:55:36,533 - INFO - ####################Training epoch 29####################
2025-02-03 17:55:36,826 - INFO - Epoch 29: train_loss=0.8778
2025-02-03 17:55:37,300 - INFO - Epoch 29: val_loss=2.6638, val_acc=33.33%
2025-02-03 17:55:37,304 - INFO - Epoch 29: EPOCH_AVG_TRAIN_LOSS=0.8778
2025-02-03 17:55:37,306 - INFO - ####################Training epoch 30####################
2025-02-03 17:55:37,597 - INFO - Epoch 30: train_loss=0.8868
2025-02-03 17:55:38,071 - INFO - Epoch 30: val_loss=2.6680, val_acc=33.33%
2025-02-03 17:55:38,074 - INFO - Epoch 30: EPOCH_AVG_TRAIN_LOSS=0.8868
2025-02-03 17:55:38,077 - INFO - ####################Training epoch 31####################
2025-02-03 17:55:38,369 - INFO - Epoch 31: train_loss=0.8805
2025-02-03 17:55:38,842 - INFO - Epoch 31: val_loss=2.6230, val_acc=33.33%
2025-02-03 17:55:38,846 - INFO - Epoch 31: EPOCH_AVG_TRAIN_LOSS=0.8805
2025-02-03 17:55:38,848 - INFO - ####################Training epoch 32####################
2025-02-03 17:55:39,143 - INFO - Epoch 32: train_loss=0.8661
2025-02-03 17:55:39,627 - INFO - Epoch 32: val_loss=2.5941, val_acc=33.33%
2025-02-03 17:55:39,631 - INFO - Epoch 32: EPOCH_AVG_TRAIN_LOSS=0.8661
2025-02-03 17:55:39,634 - INFO - ####################Training epoch 33####################
2025-02-03 17:55:39,924 - INFO - Epoch 33: train_loss=0.8597
2025-02-03 17:55:40,396 - INFO - Epoch 33: val_loss=2.5630, val_acc=33.33%
2025-02-03 17:55:40,399 - INFO - Epoch 33: EPOCH_AVG_TRAIN_LOSS=0.8597
2025-02-03 17:55:40,402 - INFO - ####################Training epoch 34####################
2025-02-03 17:55:40,691 - INFO - Epoch 34: train_loss=0.8525
2025-02-03 17:55:41,165 - INFO - Epoch 34: val_loss=2.5424, val_acc=33.33%
2025-02-03 17:55:41,168 - INFO - Epoch 34: EPOCH_AVG_TRAIN_LOSS=0.8525
2025-02-03 17:55:41,170 - INFO - ####################Training epoch 35####################
2025-02-03 17:55:41,461 - INFO - Epoch 35: train_loss=0.8527
2025-02-03 17:55:41,932 - INFO - Epoch 35: val_loss=2.5472, val_acc=33.33%
2025-02-03 17:55:41,936 - INFO - Epoch 35: EPOCH_AVG_TRAIN_LOSS=0.8527
2025-02-03 17:55:41,938 - INFO - ####################Training epoch 36####################
2025-02-03 17:55:42,230 - INFO - Epoch 36: train_loss=0.8529
2025-02-03 17:55:42,700 - INFO - Epoch 36: val_loss=2.5451, val_acc=33.33%
2025-02-03 17:55:42,703 - INFO - Epoch 36: EPOCH_AVG_TRAIN_LOSS=0.8529
2025-02-03 17:55:42,706 - INFO - ####################Training epoch 37####################
2025-02-03 17:55:42,995 - INFO - Epoch 37: train_loss=0.8551
2025-02-03 17:55:43,471 - INFO - Epoch 37: val_loss=2.5358, val_acc=33.33%
2025-02-03 17:55:43,475 - INFO - Epoch 37: EPOCH_AVG_TRAIN_LOSS=0.8551
2025-02-03 17:55:43,477 - INFO - ####################Training epoch 38####################
2025-02-03 17:55:43,770 - INFO - Epoch 38: train_loss=0.8532
2025-02-03 17:55:44,241 - INFO - Epoch 38: val_loss=2.5398, val_acc=33.33%
2025-02-03 17:55:44,245 - INFO - Epoch 38: EPOCH_AVG_TRAIN_LOSS=0.8532
2025-02-03 17:55:44,247 - INFO - ####################Training epoch 39####################
2025-02-03 17:55:44,536 - INFO - Epoch 39: train_loss=0.8553
2025-02-03 17:55:45,007 - INFO - Epoch 39: val_loss=2.5450, val_acc=33.33%
2025-02-03 17:55:45,011 - INFO - Epoch 39: EPOCH_AVG_TRAIN_LOSS=0.8553
2025-02-03 17:55:45,013 - INFO - ####################Training epoch 40####################
2025-02-03 17:55:45,302 - INFO - Epoch 40: train_loss=0.8489
2025-02-03 17:55:45,770 - INFO - Epoch 40: val_loss=2.5480, val_acc=33.33%
2025-02-03 17:55:45,774 - INFO - Epoch 40: EPOCH_AVG_TRAIN_LOSS=0.8489
2025-02-03 17:55:45,776 - INFO - ####################Training epoch 41####################
2025-02-03 17:55:46,066 - INFO - Epoch 41: train_loss=0.8492
2025-02-03 17:55:46,541 - INFO - Epoch 41: val_loss=2.5402, val_acc=33.33%
2025-02-03 17:55:46,545 - INFO - Epoch 41: EPOCH_AVG_TRAIN_LOSS=0.8492
2025-02-03 17:55:46,547 - INFO - ####################Training epoch 42####################
2025-02-03 17:55:46,839 - INFO - Epoch 42: train_loss=0.8438
2025-02-03 17:55:47,312 - INFO - Epoch 42: val_loss=2.5501, val_acc=33.33%
2025-02-03 17:55:47,316 - INFO - Epoch 42: EPOCH_AVG_TRAIN_LOSS=0.8438
2025-02-03 17:55:47,318 - INFO - ####################Training epoch 43####################
2025-02-03 17:55:47,609 - INFO - Epoch 43: train_loss=0.8436
2025-02-03 17:55:48,102 - INFO - Epoch 43: val_loss=2.5575, val_acc=33.33%
2025-02-03 17:55:48,106 - INFO - Epoch 43: EPOCH_AVG_TRAIN_LOSS=0.8436
2025-02-03 17:55:48,108 - INFO - ####################Training epoch 44####################
2025-02-03 17:55:48,398 - INFO - Epoch 44: train_loss=0.8417
2025-02-03 17:55:48,870 - INFO - Epoch 44: val_loss=2.5620, val_acc=33.33%
2025-02-03 17:55:48,874 - INFO - Epoch 44: EPOCH_AVG_TRAIN_LOSS=0.8417
2025-02-03 17:55:48,876 - INFO - ####################Training epoch 45####################
2025-02-03 17:55:49,166 - INFO - Epoch 45: train_loss=0.8461
2025-02-03 17:55:49,638 - INFO - Epoch 45: val_loss=2.5624, val_acc=33.33%
2025-02-03 17:55:49,641 - INFO - Epoch 45: EPOCH_AVG_TRAIN_LOSS=0.8461
2025-02-03 17:55:49,643 - INFO - ####################Training epoch 46####################
2025-02-03 17:55:49,934 - INFO - Epoch 46: train_loss=0.8437
2025-02-03 17:55:50,406 - INFO - Epoch 46: val_loss=2.5624, val_acc=33.33%
2025-02-03 17:55:50,410 - INFO - Epoch 46: EPOCH_AVG_TRAIN_LOSS=0.8437
2025-02-03 17:55:50,412 - INFO - ####################Training epoch 47####################
2025-02-03 17:55:50,704 - INFO - Epoch 47: train_loss=0.8408
2025-02-03 17:55:51,175 - INFO - Epoch 47: val_loss=2.5719, val_acc=33.33%
2025-02-03 17:55:51,178 - INFO - Epoch 47: EPOCH_AVG_TRAIN_LOSS=0.8408
2025-02-03 17:55:51,181 - INFO - ####################Training epoch 48####################
2025-02-03 17:55:51,474 - INFO - Epoch 48: train_loss=0.8413
2025-02-03 17:55:51,943 - INFO - Epoch 48: val_loss=2.5652, val_acc=33.33%
2025-02-03 17:55:51,947 - INFO - Epoch 48: EPOCH_AVG_TRAIN_LOSS=0.8413
2025-02-03 17:55:51,949 - INFO - ####################Training epoch 49####################
2025-02-03 17:55:52,243 - INFO - Epoch 49: train_loss=0.8417
2025-02-03 17:55:52,714 - INFO - Epoch 49: val_loss=2.5646, val_acc=33.33%
2025-02-03 17:55:52,717 - INFO - Epoch 49: EPOCH_AVG_TRAIN_LOSS=0.8417
2025-02-03 17:55:52,720 - INFO - ####################Training epoch 50####################
2025-02-03 17:55:53,009 - INFO - Epoch 50: train_loss=0.8440
2025-02-03 17:55:53,481 - INFO - Epoch 50: val_loss=2.5636, val_acc=33.33%
2025-02-03 17:55:53,485 - INFO - Epoch 50: EPOCH_AVG_TRAIN_LOSS=0.8440
2025-02-03 17:55:53,487 - INFO - ####################Training epoch 51####################
2025-02-03 17:55:53,779 - INFO - Epoch 51: train_loss=0.8397
2025-02-03 17:55:54,250 - INFO - Epoch 51: val_loss=2.5687, val_acc=33.33%
2025-02-03 17:55:54,253 - INFO - Epoch 51: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 17:55:54,256 - INFO - ####################Training epoch 52####################
2025-02-03 17:55:54,544 - INFO - Epoch 52: train_loss=0.8436
2025-02-03 17:55:55,015 - INFO - Epoch 52: val_loss=2.5556, val_acc=33.33%
2025-02-03 17:55:55,018 - INFO - Epoch 52: EPOCH_AVG_TRAIN_LOSS=0.8436
2025-02-03 17:55:55,021 - INFO - ####################Training epoch 53####################
2025-02-03 17:55:55,310 - INFO - Epoch 53: train_loss=0.8419
2025-02-03 17:55:55,779 - INFO - Epoch 53: val_loss=2.5529, val_acc=33.33%
2025-02-03 17:55:55,782 - INFO - Epoch 53: EPOCH_AVG_TRAIN_LOSS=0.8419
2025-02-03 17:55:55,785 - INFO - ####################Training epoch 54####################
2025-02-03 17:55:56,073 - INFO - Epoch 54: train_loss=0.8419
2025-02-03 17:55:56,569 - INFO - Epoch 54: val_loss=2.5564, val_acc=33.33%
2025-02-03 17:55:56,573 - INFO - Epoch 54: EPOCH_AVG_TRAIN_LOSS=0.8419
2025-02-03 17:55:56,575 - INFO - ####################Training epoch 55####################
2025-02-03 17:55:56,861 - INFO - Epoch 55: train_loss=0.8390
2025-02-03 17:55:57,336 - INFO - Epoch 55: val_loss=2.5556, val_acc=33.33%
2025-02-03 17:55:57,340 - INFO - Epoch 55: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:55:57,342 - INFO - ####################Training epoch 56####################
2025-02-03 17:55:57,630 - INFO - Epoch 56: train_loss=0.8425
2025-02-03 17:55:58,105 - INFO - Epoch 56: val_loss=2.5591, val_acc=33.33%
2025-02-03 17:55:58,108 - INFO - Epoch 56: EPOCH_AVG_TRAIN_LOSS=0.8425
2025-02-03 17:55:58,111 - INFO - ####################Training epoch 57####################
2025-02-03 17:55:58,404 - INFO - Epoch 57: train_loss=0.8387
2025-02-03 17:55:58,874 - INFO - Epoch 57: val_loss=2.5572, val_acc=33.33%
2025-02-03 17:55:58,877 - INFO - Epoch 57: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 17:55:58,880 - INFO - ####################Training epoch 58####################
2025-02-03 17:55:59,168 - INFO - Epoch 58: train_loss=0.8375
2025-02-03 17:55:59,640 - INFO - Epoch 58: val_loss=2.5521, val_acc=33.33%
2025-02-03 17:55:59,644 - INFO - Epoch 58: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 17:55:59,646 - INFO - ####################Training epoch 59####################
2025-02-03 17:55:59,934 - INFO - Epoch 59: train_loss=0.8396
2025-02-03 17:56:00,414 - INFO - Epoch 59: val_loss=2.5541, val_acc=33.33%
2025-02-03 17:56:00,418 - INFO - Epoch 59: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 17:56:00,420 - INFO - ####################Training epoch 60####################
2025-02-03 17:56:00,713 - INFO - Epoch 60: train_loss=0.8401
2025-02-03 17:56:01,187 - INFO - Epoch 60: val_loss=2.5576, val_acc=33.33%
2025-02-03 17:56:01,191 - INFO - Epoch 60: EPOCH_AVG_TRAIN_LOSS=0.8401
2025-02-03 17:56:01,194 - INFO - ####################Training epoch 61####################
2025-02-03 17:56:01,483 - INFO - Epoch 61: train_loss=0.8405
2025-02-03 17:56:01,956 - INFO - Epoch 61: val_loss=2.5513, val_acc=33.33%
2025-02-03 17:56:01,959 - INFO - Epoch 61: EPOCH_AVG_TRAIN_LOSS=0.8405
2025-02-03 17:56:01,962 - INFO - ####################Training epoch 62####################
2025-02-03 17:56:02,252 - INFO - Epoch 62: train_loss=0.8385
2025-02-03 17:56:02,724 - INFO - Epoch 62: val_loss=2.5506, val_acc=33.33%
2025-02-03 17:56:02,727 - INFO - Epoch 62: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 17:56:02,730 - INFO - ####################Training epoch 63####################
2025-02-03 17:56:03,022 - INFO - Epoch 63: train_loss=0.8386
2025-02-03 17:56:03,495 - INFO - Epoch 63: val_loss=2.5504, val_acc=33.33%
2025-02-03 17:56:03,499 - INFO - Epoch 63: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 17:56:03,501 - INFO - ####################Training epoch 64####################
2025-02-03 17:56:03,793 - INFO - Epoch 64: train_loss=0.8402
2025-02-03 17:56:04,266 - INFO - Epoch 64: val_loss=2.5558, val_acc=33.33%
2025-02-03 17:56:04,270 - INFO - Epoch 64: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:56:04,272 - INFO - ####################Training epoch 65####################
2025-02-03 17:56:04,559 - INFO - Epoch 65: train_loss=0.8379
2025-02-03 17:56:05,028 - INFO - Epoch 65: val_loss=2.5507, val_acc=33.33%
2025-02-03 17:56:05,032 - INFO - Epoch 65: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 17:56:05,035 - INFO - ####################Training epoch 66####################
2025-02-03 17:56:05,324 - INFO - Epoch 66: train_loss=0.8400
2025-02-03 17:56:05,803 - INFO - Epoch 66: val_loss=2.5522, val_acc=33.33%
2025-02-03 17:56:05,806 - INFO - Epoch 66: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 17:56:05,808 - INFO - ####################Training epoch 67####################
2025-02-03 17:56:06,100 - INFO - Epoch 67: train_loss=0.8384
2025-02-03 17:56:06,577 - INFO - Epoch 67: val_loss=2.5582, val_acc=33.33%
2025-02-03 17:56:06,581 - INFO - Epoch 67: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 17:56:06,583 - INFO - ####################Training epoch 68####################
2025-02-03 17:56:06,872 - INFO - Epoch 68: train_loss=0.8377
2025-02-03 17:56:07,346 - INFO - Epoch 68: val_loss=2.5470, val_acc=33.33%
2025-02-03 17:56:07,349 - INFO - Epoch 68: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 17:56:07,352 - INFO - ####################Training epoch 69####################
2025-02-03 17:56:07,641 - INFO - Epoch 69: train_loss=0.8391
2025-02-03 17:56:08,114 - INFO - Epoch 69: val_loss=2.5489, val_acc=33.33%
2025-02-03 17:56:08,118 - INFO - Epoch 69: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:56:08,120 - INFO - ####################Training epoch 70####################
2025-02-03 17:56:08,411 - INFO - Epoch 70: train_loss=0.8388
2025-02-03 17:56:08,884 - INFO - Epoch 70: val_loss=2.5522, val_acc=33.33%
2025-02-03 17:56:08,887 - INFO - Epoch 70: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 17:56:08,890 - INFO - ####################Training epoch 71####################
2025-02-03 17:56:09,181 - INFO - Epoch 71: train_loss=0.8390
2025-02-03 17:56:09,652 - INFO - Epoch 71: val_loss=2.5505, val_acc=33.33%
2025-02-03 17:56:09,655 - INFO - Epoch 71: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:56:09,657 - INFO - ####################Training epoch 72####################
2025-02-03 17:56:09,946 - INFO - Epoch 72: train_loss=0.8363
2025-02-03 17:56:10,416 - INFO - Epoch 72: val_loss=2.5563, val_acc=33.33%
2025-02-03 17:56:10,420 - INFO - Epoch 72: EPOCH_AVG_TRAIN_LOSS=0.8363
2025-02-03 17:56:10,422 - INFO - ####################Training epoch 73####################
2025-02-03 17:56:10,717 - INFO - Epoch 73: train_loss=0.8391
2025-02-03 17:56:11,190 - INFO - Epoch 73: val_loss=2.5593, val_acc=33.33%
2025-02-03 17:56:11,194 - INFO - Epoch 73: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:56:11,196 - INFO - ####################Training epoch 74####################
2025-02-03 17:56:11,486 - INFO - Epoch 74: train_loss=0.8382
2025-02-03 17:56:11,963 - INFO - Epoch 74: val_loss=2.5518, val_acc=33.33%
2025-02-03 17:56:11,966 - INFO - Epoch 74: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:56:11,969 - INFO - ####################Training epoch 75####################
2025-02-03 17:56:12,262 - INFO - Epoch 75: train_loss=0.8395
2025-02-03 17:56:12,737 - INFO - Epoch 75: val_loss=2.5506, val_acc=33.33%
2025-02-03 17:56:12,740 - INFO - Epoch 75: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:56:12,743 - INFO - ####################Training epoch 76####################
2025-02-03 17:56:13,031 - INFO - Epoch 76: train_loss=0.8370
2025-02-03 17:56:13,545 - INFO - Epoch 76: val_loss=2.5506, val_acc=33.33%
2025-02-03 17:56:13,549 - INFO - Epoch 76: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 17:56:13,551 - INFO - ####################Training epoch 77####################
2025-02-03 17:56:13,845 - INFO - Epoch 77: train_loss=0.8355
2025-02-03 17:56:14,317 - INFO - Epoch 77: val_loss=2.5531, val_acc=33.33%
2025-02-03 17:56:14,320 - INFO - Epoch 77: EPOCH_AVG_TRAIN_LOSS=0.8355
2025-02-03 17:56:14,323 - INFO - ####################Training epoch 78####################
2025-02-03 17:56:14,615 - INFO - Epoch 78: train_loss=0.8364
2025-02-03 17:56:15,087 - INFO - Epoch 78: val_loss=2.5541, val_acc=33.33%
2025-02-03 17:56:15,091 - INFO - Epoch 78: EPOCH_AVG_TRAIN_LOSS=0.8364
2025-02-03 17:56:15,093 - INFO - ####################Training epoch 79####################
2025-02-03 17:56:15,382 - INFO - Epoch 79: train_loss=0.8382
2025-02-03 17:56:15,853 - INFO - Epoch 79: val_loss=2.5502, val_acc=33.33%
2025-02-03 17:56:15,856 - INFO - Epoch 79: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:56:15,859 - INFO - ####################Training epoch 80####################
2025-02-03 17:56:16,149 - INFO - Epoch 80: train_loss=0.8386
2025-02-03 17:56:16,621 - INFO - Epoch 80: val_loss=2.5513, val_acc=33.33%
2025-02-03 17:56:16,624 - INFO - Epoch 80: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 17:56:16,627 - INFO - ####################Training epoch 81####################
2025-02-03 17:56:16,913 - INFO - Epoch 81: train_loss=0.8391
2025-02-03 17:56:17,382 - INFO - Epoch 81: val_loss=2.5522, val_acc=33.33%
2025-02-03 17:56:17,386 - INFO - Epoch 81: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:56:17,388 - INFO - ####################Training epoch 82####################
2025-02-03 17:56:17,678 - INFO - Epoch 82: train_loss=0.8406
2025-02-03 17:56:18,151 - INFO - Epoch 82: val_loss=2.5501, val_acc=33.33%
2025-02-03 17:56:18,154 - INFO - Epoch 82: EPOCH_AVG_TRAIN_LOSS=0.8406
2025-02-03 17:56:18,156 - INFO - ####################Training epoch 83####################
2025-02-03 17:56:18,446 - INFO - Epoch 83: train_loss=0.8404
2025-02-03 17:56:18,920 - INFO - Epoch 83: val_loss=2.5492, val_acc=33.33%
2025-02-03 17:56:18,923 - INFO - Epoch 83: EPOCH_AVG_TRAIN_LOSS=0.8404
2025-02-03 17:56:18,926 - INFO - ####################Training epoch 84####################
2025-02-03 17:56:19,217 - INFO - Epoch 84: train_loss=0.8393
2025-02-03 17:56:19,686 - INFO - Epoch 84: val_loss=2.5563, val_acc=33.33%
2025-02-03 17:56:19,690 - INFO - Epoch 84: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 17:56:19,692 - INFO - ####################Training epoch 85####################
2025-02-03 17:56:19,981 - INFO - Epoch 85: train_loss=0.8388
2025-02-03 17:56:20,454 - INFO - Epoch 85: val_loss=2.5504, val_acc=33.33%
2025-02-03 17:56:20,458 - INFO - Epoch 85: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 17:56:20,460 - INFO - ####################Training epoch 86####################
2025-02-03 17:56:20,747 - INFO - Epoch 86: train_loss=0.8405
2025-02-03 17:56:21,220 - INFO - Epoch 86: val_loss=2.5540, val_acc=33.33%
2025-02-03 17:56:21,223 - INFO - Epoch 86: EPOCH_AVG_TRAIN_LOSS=0.8405
2025-02-03 17:56:21,226 - INFO - ####################Training epoch 87####################
2025-02-03 17:56:21,514 - INFO - Epoch 87: train_loss=0.8398
2025-02-03 17:56:21,982 - INFO - Epoch 87: val_loss=2.5537, val_acc=33.33%
2025-02-03 17:56:21,986 - INFO - Epoch 87: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 17:56:21,988 - INFO - ####################Training epoch 88####################
2025-02-03 17:56:22,277 - INFO - Epoch 88: train_loss=0.8402
2025-02-03 17:56:22,749 - INFO - Epoch 88: val_loss=2.5488, val_acc=33.33%
2025-02-03 17:56:22,752 - INFO - Epoch 88: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:56:22,754 - INFO - ####################Training epoch 89####################
2025-02-03 17:56:23,043 - INFO - Epoch 89: train_loss=0.8390
2025-02-03 17:56:23,515 - INFO - Epoch 89: val_loss=2.5565, val_acc=33.33%
2025-02-03 17:56:23,518 - INFO - Epoch 89: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:56:23,521 - INFO - ####################Training epoch 90####################
2025-02-03 17:56:23,810 - INFO - Epoch 90: train_loss=0.8369
2025-02-03 17:56:24,282 - INFO - Epoch 90: val_loss=2.5494, val_acc=33.33%
2025-02-03 17:56:24,286 - INFO - Epoch 90: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 17:56:24,288 - INFO - ####################Training epoch 91####################
2025-02-03 17:56:24,579 - INFO - Epoch 91: train_loss=0.8386
2025-02-03 17:56:25,047 - INFO - Epoch 91: val_loss=2.5489, val_acc=33.33%
2025-02-03 17:56:25,051 - INFO - Epoch 91: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 17:56:25,053 - INFO - ####################Training epoch 92####################
2025-02-03 17:56:25,346 - INFO - Epoch 92: train_loss=0.8378
2025-02-03 17:56:25,818 - INFO - Epoch 92: val_loss=2.5486, val_acc=33.33%
2025-02-03 17:56:25,822 - INFO - Epoch 92: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 17:56:25,824 - INFO - ####################Training epoch 93####################
2025-02-03 17:56:26,114 - INFO - Epoch 93: train_loss=0.8373
2025-02-03 17:56:26,587 - INFO - Epoch 93: val_loss=2.5512, val_acc=33.33%
2025-02-03 17:56:26,591 - INFO - Epoch 93: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 17:56:26,593 - INFO - ####################Training epoch 94####################
2025-02-03 17:56:26,881 - INFO - Epoch 94: train_loss=0.8379
2025-02-03 17:56:27,355 - INFO - Epoch 94: val_loss=2.5565, val_acc=33.33%
2025-02-03 17:56:27,358 - INFO - Epoch 94: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 17:56:27,361 - INFO - ####################Training epoch 95####################
2025-02-03 17:56:27,652 - INFO - Epoch 95: train_loss=0.8409
2025-02-03 17:56:28,122 - INFO - Epoch 95: val_loss=2.5534, val_acc=33.33%
2025-02-03 17:56:28,126 - INFO - Epoch 95: EPOCH_AVG_TRAIN_LOSS=0.8409
2025-02-03 17:56:28,128 - INFO - ####################Training epoch 96####################
2025-02-03 17:56:28,418 - INFO - Epoch 96: train_loss=0.8390
2025-02-03 17:56:28,887 - INFO - Epoch 96: val_loss=2.5484, val_acc=33.33%
2025-02-03 17:56:28,890 - INFO - Epoch 96: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:56:28,893 - INFO - ####################Training epoch 97####################
2025-02-03 17:56:29,181 - INFO - Epoch 97: train_loss=0.8377
2025-02-03 17:56:29,654 - INFO - Epoch 97: val_loss=2.5520, val_acc=33.33%
2025-02-03 17:56:29,657 - INFO - Epoch 97: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 17:56:29,660 - INFO - ####################Training epoch 98####################
2025-02-03 17:56:29,958 - INFO - Epoch 98: train_loss=0.8377
2025-02-03 17:56:30,425 - INFO - Epoch 98: val_loss=2.5592, val_acc=33.33%
2025-02-03 17:56:30,429 - INFO - Epoch 98: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 17:56:30,431 - INFO - ####################Training epoch 99####################
2025-02-03 17:56:30,723 - INFO - Epoch 99: train_loss=0.8376
2025-02-03 17:56:31,195 - INFO - Epoch 99: val_loss=2.5448, val_acc=33.33%
2025-02-03 17:56:31,199 - INFO - Epoch 99: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 17:56:31,201 - INFO - ####################Training epoch 100####################
2025-02-03 17:56:31,490 - INFO - Epoch 100: train_loss=0.8401
2025-02-03 17:56:31,962 - INFO - Epoch 100: val_loss=2.5550, val_acc=33.33%
2025-02-03 17:56:31,966 - INFO - Epoch 100: EPOCH_AVG_TRAIN_LOSS=0.8401
2025-02-03 17:56:31,968 - INFO - ####################Training epoch 101####################
2025-02-03 17:56:32,256 - INFO - Epoch 101: train_loss=0.8399
2025-02-03 17:56:32,728 - INFO - Epoch 101: val_loss=2.5519, val_acc=33.33%
2025-02-03 17:56:32,731 - INFO - Epoch 101: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 17:56:32,733 - INFO - ####################Training epoch 102####################
2025-02-03 17:56:33,023 - INFO - Epoch 102: train_loss=0.8395
2025-02-03 17:56:33,494 - INFO - Epoch 102: val_loss=2.5493, val_acc=33.33%
2025-02-03 17:56:33,498 - INFO - Epoch 102: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:56:33,500 - INFO - ####################Training epoch 103####################
2025-02-03 17:56:33,790 - INFO - Epoch 103: train_loss=0.8369
2025-02-03 17:56:34,262 - INFO - Epoch 103: val_loss=2.5503, val_acc=33.33%
2025-02-03 17:56:34,265 - INFO - Epoch 103: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 17:56:34,268 - INFO - ####################Training epoch 104####################
2025-02-03 17:56:34,561 - INFO - Epoch 104: train_loss=0.8373
2025-02-03 17:56:35,030 - INFO - Epoch 104: val_loss=2.5511, val_acc=33.33%
2025-02-03 17:56:35,034 - INFO - Epoch 104: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 17:56:35,036 - INFO - ####################Training epoch 105####################
2025-02-03 17:56:35,327 - INFO - Epoch 105: train_loss=0.8398
2025-02-03 17:56:35,798 - INFO - Epoch 105: val_loss=2.5549, val_acc=33.33%
2025-02-03 17:56:35,801 - INFO - Epoch 105: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 17:56:35,804 - INFO - ####################Training epoch 106####################
2025-02-03 17:56:36,093 - INFO - Epoch 106: train_loss=0.8392
2025-02-03 17:56:36,566 - INFO - Epoch 106: val_loss=2.5499, val_acc=33.33%
2025-02-03 17:56:36,569 - INFO - Epoch 106: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 17:56:36,572 - INFO - ####################Training epoch 107####################
2025-02-03 17:56:36,859 - INFO - Epoch 107: train_loss=0.8375
2025-02-03 17:56:37,333 - INFO - Epoch 107: val_loss=2.5460, val_acc=33.33%
2025-02-03 17:56:37,336 - INFO - Epoch 107: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 17:56:37,339 - INFO - ####################Training epoch 108####################
2025-02-03 17:56:37,626 - INFO - Epoch 108: train_loss=0.8397
2025-02-03 17:56:38,099 - INFO - Epoch 108: val_loss=2.5492, val_acc=33.33%
2025-02-03 17:56:38,102 - INFO - Epoch 108: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 17:56:38,105 - INFO - ####################Training epoch 109####################
2025-02-03 17:56:38,396 - INFO - Epoch 109: train_loss=0.8390
2025-02-03 17:56:38,879 - INFO - Epoch 109: val_loss=2.5518, val_acc=33.33%
2025-02-03 17:56:38,883 - INFO - Epoch 109: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:56:38,885 - INFO - ####################Training epoch 110####################
2025-02-03 17:56:39,175 - INFO - Epoch 110: train_loss=0.8408
2025-02-03 17:56:39,646 - INFO - Epoch 110: val_loss=2.5501, val_acc=33.33%
2025-02-03 17:56:39,649 - INFO - Epoch 110: EPOCH_AVG_TRAIN_LOSS=0.8408
2025-02-03 17:56:39,652 - INFO - ####################Training epoch 111####################
2025-02-03 17:56:39,941 - INFO - Epoch 111: train_loss=0.8408
2025-02-03 17:56:40,413 - INFO - Epoch 111: val_loss=2.5541, val_acc=33.33%
2025-02-03 17:56:40,416 - INFO - Epoch 111: EPOCH_AVG_TRAIN_LOSS=0.8408
2025-02-03 17:56:40,419 - INFO - ####################Training epoch 112####################
2025-02-03 17:56:40,712 - INFO - Epoch 112: train_loss=0.8377
2025-02-03 17:56:41,186 - INFO - Epoch 112: val_loss=2.5549, val_acc=33.33%
2025-02-03 17:56:41,189 - INFO - Epoch 112: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 17:56:41,191 - INFO - ####################Training epoch 113####################
2025-02-03 17:56:41,479 - INFO - Epoch 113: train_loss=0.8391
2025-02-03 17:56:41,951 - INFO - Epoch 113: val_loss=2.5484, val_acc=33.33%
2025-02-03 17:56:41,955 - INFO - Epoch 113: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:56:41,957 - INFO - ####################Training epoch 114####################
2025-02-03 17:56:42,248 - INFO - Epoch 114: train_loss=0.8373
2025-02-03 17:56:42,719 - INFO - Epoch 114: val_loss=2.5482, val_acc=33.33%
2025-02-03 17:56:42,723 - INFO - Epoch 114: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 17:56:42,725 - INFO - ####################Training epoch 115####################
2025-02-03 17:56:43,015 - INFO - Epoch 115: train_loss=0.8411
2025-02-03 17:56:43,487 - INFO - Epoch 115: val_loss=2.5557, val_acc=33.33%
2025-02-03 17:56:43,491 - INFO - Epoch 115: EPOCH_AVG_TRAIN_LOSS=0.8411
2025-02-03 17:56:43,493 - INFO - ####################Training epoch 116####################
2025-02-03 17:56:43,783 - INFO - Epoch 116: train_loss=0.8385
2025-02-03 17:56:44,257 - INFO - Epoch 116: val_loss=2.5462, val_acc=33.33%
2025-02-03 17:56:44,260 - INFO - Epoch 116: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 17:56:44,263 - INFO - ####################Training epoch 117####################
2025-02-03 17:56:44,551 - INFO - Epoch 117: train_loss=0.8380
2025-02-03 17:56:45,020 - INFO - Epoch 117: val_loss=2.5470, val_acc=33.33%
2025-02-03 17:56:45,024 - INFO - Epoch 117: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 17:56:45,026 - INFO - ####################Training epoch 118####################
2025-02-03 17:56:45,314 - INFO - Epoch 118: train_loss=0.8395
2025-02-03 17:56:45,785 - INFO - Epoch 118: val_loss=2.5513, val_acc=33.33%
2025-02-03 17:56:45,789 - INFO - Epoch 118: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:56:45,791 - INFO - ####################Training epoch 119####################
2025-02-03 17:56:46,079 - INFO - Epoch 119: train_loss=0.8378
2025-02-03 17:56:46,552 - INFO - Epoch 119: val_loss=2.5578, val_acc=33.33%
2025-02-03 17:56:46,555 - INFO - Epoch 119: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 17:56:46,557 - INFO - ####################Training epoch 120####################
2025-02-03 17:56:46,850 - INFO - Epoch 120: train_loss=0.8382
2025-02-03 17:56:47,323 - INFO - Epoch 120: val_loss=2.5579, val_acc=33.33%
2025-02-03 17:56:47,326 - INFO - Epoch 120: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:56:47,329 - INFO - ####################Training epoch 121####################
2025-02-03 17:56:47,621 - INFO - Epoch 121: train_loss=0.8371
2025-02-03 17:56:48,094 - INFO - Epoch 121: val_loss=2.5543, val_acc=33.33%
2025-02-03 17:56:48,097 - INFO - Epoch 121: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 17:56:48,100 - INFO - ####################Training epoch 122####################
2025-02-03 17:56:48,392 - INFO - Epoch 122: train_loss=0.8385
2025-02-03 17:56:48,865 - INFO - Epoch 122: val_loss=2.5514, val_acc=33.33%
2025-02-03 17:56:48,868 - INFO - Epoch 122: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 17:56:48,871 - INFO - ####################Training epoch 123####################
2025-02-03 17:56:49,160 - INFO - Epoch 123: train_loss=0.8388
2025-02-03 17:56:49,630 - INFO - Epoch 123: val_loss=2.5553, val_acc=33.33%
2025-02-03 17:56:49,634 - INFO - Epoch 123: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 17:56:49,636 - INFO - ####################Training epoch 124####################
2025-02-03 17:56:49,925 - INFO - Epoch 124: train_loss=0.8402
2025-02-03 17:56:50,398 - INFO - Epoch 124: val_loss=2.5503, val_acc=33.33%
2025-02-03 17:56:50,401 - INFO - Epoch 124: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:56:50,404 - INFO - ####################Training epoch 125####################
2025-02-03 17:56:50,696 - INFO - Epoch 125: train_loss=0.8382
2025-02-03 17:56:51,167 - INFO - Epoch 125: val_loss=2.5567, val_acc=33.33%
2025-02-03 17:56:51,170 - INFO - Epoch 125: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:56:51,173 - INFO - ####################Training epoch 126####################
2025-02-03 17:56:51,463 - INFO - Epoch 126: train_loss=0.8363
2025-02-03 17:56:51,933 - INFO - Epoch 126: val_loss=2.5489, val_acc=33.33%
2025-02-03 17:56:51,937 - INFO - Epoch 126: EPOCH_AVG_TRAIN_LOSS=0.8363
2025-02-03 17:56:51,939 - INFO - ####################Training epoch 127####################
2025-02-03 17:56:52,226 - INFO - Epoch 127: train_loss=0.8397
2025-02-03 17:56:52,699 - INFO - Epoch 127: val_loss=2.5556, val_acc=33.33%
2025-02-03 17:56:52,702 - INFO - Epoch 127: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 17:56:52,704 - INFO - ####################Training epoch 128####################
2025-02-03 17:56:52,993 - INFO - Epoch 128: train_loss=0.8391
2025-02-03 17:56:53,464 - INFO - Epoch 128: val_loss=2.5528, val_acc=33.33%
2025-02-03 17:56:53,468 - INFO - Epoch 128: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:56:53,470 - INFO - ####################Training epoch 129####################
2025-02-03 17:56:53,761 - INFO - Epoch 129: train_loss=0.8402
2025-02-03 17:56:54,234 - INFO - Epoch 129: val_loss=2.5468, val_acc=33.33%
2025-02-03 17:56:54,238 - INFO - Epoch 129: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:56:54,240 - INFO - ####################Training epoch 130####################
2025-02-03 17:56:54,529 - INFO - Epoch 130: train_loss=0.8391
2025-02-03 17:56:55,003 - INFO - Epoch 130: val_loss=2.5511, val_acc=33.33%
2025-02-03 17:56:55,007 - INFO - Epoch 130: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:56:55,009 - INFO - ####################Training epoch 131####################
2025-02-03 17:56:55,337 - INFO - Epoch 131: train_loss=0.8377
2025-02-03 17:56:55,808 - INFO - Epoch 131: val_loss=2.5495, val_acc=33.33%
2025-02-03 17:56:55,811 - INFO - Epoch 131: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 17:56:55,814 - INFO - ####################Training epoch 132####################
2025-02-03 17:56:56,109 - INFO - Epoch 132: train_loss=0.8399
2025-02-03 17:56:56,580 - INFO - Epoch 132: val_loss=2.5602, val_acc=33.33%
2025-02-03 17:56:56,583 - INFO - Epoch 132: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 17:56:56,586 - INFO - ####################Training epoch 133####################
2025-02-03 17:56:56,874 - INFO - Epoch 133: train_loss=0.8379
2025-02-03 17:56:57,346 - INFO - Epoch 133: val_loss=2.5510, val_acc=33.33%
2025-02-03 17:56:57,349 - INFO - Epoch 133: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 17:56:57,352 - INFO - ####################Training epoch 134####################
2025-02-03 17:56:57,643 - INFO - Epoch 134: train_loss=0.8365
2025-02-03 17:56:58,111 - INFO - Epoch 134: val_loss=2.5536, val_acc=33.33%
2025-02-03 17:56:58,115 - INFO - Epoch 134: EPOCH_AVG_TRAIN_LOSS=0.8365
2025-02-03 17:56:58,117 - INFO - ####################Training epoch 135####################
2025-02-03 17:56:58,408 - INFO - Epoch 135: train_loss=0.8391
2025-02-03 17:56:58,877 - INFO - Epoch 135: val_loss=2.5524, val_acc=33.33%
2025-02-03 17:56:58,881 - INFO - Epoch 135: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:56:58,883 - INFO - ####################Training epoch 136####################
2025-02-03 17:56:59,174 - INFO - Epoch 136: train_loss=0.8365
2025-02-03 17:56:59,643 - INFO - Epoch 136: val_loss=2.5497, val_acc=33.33%
2025-02-03 17:56:59,647 - INFO - Epoch 136: EPOCH_AVG_TRAIN_LOSS=0.8365
2025-02-03 17:56:59,649 - INFO - ####################Training epoch 137####################
2025-02-03 17:56:59,938 - INFO - Epoch 137: train_loss=0.8386
2025-02-03 17:57:00,413 - INFO - Epoch 137: val_loss=2.5527, val_acc=33.33%
2025-02-03 17:57:00,417 - INFO - Epoch 137: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 17:57:00,419 - INFO - ####################Training epoch 138####################
2025-02-03 17:57:00,713 - INFO - Epoch 138: train_loss=0.8405
2025-02-03 17:57:01,185 - INFO - Epoch 138: val_loss=2.5529, val_acc=33.33%
2025-02-03 17:57:01,188 - INFO - Epoch 138: EPOCH_AVG_TRAIN_LOSS=0.8405
2025-02-03 17:57:01,191 - INFO - ####################Training epoch 139####################
2025-02-03 17:57:01,480 - INFO - Epoch 139: train_loss=0.8387
2025-02-03 17:57:01,957 - INFO - Epoch 139: val_loss=2.5507, val_acc=33.33%
2025-02-03 17:57:01,960 - INFO - Epoch 139: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 17:57:01,962 - INFO - ####################Training epoch 140####################
2025-02-03 17:57:02,251 - INFO - Epoch 140: train_loss=0.8382
2025-02-03 17:57:02,725 - INFO - Epoch 140: val_loss=2.5514, val_acc=33.33%
2025-02-03 17:57:02,728 - INFO - Epoch 140: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:57:02,731 - INFO - ####################Training epoch 141####################
2025-02-03 17:57:03,023 - INFO - Epoch 141: train_loss=0.8398
2025-02-03 17:57:03,495 - INFO - Epoch 141: val_loss=2.5560, val_acc=33.33%
2025-02-03 17:57:03,498 - INFO - Epoch 141: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 17:57:03,501 - INFO - ####################Training epoch 142####################
2025-02-03 17:57:03,832 - INFO - Epoch 142: train_loss=0.8404
2025-02-03 17:57:04,303 - INFO - Epoch 142: val_loss=2.5464, val_acc=33.33%
2025-02-03 17:57:04,307 - INFO - Epoch 142: EPOCH_AVG_TRAIN_LOSS=0.8404
2025-02-03 17:57:04,309 - INFO - ####################Training epoch 143####################
2025-02-03 17:57:04,598 - INFO - Epoch 143: train_loss=0.8395
2025-02-03 17:57:05,071 - INFO - Epoch 143: val_loss=2.5566, val_acc=33.33%
2025-02-03 17:57:05,075 - INFO - Epoch 143: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:57:05,077 - INFO - ####################Training epoch 144####################
2025-02-03 17:57:05,370 - INFO - Epoch 144: train_loss=0.8390
2025-02-03 17:57:05,844 - INFO - Epoch 144: val_loss=2.5566, val_acc=33.33%
2025-02-03 17:57:05,847 - INFO - Epoch 144: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:57:05,850 - INFO - ####################Training epoch 145####################
2025-02-03 17:57:06,144 - INFO - Epoch 145: train_loss=0.8393
2025-02-03 17:57:06,618 - INFO - Epoch 145: val_loss=2.5536, val_acc=33.33%
2025-02-03 17:57:06,621 - INFO - Epoch 145: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 17:57:06,624 - INFO - ####################Training epoch 146####################
2025-02-03 17:57:06,917 - INFO - Epoch 146: train_loss=0.8390
2025-02-03 17:57:07,388 - INFO - Epoch 146: val_loss=2.5523, val_acc=33.33%
2025-02-03 17:57:07,391 - INFO - Epoch 146: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:57:07,394 - INFO - ####################Training epoch 147####################
2025-02-03 17:57:07,682 - INFO - Epoch 147: train_loss=0.8390
2025-02-03 17:57:08,149 - INFO - Epoch 147: val_loss=2.5500, val_acc=33.33%
2025-02-03 17:57:08,153 - INFO - Epoch 147: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:57:08,155 - INFO - ####################Training epoch 148####################
2025-02-03 17:57:08,447 - INFO - Epoch 148: train_loss=0.8383
2025-02-03 17:57:08,916 - INFO - Epoch 148: val_loss=2.5491, val_acc=33.33%
2025-02-03 17:57:08,920 - INFO - Epoch 148: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 17:57:08,922 - INFO - ####################Training epoch 149####################
2025-02-03 17:57:09,211 - INFO - Epoch 149: train_loss=0.8403
2025-02-03 17:57:09,681 - INFO - Epoch 149: val_loss=2.5536, val_acc=33.33%
2025-02-03 17:57:09,684 - INFO - Epoch 149: EPOCH_AVG_TRAIN_LOSS=0.8403
2025-02-03 17:57:09,686 - INFO - ####################Training epoch 150####################
2025-02-03 17:57:09,974 - INFO - Epoch 150: train_loss=0.8387
2025-02-03 17:57:10,446 - INFO - Epoch 150: val_loss=2.5531, val_acc=33.33%
2025-02-03 17:57:10,449 - INFO - Epoch 150: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 17:57:10,451 - INFO - ####################Training epoch 151####################
2025-02-03 17:57:10,740 - INFO - Epoch 151: train_loss=0.8379
2025-02-03 17:57:11,214 - INFO - Epoch 151: val_loss=2.5511, val_acc=33.33%
2025-02-03 17:57:11,217 - INFO - Epoch 151: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 17:57:11,220 - INFO - ####################Training epoch 152####################
2025-02-03 17:57:11,510 - INFO - Epoch 152: train_loss=0.8394
2025-02-03 17:57:11,995 - INFO - Epoch 152: val_loss=2.5549, val_acc=33.33%
2025-02-03 17:57:11,999 - INFO - Epoch 152: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 17:57:12,001 - INFO - ####################Training epoch 153####################
2025-02-03 17:57:12,326 - INFO - Epoch 153: train_loss=0.8366
2025-02-03 17:57:12,796 - INFO - Epoch 153: val_loss=2.5552, val_acc=33.33%
2025-02-03 17:57:12,800 - INFO - Epoch 153: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 17:57:12,802 - INFO - ####################Training epoch 154####################
2025-02-03 17:57:13,094 - INFO - Epoch 154: train_loss=0.8405
2025-02-03 17:57:13,566 - INFO - Epoch 154: val_loss=2.5552, val_acc=33.33%
2025-02-03 17:57:13,570 - INFO - Epoch 154: EPOCH_AVG_TRAIN_LOSS=0.8405
2025-02-03 17:57:13,572 - INFO - ####################Training epoch 155####################
2025-02-03 17:57:13,863 - INFO - Epoch 155: train_loss=0.8415
2025-02-03 17:57:14,336 - INFO - Epoch 155: val_loss=2.5525, val_acc=33.33%
2025-02-03 17:57:14,339 - INFO - Epoch 155: EPOCH_AVG_TRAIN_LOSS=0.8415
2025-02-03 17:57:14,342 - INFO - ####################Training epoch 156####################
2025-02-03 17:57:14,635 - INFO - Epoch 156: train_loss=0.8403
2025-02-03 17:57:15,116 - INFO - Epoch 156: val_loss=2.5531, val_acc=33.33%
2025-02-03 17:57:15,120 - INFO - Epoch 156: EPOCH_AVG_TRAIN_LOSS=0.8403
2025-02-03 17:57:15,122 - INFO - ####################Training epoch 157####################
2025-02-03 17:57:15,411 - INFO - Epoch 157: train_loss=0.8390
2025-02-03 17:57:15,882 - INFO - Epoch 157: val_loss=2.5484, val_acc=33.33%
2025-02-03 17:57:15,886 - INFO - Epoch 157: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:57:15,888 - INFO - ####################Training epoch 158####################
2025-02-03 17:57:16,178 - INFO - Epoch 158: train_loss=0.8376
2025-02-03 17:57:16,651 - INFO - Epoch 158: val_loss=2.5496, val_acc=33.33%
2025-02-03 17:57:16,655 - INFO - Epoch 158: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 17:57:16,657 - INFO - ####################Training epoch 159####################
2025-02-03 17:57:16,946 - INFO - Epoch 159: train_loss=0.8400
2025-02-03 17:57:17,421 - INFO - Epoch 159: val_loss=2.5492, val_acc=33.33%
2025-02-03 17:57:17,425 - INFO - Epoch 159: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 17:57:17,427 - INFO - ####################Training epoch 160####################
2025-02-03 17:57:17,715 - INFO - Epoch 160: train_loss=0.8409
2025-02-03 17:57:18,186 - INFO - Epoch 160: val_loss=2.5547, val_acc=33.33%
2025-02-03 17:57:18,189 - INFO - Epoch 160: EPOCH_AVG_TRAIN_LOSS=0.8409
2025-02-03 17:57:18,192 - INFO - ####################Training epoch 161####################
2025-02-03 17:57:18,480 - INFO - Epoch 161: train_loss=0.8398
2025-02-03 17:57:18,951 - INFO - Epoch 161: val_loss=2.5520, val_acc=33.33%
2025-02-03 17:57:18,955 - INFO - Epoch 161: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 17:57:18,957 - INFO - ####################Training epoch 162####################
2025-02-03 17:57:19,248 - INFO - Epoch 162: train_loss=0.8413
2025-02-03 17:57:19,720 - INFO - Epoch 162: val_loss=2.5488, val_acc=33.33%
2025-02-03 17:57:19,723 - INFO - Epoch 162: EPOCH_AVG_TRAIN_LOSS=0.8413
2025-02-03 17:57:19,726 - INFO - ####################Training epoch 163####################
2025-02-03 17:57:20,017 - INFO - Epoch 163: train_loss=0.8383
2025-02-03 17:57:20,514 - INFO - Epoch 163: val_loss=2.5478, val_acc=33.33%
2025-02-03 17:57:20,518 - INFO - Epoch 163: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 17:57:20,520 - INFO - ####################Training epoch 164####################
2025-02-03 17:57:20,840 - INFO - Epoch 164: train_loss=0.8386
2025-02-03 17:57:21,311 - INFO - Epoch 164: val_loss=2.5542, val_acc=33.33%
2025-02-03 17:57:21,315 - INFO - Epoch 164: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 17:57:21,317 - INFO - ####################Training epoch 165####################
2025-02-03 17:57:21,603 - INFO - Epoch 165: train_loss=0.8416
2025-02-03 17:57:22,075 - INFO - Epoch 165: val_loss=2.5557, val_acc=33.33%
2025-02-03 17:57:22,079 - INFO - Epoch 165: EPOCH_AVG_TRAIN_LOSS=0.8416
2025-02-03 17:57:22,081 - INFO - ####################Training epoch 166####################
2025-02-03 17:57:22,371 - INFO - Epoch 166: train_loss=0.8413
2025-02-03 17:57:22,841 - INFO - Epoch 166: val_loss=2.5491, val_acc=33.33%
2025-02-03 17:57:22,844 - INFO - Epoch 166: EPOCH_AVG_TRAIN_LOSS=0.8413
2025-02-03 17:57:22,847 - INFO - ####################Training epoch 167####################
2025-02-03 17:57:23,134 - INFO - Epoch 167: train_loss=0.8382
2025-02-03 17:57:23,604 - INFO - Epoch 167: val_loss=2.5542, val_acc=33.33%
2025-02-03 17:57:23,608 - INFO - Epoch 167: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:57:23,610 - INFO - ####################Training epoch 168####################
2025-02-03 17:57:23,900 - INFO - Epoch 168: train_loss=0.8403
2025-02-03 17:57:24,372 - INFO - Epoch 168: val_loss=2.5464, val_acc=33.33%
2025-02-03 17:57:24,375 - INFO - Epoch 168: EPOCH_AVG_TRAIN_LOSS=0.8403
2025-02-03 17:57:24,378 - INFO - ####################Training epoch 169####################
2025-02-03 17:57:24,667 - INFO - Epoch 169: train_loss=0.8381
2025-02-03 17:57:25,142 - INFO - Epoch 169: val_loss=2.5480, val_acc=33.33%
2025-02-03 17:57:25,146 - INFO - Epoch 169: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 17:57:25,148 - INFO - ####################Training epoch 170####################
2025-02-03 17:57:25,440 - INFO - Epoch 170: train_loss=0.8380
2025-02-03 17:57:25,915 - INFO - Epoch 170: val_loss=2.5536, val_acc=33.33%
2025-02-03 17:57:25,919 - INFO - Epoch 170: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 17:57:25,921 - INFO - ####################Training epoch 171####################
2025-02-03 17:57:26,209 - INFO - Epoch 171: train_loss=0.8393
2025-02-03 17:57:26,683 - INFO - Epoch 171: val_loss=2.5526, val_acc=33.33%
2025-02-03 17:57:26,686 - INFO - Epoch 171: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 17:57:26,689 - INFO - ####################Training epoch 172####################
2025-02-03 17:57:26,978 - INFO - Epoch 172: train_loss=0.8372
2025-02-03 17:57:27,456 - INFO - Epoch 172: val_loss=2.5505, val_acc=33.33%
2025-02-03 17:57:27,460 - INFO - Epoch 172: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 17:57:27,462 - INFO - ####################Training epoch 173####################
2025-02-03 17:57:27,758 - INFO - Epoch 173: train_loss=0.8385
2025-02-03 17:57:28,233 - INFO - Epoch 173: val_loss=2.5522, val_acc=33.33%
2025-02-03 17:57:28,237 - INFO - Epoch 173: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 17:57:28,239 - INFO - ####################Training epoch 174####################
2025-02-03 17:57:28,529 - INFO - Epoch 174: train_loss=0.8390
2025-02-03 17:57:29,011 - INFO - Epoch 174: val_loss=2.5543, val_acc=33.33%
2025-02-03 17:57:29,015 - INFO - Epoch 174: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:57:29,017 - INFO - ####################Training epoch 175####################
2025-02-03 17:57:29,341 - INFO - Epoch 175: train_loss=0.8386
2025-02-03 17:57:29,814 - INFO - Epoch 175: val_loss=2.5497, val_acc=33.33%
2025-02-03 17:57:29,818 - INFO - Epoch 175: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 17:57:29,820 - INFO - ####################Training epoch 176####################
2025-02-03 17:57:30,111 - INFO - Epoch 176: train_loss=0.8364
2025-02-03 17:57:30,587 - INFO - Epoch 176: val_loss=2.5519, val_acc=33.33%
2025-02-03 17:57:30,591 - INFO - Epoch 176: EPOCH_AVG_TRAIN_LOSS=0.8364
2025-02-03 17:57:30,594 - INFO - ####################Training epoch 177####################
2025-02-03 17:57:30,890 - INFO - Epoch 177: train_loss=0.8394
2025-02-03 17:57:31,367 - INFO - Epoch 177: val_loss=2.5533, val_acc=33.33%
2025-02-03 17:57:31,370 - INFO - Epoch 177: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 17:57:31,373 - INFO - ####################Training epoch 178####################
2025-02-03 17:57:31,666 - INFO - Epoch 178: train_loss=0.8390
2025-02-03 17:57:32,143 - INFO - Epoch 178: val_loss=2.5525, val_acc=33.33%
2025-02-03 17:57:32,146 - INFO - Epoch 178: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:57:32,149 - INFO - ####################Training epoch 179####################
2025-02-03 17:57:32,441 - INFO - Epoch 179: train_loss=0.8368
2025-02-03 17:57:32,915 - INFO - Epoch 179: val_loss=2.5551, val_acc=33.33%
2025-02-03 17:57:32,919 - INFO - Epoch 179: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 17:57:32,921 - INFO - ####################Training epoch 180####################
2025-02-03 17:57:33,212 - INFO - Epoch 180: train_loss=0.8394
2025-02-03 17:57:33,683 - INFO - Epoch 180: val_loss=2.5557, val_acc=33.33%
2025-02-03 17:57:33,687 - INFO - Epoch 180: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 17:57:33,689 - INFO - ####################Training epoch 181####################
2025-02-03 17:57:33,980 - INFO - Epoch 181: train_loss=0.8383
2025-02-03 17:57:34,454 - INFO - Epoch 181: val_loss=2.5550, val_acc=33.33%
2025-02-03 17:57:34,457 - INFO - Epoch 181: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 17:57:34,459 - INFO - ####################Training epoch 182####################
2025-02-03 17:57:34,749 - INFO - Epoch 182: train_loss=0.8382
2025-02-03 17:57:35,221 - INFO - Epoch 182: val_loss=2.5505, val_acc=33.33%
2025-02-03 17:57:35,225 - INFO - Epoch 182: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:57:35,227 - INFO - ####################Training epoch 183####################
2025-02-03 17:57:35,515 - INFO - Epoch 183: train_loss=0.8385
2025-02-03 17:57:35,990 - INFO - Epoch 183: val_loss=2.5556, val_acc=33.33%
2025-02-03 17:57:35,994 - INFO - Epoch 183: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 17:57:35,996 - INFO - ####################Training epoch 184####################
2025-02-03 17:57:36,287 - INFO - Epoch 184: train_loss=0.8394
2025-02-03 17:57:36,757 - INFO - Epoch 184: val_loss=2.5503, val_acc=33.33%
2025-02-03 17:57:36,760 - INFO - Epoch 184: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 17:57:36,763 - INFO - ####################Training epoch 185####################
2025-02-03 17:57:37,049 - INFO - Epoch 185: train_loss=0.8384
2025-02-03 17:57:37,552 - INFO - Epoch 185: val_loss=2.5556, val_acc=33.33%
2025-02-03 17:57:37,558 - INFO - Epoch 185: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 17:57:37,572 - INFO - ####################Training epoch 186####################
2025-02-03 17:57:37,857 - INFO - Epoch 186: train_loss=0.8382
2025-02-03 17:57:38,326 - INFO - Epoch 186: val_loss=2.5513, val_acc=33.33%
2025-02-03 17:57:38,330 - INFO - Epoch 186: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:57:38,332 - INFO - ####################Training epoch 187####################
2025-02-03 17:57:38,620 - INFO - Epoch 187: train_loss=0.8377
2025-02-03 17:57:39,093 - INFO - Epoch 187: val_loss=2.5523, val_acc=33.33%
2025-02-03 17:57:39,096 - INFO - Epoch 187: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 17:57:39,099 - INFO - ####################Training epoch 188####################
2025-02-03 17:57:39,385 - INFO - Epoch 188: train_loss=0.8392
2025-02-03 17:57:39,857 - INFO - Epoch 188: val_loss=2.5440, val_acc=33.33%
2025-02-03 17:57:39,860 - INFO - Epoch 188: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 17:57:39,863 - INFO - ####################Training epoch 189####################
2025-02-03 17:57:40,150 - INFO - Epoch 189: train_loss=0.8371
2025-02-03 17:57:40,620 - INFO - Epoch 189: val_loss=2.5483, val_acc=33.33%
2025-02-03 17:57:40,624 - INFO - Epoch 189: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 17:57:40,626 - INFO - ####################Training epoch 190####################
2025-02-03 17:57:40,916 - INFO - Epoch 190: train_loss=0.8399
2025-02-03 17:57:41,387 - INFO - Epoch 190: val_loss=2.5546, val_acc=33.33%
2025-02-03 17:57:41,390 - INFO - Epoch 190: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 17:57:41,393 - INFO - ####################Training epoch 191####################
2025-02-03 17:57:41,684 - INFO - Epoch 191: train_loss=0.8395
2025-02-03 17:57:42,153 - INFO - Epoch 191: val_loss=2.5507, val_acc=33.33%
2025-02-03 17:57:42,156 - INFO - Epoch 191: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:57:42,159 - INFO - ####################Training epoch 192####################
2025-02-03 17:57:42,450 - INFO - Epoch 192: train_loss=0.8372
2025-02-03 17:57:42,921 - INFO - Epoch 192: val_loss=2.5499, val_acc=33.33%
2025-02-03 17:57:42,924 - INFO - Epoch 192: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 17:57:42,926 - INFO - ####################Training epoch 193####################
2025-02-03 17:57:43,217 - INFO - Epoch 193: train_loss=0.8413
2025-02-03 17:57:43,689 - INFO - Epoch 193: val_loss=2.5475, val_acc=33.33%
2025-02-03 17:57:43,693 - INFO - Epoch 193: EPOCH_AVG_TRAIN_LOSS=0.8413
2025-02-03 17:57:43,695 - INFO - ####################Training epoch 194####################
2025-02-03 17:57:43,985 - INFO - Epoch 194: train_loss=0.8409
2025-02-03 17:57:44,456 - INFO - Epoch 194: val_loss=2.5486, val_acc=33.33%
2025-02-03 17:57:44,460 - INFO - Epoch 194: EPOCH_AVG_TRAIN_LOSS=0.8409
2025-02-03 17:57:44,462 - INFO - ####################Training epoch 195####################
2025-02-03 17:57:44,748 - INFO - Epoch 195: train_loss=0.8389
2025-02-03 17:57:45,219 - INFO - Epoch 195: val_loss=2.5574, val_acc=33.33%
2025-02-03 17:57:45,222 - INFO - Epoch 195: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 17:57:45,224 - INFO - ####################Training epoch 196####################
2025-02-03 17:57:45,511 - INFO - Epoch 196: train_loss=0.8406
2025-02-03 17:57:46,027 - INFO - Epoch 196: val_loss=2.5510, val_acc=33.33%
2025-02-03 17:57:46,031 - INFO - Epoch 196: EPOCH_AVG_TRAIN_LOSS=0.8406
2025-02-03 17:57:46,033 - INFO - ####################Training epoch 197####################
2025-02-03 17:57:46,319 - INFO - Epoch 197: train_loss=0.8405
2025-02-03 17:57:46,789 - INFO - Epoch 197: val_loss=2.5521, val_acc=33.33%
2025-02-03 17:57:46,792 - INFO - Epoch 197: EPOCH_AVG_TRAIN_LOSS=0.8405
2025-02-03 17:57:46,795 - INFO - ####################Training epoch 198####################
2025-02-03 17:57:47,082 - INFO - Epoch 198: train_loss=0.8402
2025-02-03 17:57:47,556 - INFO - Epoch 198: val_loss=2.5558, val_acc=33.33%
2025-02-03 17:57:47,559 - INFO - Epoch 198: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:57:47,562 - INFO - ####################Training epoch 199####################
2025-02-03 17:57:47,854 - INFO - Epoch 199: train_loss=0.8389
2025-02-03 17:57:48,326 - INFO - Epoch 199: val_loss=2.5524, val_acc=33.33%
2025-02-03 17:57:48,329 - INFO - Epoch 199: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 17:57:48,332 - INFO - ####################Training epoch 200####################
2025-02-03 17:57:48,621 - INFO - Epoch 200: train_loss=0.8387
2025-02-03 17:57:49,094 - INFO - Epoch 200: val_loss=2.5544, val_acc=33.33%
2025-02-03 17:57:49,098 - INFO - Epoch 200: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 17:57:49,100 - INFO - ####################Training epoch 201####################
2025-02-03 17:57:49,392 - INFO - Epoch 201: train_loss=0.8392
2025-02-03 17:57:49,866 - INFO - Epoch 201: val_loss=2.5520, val_acc=33.33%
2025-02-03 17:57:49,869 - INFO - Epoch 201: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 17:57:49,871 - INFO - ####################Training epoch 202####################
2025-02-03 17:57:50,165 - INFO - Epoch 202: train_loss=0.8387
2025-02-03 17:57:50,638 - INFO - Epoch 202: val_loss=2.5524, val_acc=33.33%
2025-02-03 17:57:50,642 - INFO - Epoch 202: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 17:57:50,644 - INFO - ####################Training epoch 203####################
2025-02-03 17:57:50,934 - INFO - Epoch 203: train_loss=0.8378
2025-02-03 17:57:51,408 - INFO - Epoch 203: val_loss=2.5514, val_acc=33.33%
2025-02-03 17:57:51,411 - INFO - Epoch 203: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 17:57:51,413 - INFO - ####################Training epoch 204####################
2025-02-03 17:57:51,700 - INFO - Epoch 204: train_loss=0.8399
2025-02-03 17:57:52,168 - INFO - Epoch 204: val_loss=2.5560, val_acc=33.33%
2025-02-03 17:57:52,172 - INFO - Epoch 204: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 17:57:52,174 - INFO - ####################Training epoch 205####################
2025-02-03 17:57:52,462 - INFO - Epoch 205: train_loss=0.8381
2025-02-03 17:57:52,932 - INFO - Epoch 205: val_loss=2.5535, val_acc=33.33%
2025-02-03 17:57:52,936 - INFO - Epoch 205: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 17:57:52,938 - INFO - ####################Training epoch 206####################
2025-02-03 17:57:53,226 - INFO - Epoch 206: train_loss=0.8395
2025-02-03 17:57:53,699 - INFO - Epoch 206: val_loss=2.5510, val_acc=33.33%
2025-02-03 17:57:53,703 - INFO - Epoch 206: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:57:53,705 - INFO - ####################Training epoch 207####################
2025-02-03 17:57:53,998 - INFO - Epoch 207: train_loss=0.8384
2025-02-03 17:57:54,492 - INFO - Epoch 207: val_loss=2.5543, val_acc=33.33%
2025-02-03 17:57:54,496 - INFO - Epoch 207: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 17:57:54,498 - INFO - ####################Training epoch 208####################
2025-02-03 17:57:54,790 - INFO - Epoch 208: train_loss=0.8393
2025-02-03 17:57:55,259 - INFO - Epoch 208: val_loss=2.5504, val_acc=33.33%
2025-02-03 17:57:55,263 - INFO - Epoch 208: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 17:57:55,265 - INFO - ####################Training epoch 209####################
2025-02-03 17:57:55,552 - INFO - Epoch 209: train_loss=0.8390
2025-02-03 17:57:56,023 - INFO - Epoch 209: val_loss=2.5514, val_acc=33.33%
2025-02-03 17:57:56,027 - INFO - Epoch 209: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:57:56,029 - INFO - ####################Training epoch 210####################
2025-02-03 17:57:56,316 - INFO - Epoch 210: train_loss=0.8372
2025-02-03 17:57:56,786 - INFO - Epoch 210: val_loss=2.5485, val_acc=33.33%
2025-02-03 17:57:56,789 - INFO - Epoch 210: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 17:57:56,791 - INFO - ####################Training epoch 211####################
2025-02-03 17:57:57,082 - INFO - Epoch 211: train_loss=0.8373
2025-02-03 17:57:57,555 - INFO - Epoch 211: val_loss=2.5516, val_acc=33.33%
2025-02-03 17:57:57,558 - INFO - Epoch 211: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 17:57:57,560 - INFO - ####################Training epoch 212####################
2025-02-03 17:57:57,851 - INFO - Epoch 212: train_loss=0.8411
2025-02-03 17:57:58,324 - INFO - Epoch 212: val_loss=2.5583, val_acc=33.33%
2025-02-03 17:57:58,328 - INFO - Epoch 212: EPOCH_AVG_TRAIN_LOSS=0.8411
2025-02-03 17:57:58,330 - INFO - ####################Training epoch 213####################
2025-02-03 17:57:58,618 - INFO - Epoch 213: train_loss=0.8380
2025-02-03 17:57:59,088 - INFO - Epoch 213: val_loss=2.5462, val_acc=33.33%
2025-02-03 17:57:59,092 - INFO - Epoch 213: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 17:57:59,094 - INFO - ####################Training epoch 214####################
2025-02-03 17:57:59,385 - INFO - Epoch 214: train_loss=0.8387
2025-02-03 17:57:59,857 - INFO - Epoch 214: val_loss=2.5521, val_acc=33.33%
2025-02-03 17:57:59,861 - INFO - Epoch 214: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 17:57:59,863 - INFO - ####################Training epoch 215####################
2025-02-03 17:58:00,155 - INFO - Epoch 215: train_loss=0.8398
2025-02-03 17:58:00,626 - INFO - Epoch 215: val_loss=2.5526, val_acc=33.33%
2025-02-03 17:58:00,630 - INFO - Epoch 215: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 17:58:00,632 - INFO - ####################Training epoch 216####################
2025-02-03 17:58:00,922 - INFO - Epoch 216: train_loss=0.8394
2025-02-03 17:58:01,393 - INFO - Epoch 216: val_loss=2.5570, val_acc=33.33%
2025-02-03 17:58:01,397 - INFO - Epoch 216: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 17:58:01,399 - INFO - ####################Training epoch 217####################
2025-02-03 17:58:01,689 - INFO - Epoch 217: train_loss=0.8385
2025-02-03 17:58:02,163 - INFO - Epoch 217: val_loss=2.5540, val_acc=33.33%
2025-02-03 17:58:02,167 - INFO - Epoch 217: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 17:58:02,169 - INFO - ####################Training epoch 218####################
2025-02-03 17:58:02,458 - INFO - Epoch 218: train_loss=0.8399
2025-02-03 17:58:02,928 - INFO - Epoch 218: val_loss=2.5526, val_acc=33.33%
2025-02-03 17:58:02,931 - INFO - Epoch 218: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 17:58:02,934 - INFO - ####################Training epoch 219####################
2025-02-03 17:58:03,224 - INFO - Epoch 219: train_loss=0.8396
2025-02-03 17:58:03,695 - INFO - Epoch 219: val_loss=2.5555, val_acc=33.33%
2025-02-03 17:58:03,698 - INFO - Epoch 219: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 17:58:03,701 - INFO - ####################Training epoch 220####################
2025-02-03 17:58:03,988 - INFO - Epoch 220: train_loss=0.8391
2025-02-03 17:58:04,462 - INFO - Epoch 220: val_loss=2.5491, val_acc=33.33%
2025-02-03 17:58:04,465 - INFO - Epoch 220: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:58:04,467 - INFO - ####################Training epoch 221####################
2025-02-03 17:58:04,755 - INFO - Epoch 221: train_loss=0.8403
2025-02-03 17:58:05,227 - INFO - Epoch 221: val_loss=2.5531, val_acc=33.33%
2025-02-03 17:58:05,230 - INFO - Epoch 221: EPOCH_AVG_TRAIN_LOSS=0.8403
2025-02-03 17:58:05,232 - INFO - ####################Training epoch 222####################
2025-02-03 17:58:05,520 - INFO - Epoch 222: train_loss=0.8401
2025-02-03 17:58:05,991 - INFO - Epoch 222: val_loss=2.5553, val_acc=33.33%
2025-02-03 17:58:05,995 - INFO - Epoch 222: EPOCH_AVG_TRAIN_LOSS=0.8401
2025-02-03 17:58:05,997 - INFO - ####################Training epoch 223####################
2025-02-03 17:58:06,288 - INFO - Epoch 223: train_loss=0.8386
2025-02-03 17:58:06,757 - INFO - Epoch 223: val_loss=2.5539, val_acc=33.33%
2025-02-03 17:58:06,760 - INFO - Epoch 223: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 17:58:06,763 - INFO - ####################Training epoch 224####################
2025-02-03 17:58:07,053 - INFO - Epoch 224: train_loss=0.8384
2025-02-03 17:58:07,525 - INFO - Epoch 224: val_loss=2.5498, val_acc=33.33%
2025-02-03 17:58:07,528 - INFO - Epoch 224: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 17:58:07,531 - INFO - ####################Training epoch 225####################
2025-02-03 17:58:07,818 - INFO - Epoch 225: train_loss=0.8394
2025-02-03 17:58:08,294 - INFO - Epoch 225: val_loss=2.5578, val_acc=33.33%
2025-02-03 17:58:08,297 - INFO - Epoch 225: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 17:58:08,300 - INFO - ####################Training epoch 226####################
2025-02-03 17:58:08,586 - INFO - Epoch 226: train_loss=0.8400
2025-02-03 17:58:09,058 - INFO - Epoch 226: val_loss=2.5516, val_acc=33.33%
2025-02-03 17:58:09,061 - INFO - Epoch 226: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 17:58:09,064 - INFO - ####################Training epoch 227####################
2025-02-03 17:58:09,354 - INFO - Epoch 227: train_loss=0.8395
2025-02-03 17:58:09,825 - INFO - Epoch 227: val_loss=2.5561, val_acc=33.33%
2025-02-03 17:58:09,829 - INFO - Epoch 227: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:58:09,831 - INFO - ####################Training epoch 228####################
2025-02-03 17:58:10,116 - INFO - Epoch 228: train_loss=0.8400
2025-02-03 17:58:10,588 - INFO - Epoch 228: val_loss=2.5494, val_acc=33.33%
2025-02-03 17:58:10,592 - INFO - Epoch 228: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 17:58:10,594 - INFO - ####################Training epoch 229####################
2025-02-03 17:58:10,887 - INFO - Epoch 229: train_loss=0.8387
2025-02-03 17:58:11,356 - INFO - Epoch 229: val_loss=2.5558, val_acc=33.33%
2025-02-03 17:58:11,360 - INFO - Epoch 229: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 17:58:11,362 - INFO - ####################Training epoch 230####################
2025-02-03 17:58:11,651 - INFO - Epoch 230: train_loss=0.8362
2025-02-03 17:58:12,122 - INFO - Epoch 230: val_loss=2.5530, val_acc=33.33%
2025-02-03 17:58:12,126 - INFO - Epoch 230: EPOCH_AVG_TRAIN_LOSS=0.8362
2025-02-03 17:58:12,128 - INFO - ####################Training epoch 231####################
2025-02-03 17:58:12,417 - INFO - Epoch 231: train_loss=0.8391
2025-02-03 17:58:12,889 - INFO - Epoch 231: val_loss=2.5552, val_acc=33.33%
2025-02-03 17:58:12,893 - INFO - Epoch 231: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:58:12,895 - INFO - ####################Training epoch 232####################
2025-02-03 17:58:13,184 - INFO - Epoch 232: train_loss=0.8379
2025-02-03 17:58:13,656 - INFO - Epoch 232: val_loss=2.5503, val_acc=33.33%
2025-02-03 17:58:13,660 - INFO - Epoch 232: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 17:58:13,662 - INFO - ####################Training epoch 233####################
2025-02-03 17:58:13,952 - INFO - Epoch 233: train_loss=0.8399
2025-02-03 17:58:14,424 - INFO - Epoch 233: val_loss=2.5550, val_acc=33.33%
2025-02-03 17:58:14,427 - INFO - Epoch 233: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 17:58:14,430 - INFO - ####################Training epoch 234####################
2025-02-03 17:58:14,719 - INFO - Epoch 234: train_loss=0.8374
2025-02-03 17:58:15,192 - INFO - Epoch 234: val_loss=2.5490, val_acc=33.33%
2025-02-03 17:58:15,195 - INFO - Epoch 234: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 17:58:15,198 - INFO - ####################Training epoch 235####################
2025-02-03 17:58:15,488 - INFO - Epoch 235: train_loss=0.8398
2025-02-03 17:58:15,962 - INFO - Epoch 235: val_loss=2.5512, val_acc=33.33%
2025-02-03 17:58:15,966 - INFO - Epoch 235: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 17:58:15,968 - INFO - ####################Training epoch 236####################
2025-02-03 17:58:16,257 - INFO - Epoch 236: train_loss=0.8395
2025-02-03 17:58:16,727 - INFO - Epoch 236: val_loss=2.5529, val_acc=33.33%
2025-02-03 17:58:16,731 - INFO - Epoch 236: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:58:16,733 - INFO - ####################Training epoch 237####################
2025-02-03 17:58:17,028 - INFO - Epoch 237: train_loss=0.8398
2025-02-03 17:58:17,499 - INFO - Epoch 237: val_loss=2.5514, val_acc=33.33%
2025-02-03 17:58:17,502 - INFO - Epoch 237: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 17:58:17,504 - INFO - ####################Training epoch 238####################
2025-02-03 17:58:17,794 - INFO - Epoch 238: train_loss=0.8388
2025-02-03 17:58:18,269 - INFO - Epoch 238: val_loss=2.5535, val_acc=33.33%
2025-02-03 17:58:18,273 - INFO - Epoch 238: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 17:58:18,275 - INFO - ####################Training epoch 239####################
2025-02-03 17:58:18,562 - INFO - Epoch 239: train_loss=0.8380
2025-02-03 17:58:19,035 - INFO - Epoch 239: val_loss=2.5547, val_acc=33.33%
2025-02-03 17:58:19,039 - INFO - Epoch 239: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 17:58:19,041 - INFO - ####################Training epoch 240####################
2025-02-03 17:58:19,332 - INFO - Epoch 240: train_loss=0.8383
2025-02-03 17:58:19,802 - INFO - Epoch 240: val_loss=2.5567, val_acc=33.33%
2025-02-03 17:58:19,806 - INFO - Epoch 240: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 17:58:19,808 - INFO - ####################Training epoch 241####################
2025-02-03 17:58:20,098 - INFO - Epoch 241: train_loss=0.8387
2025-02-03 17:58:20,568 - INFO - Epoch 241: val_loss=2.5536, val_acc=33.33%
2025-02-03 17:58:20,571 - INFO - Epoch 241: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 17:58:20,574 - INFO - ####################Training epoch 242####################
2025-02-03 17:58:20,861 - INFO - Epoch 242: train_loss=0.8409
2025-02-03 17:58:21,333 - INFO - Epoch 242: val_loss=2.5517, val_acc=33.33%
2025-02-03 17:58:21,336 - INFO - Epoch 242: EPOCH_AVG_TRAIN_LOSS=0.8409
2025-02-03 17:58:21,339 - INFO - ####################Training epoch 243####################
2025-02-03 17:58:21,627 - INFO - Epoch 243: train_loss=0.8370
2025-02-03 17:58:22,100 - INFO - Epoch 243: val_loss=2.5527, val_acc=33.33%
2025-02-03 17:58:22,104 - INFO - Epoch 243: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 17:58:22,106 - INFO - ####################Training epoch 244####################
2025-02-03 17:58:22,395 - INFO - Epoch 244: train_loss=0.8396
2025-02-03 17:58:22,867 - INFO - Epoch 244: val_loss=2.5569, val_acc=33.33%
2025-02-03 17:58:22,871 - INFO - Epoch 244: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 17:58:22,873 - INFO - ####################Training epoch 245####################
2025-02-03 17:58:23,158 - INFO - Epoch 245: train_loss=0.8378
2025-02-03 17:58:23,630 - INFO - Epoch 245: val_loss=2.5510, val_acc=33.33%
2025-02-03 17:58:23,634 - INFO - Epoch 245: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 17:58:23,636 - INFO - ####################Training epoch 246####################
2025-02-03 17:58:23,925 - INFO - Epoch 246: train_loss=0.8409
2025-02-03 17:58:24,397 - INFO - Epoch 246: val_loss=2.5537, val_acc=33.33%
2025-02-03 17:58:24,400 - INFO - Epoch 246: EPOCH_AVG_TRAIN_LOSS=0.8409
2025-02-03 17:58:24,403 - INFO - ####################Training epoch 247####################
2025-02-03 17:58:24,691 - INFO - Epoch 247: train_loss=0.8390
2025-02-03 17:58:25,162 - INFO - Epoch 247: val_loss=2.5517, val_acc=33.33%
2025-02-03 17:58:25,166 - INFO - Epoch 247: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:58:25,168 - INFO - ####################Training epoch 248####################
2025-02-03 17:58:25,457 - INFO - Epoch 248: train_loss=0.8400
2025-02-03 17:58:25,929 - INFO - Epoch 248: val_loss=2.5585, val_acc=33.33%
2025-02-03 17:58:25,932 - INFO - Epoch 248: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 17:58:25,934 - INFO - ####################Training epoch 249####################
2025-02-03 17:58:26,225 - INFO - Epoch 249: train_loss=0.8387
2025-02-03 17:58:26,694 - INFO - Epoch 249: val_loss=2.5552, val_acc=33.33%
2025-02-03 17:58:26,698 - INFO - Epoch 249: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 17:58:26,700 - INFO - ####################Training epoch 250####################
2025-02-03 17:58:26,989 - INFO - Epoch 250: train_loss=0.8393
2025-02-03 17:58:27,465 - INFO - Epoch 250: val_loss=2.5563, val_acc=33.33%
2025-02-03 17:58:27,469 - INFO - Epoch 250: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 17:58:27,471 - INFO - ####################Training epoch 251####################
2025-02-03 17:58:27,773 - INFO - Epoch 251: train_loss=0.8383
2025-02-03 17:58:28,241 - INFO - Epoch 251: val_loss=2.5533, val_acc=33.33%
2025-02-03 17:58:28,244 - INFO - Epoch 251: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 17:58:28,247 - INFO - ####################Training epoch 252####################
2025-02-03 17:58:28,536 - INFO - Epoch 252: train_loss=0.8401
2025-02-03 17:58:29,006 - INFO - Epoch 252: val_loss=2.5542, val_acc=33.33%
2025-02-03 17:58:29,009 - INFO - Epoch 252: EPOCH_AVG_TRAIN_LOSS=0.8401
2025-02-03 17:58:29,012 - INFO - ####################Training epoch 253####################
2025-02-03 17:58:29,300 - INFO - Epoch 253: train_loss=0.8358
2025-02-03 17:58:29,768 - INFO - Epoch 253: val_loss=2.5566, val_acc=33.33%
2025-02-03 17:58:29,772 - INFO - Epoch 253: EPOCH_AVG_TRAIN_LOSS=0.8358
2025-02-03 17:58:29,774 - INFO - ####################Training epoch 254####################
2025-02-03 17:58:30,060 - INFO - Epoch 254: train_loss=0.8372
2025-02-03 17:58:30,528 - INFO - Epoch 254: val_loss=2.5482, val_acc=33.33%
2025-02-03 17:58:30,532 - INFO - Epoch 254: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 17:58:30,534 - INFO - ####################Training epoch 255####################
2025-02-03 17:58:30,822 - INFO - Epoch 255: train_loss=0.8362
2025-02-03 17:58:31,291 - INFO - Epoch 255: val_loss=2.5487, val_acc=33.33%
2025-02-03 17:58:31,294 - INFO - Epoch 255: EPOCH_AVG_TRAIN_LOSS=0.8362
2025-02-03 17:58:31,297 - INFO - ####################Training epoch 256####################
2025-02-03 17:58:31,584 - INFO - Epoch 256: train_loss=0.8384
2025-02-03 17:58:32,051 - INFO - Epoch 256: val_loss=2.5563, val_acc=33.33%
2025-02-03 17:58:32,054 - INFO - Epoch 256: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 17:58:32,057 - INFO - ####################Training epoch 257####################
2025-02-03 17:58:32,342 - INFO - Epoch 257: train_loss=0.8390
2025-02-03 17:58:32,811 - INFO - Epoch 257: val_loss=2.5548, val_acc=33.33%
2025-02-03 17:58:32,814 - INFO - Epoch 257: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:58:32,817 - INFO - ####################Training epoch 258####################
2025-02-03 17:58:33,103 - INFO - Epoch 258: train_loss=0.8373
2025-02-03 17:58:33,572 - INFO - Epoch 258: val_loss=2.5539, val_acc=33.33%
2025-02-03 17:58:33,576 - INFO - Epoch 258: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 17:58:33,578 - INFO - ####################Training epoch 259####################
2025-02-03 17:58:33,866 - INFO - Epoch 259: train_loss=0.8396
2025-02-03 17:58:34,337 - INFO - Epoch 259: val_loss=2.5549, val_acc=33.33%
2025-02-03 17:58:34,341 - INFO - Epoch 259: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 17:58:34,343 - INFO - ####################Training epoch 260####################
2025-02-03 17:58:34,630 - INFO - Epoch 260: train_loss=0.8374
2025-02-03 17:58:35,101 - INFO - Epoch 260: val_loss=2.5513, val_acc=33.33%
2025-02-03 17:58:35,104 - INFO - Epoch 260: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 17:58:35,107 - INFO - ####################Training epoch 261####################
2025-02-03 17:58:35,394 - INFO - Epoch 261: train_loss=0.8363
2025-02-03 17:58:35,863 - INFO - Epoch 261: val_loss=2.5476, val_acc=33.33%
2025-02-03 17:58:35,867 - INFO - Epoch 261: EPOCH_AVG_TRAIN_LOSS=0.8363
2025-02-03 17:58:35,869 - INFO - ####################Training epoch 262####################
2025-02-03 17:58:36,177 - INFO - Epoch 262: train_loss=0.8370
2025-02-03 17:58:36,648 - INFO - Epoch 262: val_loss=2.5551, val_acc=33.33%
2025-02-03 17:58:36,651 - INFO - Epoch 262: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 17:58:36,653 - INFO - ####################Training epoch 263####################
2025-02-03 17:58:36,942 - INFO - Epoch 263: train_loss=0.8399
2025-02-03 17:58:37,418 - INFO - Epoch 263: val_loss=2.5539, val_acc=33.33%
2025-02-03 17:58:37,421 - INFO - Epoch 263: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 17:58:37,424 - INFO - ####################Training epoch 264####################
2025-02-03 17:58:37,713 - INFO - Epoch 264: train_loss=0.8394
2025-02-03 17:58:38,187 - INFO - Epoch 264: val_loss=2.5563, val_acc=33.33%
2025-02-03 17:58:38,191 - INFO - Epoch 264: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 17:58:38,193 - INFO - ####################Training epoch 265####################
2025-02-03 17:58:38,484 - INFO - Epoch 265: train_loss=0.8388
2025-02-03 17:58:38,959 - INFO - Epoch 265: val_loss=2.5505, val_acc=33.33%
2025-02-03 17:58:38,962 - INFO - Epoch 265: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 17:58:38,965 - INFO - ####################Training epoch 266####################
2025-02-03 17:58:39,257 - INFO - Epoch 266: train_loss=0.8401
2025-02-03 17:58:39,732 - INFO - Epoch 266: val_loss=2.5554, val_acc=33.33%
2025-02-03 17:58:39,736 - INFO - Epoch 266: EPOCH_AVG_TRAIN_LOSS=0.8401
2025-02-03 17:58:39,738 - INFO - ####################Training epoch 267####################
2025-02-03 17:58:40,032 - INFO - Epoch 267: train_loss=0.8373
2025-02-03 17:58:40,506 - INFO - Epoch 267: val_loss=2.5510, val_acc=33.33%
2025-02-03 17:58:40,509 - INFO - Epoch 267: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 17:58:40,511 - INFO - ####################Training epoch 268####################
2025-02-03 17:58:40,803 - INFO - Epoch 268: train_loss=0.8395
2025-02-03 17:58:41,276 - INFO - Epoch 268: val_loss=2.5523, val_acc=33.33%
2025-02-03 17:58:41,279 - INFO - Epoch 268: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:58:41,281 - INFO - ####################Training epoch 269####################
2025-02-03 17:58:41,576 - INFO - Epoch 269: train_loss=0.8371
2025-02-03 17:58:42,050 - INFO - Epoch 269: val_loss=2.5534, val_acc=33.33%
2025-02-03 17:58:42,053 - INFO - Epoch 269: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 17:58:42,055 - INFO - ####################Training epoch 270####################
2025-02-03 17:58:42,347 - INFO - Epoch 270: train_loss=0.8404
2025-02-03 17:58:42,822 - INFO - Epoch 270: val_loss=2.5519, val_acc=33.33%
2025-02-03 17:58:42,825 - INFO - Epoch 270: EPOCH_AVG_TRAIN_LOSS=0.8404
2025-02-03 17:58:42,828 - INFO - ####################Training epoch 271####################
2025-02-03 17:58:43,121 - INFO - Epoch 271: train_loss=0.8402
2025-02-03 17:58:43,595 - INFO - Epoch 271: val_loss=2.5526, val_acc=33.33%
2025-02-03 17:58:43,599 - INFO - Epoch 271: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:58:43,601 - INFO - ####################Training epoch 272####################
2025-02-03 17:58:43,897 - INFO - Epoch 272: train_loss=0.8403
2025-02-03 17:58:44,367 - INFO - Epoch 272: val_loss=2.5513, val_acc=33.33%
2025-02-03 17:58:44,370 - INFO - Epoch 272: EPOCH_AVG_TRAIN_LOSS=0.8403
2025-02-03 17:58:44,372 - INFO - ####################Training epoch 273####################
2025-02-03 17:58:44,705 - INFO - Epoch 273: train_loss=0.8383
2025-02-03 17:58:45,173 - INFO - Epoch 273: val_loss=2.5511, val_acc=33.33%
2025-02-03 17:58:45,177 - INFO - Epoch 273: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 17:58:45,180 - INFO - ####################Training epoch 274####################
2025-02-03 17:58:45,475 - INFO - Epoch 274: train_loss=0.8401
2025-02-03 17:58:45,954 - INFO - Epoch 274: val_loss=2.5572, val_acc=33.33%
2025-02-03 17:58:45,958 - INFO - Epoch 274: EPOCH_AVG_TRAIN_LOSS=0.8401
2025-02-03 17:58:45,961 - INFO - ####################Training epoch 275####################
2025-02-03 17:58:46,257 - INFO - Epoch 275: train_loss=0.8379
2025-02-03 17:58:46,743 - INFO - Epoch 275: val_loss=2.5584, val_acc=33.33%
2025-02-03 17:58:46,747 - INFO - Epoch 275: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 17:58:46,750 - INFO - ####################Training epoch 276####################
2025-02-03 17:58:47,041 - INFO - Epoch 276: train_loss=0.8374
2025-02-03 17:58:47,515 - INFO - Epoch 276: val_loss=2.5521, val_acc=33.33%
2025-02-03 17:58:47,518 - INFO - Epoch 276: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 17:58:47,520 - INFO - ####################Training epoch 277####################
2025-02-03 17:58:47,812 - INFO - Epoch 277: train_loss=0.8402
2025-02-03 17:58:48,286 - INFO - Epoch 277: val_loss=2.5494, val_acc=33.33%
2025-02-03 17:58:48,289 - INFO - Epoch 277: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:58:48,292 - INFO - ####################Training epoch 278####################
2025-02-03 17:58:48,581 - INFO - Epoch 278: train_loss=0.8377
2025-02-03 17:58:49,054 - INFO - Epoch 278: val_loss=2.5524, val_acc=33.33%
2025-02-03 17:58:49,058 - INFO - Epoch 278: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 17:58:49,060 - INFO - ####################Training epoch 279####################
2025-02-03 17:58:49,348 - INFO - Epoch 279: train_loss=0.8367
2025-02-03 17:58:49,821 - INFO - Epoch 279: val_loss=2.5478, val_acc=33.33%
2025-02-03 17:58:49,825 - INFO - Epoch 279: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 17:58:49,827 - INFO - ####################Training epoch 280####################
2025-02-03 17:58:50,116 - INFO - Epoch 280: train_loss=0.8394
2025-02-03 17:58:50,590 - INFO - Epoch 280: val_loss=2.5500, val_acc=33.33%
2025-02-03 17:58:50,594 - INFO - Epoch 280: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 17:58:50,596 - INFO - ####################Training epoch 281####################
2025-02-03 17:58:50,882 - INFO - Epoch 281: train_loss=0.8402
2025-02-03 17:58:51,355 - INFO - Epoch 281: val_loss=2.5560, val_acc=33.33%
2025-02-03 17:58:51,359 - INFO - Epoch 281: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:58:51,361 - INFO - ####################Training epoch 282####################
2025-02-03 17:58:51,645 - INFO - Epoch 282: train_loss=0.8375
2025-02-03 17:58:52,114 - INFO - Epoch 282: val_loss=2.5567, val_acc=33.33%
2025-02-03 17:58:52,117 - INFO - Epoch 282: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 17:58:52,119 - INFO - ####################Training epoch 283####################
2025-02-03 17:58:52,411 - INFO - Epoch 283: train_loss=0.8366
2025-02-03 17:58:52,881 - INFO - Epoch 283: val_loss=2.5524, val_acc=33.33%
2025-02-03 17:58:52,885 - INFO - Epoch 283: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 17:58:52,887 - INFO - ####################Training epoch 284####################
2025-02-03 17:58:53,223 - INFO - Epoch 284: train_loss=0.8368
2025-02-03 17:58:53,694 - INFO - Epoch 284: val_loss=2.5542, val_acc=33.33%
2025-02-03 17:58:53,698 - INFO - Epoch 284: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 17:58:53,700 - INFO - ####################Training epoch 285####################
2025-02-03 17:58:53,989 - INFO - Epoch 285: train_loss=0.8392
2025-02-03 17:58:54,458 - INFO - Epoch 285: val_loss=2.5490, val_acc=33.33%
2025-02-03 17:58:54,462 - INFO - Epoch 285: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 17:58:54,464 - INFO - ####################Training epoch 286####################
2025-02-03 17:58:54,757 - INFO - Epoch 286: train_loss=0.8368
2025-02-03 17:58:55,227 - INFO - Epoch 286: val_loss=2.5524, val_acc=33.33%
2025-02-03 17:58:55,231 - INFO - Epoch 286: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 17:58:55,233 - INFO - ####################Training epoch 287####################
2025-02-03 17:58:55,520 - INFO - Epoch 287: train_loss=0.8367
2025-02-03 17:58:55,989 - INFO - Epoch 287: val_loss=2.5514, val_acc=33.33%
2025-02-03 17:58:55,993 - INFO - Epoch 287: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 17:58:55,995 - INFO - ####################Training epoch 288####################
2025-02-03 17:58:56,281 - INFO - Epoch 288: train_loss=0.8375
2025-02-03 17:58:56,753 - INFO - Epoch 288: val_loss=2.5529, val_acc=33.33%
2025-02-03 17:58:56,756 - INFO - Epoch 288: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 17:58:56,759 - INFO - ####################Training epoch 289####################
2025-02-03 17:58:57,049 - INFO - Epoch 289: train_loss=0.8394
2025-02-03 17:58:57,521 - INFO - Epoch 289: val_loss=2.5498, val_acc=33.33%
2025-02-03 17:58:57,524 - INFO - Epoch 289: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 17:58:57,527 - INFO - ####################Training epoch 290####################
2025-02-03 17:58:57,815 - INFO - Epoch 290: train_loss=0.8377
2025-02-03 17:58:58,287 - INFO - Epoch 290: val_loss=2.5527, val_acc=33.33%
2025-02-03 17:58:58,291 - INFO - Epoch 290: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 17:58:58,293 - INFO - ####################Training epoch 291####################
2025-02-03 17:58:58,585 - INFO - Epoch 291: train_loss=0.8418
2025-02-03 17:58:59,053 - INFO - Epoch 291: val_loss=2.5582, val_acc=33.33%
2025-02-03 17:58:59,057 - INFO - Epoch 291: EPOCH_AVG_TRAIN_LOSS=0.8418
2025-02-03 17:58:59,059 - INFO - ####################Training epoch 292####################
2025-02-03 17:58:59,346 - INFO - Epoch 292: train_loss=0.8377
2025-02-03 17:58:59,818 - INFO - Epoch 292: val_loss=2.5530, val_acc=33.33%
2025-02-03 17:58:59,821 - INFO - Epoch 292: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 17:58:59,823 - INFO - ####################Training epoch 293####################
2025-02-03 17:59:00,113 - INFO - Epoch 293: train_loss=0.8376
2025-02-03 17:59:00,585 - INFO - Epoch 293: val_loss=2.5597, val_acc=33.33%
2025-02-03 17:59:00,589 - INFO - Epoch 293: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 17:59:00,591 - INFO - ####################Training epoch 294####################
2025-02-03 17:59:00,879 - INFO - Epoch 294: train_loss=0.8398
2025-02-03 17:59:01,352 - INFO - Epoch 294: val_loss=2.5512, val_acc=33.33%
2025-02-03 17:59:01,356 - INFO - Epoch 294: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 17:59:01,359 - INFO - ####################Training epoch 295####################
2025-02-03 17:59:01,647 - INFO - Epoch 295: train_loss=0.8389
2025-02-03 17:59:02,122 - INFO - Epoch 295: val_loss=2.5527, val_acc=33.33%
2025-02-03 17:59:02,126 - INFO - Epoch 295: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 17:59:02,128 - INFO - ####################Training epoch 296####################
2025-02-03 17:59:02,418 - INFO - Epoch 296: train_loss=0.8398
2025-02-03 17:59:02,893 - INFO - Epoch 296: val_loss=2.5519, val_acc=33.33%
2025-02-03 17:59:02,896 - INFO - Epoch 296: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 17:59:02,899 - INFO - ####################Training epoch 297####################
2025-02-03 17:59:03,190 - INFO - Epoch 297: train_loss=0.8368
2025-02-03 17:59:03,659 - INFO - Epoch 297: val_loss=2.5543, val_acc=33.33%
2025-02-03 17:59:03,663 - INFO - Epoch 297: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 17:59:03,665 - INFO - ####################Training epoch 298####################
2025-02-03 17:59:03,958 - INFO - Epoch 298: train_loss=0.8371
2025-02-03 17:59:04,434 - INFO - Epoch 298: val_loss=2.5509, val_acc=33.33%
2025-02-03 17:59:04,438 - INFO - Epoch 298: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 17:59:04,440 - INFO - ####################Training epoch 299####################
2025-02-03 17:59:04,730 - INFO - Epoch 299: train_loss=0.8397
2025-02-03 17:59:05,205 - INFO - Epoch 299: val_loss=2.5533, val_acc=33.33%
2025-02-03 17:59:05,209 - INFO - Epoch 299: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 17:59:05,211 - INFO - ####################Training epoch 300####################
2025-02-03 17:59:05,499 - INFO - Epoch 300: train_loss=0.8392
2025-02-03 17:59:05,971 - INFO - Epoch 300: val_loss=2.5571, val_acc=33.33%
2025-02-03 17:59:05,975 - INFO - Epoch 300: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 17:59:05,977 - INFO - ####################Training epoch 301####################
2025-02-03 17:59:06,262 - INFO - Epoch 301: train_loss=0.8383
2025-02-03 17:59:06,736 - INFO - Epoch 301: val_loss=2.5517, val_acc=33.33%
2025-02-03 17:59:06,739 - INFO - Epoch 301: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 17:59:06,741 - INFO - ####################Training epoch 302####################
2025-02-03 17:59:07,028 - INFO - Epoch 302: train_loss=0.8413
2025-02-03 17:59:07,501 - INFO - Epoch 302: val_loss=2.5521, val_acc=33.33%
2025-02-03 17:59:07,505 - INFO - Epoch 302: EPOCH_AVG_TRAIN_LOSS=0.8413
2025-02-03 17:59:07,507 - INFO - ####################Training epoch 303####################
2025-02-03 17:59:07,794 - INFO - Epoch 303: train_loss=0.8397
2025-02-03 17:59:08,265 - INFO - Epoch 303: val_loss=2.5549, val_acc=33.33%
2025-02-03 17:59:08,269 - INFO - Epoch 303: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 17:59:08,271 - INFO - ####################Training epoch 304####################
2025-02-03 17:59:08,561 - INFO - Epoch 304: train_loss=0.8378
2025-02-03 17:59:09,030 - INFO - Epoch 304: val_loss=2.5521, val_acc=33.33%
2025-02-03 17:59:09,034 - INFO - Epoch 304: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 17:59:09,036 - INFO - ####################Training epoch 305####################
2025-02-03 17:59:09,324 - INFO - Epoch 305: train_loss=0.8382
2025-02-03 17:59:09,795 - INFO - Epoch 305: val_loss=2.5506, val_acc=33.33%
2025-02-03 17:59:09,798 - INFO - Epoch 305: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:59:09,800 - INFO - ####################Training epoch 306####################
2025-02-03 17:59:10,090 - INFO - Epoch 306: train_loss=0.8390
2025-02-03 17:59:10,561 - INFO - Epoch 306: val_loss=2.5546, val_acc=33.33%
2025-02-03 17:59:10,564 - INFO - Epoch 306: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:59:10,567 - INFO - ####################Training epoch 307####################
2025-02-03 17:59:10,865 - INFO - Epoch 307: train_loss=0.8402
2025-02-03 17:59:11,335 - INFO - Epoch 307: val_loss=2.5544, val_acc=33.33%
2025-02-03 17:59:11,339 - INFO - Epoch 307: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:59:11,341 - INFO - ####################Training epoch 308####################
2025-02-03 17:59:11,631 - INFO - Epoch 308: train_loss=0.8394
2025-02-03 17:59:12,107 - INFO - Epoch 308: val_loss=2.5476, val_acc=33.33%
2025-02-03 17:59:12,111 - INFO - Epoch 308: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 17:59:12,113 - INFO - ####################Training epoch 309####################
2025-02-03 17:59:12,403 - INFO - Epoch 309: train_loss=0.8391
2025-02-03 17:59:12,875 - INFO - Epoch 309: val_loss=2.5515, val_acc=33.33%
2025-02-03 17:59:12,879 - INFO - Epoch 309: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:59:12,882 - INFO - ####################Training epoch 310####################
2025-02-03 17:59:13,173 - INFO - Epoch 310: train_loss=0.8399
2025-02-03 17:59:13,655 - INFO - Epoch 310: val_loss=2.5492, val_acc=33.33%
2025-02-03 17:59:13,658 - INFO - Epoch 310: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 17:59:13,660 - INFO - ####################Training epoch 311####################
2025-02-03 17:59:13,956 - INFO - Epoch 311: train_loss=0.8403
2025-02-03 17:59:14,432 - INFO - Epoch 311: val_loss=2.5529, val_acc=33.33%
2025-02-03 17:59:14,436 - INFO - Epoch 311: EPOCH_AVG_TRAIN_LOSS=0.8403
2025-02-03 17:59:14,438 - INFO - ####################Training epoch 312####################
2025-02-03 17:59:14,729 - INFO - Epoch 312: train_loss=0.8414
2025-02-03 17:59:15,206 - INFO - Epoch 312: val_loss=2.5488, val_acc=33.33%
2025-02-03 17:59:15,210 - INFO - Epoch 312: EPOCH_AVG_TRAIN_LOSS=0.8414
2025-02-03 17:59:15,212 - INFO - ####################Training epoch 313####################
2025-02-03 17:59:15,503 - INFO - Epoch 313: train_loss=0.8382
2025-02-03 17:59:15,976 - INFO - Epoch 313: val_loss=2.5484, val_acc=33.33%
2025-02-03 17:59:15,980 - INFO - Epoch 313: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:59:15,982 - INFO - ####################Training epoch 314####################
2025-02-03 17:59:16,275 - INFO - Epoch 314: train_loss=0.8391
2025-02-03 17:59:16,751 - INFO - Epoch 314: val_loss=2.5461, val_acc=33.33%
2025-02-03 17:59:16,755 - INFO - Epoch 314: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:59:16,757 - INFO - ####################Training epoch 315####################
2025-02-03 17:59:17,053 - INFO - Epoch 315: train_loss=0.8382
2025-02-03 17:59:17,525 - INFO - Epoch 315: val_loss=2.5495, val_acc=33.33%
2025-02-03 17:59:17,529 - INFO - Epoch 315: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:59:17,531 - INFO - ####################Training epoch 316####################
2025-02-03 17:59:17,819 - INFO - Epoch 316: train_loss=0.8375
2025-02-03 17:59:18,291 - INFO - Epoch 316: val_loss=2.5552, val_acc=33.33%
2025-02-03 17:59:18,295 - INFO - Epoch 316: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 17:59:18,297 - INFO - ####################Training epoch 317####################
2025-02-03 17:59:18,589 - INFO - Epoch 317: train_loss=0.8383
2025-02-03 17:59:19,062 - INFO - Epoch 317: val_loss=2.5486, val_acc=33.33%
2025-02-03 17:59:19,066 - INFO - Epoch 317: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 17:59:19,068 - INFO - ####################Training epoch 318####################
2025-02-03 17:59:19,388 - INFO - Epoch 318: train_loss=0.8395
2025-02-03 17:59:19,858 - INFO - Epoch 318: val_loss=2.5515, val_acc=33.33%
2025-02-03 17:59:19,862 - INFO - Epoch 318: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:59:19,864 - INFO - ####################Training epoch 319####################
2025-02-03 17:59:20,153 - INFO - Epoch 319: train_loss=0.8391
2025-02-03 17:59:20,628 - INFO - Epoch 319: val_loss=2.5493, val_acc=33.33%
2025-02-03 17:59:20,631 - INFO - Epoch 319: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:59:20,634 - INFO - ####################Training epoch 320####################
2025-02-03 17:59:20,925 - INFO - Epoch 320: train_loss=0.8362
2025-02-03 17:59:21,397 - INFO - Epoch 320: val_loss=2.5535, val_acc=33.33%
2025-02-03 17:59:21,400 - INFO - Epoch 320: EPOCH_AVG_TRAIN_LOSS=0.8362
2025-02-03 17:59:21,402 - INFO - ####################Training epoch 321####################
2025-02-03 17:59:21,690 - INFO - Epoch 321: train_loss=0.8389
2025-02-03 17:59:22,162 - INFO - Epoch 321: val_loss=2.5432, val_acc=33.33%
2025-02-03 17:59:22,166 - INFO - Epoch 321: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 17:59:22,168 - INFO - ####################Training epoch 322####################
2025-02-03 17:59:22,589 - INFO - Epoch 322: train_loss=0.8367
2025-02-03 17:59:23,060 - INFO - Epoch 322: val_loss=2.5543, val_acc=33.33%
2025-02-03 17:59:23,064 - INFO - Epoch 322: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 17:59:23,066 - INFO - ####################Training epoch 323####################
2025-02-03 17:59:23,356 - INFO - Epoch 323: train_loss=0.8399
2025-02-03 17:59:23,826 - INFO - Epoch 323: val_loss=2.5533, val_acc=33.33%
2025-02-03 17:59:23,830 - INFO - Epoch 323: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 17:59:23,832 - INFO - ####################Training epoch 324####################
2025-02-03 17:59:24,122 - INFO - Epoch 324: train_loss=0.8376
2025-02-03 17:59:24,591 - INFO - Epoch 324: val_loss=2.5531, val_acc=33.33%
2025-02-03 17:59:24,594 - INFO - Epoch 324: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 17:59:24,597 - INFO - ####################Training epoch 325####################
2025-02-03 17:59:24,884 - INFO - Epoch 325: train_loss=0.8404
2025-02-03 17:59:25,355 - INFO - Epoch 325: val_loss=2.5532, val_acc=33.33%
2025-02-03 17:59:25,358 - INFO - Epoch 325: EPOCH_AVG_TRAIN_LOSS=0.8404
2025-02-03 17:59:25,361 - INFO - ####################Training epoch 326####################
2025-02-03 17:59:25,649 - INFO - Epoch 326: train_loss=0.8392
2025-02-03 17:59:26,118 - INFO - Epoch 326: val_loss=2.5507, val_acc=33.33%
2025-02-03 17:59:26,121 - INFO - Epoch 326: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 17:59:26,123 - INFO - ####################Training epoch 327####################
2025-02-03 17:59:26,412 - INFO - Epoch 327: train_loss=0.8375
2025-02-03 17:59:26,882 - INFO - Epoch 327: val_loss=2.5490, val_acc=33.33%
2025-02-03 17:59:26,885 - INFO - Epoch 327: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 17:59:26,888 - INFO - ####################Training epoch 328####################
2025-02-03 17:59:27,174 - INFO - Epoch 328: train_loss=0.8389
2025-02-03 17:59:27,644 - INFO - Epoch 328: val_loss=2.5561, val_acc=33.33%
2025-02-03 17:59:27,647 - INFO - Epoch 328: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 17:59:27,650 - INFO - ####################Training epoch 329####################
2025-02-03 17:59:27,967 - INFO - Epoch 329: train_loss=0.8371
2025-02-03 17:59:28,436 - INFO - Epoch 329: val_loss=2.5500, val_acc=33.33%
2025-02-03 17:59:28,439 - INFO - Epoch 329: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 17:59:28,442 - INFO - ####################Training epoch 330####################
2025-02-03 17:59:28,731 - INFO - Epoch 330: train_loss=0.8395
2025-02-03 17:59:29,199 - INFO - Epoch 330: val_loss=2.5559, val_acc=33.33%
2025-02-03 17:59:29,202 - INFO - Epoch 330: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 17:59:29,205 - INFO - ####################Training epoch 331####################
2025-02-03 17:59:29,490 - INFO - Epoch 331: train_loss=0.8366
2025-02-03 17:59:29,960 - INFO - Epoch 331: val_loss=2.5504, val_acc=33.33%
2025-02-03 17:59:29,963 - INFO - Epoch 331: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 17:59:29,966 - INFO - ####################Training epoch 332####################
2025-02-03 17:59:30,255 - INFO - Epoch 332: train_loss=0.8380
2025-02-03 17:59:30,725 - INFO - Epoch 332: val_loss=2.5518, val_acc=33.33%
2025-02-03 17:59:30,729 - INFO - Epoch 332: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 17:59:30,731 - INFO - ####################Training epoch 333####################
2025-02-03 17:59:31,022 - INFO - Epoch 333: train_loss=0.8383
2025-02-03 17:59:31,496 - INFO - Epoch 333: val_loss=2.5551, val_acc=33.33%
2025-02-03 17:59:31,500 - INFO - Epoch 333: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 17:59:31,502 - INFO - ####################Training epoch 334####################
2025-02-03 17:59:31,791 - INFO - Epoch 334: train_loss=0.8386
2025-02-03 17:59:32,261 - INFO - Epoch 334: val_loss=2.5545, val_acc=33.33%
2025-02-03 17:59:32,265 - INFO - Epoch 334: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 17:59:32,267 - INFO - ####################Training epoch 335####################
2025-02-03 17:59:32,554 - INFO - Epoch 335: train_loss=0.8380
2025-02-03 17:59:33,027 - INFO - Epoch 335: val_loss=2.5543, val_acc=33.33%
2025-02-03 17:59:33,031 - INFO - Epoch 335: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 17:59:33,033 - INFO - ####################Training epoch 336####################
2025-02-03 17:59:33,321 - INFO - Epoch 336: train_loss=0.8381
2025-02-03 17:59:33,794 - INFO - Epoch 336: val_loss=2.5553, val_acc=33.33%
2025-02-03 17:59:33,798 - INFO - Epoch 336: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 17:59:33,800 - INFO - ####################Training epoch 337####################
2025-02-03 17:59:34,091 - INFO - Epoch 337: train_loss=0.8392
2025-02-03 17:59:34,563 - INFO - Epoch 337: val_loss=2.5479, val_acc=33.33%
2025-02-03 17:59:34,567 - INFO - Epoch 337: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 17:59:34,569 - INFO - ####################Training epoch 338####################
2025-02-03 17:59:34,859 - INFO - Epoch 338: train_loss=0.8402
2025-02-03 17:59:35,328 - INFO - Epoch 338: val_loss=2.5541, val_acc=33.33%
2025-02-03 17:59:35,331 - INFO - Epoch 338: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:59:35,334 - INFO - ####################Training epoch 339####################
2025-02-03 17:59:35,627 - INFO - Epoch 339: train_loss=0.8407
2025-02-03 17:59:36,121 - INFO - Epoch 339: val_loss=2.5455, val_acc=33.33%
2025-02-03 17:59:36,125 - INFO - Epoch 339: EPOCH_AVG_TRAIN_LOSS=0.8407
2025-02-03 17:59:36,127 - INFO - ####################Training epoch 340####################
2025-02-03 17:59:36,437 - INFO - Epoch 340: train_loss=0.8382
2025-02-03 17:59:36,908 - INFO - Epoch 340: val_loss=2.5540, val_acc=33.33%
2025-02-03 17:59:36,911 - INFO - Epoch 340: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 17:59:36,913 - INFO - ####################Training epoch 341####################
2025-02-03 17:59:37,208 - INFO - Epoch 341: train_loss=0.8398
2025-02-03 17:59:37,678 - INFO - Epoch 341: val_loss=2.5477, val_acc=33.33%
2025-02-03 17:59:37,682 - INFO - Epoch 341: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 17:59:37,685 - INFO - ####################Training epoch 342####################
2025-02-03 17:59:37,976 - INFO - Epoch 342: train_loss=0.8397
2025-02-03 17:59:38,445 - INFO - Epoch 342: val_loss=2.5599, val_acc=33.33%
2025-02-03 17:59:38,448 - INFO - Epoch 342: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 17:59:38,451 - INFO - ####################Training epoch 343####################
2025-02-03 17:59:38,743 - INFO - Epoch 343: train_loss=0.8391
2025-02-03 17:59:39,216 - INFO - Epoch 343: val_loss=2.5518, val_acc=33.33%
2025-02-03 17:59:39,219 - INFO - Epoch 343: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:59:39,222 - INFO - ####################Training epoch 344####################
2025-02-03 17:59:39,513 - INFO - Epoch 344: train_loss=0.8376
2025-02-03 17:59:39,987 - INFO - Epoch 344: val_loss=2.5595, val_acc=33.33%
2025-02-03 17:59:39,991 - INFO - Epoch 344: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 17:59:39,993 - INFO - ####################Training epoch 345####################
2025-02-03 17:59:40,285 - INFO - Epoch 345: train_loss=0.8393
2025-02-03 17:59:40,758 - INFO - Epoch 345: val_loss=2.5504, val_acc=33.33%
2025-02-03 17:59:40,762 - INFO - Epoch 345: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 17:59:40,764 - INFO - ####################Training epoch 346####################
2025-02-03 17:59:41,053 - INFO - Epoch 346: train_loss=0.8389
2025-02-03 17:59:41,528 - INFO - Epoch 346: val_loss=2.5479, val_acc=33.33%
2025-02-03 17:59:41,532 - INFO - Epoch 346: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 17:59:41,534 - INFO - ####################Training epoch 347####################
2025-02-03 17:59:41,826 - INFO - Epoch 347: train_loss=0.8381
2025-02-03 17:59:42,302 - INFO - Epoch 347: val_loss=2.5560, val_acc=33.33%
2025-02-03 17:59:42,306 - INFO - Epoch 347: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 17:59:42,308 - INFO - ####################Training epoch 348####################
2025-02-03 17:59:42,602 - INFO - Epoch 348: train_loss=0.8387
2025-02-03 17:59:43,075 - INFO - Epoch 348: val_loss=2.5540, val_acc=33.33%
2025-02-03 17:59:43,078 - INFO - Epoch 348: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 17:59:43,081 - INFO - ####################Training epoch 349####################
2025-02-03 17:59:43,369 - INFO - Epoch 349: train_loss=0.8371
2025-02-03 17:59:43,845 - INFO - Epoch 349: val_loss=2.5530, val_acc=33.33%
2025-02-03 17:59:43,849 - INFO - Epoch 349: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 17:59:43,851 - INFO - ####################Training epoch 350####################
2025-02-03 17:59:44,144 - INFO - Epoch 350: train_loss=0.8389
2025-02-03 17:59:44,663 - INFO - Epoch 350: val_loss=2.5541, val_acc=33.33%
2025-02-03 17:59:44,667 - INFO - Epoch 350: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 17:59:44,669 - INFO - ####################Training epoch 351####################
2025-02-03 17:59:44,971 - INFO - Epoch 351: train_loss=0.8368
2025-02-03 17:59:45,448 - INFO - Epoch 351: val_loss=2.5537, val_acc=33.33%
2025-02-03 17:59:45,451 - INFO - Epoch 351: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 17:59:45,454 - INFO - ####################Training epoch 352####################
2025-02-03 17:59:45,746 - INFO - Epoch 352: train_loss=0.8380
2025-02-03 17:59:46,223 - INFO - Epoch 352: val_loss=2.5583, val_acc=33.33%
2025-02-03 17:59:46,226 - INFO - Epoch 352: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 17:59:46,229 - INFO - ####################Training epoch 353####################
2025-02-03 17:59:46,520 - INFO - Epoch 353: train_loss=0.8405
2025-02-03 17:59:46,991 - INFO - Epoch 353: val_loss=2.5508, val_acc=33.33%
2025-02-03 17:59:46,995 - INFO - Epoch 353: EPOCH_AVG_TRAIN_LOSS=0.8405
2025-02-03 17:59:46,997 - INFO - ####################Training epoch 354####################
2025-02-03 17:59:47,289 - INFO - Epoch 354: train_loss=0.8410
2025-02-03 17:59:47,760 - INFO - Epoch 354: val_loss=2.5475, val_acc=33.33%
2025-02-03 17:59:47,764 - INFO - Epoch 354: EPOCH_AVG_TRAIN_LOSS=0.8410
2025-02-03 17:59:47,766 - INFO - ####################Training epoch 355####################
2025-02-03 17:59:48,060 - INFO - Epoch 355: train_loss=0.8405
2025-02-03 17:59:48,542 - INFO - Epoch 355: val_loss=2.5532, val_acc=33.33%
2025-02-03 17:59:48,546 - INFO - Epoch 355: EPOCH_AVG_TRAIN_LOSS=0.8405
2025-02-03 17:59:48,548 - INFO - ####################Training epoch 356####################
2025-02-03 17:59:48,841 - INFO - Epoch 356: train_loss=0.8373
2025-02-03 17:59:49,316 - INFO - Epoch 356: val_loss=2.5542, val_acc=33.33%
2025-02-03 17:59:49,319 - INFO - Epoch 356: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 17:59:49,322 - INFO - ####################Training epoch 357####################
2025-02-03 17:59:49,613 - INFO - Epoch 357: train_loss=0.8367
2025-02-03 17:59:50,086 - INFO - Epoch 357: val_loss=2.5525, val_acc=33.33%
2025-02-03 17:59:50,090 - INFO - Epoch 357: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 17:59:50,092 - INFO - ####################Training epoch 358####################
2025-02-03 17:59:50,384 - INFO - Epoch 358: train_loss=0.8369
2025-02-03 17:59:50,862 - INFO - Epoch 358: val_loss=2.5547, val_acc=33.33%
2025-02-03 17:59:50,866 - INFO - Epoch 358: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 17:59:50,868 - INFO - ####################Training epoch 359####################
2025-02-03 17:59:51,160 - INFO - Epoch 359: train_loss=0.8388
2025-02-03 17:59:51,634 - INFO - Epoch 359: val_loss=2.5556, val_acc=33.33%
2025-02-03 17:59:51,637 - INFO - Epoch 359: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 17:59:51,640 - INFO - ####################Training epoch 360####################
2025-02-03 17:59:51,927 - INFO - Epoch 360: train_loss=0.8380
2025-02-03 17:59:52,399 - INFO - Epoch 360: val_loss=2.5511, val_acc=33.33%
2025-02-03 17:59:52,402 - INFO - Epoch 360: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 17:59:52,405 - INFO - ####################Training epoch 361####################
2025-02-03 17:59:52,692 - INFO - Epoch 361: train_loss=0.8400
2025-02-03 17:59:53,188 - INFO - Epoch 361: val_loss=2.5494, val_acc=33.33%
2025-02-03 17:59:53,191 - INFO - Epoch 361: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 17:59:53,194 - INFO - ####################Training epoch 362####################
2025-02-03 17:59:53,502 - INFO - Epoch 362: train_loss=0.8371
2025-02-03 17:59:53,973 - INFO - Epoch 362: val_loss=2.5515, val_acc=33.33%
2025-02-03 17:59:53,976 - INFO - Epoch 362: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 17:59:53,979 - INFO - ####################Training epoch 363####################
2025-02-03 17:59:54,267 - INFO - Epoch 363: train_loss=0.8392
2025-02-03 17:59:54,738 - INFO - Epoch 363: val_loss=2.5559, val_acc=33.33%
2025-02-03 17:59:54,742 - INFO - Epoch 363: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 17:59:54,744 - INFO - ####################Training epoch 364####################
2025-02-03 17:59:55,034 - INFO - Epoch 364: train_loss=0.8391
2025-02-03 17:59:55,506 - INFO - Epoch 364: val_loss=2.5513, val_acc=33.33%
2025-02-03 17:59:55,510 - INFO - Epoch 364: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 17:59:55,512 - INFO - ####################Training epoch 365####################
2025-02-03 17:59:55,803 - INFO - Epoch 365: train_loss=0.8393
2025-02-03 17:59:56,275 - INFO - Epoch 365: val_loss=2.5542, val_acc=33.33%
2025-02-03 17:59:56,278 - INFO - Epoch 365: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 17:59:56,281 - INFO - ####################Training epoch 366####################
2025-02-03 17:59:56,573 - INFO - Epoch 366: train_loss=0.8402
2025-02-03 17:59:57,043 - INFO - Epoch 366: val_loss=2.5520, val_acc=33.33%
2025-02-03 17:59:57,047 - INFO - Epoch 366: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:59:57,049 - INFO - ####################Training epoch 367####################
2025-02-03 17:59:57,339 - INFO - Epoch 367: train_loss=0.8375
2025-02-03 17:59:57,811 - INFO - Epoch 367: val_loss=2.5496, val_acc=33.33%
2025-02-03 17:59:57,814 - INFO - Epoch 367: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 17:59:57,816 - INFO - ####################Training epoch 368####################
2025-02-03 17:59:58,109 - INFO - Epoch 368: train_loss=0.8390
2025-02-03 17:59:58,583 - INFO - Epoch 368: val_loss=2.5528, val_acc=33.33%
2025-02-03 17:59:58,587 - INFO - Epoch 368: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 17:59:58,589 - INFO - ####################Training epoch 369####################
2025-02-03 17:59:58,881 - INFO - Epoch 369: train_loss=0.8402
2025-02-03 17:59:59,358 - INFO - Epoch 369: val_loss=2.5474, val_acc=33.33%
2025-02-03 17:59:59,362 - INFO - Epoch 369: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 17:59:59,364 - INFO - ####################Training epoch 370####################
2025-02-03 17:59:59,653 - INFO - Epoch 370: train_loss=0.8409
2025-02-03 18:00:00,126 - INFO - Epoch 370: val_loss=2.5561, val_acc=33.33%
2025-02-03 18:00:00,129 - INFO - Epoch 370: EPOCH_AVG_TRAIN_LOSS=0.8409
2025-02-03 18:00:00,132 - INFO - ####################Training epoch 371####################
2025-02-03 18:00:00,422 - INFO - Epoch 371: train_loss=0.8388
2025-02-03 18:00:00,892 - INFO - Epoch 371: val_loss=2.5500, val_acc=33.33%
2025-02-03 18:00:00,895 - INFO - Epoch 371: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:00:00,898 - INFO - ####################Training epoch 372####################
2025-02-03 18:00:01,188 - INFO - Epoch 372: train_loss=0.8361
2025-02-03 18:00:01,686 - INFO - Epoch 372: val_loss=2.5500, val_acc=33.33%
2025-02-03 18:00:01,690 - INFO - Epoch 372: EPOCH_AVG_TRAIN_LOSS=0.8361
2025-02-03 18:00:01,692 - INFO - ####################Training epoch 373####################
2025-02-03 18:00:01,983 - INFO - Epoch 373: train_loss=0.8393
2025-02-03 18:00:02,456 - INFO - Epoch 373: val_loss=2.5543, val_acc=33.33%
2025-02-03 18:00:02,459 - INFO - Epoch 373: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:00:02,462 - INFO - ####################Training epoch 374####################
2025-02-03 18:00:02,754 - INFO - Epoch 374: train_loss=0.8393
2025-02-03 18:00:03,228 - INFO - Epoch 374: val_loss=2.5509, val_acc=33.33%
2025-02-03 18:00:03,231 - INFO - Epoch 374: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:00:03,233 - INFO - ####################Training epoch 375####################
2025-02-03 18:00:03,524 - INFO - Epoch 375: train_loss=0.8408
2025-02-03 18:00:03,996 - INFO - Epoch 375: val_loss=2.5495, val_acc=33.33%
2025-02-03 18:00:03,999 - INFO - Epoch 375: EPOCH_AVG_TRAIN_LOSS=0.8408
2025-02-03 18:00:04,002 - INFO - ####################Training epoch 376####################
2025-02-03 18:00:04,291 - INFO - Epoch 376: train_loss=0.8387
2025-02-03 18:00:04,764 - INFO - Epoch 376: val_loss=2.5497, val_acc=33.33%
2025-02-03 18:00:04,768 - INFO - Epoch 376: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:00:04,770 - INFO - ####################Training epoch 377####################
2025-02-03 18:00:05,058 - INFO - Epoch 377: train_loss=0.8387
2025-02-03 18:00:05,529 - INFO - Epoch 377: val_loss=2.5592, val_acc=33.33%
2025-02-03 18:00:05,532 - INFO - Epoch 377: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:00:05,535 - INFO - ####################Training epoch 378####################
2025-02-03 18:00:05,824 - INFO - Epoch 378: train_loss=0.8411
2025-02-03 18:00:06,296 - INFO - Epoch 378: val_loss=2.5551, val_acc=33.33%
2025-02-03 18:00:06,300 - INFO - Epoch 378: EPOCH_AVG_TRAIN_LOSS=0.8411
2025-02-03 18:00:06,302 - INFO - ####################Training epoch 379####################
2025-02-03 18:00:06,591 - INFO - Epoch 379: train_loss=0.8424
2025-02-03 18:00:07,062 - INFO - Epoch 379: val_loss=2.5541, val_acc=33.33%
2025-02-03 18:00:07,066 - INFO - Epoch 379: EPOCH_AVG_TRAIN_LOSS=0.8424
2025-02-03 18:00:07,068 - INFO - ####################Training epoch 380####################
2025-02-03 18:00:07,362 - INFO - Epoch 380: train_loss=0.8381
2025-02-03 18:00:07,837 - INFO - Epoch 380: val_loss=2.5488, val_acc=33.33%
2025-02-03 18:00:07,841 - INFO - Epoch 380: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:00:07,843 - INFO - ####################Training epoch 381####################
2025-02-03 18:00:08,134 - INFO - Epoch 381: train_loss=0.8381
2025-02-03 18:00:08,607 - INFO - Epoch 381: val_loss=2.5471, val_acc=33.33%
2025-02-03 18:00:08,610 - INFO - Epoch 381: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:00:08,613 - INFO - ####################Training epoch 382####################
2025-02-03 18:00:08,903 - INFO - Epoch 382: train_loss=0.8381
2025-02-03 18:00:09,391 - INFO - Epoch 382: val_loss=2.5565, val_acc=33.33%
2025-02-03 18:00:09,395 - INFO - Epoch 382: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:00:09,398 - INFO - ####################Training epoch 383####################
2025-02-03 18:00:09,689 - INFO - Epoch 383: train_loss=0.8379
2025-02-03 18:00:10,198 - INFO - Epoch 383: val_loss=2.5537, val_acc=33.33%
2025-02-03 18:00:10,201 - INFO - Epoch 383: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:00:10,203 - INFO - ####################Training epoch 384####################
2025-02-03 18:00:10,489 - INFO - Epoch 384: train_loss=0.8392
2025-02-03 18:00:10,959 - INFO - Epoch 384: val_loss=2.5472, val_acc=33.33%
2025-02-03 18:00:10,963 - INFO - Epoch 384: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:00:10,965 - INFO - ####################Training epoch 385####################
2025-02-03 18:00:11,257 - INFO - Epoch 385: train_loss=0.8375
2025-02-03 18:00:11,730 - INFO - Epoch 385: val_loss=2.5537, val_acc=33.33%
2025-02-03 18:00:11,734 - INFO - Epoch 385: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:00:11,736 - INFO - ####################Training epoch 386####################
2025-02-03 18:00:12,028 - INFO - Epoch 386: train_loss=0.8381
2025-02-03 18:00:12,506 - INFO - Epoch 386: val_loss=2.5519, val_acc=33.33%
2025-02-03 18:00:12,510 - INFO - Epoch 386: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:00:12,513 - INFO - ####################Training epoch 387####################
2025-02-03 18:00:12,810 - INFO - Epoch 387: train_loss=0.8392
2025-02-03 18:00:13,280 - INFO - Epoch 387: val_loss=2.5517, val_acc=33.33%
2025-02-03 18:00:13,284 - INFO - Epoch 387: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:00:13,286 - INFO - ####################Training epoch 388####################
2025-02-03 18:00:13,575 - INFO - Epoch 388: train_loss=0.8376
2025-02-03 18:00:14,051 - INFO - Epoch 388: val_loss=2.5507, val_acc=33.33%
2025-02-03 18:00:14,054 - INFO - Epoch 388: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:00:14,057 - INFO - ####################Training epoch 389####################
2025-02-03 18:00:14,349 - INFO - Epoch 389: train_loss=0.8393
2025-02-03 18:00:14,825 - INFO - Epoch 389: val_loss=2.5544, val_acc=33.33%
2025-02-03 18:00:14,829 - INFO - Epoch 389: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:00:14,831 - INFO - ####################Training epoch 390####################
2025-02-03 18:00:15,122 - INFO - Epoch 390: train_loss=0.8396
2025-02-03 18:00:15,597 - INFO - Epoch 390: val_loss=2.5555, val_acc=33.33%
2025-02-03 18:00:15,601 - INFO - Epoch 390: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:00:15,603 - INFO - ####################Training epoch 391####################
2025-02-03 18:00:15,903 - INFO - Epoch 391: train_loss=0.8379
2025-02-03 18:00:16,378 - INFO - Epoch 391: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:00:16,382 - INFO - Epoch 391: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:00:16,384 - INFO - ####################Training epoch 392####################
2025-02-03 18:00:16,677 - INFO - Epoch 392: train_loss=0.8386
2025-02-03 18:00:17,158 - INFO - Epoch 392: val_loss=2.5484, val_acc=33.33%
2025-02-03 18:00:17,162 - INFO - Epoch 392: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:00:17,164 - INFO - ####################Training epoch 393####################
2025-02-03 18:00:17,458 - INFO - Epoch 393: train_loss=0.8391
2025-02-03 18:00:17,935 - INFO - Epoch 393: val_loss=2.5535, val_acc=33.33%
2025-02-03 18:00:17,939 - INFO - Epoch 393: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:00:17,942 - INFO - ####################Training epoch 394####################
2025-02-03 18:00:18,238 - INFO - Epoch 394: train_loss=0.8387
2025-02-03 18:00:18,763 - INFO - Epoch 394: val_loss=2.5529, val_acc=33.33%
2025-02-03 18:00:18,767 - INFO - Epoch 394: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:00:18,770 - INFO - ####################Training epoch 395####################
2025-02-03 18:00:19,090 - INFO - Epoch 395: train_loss=0.8379
2025-02-03 18:00:19,577 - INFO - Epoch 395: val_loss=2.5563, val_acc=33.33%
2025-02-03 18:00:19,581 - INFO - Epoch 395: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:00:19,583 - INFO - ####################Training epoch 396####################
2025-02-03 18:00:19,881 - INFO - Epoch 396: train_loss=0.8397
2025-02-03 18:00:20,369 - INFO - Epoch 396: val_loss=2.5560, val_acc=33.33%
2025-02-03 18:00:20,373 - INFO - Epoch 396: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 18:00:20,375 - INFO - ####################Training epoch 397####################
2025-02-03 18:00:20,668 - INFO - Epoch 397: train_loss=0.8379
2025-02-03 18:00:21,144 - INFO - Epoch 397: val_loss=2.5548, val_acc=33.33%
2025-02-03 18:00:21,148 - INFO - Epoch 397: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:00:21,151 - INFO - ####################Training epoch 398####################
2025-02-03 18:00:21,451 - INFO - Epoch 398: train_loss=0.8376
2025-02-03 18:00:21,931 - INFO - Epoch 398: val_loss=2.5556, val_acc=33.33%
2025-02-03 18:00:21,935 - INFO - Epoch 398: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:00:21,937 - INFO - ####################Training epoch 399####################
2025-02-03 18:00:22,230 - INFO - Epoch 399: train_loss=0.8377
2025-02-03 18:00:22,705 - INFO - Epoch 399: val_loss=2.5549, val_acc=33.33%
2025-02-03 18:00:22,709 - INFO - Epoch 399: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:00:22,711 - INFO - ####################Training epoch 400####################
2025-02-03 18:00:23,003 - INFO - Epoch 400: train_loss=0.8384
2025-02-03 18:00:23,481 - INFO - Epoch 400: val_loss=2.5481, val_acc=33.33%
2025-02-03 18:00:23,485 - INFO - Epoch 400: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:00:23,487 - INFO - ####################Training epoch 401####################
2025-02-03 18:00:23,774 - INFO - Epoch 401: train_loss=0.8394
2025-02-03 18:00:24,248 - INFO - Epoch 401: val_loss=2.5451, val_acc=33.33%
2025-02-03 18:00:24,251 - INFO - Epoch 401: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:00:24,254 - INFO - ####################Training epoch 402####################
2025-02-03 18:00:24,549 - INFO - Epoch 402: train_loss=0.8374
2025-02-03 18:00:25,020 - INFO - Epoch 402: val_loss=2.5550, val_acc=33.33%
2025-02-03 18:00:25,024 - INFO - Epoch 402: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:00:25,026 - INFO - ####################Training epoch 403####################
2025-02-03 18:00:25,318 - INFO - Epoch 403: train_loss=0.8371
2025-02-03 18:00:25,792 - INFO - Epoch 403: val_loss=2.5476, val_acc=33.33%
2025-02-03 18:00:25,796 - INFO - Epoch 403: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:00:25,799 - INFO - ####################Training epoch 404####################
2025-02-03 18:00:26,092 - INFO - Epoch 404: train_loss=0.8403
2025-02-03 18:00:26,567 - INFO - Epoch 404: val_loss=2.5584, val_acc=33.33%
2025-02-03 18:00:26,570 - INFO - Epoch 404: EPOCH_AVG_TRAIN_LOSS=0.8403
2025-02-03 18:00:26,573 - INFO - ####################Training epoch 405####################
2025-02-03 18:00:26,870 - INFO - Epoch 405: train_loss=0.8368
2025-02-03 18:00:27,400 - INFO - Epoch 405: val_loss=2.5535, val_acc=33.33%
2025-02-03 18:00:27,404 - INFO - Epoch 405: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:00:27,407 - INFO - ####################Training epoch 406####################
2025-02-03 18:00:27,699 - INFO - Epoch 406: train_loss=0.8390
2025-02-03 18:00:28,179 - INFO - Epoch 406: val_loss=2.5521, val_acc=33.33%
2025-02-03 18:00:28,183 - INFO - Epoch 406: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:00:28,186 - INFO - ####################Training epoch 407####################
2025-02-03 18:00:28,483 - INFO - Epoch 407: train_loss=0.8424
2025-02-03 18:00:28,959 - INFO - Epoch 407: val_loss=2.5504, val_acc=33.33%
2025-02-03 18:00:28,963 - INFO - Epoch 407: EPOCH_AVG_TRAIN_LOSS=0.8424
2025-02-03 18:00:28,965 - INFO - ####################Training epoch 408####################
2025-02-03 18:00:29,264 - INFO - Epoch 408: train_loss=0.8374
2025-02-03 18:00:29,734 - INFO - Epoch 408: val_loss=2.5510, val_acc=33.33%
2025-02-03 18:00:29,738 - INFO - Epoch 408: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:00:29,741 - INFO - ####################Training epoch 409####################
2025-02-03 18:00:30,032 - INFO - Epoch 409: train_loss=0.8383
2025-02-03 18:00:30,503 - INFO - Epoch 409: val_loss=2.5479, val_acc=33.33%
2025-02-03 18:00:30,507 - INFO - Epoch 409: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:00:30,509 - INFO - ####################Training epoch 410####################
2025-02-03 18:00:30,798 - INFO - Epoch 410: train_loss=0.8377
2025-02-03 18:00:31,273 - INFO - Epoch 410: val_loss=2.5537, val_acc=33.33%
2025-02-03 18:00:31,277 - INFO - Epoch 410: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:00:31,279 - INFO - ####################Training epoch 411####################
2025-02-03 18:00:31,570 - INFO - Epoch 411: train_loss=0.8371
2025-02-03 18:00:32,046 - INFO - Epoch 411: val_loss=2.5505, val_acc=33.33%
2025-02-03 18:00:32,050 - INFO - Epoch 411: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:00:32,053 - INFO - ####################Training epoch 412####################
2025-02-03 18:00:32,347 - INFO - Epoch 412: train_loss=0.8368
2025-02-03 18:00:32,821 - INFO - Epoch 412: val_loss=2.5473, val_acc=33.33%
2025-02-03 18:00:32,824 - INFO - Epoch 412: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:00:32,827 - INFO - ####################Training epoch 413####################
2025-02-03 18:00:33,122 - INFO - Epoch 413: train_loss=0.8392
2025-02-03 18:00:33,598 - INFO - Epoch 413: val_loss=2.5513, val_acc=33.33%
2025-02-03 18:00:33,602 - INFO - Epoch 413: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:00:33,604 - INFO - ####################Training epoch 414####################
2025-02-03 18:00:33,899 - INFO - Epoch 414: train_loss=0.8406
2025-02-03 18:00:34,371 - INFO - Epoch 414: val_loss=2.5509, val_acc=33.33%
2025-02-03 18:00:34,374 - INFO - Epoch 414: EPOCH_AVG_TRAIN_LOSS=0.8406
2025-02-03 18:00:34,377 - INFO - ####################Training epoch 415####################
2025-02-03 18:00:34,666 - INFO - Epoch 415: train_loss=0.8389
2025-02-03 18:00:35,139 - INFO - Epoch 415: val_loss=2.5551, val_acc=33.33%
2025-02-03 18:00:35,143 - INFO - Epoch 415: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:00:35,145 - INFO - ####################Training epoch 416####################
2025-02-03 18:00:35,439 - INFO - Epoch 416: train_loss=0.8392
2025-02-03 18:00:35,923 - INFO - Epoch 416: val_loss=2.5551, val_acc=33.33%
2025-02-03 18:00:35,926 - INFO - Epoch 416: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:00:35,929 - INFO - ####################Training epoch 417####################
2025-02-03 18:00:36,218 - INFO - Epoch 417: train_loss=0.8394
2025-02-03 18:00:36,689 - INFO - Epoch 417: val_loss=2.5543, val_acc=33.33%
2025-02-03 18:00:36,692 - INFO - Epoch 417: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:00:36,695 - INFO - ####################Training epoch 418####################
2025-02-03 18:00:36,987 - INFO - Epoch 418: train_loss=0.8381
2025-02-03 18:00:37,461 - INFO - Epoch 418: val_loss=2.5501, val_acc=33.33%
2025-02-03 18:00:37,465 - INFO - Epoch 418: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:00:37,467 - INFO - ####################Training epoch 419####################
2025-02-03 18:00:37,762 - INFO - Epoch 419: train_loss=0.8386
2025-02-03 18:00:38,237 - INFO - Epoch 419: val_loss=2.5519, val_acc=33.33%
2025-02-03 18:00:38,241 - INFO - Epoch 419: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:00:38,243 - INFO - ####################Training epoch 420####################
2025-02-03 18:00:38,533 - INFO - Epoch 420: train_loss=0.8399
2025-02-03 18:00:39,010 - INFO - Epoch 420: val_loss=2.5514, val_acc=33.33%
2025-02-03 18:00:39,016 - INFO - Epoch 420: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 18:00:39,019 - INFO - ####################Training epoch 421####################
2025-02-03 18:00:39,324 - INFO - Epoch 421: train_loss=0.8389
2025-02-03 18:00:39,808 - INFO - Epoch 421: val_loss=2.5508, val_acc=33.33%
2025-02-03 18:00:39,812 - INFO - Epoch 421: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:00:39,815 - INFO - ####################Training epoch 422####################
2025-02-03 18:00:40,104 - INFO - Epoch 422: train_loss=0.8391
2025-02-03 18:00:40,582 - INFO - Epoch 422: val_loss=2.5498, val_acc=33.33%
2025-02-03 18:00:40,585 - INFO - Epoch 422: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:00:40,588 - INFO - ####################Training epoch 423####################
2025-02-03 18:00:40,883 - INFO - Epoch 423: train_loss=0.8382
2025-02-03 18:00:41,359 - INFO - Epoch 423: val_loss=2.5517, val_acc=33.33%
2025-02-03 18:00:41,363 - INFO - Epoch 423: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:00:41,365 - INFO - ####################Training epoch 424####################
2025-02-03 18:00:41,655 - INFO - Epoch 424: train_loss=0.8368
2025-02-03 18:00:42,129 - INFO - Epoch 424: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:00:42,133 - INFO - Epoch 424: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:00:42,135 - INFO - ####################Training epoch 425####################
2025-02-03 18:00:42,426 - INFO - Epoch 425: train_loss=0.8385
2025-02-03 18:00:42,902 - INFO - Epoch 425: val_loss=2.5551, val_acc=33.33%
2025-02-03 18:00:42,906 - INFO - Epoch 425: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:00:42,909 - INFO - ####################Training epoch 426####################
2025-02-03 18:00:43,202 - INFO - Epoch 426: train_loss=0.8389
2025-02-03 18:00:43,675 - INFO - Epoch 426: val_loss=2.5545, val_acc=33.33%
2025-02-03 18:00:43,679 - INFO - Epoch 426: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:00:43,681 - INFO - ####################Training epoch 427####################
2025-02-03 18:00:43,974 - INFO - Epoch 427: train_loss=0.8376
2025-02-03 18:00:44,478 - INFO - Epoch 427: val_loss=2.5506, val_acc=33.33%
2025-02-03 18:00:44,482 - INFO - Epoch 427: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:00:44,484 - INFO - ####################Training epoch 428####################
2025-02-03 18:00:44,776 - INFO - Epoch 428: train_loss=0.8376
2025-02-03 18:00:45,250 - INFO - Epoch 428: val_loss=2.5512, val_acc=33.33%
2025-02-03 18:00:45,254 - INFO - Epoch 428: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:00:45,257 - INFO - ####################Training epoch 429####################
2025-02-03 18:00:45,556 - INFO - Epoch 429: train_loss=0.8378
2025-02-03 18:00:46,031 - INFO - Epoch 429: val_loss=2.5528, val_acc=33.33%
2025-02-03 18:00:46,035 - INFO - Epoch 429: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:00:46,037 - INFO - ####################Training epoch 430####################
2025-02-03 18:00:46,328 - INFO - Epoch 430: train_loss=0.8381
2025-02-03 18:00:46,801 - INFO - Epoch 430: val_loss=2.5515, val_acc=33.33%
2025-02-03 18:00:46,804 - INFO - Epoch 430: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:00:46,807 - INFO - ####################Training epoch 431####################
2025-02-03 18:00:47,102 - INFO - Epoch 431: train_loss=0.8368
2025-02-03 18:00:47,578 - INFO - Epoch 431: val_loss=2.5491, val_acc=33.33%
2025-02-03 18:00:47,581 - INFO - Epoch 431: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:00:47,584 - INFO - ####################Training epoch 432####################
2025-02-03 18:00:47,873 - INFO - Epoch 432: train_loss=0.8398
2025-02-03 18:00:48,346 - INFO - Epoch 432: val_loss=2.5527, val_acc=33.33%
2025-02-03 18:00:48,350 - INFO - Epoch 432: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:00:48,352 - INFO - ####################Training epoch 433####################
2025-02-03 18:00:48,643 - INFO - Epoch 433: train_loss=0.8398
2025-02-03 18:00:49,115 - INFO - Epoch 433: val_loss=2.5539, val_acc=33.33%
2025-02-03 18:00:49,119 - INFO - Epoch 433: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:00:49,121 - INFO - ####################Training epoch 434####################
2025-02-03 18:00:49,411 - INFO - Epoch 434: train_loss=0.8381
2025-02-03 18:00:49,883 - INFO - Epoch 434: val_loss=2.5572, val_acc=33.33%
2025-02-03 18:00:49,887 - INFO - Epoch 434: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:00:49,889 - INFO - ####################Training epoch 435####################
2025-02-03 18:00:50,181 - INFO - Epoch 435: train_loss=0.8398
2025-02-03 18:00:50,653 - INFO - Epoch 435: val_loss=2.5504, val_acc=33.33%
2025-02-03 18:00:50,656 - INFO - Epoch 435: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:00:50,659 - INFO - ####################Training epoch 436####################
2025-02-03 18:00:50,948 - INFO - Epoch 436: train_loss=0.8386
2025-02-03 18:00:51,419 - INFO - Epoch 436: val_loss=2.5556, val_acc=33.33%
2025-02-03 18:00:51,423 - INFO - Epoch 436: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:00:51,425 - INFO - ####################Training epoch 437####################
2025-02-03 18:00:51,717 - INFO - Epoch 437: train_loss=0.8393
2025-02-03 18:00:52,192 - INFO - Epoch 437: val_loss=2.5564, val_acc=33.33%
2025-02-03 18:00:52,195 - INFO - Epoch 437: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:00:52,198 - INFO - ####################Training epoch 438####################
2025-02-03 18:00:52,483 - INFO - Epoch 438: train_loss=0.8369
2025-02-03 18:00:52,979 - INFO - Epoch 438: val_loss=2.5506, val_acc=33.33%
2025-02-03 18:00:52,983 - INFO - Epoch 438: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:00:52,985 - INFO - ####################Training epoch 439####################
2025-02-03 18:00:53,274 - INFO - Epoch 439: train_loss=0.8360
2025-02-03 18:00:53,749 - INFO - Epoch 439: val_loss=2.5482, val_acc=33.33%
2025-02-03 18:00:53,753 - INFO - Epoch 439: EPOCH_AVG_TRAIN_LOSS=0.8360
2025-02-03 18:00:53,755 - INFO - ####################Training epoch 440####################
2025-02-03 18:00:54,045 - INFO - Epoch 440: train_loss=0.8383
2025-02-03 18:00:54,517 - INFO - Epoch 440: val_loss=2.5526, val_acc=33.33%
2025-02-03 18:00:54,521 - INFO - Epoch 440: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:00:54,523 - INFO - ####################Training epoch 441####################
2025-02-03 18:00:54,816 - INFO - Epoch 441: train_loss=0.8388
2025-02-03 18:00:55,292 - INFO - Epoch 441: val_loss=2.5533, val_acc=33.33%
2025-02-03 18:00:55,295 - INFO - Epoch 441: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:00:55,298 - INFO - ####################Training epoch 442####################
2025-02-03 18:00:55,589 - INFO - Epoch 442: train_loss=0.8370
2025-02-03 18:00:56,061 - INFO - Epoch 442: val_loss=2.5544, val_acc=33.33%
2025-02-03 18:00:56,064 - INFO - Epoch 442: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:00:56,067 - INFO - ####################Training epoch 443####################
2025-02-03 18:00:56,358 - INFO - Epoch 443: train_loss=0.8384
2025-02-03 18:00:56,829 - INFO - Epoch 443: val_loss=2.5559, val_acc=33.33%
2025-02-03 18:00:56,832 - INFO - Epoch 443: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:00:56,835 - INFO - ####################Training epoch 444####################
2025-02-03 18:00:57,126 - INFO - Epoch 444: train_loss=0.8398
2025-02-03 18:00:57,597 - INFO - Epoch 444: val_loss=2.5547, val_acc=33.33%
2025-02-03 18:00:57,600 - INFO - Epoch 444: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:00:57,603 - INFO - ####################Training epoch 445####################
2025-02-03 18:00:57,893 - INFO - Epoch 445: train_loss=0.8398
2025-02-03 18:00:58,365 - INFO - Epoch 445: val_loss=2.5540, val_acc=33.33%
2025-02-03 18:00:58,368 - INFO - Epoch 445: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:00:58,371 - INFO - ####################Training epoch 446####################
2025-02-03 18:00:58,662 - INFO - Epoch 446: train_loss=0.8382
2025-02-03 18:00:59,136 - INFO - Epoch 446: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:00:59,140 - INFO - Epoch 446: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:00:59,142 - INFO - ####################Training epoch 447####################
2025-02-03 18:00:59,436 - INFO - Epoch 447: train_loss=0.8381
2025-02-03 18:00:59,912 - INFO - Epoch 447: val_loss=2.5488, val_acc=33.33%
2025-02-03 18:00:59,916 - INFO - Epoch 447: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:00:59,918 - INFO - ####################Training epoch 448####################
2025-02-03 18:01:00,210 - INFO - Epoch 448: train_loss=0.8392
2025-02-03 18:01:00,686 - INFO - Epoch 448: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:01:00,690 - INFO - Epoch 448: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:01:00,692 - INFO - ####################Training epoch 449####################
2025-02-03 18:01:00,982 - INFO - Epoch 449: train_loss=0.8389
2025-02-03 18:01:01,492 - INFO - Epoch 449: val_loss=2.5510, val_acc=33.33%
2025-02-03 18:01:01,496 - INFO - Epoch 449: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:01:01,498 - INFO - ####################Training epoch 450####################
2025-02-03 18:01:01,785 - INFO - Epoch 450: train_loss=0.8390
2025-02-03 18:01:02,258 - INFO - Epoch 450: val_loss=2.5515, val_acc=33.33%
2025-02-03 18:01:02,262 - INFO - Epoch 450: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:01:02,264 - INFO - ####################Training epoch 451####################
2025-02-03 18:01:02,567 - INFO - Epoch 451: train_loss=0.8398
2025-02-03 18:01:03,042 - INFO - Epoch 451: val_loss=2.5512, val_acc=33.33%
2025-02-03 18:01:03,045 - INFO - Epoch 451: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:01:03,047 - INFO - ####################Training epoch 452####################
2025-02-03 18:01:03,340 - INFO - Epoch 452: train_loss=0.8389
2025-02-03 18:01:03,815 - INFO - Epoch 452: val_loss=2.5518, val_acc=33.33%
2025-02-03 18:01:03,819 - INFO - Epoch 452: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:01:03,821 - INFO - ####################Training epoch 453####################
2025-02-03 18:01:04,112 - INFO - Epoch 453: train_loss=0.8390
2025-02-03 18:01:04,581 - INFO - Epoch 453: val_loss=2.5586, val_acc=33.33%
2025-02-03 18:01:04,585 - INFO - Epoch 453: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:01:04,587 - INFO - ####################Training epoch 454####################
2025-02-03 18:01:04,876 - INFO - Epoch 454: train_loss=0.8367
2025-02-03 18:01:05,344 - INFO - Epoch 454: val_loss=2.5490, val_acc=33.33%
2025-02-03 18:01:05,348 - INFO - Epoch 454: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:01:05,350 - INFO - ####################Training epoch 455####################
2025-02-03 18:01:05,637 - INFO - Epoch 455: train_loss=0.8396
2025-02-03 18:01:06,106 - INFO - Epoch 455: val_loss=2.5558, val_acc=33.33%
2025-02-03 18:01:06,110 - INFO - Epoch 455: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:01:06,112 - INFO - ####################Training epoch 456####################
2025-02-03 18:01:06,401 - INFO - Epoch 456: train_loss=0.8378
2025-02-03 18:01:06,872 - INFO - Epoch 456: val_loss=2.5526, val_acc=33.33%
2025-02-03 18:01:06,876 - INFO - Epoch 456: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:01:06,878 - INFO - ####################Training epoch 457####################
2025-02-03 18:01:07,175 - INFO - Epoch 457: train_loss=0.8418
2025-02-03 18:01:07,650 - INFO - Epoch 457: val_loss=2.5526, val_acc=33.33%
2025-02-03 18:01:07,653 - INFO - Epoch 457: EPOCH_AVG_TRAIN_LOSS=0.8418
2025-02-03 18:01:07,656 - INFO - ####################Training epoch 458####################
2025-02-03 18:01:07,951 - INFO - Epoch 458: train_loss=0.8397
2025-02-03 18:01:08,421 - INFO - Epoch 458: val_loss=2.5508, val_acc=33.33%
2025-02-03 18:01:08,425 - INFO - Epoch 458: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 18:01:08,427 - INFO - ####################Training epoch 459####################
2025-02-03 18:01:08,724 - INFO - Epoch 459: train_loss=0.8379
2025-02-03 18:01:09,196 - INFO - Epoch 459: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:01:09,200 - INFO - Epoch 459: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:01:09,202 - INFO - ####################Training epoch 460####################
2025-02-03 18:01:09,496 - INFO - Epoch 460: train_loss=0.8372
2025-02-03 18:01:09,999 - INFO - Epoch 460: val_loss=2.5513, val_acc=33.33%
2025-02-03 18:01:10,002 - INFO - Epoch 460: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:01:10,005 - INFO - ####################Training epoch 461####################
2025-02-03 18:01:10,296 - INFO - Epoch 461: train_loss=0.8408
2025-02-03 18:01:10,770 - INFO - Epoch 461: val_loss=2.5486, val_acc=33.33%
2025-02-03 18:01:10,774 - INFO - Epoch 461: EPOCH_AVG_TRAIN_LOSS=0.8408
2025-02-03 18:01:10,776 - INFO - ####################Training epoch 462####################
2025-02-03 18:01:11,070 - INFO - Epoch 462: train_loss=0.8389
2025-02-03 18:01:11,547 - INFO - Epoch 462: val_loss=2.5473, val_acc=33.33%
2025-02-03 18:01:11,551 - INFO - Epoch 462: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:01:11,553 - INFO - ####################Training epoch 463####################
2025-02-03 18:01:11,843 - INFO - Epoch 463: train_loss=0.8394
2025-02-03 18:01:12,318 - INFO - Epoch 463: val_loss=2.5564, val_acc=33.33%
2025-02-03 18:01:12,321 - INFO - Epoch 463: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:01:12,324 - INFO - ####################Training epoch 464####################
2025-02-03 18:01:12,611 - INFO - Epoch 464: train_loss=0.8356
2025-02-03 18:01:13,088 - INFO - Epoch 464: val_loss=2.5534, val_acc=33.33%
2025-02-03 18:01:13,092 - INFO - Epoch 464: EPOCH_AVG_TRAIN_LOSS=0.8356
2025-02-03 18:01:13,095 - INFO - ####################Training epoch 465####################
2025-02-03 18:01:13,389 - INFO - Epoch 465: train_loss=0.8392
2025-02-03 18:01:13,860 - INFO - Epoch 465: val_loss=2.5531, val_acc=33.33%
2025-02-03 18:01:13,864 - INFO - Epoch 465: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:01:13,867 - INFO - ####################Training epoch 466####################
2025-02-03 18:01:14,158 - INFO - Epoch 466: train_loss=0.8385
2025-02-03 18:01:14,632 - INFO - Epoch 466: val_loss=2.5527, val_acc=33.33%
2025-02-03 18:01:14,636 - INFO - Epoch 466: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:01:14,638 - INFO - ####################Training epoch 467####################
2025-02-03 18:01:14,933 - INFO - Epoch 467: train_loss=0.8391
2025-02-03 18:01:15,405 - INFO - Epoch 467: val_loss=2.5594, val_acc=33.33%
2025-02-03 18:01:15,409 - INFO - Epoch 467: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:01:15,412 - INFO - ####################Training epoch 468####################
2025-02-03 18:01:15,705 - INFO - Epoch 468: train_loss=0.8385
2025-02-03 18:01:16,182 - INFO - Epoch 468: val_loss=2.5495, val_acc=33.33%
2025-02-03 18:01:16,187 - INFO - Epoch 468: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:01:16,191 - INFO - ####################Training epoch 469####################
2025-02-03 18:01:16,495 - INFO - Epoch 469: train_loss=0.8371
2025-02-03 18:01:16,970 - INFO - Epoch 469: val_loss=2.5550, val_acc=33.33%
2025-02-03 18:01:16,974 - INFO - Epoch 469: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:01:16,976 - INFO - ####################Training epoch 470####################
2025-02-03 18:01:17,267 - INFO - Epoch 470: train_loss=0.8381
2025-02-03 18:01:17,749 - INFO - Epoch 470: val_loss=2.5521, val_acc=33.33%
2025-02-03 18:01:17,752 - INFO - Epoch 470: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:01:17,755 - INFO - ####################Training epoch 471####################
2025-02-03 18:01:18,045 - INFO - Epoch 471: train_loss=0.8376
2025-02-03 18:01:18,517 - INFO - Epoch 471: val_loss=2.5520, val_acc=33.33%
2025-02-03 18:01:18,521 - INFO - Epoch 471: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:01:18,523 - INFO - ####################Training epoch 472####################
2025-02-03 18:01:18,819 - INFO - Epoch 472: train_loss=0.8384
2025-02-03 18:01:19,306 - INFO - Epoch 472: val_loss=2.5508, val_acc=33.33%
2025-02-03 18:01:19,310 - INFO - Epoch 472: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:01:19,312 - INFO - ####################Training epoch 473####################
2025-02-03 18:01:19,604 - INFO - Epoch 473: train_loss=0.8406
2025-02-03 18:01:20,081 - INFO - Epoch 473: val_loss=2.5535, val_acc=33.33%
2025-02-03 18:01:20,084 - INFO - Epoch 473: EPOCH_AVG_TRAIN_LOSS=0.8406
2025-02-03 18:01:20,086 - INFO - ####################Training epoch 474####################
2025-02-03 18:01:20,379 - INFO - Epoch 474: train_loss=0.8372
2025-02-03 18:01:20,857 - INFO - Epoch 474: val_loss=2.5550, val_acc=33.33%
2025-02-03 18:01:20,860 - INFO - Epoch 474: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:01:20,863 - INFO - ####################Training epoch 475####################
2025-02-03 18:01:21,155 - INFO - Epoch 475: train_loss=0.8397
2025-02-03 18:01:21,633 - INFO - Epoch 475: val_loss=2.5546, val_acc=33.33%
2025-02-03 18:01:21,637 - INFO - Epoch 475: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 18:01:21,639 - INFO - ####################Training epoch 476####################
2025-02-03 18:01:21,931 - INFO - Epoch 476: train_loss=0.8396
2025-02-03 18:01:22,404 - INFO - Epoch 476: val_loss=2.5581, val_acc=33.33%
2025-02-03 18:01:22,408 - INFO - Epoch 476: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:01:22,410 - INFO - ####################Training epoch 477####################
2025-02-03 18:01:22,710 - INFO - Epoch 477: train_loss=0.8382
2025-02-03 18:01:23,187 - INFO - Epoch 477: val_loss=2.5577, val_acc=33.33%
2025-02-03 18:01:23,191 - INFO - Epoch 477: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:01:23,193 - INFO - ####################Training epoch 478####################
2025-02-03 18:01:23,490 - INFO - Epoch 478: train_loss=0.8375
2025-02-03 18:01:23,967 - INFO - Epoch 478: val_loss=2.5560, val_acc=33.33%
2025-02-03 18:01:23,970 - INFO - Epoch 478: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:01:23,972 - INFO - ####################Training epoch 479####################
2025-02-03 18:01:24,267 - INFO - Epoch 479: train_loss=0.8390
2025-02-03 18:01:24,743 - INFO - Epoch 479: val_loss=2.5533, val_acc=33.33%
2025-02-03 18:01:24,747 - INFO - Epoch 479: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:01:24,749 - INFO - ####################Training epoch 480####################
2025-02-03 18:01:25,041 - INFO - Epoch 480: train_loss=0.8370
2025-02-03 18:01:25,515 - INFO - Epoch 480: val_loss=2.5550, val_acc=33.33%
2025-02-03 18:01:25,518 - INFO - Epoch 480: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:01:25,521 - INFO - ####################Training epoch 481####################
2025-02-03 18:01:25,817 - INFO - Epoch 481: train_loss=0.8384
2025-02-03 18:01:26,295 - INFO - Epoch 481: val_loss=2.5485, val_acc=33.33%
2025-02-03 18:01:26,299 - INFO - Epoch 481: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:01:26,301 - INFO - ####################Training epoch 482####################
2025-02-03 18:01:26,631 - INFO - Epoch 482: train_loss=0.8373
2025-02-03 18:01:27,102 - INFO - Epoch 482: val_loss=2.5530, val_acc=33.33%
2025-02-03 18:01:27,105 - INFO - Epoch 482: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:01:27,108 - INFO - ####################Training epoch 483####################
2025-02-03 18:01:27,400 - INFO - Epoch 483: train_loss=0.8382
2025-02-03 18:01:27,871 - INFO - Epoch 483: val_loss=2.5543, val_acc=33.33%
2025-02-03 18:01:27,874 - INFO - Epoch 483: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:01:27,877 - INFO - ####################Training epoch 484####################
2025-02-03 18:01:28,169 - INFO - Epoch 484: train_loss=0.8387
2025-02-03 18:01:28,645 - INFO - Epoch 484: val_loss=2.5444, val_acc=33.33%
2025-02-03 18:01:28,649 - INFO - Epoch 484: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:01:28,651 - INFO - ####################Training epoch 485####################
2025-02-03 18:01:28,948 - INFO - Epoch 485: train_loss=0.8385
2025-02-03 18:01:29,423 - INFO - Epoch 485: val_loss=2.5571, val_acc=33.33%
2025-02-03 18:01:29,427 - INFO - Epoch 485: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:01:29,429 - INFO - ####################Training epoch 486####################
2025-02-03 18:01:29,727 - INFO - Epoch 486: train_loss=0.8381
2025-02-03 18:01:30,201 - INFO - Epoch 486: val_loss=2.5538, val_acc=33.33%
2025-02-03 18:01:30,204 - INFO - Epoch 486: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:01:30,207 - INFO - ####################Training epoch 487####################
2025-02-03 18:01:30,501 - INFO - Epoch 487: train_loss=0.8380
2025-02-03 18:01:30,978 - INFO - Epoch 487: val_loss=2.5627, val_acc=33.33%
2025-02-03 18:01:30,982 - INFO - Epoch 487: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:01:30,984 - INFO - ####################Training epoch 488####################
2025-02-03 18:01:31,273 - INFO - Epoch 488: train_loss=0.8373
2025-02-03 18:01:31,750 - INFO - Epoch 488: val_loss=2.5549, val_acc=33.33%
2025-02-03 18:01:31,754 - INFO - Epoch 488: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:01:31,756 - INFO - ####################Training epoch 489####################
2025-02-03 18:01:32,053 - INFO - Epoch 489: train_loss=0.8379
2025-02-03 18:01:32,530 - INFO - Epoch 489: val_loss=2.5562, val_acc=33.33%
2025-02-03 18:01:32,534 - INFO - Epoch 489: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:01:32,537 - INFO - ####################Training epoch 490####################
2025-02-03 18:01:32,828 - INFO - Epoch 490: train_loss=0.8385
2025-02-03 18:01:33,306 - INFO - Epoch 490: val_loss=2.5532, val_acc=33.33%
2025-02-03 18:01:33,310 - INFO - Epoch 490: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:01:33,312 - INFO - ####################Training epoch 491####################
2025-02-03 18:01:33,607 - INFO - Epoch 491: train_loss=0.8375
2025-02-03 18:01:34,085 - INFO - Epoch 491: val_loss=2.5489, val_acc=33.33%
2025-02-03 18:01:34,088 - INFO - Epoch 491: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:01:34,091 - INFO - ####################Training epoch 492####################
2025-02-03 18:01:34,383 - INFO - Epoch 492: train_loss=0.8369
2025-02-03 18:01:34,869 - INFO - Epoch 492: val_loss=2.5448, val_acc=33.33%
2025-02-03 18:01:34,873 - INFO - Epoch 492: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:01:34,876 - INFO - ####################Training epoch 493####################
2025-02-03 18:01:35,201 - INFO - Epoch 493: train_loss=0.8395
2025-02-03 18:01:35,676 - INFO - Epoch 493: val_loss=2.5530, val_acc=33.33%
2025-02-03 18:01:35,680 - INFO - Epoch 493: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:01:35,683 - INFO - ####################Training epoch 494####################
2025-02-03 18:01:35,977 - INFO - Epoch 494: train_loss=0.8407
2025-02-03 18:01:36,451 - INFO - Epoch 494: val_loss=2.5551, val_acc=33.33%
2025-02-03 18:01:36,454 - INFO - Epoch 494: EPOCH_AVG_TRAIN_LOSS=0.8407
2025-02-03 18:01:36,457 - INFO - ####################Training epoch 495####################
2025-02-03 18:01:36,747 - INFO - Epoch 495: train_loss=0.8382
2025-02-03 18:01:37,224 - INFO - Epoch 495: val_loss=2.5530, val_acc=33.33%
2025-02-03 18:01:37,228 - INFO - Epoch 495: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:01:37,230 - INFO - ####################Training epoch 496####################
2025-02-03 18:01:37,521 - INFO - Epoch 496: train_loss=0.8388
2025-02-03 18:01:37,996 - INFO - Epoch 496: val_loss=2.5507, val_acc=33.33%
2025-02-03 18:01:37,999 - INFO - Epoch 496: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:01:38,002 - INFO - ####################Training epoch 497####################
2025-02-03 18:01:38,295 - INFO - Epoch 497: train_loss=0.8397
2025-02-03 18:01:38,772 - INFO - Epoch 497: val_loss=2.5525, val_acc=33.33%
2025-02-03 18:01:38,776 - INFO - Epoch 497: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 18:01:38,778 - INFO - ####################Training epoch 498####################
2025-02-03 18:01:39,078 - INFO - Epoch 498: train_loss=0.8405
2025-02-03 18:01:39,567 - INFO - Epoch 498: val_loss=2.5562, val_acc=33.33%
2025-02-03 18:01:39,570 - INFO - Epoch 498: EPOCH_AVG_TRAIN_LOSS=0.8405
2025-02-03 18:01:39,573 - INFO - ####################Training epoch 499####################
2025-02-03 18:01:39,867 - INFO - Epoch 499: train_loss=0.8361
2025-02-03 18:01:40,338 - INFO - Epoch 499: val_loss=2.5545, val_acc=33.33%
2025-02-03 18:01:40,342 - INFO - Epoch 499: EPOCH_AVG_TRAIN_LOSS=0.8361
2025-02-03 18:01:40,344 - INFO - ####################Training epoch 500####################
2025-02-03 18:01:40,635 - INFO - Epoch 500: train_loss=0.8372
2025-02-03 18:01:41,113 - INFO - Epoch 500: val_loss=2.5555, val_acc=33.33%
2025-02-03 18:01:41,116 - INFO - Epoch 500: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:01:41,119 - INFO - ####################Training epoch 501####################
2025-02-03 18:01:41,412 - INFO - Epoch 501: train_loss=0.8383
2025-02-03 18:01:41,889 - INFO - Epoch 501: val_loss=2.5521, val_acc=33.33%
2025-02-03 18:01:41,893 - INFO - Epoch 501: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:01:41,895 - INFO - ####################Training epoch 502####################
2025-02-03 18:01:42,185 - INFO - Epoch 502: train_loss=0.8385
2025-02-03 18:01:42,665 - INFO - Epoch 502: val_loss=2.5556, val_acc=33.33%
2025-02-03 18:01:42,668 - INFO - Epoch 502: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:01:42,671 - INFO - ####################Training epoch 503####################
2025-02-03 18:01:42,961 - INFO - Epoch 503: train_loss=0.8392
2025-02-03 18:01:43,451 - INFO - Epoch 503: val_loss=2.5500, val_acc=33.33%
2025-02-03 18:01:43,455 - INFO - Epoch 503: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:01:43,457 - INFO - ####################Training epoch 504####################
2025-02-03 18:01:43,783 - INFO - Epoch 504: train_loss=0.8407
2025-02-03 18:01:44,257 - INFO - Epoch 504: val_loss=2.5499, val_acc=33.33%
2025-02-03 18:01:44,260 - INFO - Epoch 504: EPOCH_AVG_TRAIN_LOSS=0.8407
2025-02-03 18:01:44,263 - INFO - ####################Training epoch 505####################
2025-02-03 18:01:44,558 - INFO - Epoch 505: train_loss=0.8392
2025-02-03 18:01:45,038 - INFO - Epoch 505: val_loss=2.5530, val_acc=33.33%
2025-02-03 18:01:45,042 - INFO - Epoch 505: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:01:45,044 - INFO - ####################Training epoch 506####################
2025-02-03 18:01:45,338 - INFO - Epoch 506: train_loss=0.8389
2025-02-03 18:01:45,825 - INFO - Epoch 506: val_loss=2.5534, val_acc=33.33%
2025-02-03 18:01:45,829 - INFO - Epoch 506: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:01:45,831 - INFO - ####################Training epoch 507####################
2025-02-03 18:01:46,139 - INFO - Epoch 507: train_loss=0.8381
2025-02-03 18:01:46,613 - INFO - Epoch 507: val_loss=2.5532, val_acc=33.33%
2025-02-03 18:01:46,617 - INFO - Epoch 507: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:01:46,619 - INFO - ####################Training epoch 508####################
2025-02-03 18:01:46,924 - INFO - Epoch 508: train_loss=0.8388
2025-02-03 18:01:47,397 - INFO - Epoch 508: val_loss=2.5542, val_acc=33.33%
2025-02-03 18:01:47,401 - INFO - Epoch 508: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:01:47,403 - INFO - ####################Training epoch 509####################
2025-02-03 18:01:47,695 - INFO - Epoch 509: train_loss=0.8379
2025-02-03 18:01:48,167 - INFO - Epoch 509: val_loss=2.5572, val_acc=33.33%
2025-02-03 18:01:48,171 - INFO - Epoch 509: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:01:48,173 - INFO - ####################Training epoch 510####################
2025-02-03 18:01:48,466 - INFO - Epoch 510: train_loss=0.8412
2025-02-03 18:01:48,936 - INFO - Epoch 510: val_loss=2.5603, val_acc=33.33%
2025-02-03 18:01:48,939 - INFO - Epoch 510: EPOCH_AVG_TRAIN_LOSS=0.8412
2025-02-03 18:01:48,942 - INFO - ####################Training epoch 511####################
2025-02-03 18:01:49,233 - INFO - Epoch 511: train_loss=0.8390
2025-02-03 18:01:49,703 - INFO - Epoch 511: val_loss=2.5542, val_acc=33.33%
2025-02-03 18:01:49,706 - INFO - Epoch 511: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:01:49,709 - INFO - ####################Training epoch 512####################
2025-02-03 18:01:49,997 - INFO - Epoch 512: train_loss=0.8382
2025-02-03 18:01:50,467 - INFO - Epoch 512: val_loss=2.5480, val_acc=33.33%
2025-02-03 18:01:50,471 - INFO - Epoch 512: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:01:50,473 - INFO - ####################Training epoch 513####################
2025-02-03 18:01:50,763 - INFO - Epoch 513: train_loss=0.8384
2025-02-03 18:01:51,234 - INFO - Epoch 513: val_loss=2.5563, val_acc=33.33%
2025-02-03 18:01:51,238 - INFO - Epoch 513: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:01:51,240 - INFO - ####################Training epoch 514####################
2025-02-03 18:01:51,526 - INFO - Epoch 514: train_loss=0.8381
2025-02-03 18:01:52,001 - INFO - Epoch 514: val_loss=2.5480, val_acc=33.33%
2025-02-03 18:01:52,004 - INFO - Epoch 514: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:01:52,006 - INFO - ####################Training epoch 515####################
2025-02-03 18:01:52,295 - INFO - Epoch 515: train_loss=0.8389
2025-02-03 18:01:52,767 - INFO - Epoch 515: val_loss=2.5475, val_acc=33.33%
2025-02-03 18:01:52,771 - INFO - Epoch 515: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:01:52,773 - INFO - ####################Training epoch 516####################
2025-02-03 18:01:53,061 - INFO - Epoch 516: train_loss=0.8374
2025-02-03 18:01:53,588 - INFO - Epoch 516: val_loss=2.5557, val_acc=33.33%
2025-02-03 18:01:53,592 - INFO - Epoch 516: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:01:53,594 - INFO - ####################Training epoch 517####################
2025-02-03 18:01:53,885 - INFO - Epoch 517: train_loss=0.8375
2025-02-03 18:01:54,358 - INFO - Epoch 517: val_loss=2.5593, val_acc=33.33%
2025-02-03 18:01:54,362 - INFO - Epoch 517: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:01:54,364 - INFO - ####################Training epoch 518####################
2025-02-03 18:01:54,656 - INFO - Epoch 518: train_loss=0.8388
2025-02-03 18:01:55,128 - INFO - Epoch 518: val_loss=2.5466, val_acc=33.33%
2025-02-03 18:01:55,132 - INFO - Epoch 518: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:01:55,134 - INFO - ####################Training epoch 519####################
2025-02-03 18:01:55,423 - INFO - Epoch 519: train_loss=0.8369
2025-02-03 18:01:55,895 - INFO - Epoch 519: val_loss=2.5579, val_acc=33.33%
2025-02-03 18:01:55,899 - INFO - Epoch 519: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:01:55,901 - INFO - ####################Training epoch 520####################
2025-02-03 18:01:56,188 - INFO - Epoch 520: train_loss=0.8382
2025-02-03 18:01:56,698 - INFO - Epoch 520: val_loss=2.5570, val_acc=33.33%
2025-02-03 18:01:56,702 - INFO - Epoch 520: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:01:56,705 - INFO - ####################Training epoch 521####################
2025-02-03 18:01:56,993 - INFO - Epoch 521: train_loss=0.8380
2025-02-03 18:01:57,464 - INFO - Epoch 521: val_loss=2.5499, val_acc=33.33%
2025-02-03 18:01:57,468 - INFO - Epoch 521: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:01:57,470 - INFO - ####################Training epoch 522####################
2025-02-03 18:01:57,760 - INFO - Epoch 522: train_loss=0.8390
2025-02-03 18:01:58,233 - INFO - Epoch 522: val_loss=2.5506, val_acc=33.33%
2025-02-03 18:01:58,237 - INFO - Epoch 522: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:01:58,239 - INFO - ####################Training epoch 523####################
2025-02-03 18:01:58,530 - INFO - Epoch 523: train_loss=0.8393
2025-02-03 18:01:59,002 - INFO - Epoch 523: val_loss=2.5465, val_acc=33.33%
2025-02-03 18:01:59,005 - INFO - Epoch 523: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:01:59,008 - INFO - ####################Training epoch 524####################
2025-02-03 18:01:59,296 - INFO - Epoch 524: train_loss=0.8379
2025-02-03 18:01:59,767 - INFO - Epoch 524: val_loss=2.5571, val_acc=33.33%
2025-02-03 18:01:59,771 - INFO - Epoch 524: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:01:59,773 - INFO - ####################Training epoch 525####################
2025-02-03 18:02:00,110 - INFO - Epoch 525: train_loss=0.8381
2025-02-03 18:02:00,588 - INFO - Epoch 525: val_loss=2.5503, val_acc=33.33%
2025-02-03 18:02:00,592 - INFO - Epoch 525: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:02:00,594 - INFO - ####################Training epoch 526####################
2025-02-03 18:02:00,886 - INFO - Epoch 526: train_loss=0.8373
2025-02-03 18:02:01,363 - INFO - Epoch 526: val_loss=2.5514, val_acc=33.33%
2025-02-03 18:02:01,367 - INFO - Epoch 526: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:02:01,369 - INFO - ####################Training epoch 527####################
2025-02-03 18:02:01,657 - INFO - Epoch 527: train_loss=0.8382
2025-02-03 18:02:02,131 - INFO - Epoch 527: val_loss=2.5510, val_acc=33.33%
2025-02-03 18:02:02,134 - INFO - Epoch 527: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:02:02,137 - INFO - ####################Training epoch 528####################
2025-02-03 18:02:02,427 - INFO - Epoch 528: train_loss=0.8372
2025-02-03 18:02:02,904 - INFO - Epoch 528: val_loss=2.5559, val_acc=33.33%
2025-02-03 18:02:02,907 - INFO - Epoch 528: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:02:02,910 - INFO - ####################Training epoch 529####################
2025-02-03 18:02:03,206 - INFO - Epoch 529: train_loss=0.8373
2025-02-03 18:02:03,677 - INFO - Epoch 529: val_loss=2.5570, val_acc=33.33%
2025-02-03 18:02:03,680 - INFO - Epoch 529: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:02:03,683 - INFO - ####################Training epoch 530####################
2025-02-03 18:02:03,977 - INFO - Epoch 530: train_loss=0.8408
2025-02-03 18:02:04,452 - INFO - Epoch 530: val_loss=2.5495, val_acc=33.33%
2025-02-03 18:02:04,455 - INFO - Epoch 530: EPOCH_AVG_TRAIN_LOSS=0.8408
2025-02-03 18:02:04,458 - INFO - ####################Training epoch 531####################
2025-02-03 18:02:04,750 - INFO - Epoch 531: train_loss=0.8406
2025-02-03 18:02:05,224 - INFO - Epoch 531: val_loss=2.5499, val_acc=33.33%
2025-02-03 18:02:05,228 - INFO - Epoch 531: EPOCH_AVG_TRAIN_LOSS=0.8406
2025-02-03 18:02:05,230 - INFO - ####################Training epoch 532####################
2025-02-03 18:02:05,522 - INFO - Epoch 532: train_loss=0.8382
2025-02-03 18:02:05,997 - INFO - Epoch 532: val_loss=2.5456, val_acc=33.33%
2025-02-03 18:02:06,001 - INFO - Epoch 532: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:02:06,003 - INFO - ####################Training epoch 533####################
2025-02-03 18:02:06,294 - INFO - Epoch 533: train_loss=0.8392
2025-02-03 18:02:06,766 - INFO - Epoch 533: val_loss=2.5508, val_acc=33.33%
2025-02-03 18:02:06,770 - INFO - Epoch 533: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:02:06,772 - INFO - ####################Training epoch 534####################
2025-02-03 18:02:07,066 - INFO - Epoch 534: train_loss=0.8397
2025-02-03 18:02:07,537 - INFO - Epoch 534: val_loss=2.5481, val_acc=33.33%
2025-02-03 18:02:07,540 - INFO - Epoch 534: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 18:02:07,543 - INFO - ####################Training epoch 535####################
2025-02-03 18:02:07,830 - INFO - Epoch 535: train_loss=0.8385
2025-02-03 18:02:08,303 - INFO - Epoch 535: val_loss=2.5491, val_acc=33.33%
2025-02-03 18:02:08,307 - INFO - Epoch 535: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:02:08,309 - INFO - ####################Training epoch 536####################
2025-02-03 18:02:08,598 - INFO - Epoch 536: train_loss=0.8420
2025-02-03 18:02:09,069 - INFO - Epoch 536: val_loss=2.5594, val_acc=33.33%
2025-02-03 18:02:09,073 - INFO - Epoch 536: EPOCH_AVG_TRAIN_LOSS=0.8420
2025-02-03 18:02:09,075 - INFO - ####################Training epoch 537####################
2025-02-03 18:02:09,363 - INFO - Epoch 537: train_loss=0.8383
2025-02-03 18:02:09,863 - INFO - Epoch 537: val_loss=2.5527, val_acc=33.33%
2025-02-03 18:02:09,866 - INFO - Epoch 537: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:02:09,869 - INFO - ####################Training epoch 538####################
2025-02-03 18:02:10,162 - INFO - Epoch 538: train_loss=0.8404
2025-02-03 18:02:10,637 - INFO - Epoch 538: val_loss=2.5547, val_acc=33.33%
2025-02-03 18:02:10,641 - INFO - Epoch 538: EPOCH_AVG_TRAIN_LOSS=0.8404
2025-02-03 18:02:10,643 - INFO - ####################Training epoch 539####################
2025-02-03 18:02:10,932 - INFO - Epoch 539: train_loss=0.8387
2025-02-03 18:02:11,406 - INFO - Epoch 539: val_loss=2.5522, val_acc=33.33%
2025-02-03 18:02:11,409 - INFO - Epoch 539: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:02:11,412 - INFO - ####################Training epoch 540####################
2025-02-03 18:02:11,702 - INFO - Epoch 540: train_loss=0.8377
2025-02-03 18:02:12,172 - INFO - Epoch 540: val_loss=2.5561, val_acc=33.33%
2025-02-03 18:02:12,176 - INFO - Epoch 540: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:02:12,178 - INFO - ####################Training epoch 541####################
2025-02-03 18:02:12,467 - INFO - Epoch 541: train_loss=0.8406
2025-02-03 18:02:12,985 - INFO - Epoch 541: val_loss=2.5525, val_acc=33.33%
2025-02-03 18:02:12,989 - INFO - Epoch 541: EPOCH_AVG_TRAIN_LOSS=0.8406
2025-02-03 18:02:12,992 - INFO - ####################Training epoch 542####################
2025-02-03 18:02:13,276 - INFO - Epoch 542: train_loss=0.8391
2025-02-03 18:02:13,749 - INFO - Epoch 542: val_loss=2.5435, val_acc=33.33%
2025-02-03 18:02:13,753 - INFO - Epoch 542: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:02:13,755 - INFO - ####################Training epoch 543####################
2025-02-03 18:02:14,041 - INFO - Epoch 543: train_loss=0.8399
2025-02-03 18:02:14,514 - INFO - Epoch 543: val_loss=2.5567, val_acc=33.33%
2025-02-03 18:02:14,518 - INFO - Epoch 543: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 18:02:14,520 - INFO - ####################Training epoch 544####################
2025-02-03 18:02:14,810 - INFO - Epoch 544: train_loss=0.8385
2025-02-03 18:02:15,280 - INFO - Epoch 544: val_loss=2.5566, val_acc=33.33%
2025-02-03 18:02:15,283 - INFO - Epoch 544: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:02:15,286 - INFO - ####################Training epoch 545####################
2025-02-03 18:02:15,575 - INFO - Epoch 545: train_loss=0.8402
2025-02-03 18:02:16,045 - INFO - Epoch 545: val_loss=2.5539, val_acc=33.33%
2025-02-03 18:02:16,049 - INFO - Epoch 545: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 18:02:16,051 - INFO - ####################Training epoch 546####################
2025-02-03 18:02:16,393 - INFO - Epoch 546: train_loss=0.8387
2025-02-03 18:02:16,863 - INFO - Epoch 546: val_loss=2.5498, val_acc=33.33%
2025-02-03 18:02:16,867 - INFO - Epoch 546: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:02:16,869 - INFO - ####################Training epoch 547####################
2025-02-03 18:02:17,162 - INFO - Epoch 547: train_loss=0.8400
2025-02-03 18:02:17,632 - INFO - Epoch 547: val_loss=2.5531, val_acc=33.33%
2025-02-03 18:02:17,636 - INFO - Epoch 547: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 18:02:17,638 - INFO - ####################Training epoch 548####################
2025-02-03 18:02:17,926 - INFO - Epoch 548: train_loss=0.8390
2025-02-03 18:02:18,399 - INFO - Epoch 548: val_loss=2.5525, val_acc=33.33%
2025-02-03 18:02:18,402 - INFO - Epoch 548: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:02:18,405 - INFO - ####################Training epoch 549####################
2025-02-03 18:02:18,695 - INFO - Epoch 549: train_loss=0.8395
2025-02-03 18:02:19,167 - INFO - Epoch 549: val_loss=2.5551, val_acc=33.33%
2025-02-03 18:02:19,171 - INFO - Epoch 549: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:02:19,173 - INFO - ####################Training epoch 550####################
2025-02-03 18:02:19,497 - INFO - Epoch 550: train_loss=0.8376
2025-02-03 18:02:19,969 - INFO - Epoch 550: val_loss=2.5515, val_acc=33.33%
2025-02-03 18:02:19,973 - INFO - Epoch 550: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:02:19,975 - INFO - ####################Training epoch 551####################
2025-02-03 18:02:20,267 - INFO - Epoch 551: train_loss=0.8379
2025-02-03 18:02:20,737 - INFO - Epoch 551: val_loss=2.5510, val_acc=33.33%
2025-02-03 18:02:20,741 - INFO - Epoch 551: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:02:20,743 - INFO - ####################Training epoch 552####################
2025-02-03 18:02:21,032 - INFO - Epoch 552: train_loss=0.8374
2025-02-03 18:02:21,507 - INFO - Epoch 552: val_loss=2.5522, val_acc=33.33%
2025-02-03 18:02:21,511 - INFO - Epoch 552: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:02:21,514 - INFO - ####################Training epoch 553####################
2025-02-03 18:02:21,805 - INFO - Epoch 553: train_loss=0.8378
2025-02-03 18:02:22,282 - INFO - Epoch 553: val_loss=2.5560, val_acc=33.33%
2025-02-03 18:02:22,286 - INFO - Epoch 553: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:02:22,288 - INFO - ####################Training epoch 554####################
2025-02-03 18:02:22,576 - INFO - Epoch 554: train_loss=0.8393
2025-02-03 18:02:23,049 - INFO - Epoch 554: val_loss=2.5517, val_acc=33.33%
2025-02-03 18:02:23,053 - INFO - Epoch 554: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:02:23,055 - INFO - ####################Training epoch 555####################
2025-02-03 18:02:23,342 - INFO - Epoch 555: train_loss=0.8396
2025-02-03 18:02:23,815 - INFO - Epoch 555: val_loss=2.5506, val_acc=33.33%
2025-02-03 18:02:23,819 - INFO - Epoch 555: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:02:23,822 - INFO - ####################Training epoch 556####################
2025-02-03 18:02:24,111 - INFO - Epoch 556: train_loss=0.8394
2025-02-03 18:02:24,588 - INFO - Epoch 556: val_loss=2.5497, val_acc=33.33%
2025-02-03 18:02:24,591 - INFO - Epoch 556: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:02:24,594 - INFO - ####################Training epoch 557####################
2025-02-03 18:02:24,882 - INFO - Epoch 557: train_loss=0.8377
2025-02-03 18:02:25,354 - INFO - Epoch 557: val_loss=2.5551, val_acc=33.33%
2025-02-03 18:02:25,358 - INFO - Epoch 557: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:02:25,360 - INFO - ####################Training epoch 558####################
2025-02-03 18:02:25,651 - INFO - Epoch 558: train_loss=0.8385
2025-02-03 18:02:26,137 - INFO - Epoch 558: val_loss=2.5554, val_acc=33.33%
2025-02-03 18:02:26,141 - INFO - Epoch 558: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:02:26,144 - INFO - ####################Training epoch 559####################
2025-02-03 18:02:26,435 - INFO - Epoch 559: train_loss=0.8390
2025-02-03 18:02:26,907 - INFO - Epoch 559: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:02:26,911 - INFO - Epoch 559: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:02:26,913 - INFO - ####################Training epoch 560####################
2025-02-03 18:02:27,202 - INFO - Epoch 560: train_loss=0.8389
2025-02-03 18:02:27,676 - INFO - Epoch 560: val_loss=2.5517, val_acc=33.33%
2025-02-03 18:02:27,680 - INFO - Epoch 560: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:02:27,682 - INFO - ####################Training epoch 561####################
2025-02-03 18:02:27,969 - INFO - Epoch 561: train_loss=0.8390
2025-02-03 18:02:28,440 - INFO - Epoch 561: val_loss=2.5615, val_acc=33.33%
2025-02-03 18:02:28,444 - INFO - Epoch 561: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:02:28,446 - INFO - ####################Training epoch 562####################
2025-02-03 18:02:28,739 - INFO - Epoch 562: train_loss=0.8378
2025-02-03 18:02:29,264 - INFO - Epoch 562: val_loss=2.5547, val_acc=33.33%
2025-02-03 18:02:29,268 - INFO - Epoch 562: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:02:29,270 - INFO - ####################Training epoch 563####################
2025-02-03 18:02:29,560 - INFO - Epoch 563: train_loss=0.8383
2025-02-03 18:02:30,033 - INFO - Epoch 563: val_loss=2.5526, val_acc=33.33%
2025-02-03 18:02:30,037 - INFO - Epoch 563: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:02:30,039 - INFO - ####################Training epoch 564####################
2025-02-03 18:02:30,329 - INFO - Epoch 564: train_loss=0.8398
2025-02-03 18:02:30,802 - INFO - Epoch 564: val_loss=2.5535, val_acc=33.33%
2025-02-03 18:02:30,806 - INFO - Epoch 564: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:02:30,808 - INFO - ####################Training epoch 565####################
2025-02-03 18:02:31,099 - INFO - Epoch 565: train_loss=0.8389
2025-02-03 18:02:31,570 - INFO - Epoch 565: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:02:31,574 - INFO - Epoch 565: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:02:31,576 - INFO - ####################Training epoch 566####################
2025-02-03 18:02:31,867 - INFO - Epoch 566: train_loss=0.8378
2025-02-03 18:02:32,341 - INFO - Epoch 566: val_loss=2.5496, val_acc=33.33%
2025-02-03 18:02:32,344 - INFO - Epoch 566: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:02:32,346 - INFO - ####################Training epoch 567####################
2025-02-03 18:02:32,686 - INFO - Epoch 567: train_loss=0.8362
2025-02-03 18:02:33,162 - INFO - Epoch 567: val_loss=2.5546, val_acc=33.33%
2025-02-03 18:02:33,165 - INFO - Epoch 567: EPOCH_AVG_TRAIN_LOSS=0.8362
2025-02-03 18:02:33,168 - INFO - ####################Training epoch 568####################
2025-02-03 18:02:33,458 - INFO - Epoch 568: train_loss=0.8382
2025-02-03 18:02:33,937 - INFO - Epoch 568: val_loss=2.5571, val_acc=33.33%
2025-02-03 18:02:33,940 - INFO - Epoch 568: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:02:33,943 - INFO - ####################Training epoch 569####################
2025-02-03 18:02:34,231 - INFO - Epoch 569: train_loss=0.8386
2025-02-03 18:02:34,705 - INFO - Epoch 569: val_loss=2.5517, val_acc=33.33%
2025-02-03 18:02:34,708 - INFO - Epoch 569: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:02:34,711 - INFO - ####################Training epoch 570####################
2025-02-03 18:02:34,999 - INFO - Epoch 570: train_loss=0.8374
2025-02-03 18:02:35,472 - INFO - Epoch 570: val_loss=2.5535, val_acc=33.33%
2025-02-03 18:02:35,475 - INFO - Epoch 570: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:02:35,478 - INFO - ####################Training epoch 571####################
2025-02-03 18:02:35,819 - INFO - Epoch 571: train_loss=0.8397
2025-02-03 18:02:36,292 - INFO - Epoch 571: val_loss=2.5555, val_acc=33.33%
2025-02-03 18:02:36,295 - INFO - Epoch 571: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 18:02:36,298 - INFO - ####################Training epoch 572####################
2025-02-03 18:02:36,590 - INFO - Epoch 572: train_loss=0.8387
2025-02-03 18:02:37,063 - INFO - Epoch 572: val_loss=2.5559, val_acc=33.33%
2025-02-03 18:02:37,067 - INFO - Epoch 572: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:02:37,069 - INFO - ####################Training epoch 573####################
2025-02-03 18:02:37,358 - INFO - Epoch 573: train_loss=0.8398
2025-02-03 18:02:37,832 - INFO - Epoch 573: val_loss=2.5507, val_acc=33.33%
2025-02-03 18:02:37,836 - INFO - Epoch 573: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:02:37,838 - INFO - ####################Training epoch 574####################
2025-02-03 18:02:38,131 - INFO - Epoch 574: train_loss=0.8403
2025-02-03 18:02:38,607 - INFO - Epoch 574: val_loss=2.5542, val_acc=33.33%
2025-02-03 18:02:38,611 - INFO - Epoch 574: EPOCH_AVG_TRAIN_LOSS=0.8403
2025-02-03 18:02:38,613 - INFO - ####################Training epoch 575####################
2025-02-03 18:02:38,903 - INFO - Epoch 575: train_loss=0.8412
2025-02-03 18:02:39,373 - INFO - Epoch 575: val_loss=2.5566, val_acc=33.33%
2025-02-03 18:02:39,377 - INFO - Epoch 575: EPOCH_AVG_TRAIN_LOSS=0.8412
2025-02-03 18:02:39,379 - INFO - ####################Training epoch 576####################
2025-02-03 18:02:39,669 - INFO - Epoch 576: train_loss=0.8395
2025-02-03 18:02:40,142 - INFO - Epoch 576: val_loss=2.5581, val_acc=33.33%
2025-02-03 18:02:40,145 - INFO - Epoch 576: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:02:40,148 - INFO - ####################Training epoch 577####################
2025-02-03 18:02:40,439 - INFO - Epoch 577: train_loss=0.8396
2025-02-03 18:02:40,912 - INFO - Epoch 577: val_loss=2.5497, val_acc=33.33%
2025-02-03 18:02:40,916 - INFO - Epoch 577: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:02:40,919 - INFO - ####################Training epoch 578####################
2025-02-03 18:02:41,214 - INFO - Epoch 578: train_loss=0.8376
2025-02-03 18:02:41,688 - INFO - Epoch 578: val_loss=2.5578, val_acc=33.33%
2025-02-03 18:02:41,691 - INFO - Epoch 578: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:02:41,694 - INFO - ####################Training epoch 579####################
2025-02-03 18:02:41,985 - INFO - Epoch 579: train_loss=0.8372
2025-02-03 18:02:42,455 - INFO - Epoch 579: val_loss=2.5561, val_acc=33.33%
2025-02-03 18:02:42,459 - INFO - Epoch 579: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:02:42,461 - INFO - ####################Training epoch 580####################
2025-02-03 18:02:42,748 - INFO - Epoch 580: train_loss=0.8376
2025-02-03 18:02:43,219 - INFO - Epoch 580: val_loss=2.5574, val_acc=33.33%
2025-02-03 18:02:43,222 - INFO - Epoch 580: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:02:43,224 - INFO - ####################Training epoch 581####################
2025-02-03 18:02:43,516 - INFO - Epoch 581: train_loss=0.8362
2025-02-03 18:02:43,989 - INFO - Epoch 581: val_loss=2.5560, val_acc=33.33%
2025-02-03 18:02:43,992 - INFO - Epoch 581: EPOCH_AVG_TRAIN_LOSS=0.8362
2025-02-03 18:02:43,995 - INFO - ####################Training epoch 582####################
2025-02-03 18:02:44,285 - INFO - Epoch 582: train_loss=0.8383
2025-02-03 18:02:44,756 - INFO - Epoch 582: val_loss=2.5547, val_acc=33.33%
2025-02-03 18:02:44,760 - INFO - Epoch 582: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:02:44,762 - INFO - ####################Training epoch 583####################
2025-02-03 18:02:45,049 - INFO - Epoch 583: train_loss=0.8395
2025-02-03 18:02:45,574 - INFO - Epoch 583: val_loss=2.5507, val_acc=33.33%
2025-02-03 18:02:45,577 - INFO - Epoch 583: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:02:45,580 - INFO - ####################Training epoch 584####################
2025-02-03 18:02:45,870 - INFO - Epoch 584: train_loss=0.8367
2025-02-03 18:02:46,342 - INFO - Epoch 584: val_loss=2.5540, val_acc=33.33%
2025-02-03 18:02:46,345 - INFO - Epoch 584: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:02:46,348 - INFO - ####################Training epoch 585####################
2025-02-03 18:02:46,637 - INFO - Epoch 585: train_loss=0.8391
2025-02-03 18:02:47,107 - INFO - Epoch 585: val_loss=2.5575, val_acc=33.33%
2025-02-03 18:02:47,110 - INFO - Epoch 585: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:02:47,112 - INFO - ####################Training epoch 586####################
2025-02-03 18:02:47,403 - INFO - Epoch 586: train_loss=0.8405
2025-02-03 18:02:47,874 - INFO - Epoch 586: val_loss=2.5493, val_acc=33.33%
2025-02-03 18:02:47,877 - INFO - Epoch 586: EPOCH_AVG_TRAIN_LOSS=0.8405
2025-02-03 18:02:47,880 - INFO - ####################Training epoch 587####################
2025-02-03 18:02:48,167 - INFO - Epoch 587: train_loss=0.8415
2025-02-03 18:02:48,673 - INFO - Epoch 587: val_loss=2.5544, val_acc=33.33%
2025-02-03 18:02:48,690 - INFO - Epoch 587: EPOCH_AVG_TRAIN_LOSS=0.8415
2025-02-03 18:02:48,693 - INFO - ####################Training epoch 588####################
2025-02-03 18:02:48,978 - INFO - Epoch 588: train_loss=0.8367
2025-02-03 18:02:49,453 - INFO - Epoch 588: val_loss=2.5568, val_acc=33.33%
2025-02-03 18:02:49,456 - INFO - Epoch 588: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:02:49,459 - INFO - ####################Training epoch 589####################
2025-02-03 18:02:49,749 - INFO - Epoch 589: train_loss=0.8393
2025-02-03 18:02:50,230 - INFO - Epoch 589: val_loss=2.5537, val_acc=33.33%
2025-02-03 18:02:50,234 - INFO - Epoch 589: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:02:50,236 - INFO - ####################Training epoch 590####################
2025-02-03 18:02:50,524 - INFO - Epoch 590: train_loss=0.8399
2025-02-03 18:02:51,001 - INFO - Epoch 590: val_loss=2.5539, val_acc=33.33%
2025-02-03 18:02:51,004 - INFO - Epoch 590: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 18:02:51,007 - INFO - ####################Training epoch 591####################
2025-02-03 18:02:51,296 - INFO - Epoch 591: train_loss=0.8394
2025-02-03 18:02:51,768 - INFO - Epoch 591: val_loss=2.5513, val_acc=33.33%
2025-02-03 18:02:51,771 - INFO - Epoch 591: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:02:51,774 - INFO - ####################Training epoch 592####################
2025-02-03 18:02:52,116 - INFO - Epoch 592: train_loss=0.8382
2025-02-03 18:02:52,587 - INFO - Epoch 592: val_loss=2.5525, val_acc=33.33%
2025-02-03 18:02:52,590 - INFO - Epoch 592: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:02:52,593 - INFO - ####################Training epoch 593####################
2025-02-03 18:02:52,885 - INFO - Epoch 593: train_loss=0.8369
2025-02-03 18:02:53,357 - INFO - Epoch 593: val_loss=2.5547, val_acc=33.33%
2025-02-03 18:02:53,360 - INFO - Epoch 593: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:02:53,362 - INFO - ####################Training epoch 594####################
2025-02-03 18:02:53,651 - INFO - Epoch 594: train_loss=0.8374
2025-02-03 18:02:54,122 - INFO - Epoch 594: val_loss=2.5497, val_acc=33.33%
2025-02-03 18:02:54,126 - INFO - Epoch 594: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:02:54,128 - INFO - ####################Training epoch 595####################
2025-02-03 18:02:54,416 - INFO - Epoch 595: train_loss=0.8397
2025-02-03 18:02:54,891 - INFO - Epoch 595: val_loss=2.5532, val_acc=33.33%
2025-02-03 18:02:54,894 - INFO - Epoch 595: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 18:02:54,897 - INFO - ####################Training epoch 596####################
2025-02-03 18:02:55,234 - INFO - Epoch 596: train_loss=0.8381
2025-02-03 18:02:55,707 - INFO - Epoch 596: val_loss=2.5511, val_acc=33.33%
2025-02-03 18:02:55,711 - INFO - Epoch 596: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:02:55,713 - INFO - ####################Training epoch 597####################
2025-02-03 18:02:56,000 - INFO - Epoch 597: train_loss=0.8381
2025-02-03 18:02:56,470 - INFO - Epoch 597: val_loss=2.5493, val_acc=33.33%
2025-02-03 18:02:56,474 - INFO - Epoch 597: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:02:56,476 - INFO - ####################Training epoch 598####################
2025-02-03 18:02:56,764 - INFO - Epoch 598: train_loss=0.8398
2025-02-03 18:02:57,235 - INFO - Epoch 598: val_loss=2.5493, val_acc=33.33%
2025-02-03 18:02:57,238 - INFO - Epoch 598: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:02:57,240 - INFO - ####################Training epoch 599####################
2025-02-03 18:02:57,528 - INFO - Epoch 599: train_loss=0.8385
2025-02-03 18:02:58,001 - INFO - Epoch 599: val_loss=2.5546, val_acc=33.33%
2025-02-03 18:02:58,005 - INFO - Epoch 599: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:02:58,007 - INFO - ####################Training epoch 600####################
2025-02-03 18:02:58,295 - INFO - Epoch 600: train_loss=0.8353
2025-02-03 18:02:58,771 - INFO - Epoch 600: val_loss=2.5572, val_acc=33.33%
2025-02-03 18:02:58,774 - INFO - Epoch 600: EPOCH_AVG_TRAIN_LOSS=0.8353
2025-02-03 18:02:58,777 - INFO - ####################Training epoch 601####################
2025-02-03 18:02:59,069 - INFO - Epoch 601: train_loss=0.8398
2025-02-03 18:02:59,614 - INFO - Epoch 601: val_loss=2.5553, val_acc=33.33%
2025-02-03 18:02:59,618 - INFO - Epoch 601: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:02:59,620 - INFO - ####################Training epoch 602####################
2025-02-03 18:02:59,908 - INFO - Epoch 602: train_loss=0.8388
2025-02-03 18:03:00,381 - INFO - Epoch 602: val_loss=2.5565, val_acc=33.33%
2025-02-03 18:03:00,385 - INFO - Epoch 602: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:03:00,387 - INFO - ####################Training epoch 603####################
2025-02-03 18:03:00,676 - INFO - Epoch 603: train_loss=0.8392
2025-02-03 18:03:01,150 - INFO - Epoch 603: val_loss=2.5502, val_acc=33.33%
2025-02-03 18:03:01,154 - INFO - Epoch 603: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:03:01,156 - INFO - ####################Training epoch 604####################
2025-02-03 18:03:01,443 - INFO - Epoch 604: train_loss=0.8383
2025-02-03 18:03:01,914 - INFO - Epoch 604: val_loss=2.5493, val_acc=33.33%
2025-02-03 18:03:01,917 - INFO - Epoch 604: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:03:01,920 - INFO - ####################Training epoch 605####################
2025-02-03 18:03:02,208 - INFO - Epoch 605: train_loss=0.8394
2025-02-03 18:03:02,679 - INFO - Epoch 605: val_loss=2.5514, val_acc=33.33%
2025-02-03 18:03:02,683 - INFO - Epoch 605: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:03:02,685 - INFO - ####################Training epoch 606####################
2025-02-03 18:03:02,979 - INFO - Epoch 606: train_loss=0.8408
2025-02-03 18:03:03,452 - INFO - Epoch 606: val_loss=2.5563, val_acc=33.33%
2025-02-03 18:03:03,455 - INFO - Epoch 606: EPOCH_AVG_TRAIN_LOSS=0.8408
2025-02-03 18:03:03,457 - INFO - ####################Training epoch 607####################
2025-02-03 18:03:03,746 - INFO - Epoch 607: train_loss=0.8393
2025-02-03 18:03:04,229 - INFO - Epoch 607: val_loss=2.5502, val_acc=33.33%
2025-02-03 18:03:04,235 - INFO - Epoch 607: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:03:04,239 - INFO - ####################Training epoch 608####################
2025-02-03 18:03:04,534 - INFO - Epoch 608: train_loss=0.8391
2025-02-03 18:03:05,009 - INFO - Epoch 608: val_loss=2.5531, val_acc=33.33%
2025-02-03 18:03:05,012 - INFO - Epoch 608: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:03:05,015 - INFO - ####################Training epoch 609####################
2025-02-03 18:03:05,304 - INFO - Epoch 609: train_loss=0.8372
2025-02-03 18:03:05,780 - INFO - Epoch 609: val_loss=2.5578, val_acc=33.33%
2025-02-03 18:03:05,784 - INFO - Epoch 609: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:03:05,786 - INFO - ####################Training epoch 610####################
2025-02-03 18:03:06,080 - INFO - Epoch 610: train_loss=0.8364
2025-02-03 18:03:06,554 - INFO - Epoch 610: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:03:06,557 - INFO - Epoch 610: EPOCH_AVG_TRAIN_LOSS=0.8364
2025-02-03 18:03:06,560 - INFO - ####################Training epoch 611####################
2025-02-03 18:03:06,851 - INFO - Epoch 611: train_loss=0.8384
2025-02-03 18:03:07,326 - INFO - Epoch 611: val_loss=2.5471, val_acc=33.33%
2025-02-03 18:03:07,330 - INFO - Epoch 611: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:03:07,332 - INFO - ####################Training epoch 612####################
2025-02-03 18:03:07,632 - INFO - Epoch 612: train_loss=0.8395
2025-02-03 18:03:08,102 - INFO - Epoch 612: val_loss=2.5559, val_acc=33.33%
2025-02-03 18:03:08,105 - INFO - Epoch 612: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:03:08,107 - INFO - ####################Training epoch 613####################
2025-02-03 18:03:08,395 - INFO - Epoch 613: train_loss=0.8369
2025-02-03 18:03:08,869 - INFO - Epoch 613: val_loss=2.5545, val_acc=33.33%
2025-02-03 18:03:08,873 - INFO - Epoch 613: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:03:08,875 - INFO - ####################Training epoch 614####################
2025-02-03 18:03:09,167 - INFO - Epoch 614: train_loss=0.8376
2025-02-03 18:03:09,644 - INFO - Epoch 614: val_loss=2.5520, val_acc=33.33%
2025-02-03 18:03:09,647 - INFO - Epoch 614: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:03:09,649 - INFO - ####################Training epoch 615####################
2025-02-03 18:03:09,934 - INFO - Epoch 615: train_loss=0.8391
2025-02-03 18:03:10,405 - INFO - Epoch 615: val_loss=2.5528, val_acc=33.33%
2025-02-03 18:03:10,408 - INFO - Epoch 615: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:03:10,411 - INFO - ####################Training epoch 616####################
2025-02-03 18:03:10,703 - INFO - Epoch 616: train_loss=0.8395
2025-02-03 18:03:11,175 - INFO - Epoch 616: val_loss=2.5495, val_acc=33.33%
2025-02-03 18:03:11,179 - INFO - Epoch 616: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:03:11,182 - INFO - ####################Training epoch 617####################
2025-02-03 18:03:11,473 - INFO - Epoch 617: train_loss=0.8393
2025-02-03 18:03:12,015 - INFO - Epoch 617: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:03:12,019 - INFO - Epoch 617: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:03:12,021 - INFO - ####################Training epoch 618####################
2025-02-03 18:03:12,311 - INFO - Epoch 618: train_loss=0.8355
2025-02-03 18:03:12,790 - INFO - Epoch 618: val_loss=2.5522, val_acc=33.33%
2025-02-03 18:03:12,794 - INFO - Epoch 618: EPOCH_AVG_TRAIN_LOSS=0.8355
2025-02-03 18:03:12,796 - INFO - ####################Training epoch 619####################
2025-02-03 18:03:13,086 - INFO - Epoch 619: train_loss=0.8390
2025-02-03 18:03:13,562 - INFO - Epoch 619: val_loss=2.5449, val_acc=33.33%
2025-02-03 18:03:13,566 - INFO - Epoch 619: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:03:13,568 - INFO - ####################Training epoch 620####################
2025-02-03 18:03:13,862 - INFO - Epoch 620: train_loss=0.8418
2025-02-03 18:03:14,434 - INFO - Epoch 620: val_loss=2.5565, val_acc=33.33%
2025-02-03 18:03:14,439 - INFO - Epoch 620: EPOCH_AVG_TRAIN_LOSS=0.8418
2025-02-03 18:03:14,449 - INFO - ####################Training epoch 621####################
2025-02-03 18:03:14,851 - INFO - Epoch 621: train_loss=0.8383
2025-02-03 18:03:15,497 - INFO - Epoch 621: val_loss=2.5523, val_acc=33.33%
2025-02-03 18:03:15,500 - INFO - Epoch 621: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:03:15,503 - INFO - ####################Training epoch 622####################
2025-02-03 18:03:15,797 - INFO - Epoch 622: train_loss=0.8379
2025-02-03 18:03:16,503 - INFO - Epoch 622: val_loss=2.5513, val_acc=33.33%
2025-02-03 18:03:16,508 - INFO - Epoch 622: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:03:16,513 - INFO - ####################Training epoch 623####################
2025-02-03 18:03:16,800 - INFO - Epoch 623: train_loss=0.8374
2025-02-03 18:03:17,390 - INFO - Epoch 623: val_loss=2.5507, val_acc=33.33%
2025-02-03 18:03:17,396 - INFO - Epoch 623: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:03:17,406 - INFO - ####################Training epoch 624####################
2025-02-03 18:03:17,858 - INFO - Epoch 624: train_loss=0.8396
2025-02-03 18:03:18,531 - INFO - Epoch 624: val_loss=2.5519, val_acc=33.33%
2025-02-03 18:03:18,535 - INFO - Epoch 624: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:03:18,537 - INFO - ####################Training epoch 625####################
2025-02-03 18:03:18,895 - INFO - Epoch 625: train_loss=0.8373
2025-02-03 18:03:19,717 - INFO - Epoch 625: val_loss=2.5526, val_acc=33.33%
2025-02-03 18:03:19,720 - INFO - Epoch 625: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:03:19,722 - INFO - ####################Training epoch 626####################
2025-02-03 18:03:20,059 - INFO - Epoch 626: train_loss=0.8389
2025-02-03 18:03:20,709 - INFO - Epoch 626: val_loss=2.5562, val_acc=33.33%
2025-02-03 18:03:20,714 - INFO - Epoch 626: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:03:20,724 - INFO - ####################Training epoch 627####################
2025-02-03 18:03:21,047 - INFO - Epoch 627: train_loss=0.8386
2025-02-03 18:03:21,588 - INFO - Epoch 627: val_loss=2.5533, val_acc=33.33%
2025-02-03 18:03:21,594 - INFO - Epoch 627: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:03:21,604 - INFO - ####################Training epoch 628####################
2025-02-03 18:03:22,079 - INFO - Epoch 628: train_loss=0.8386
2025-02-03 18:03:22,747 - INFO - Epoch 628: val_loss=2.5560, val_acc=33.33%
2025-02-03 18:03:22,751 - INFO - Epoch 628: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:03:22,753 - INFO - ####################Training epoch 629####################
2025-02-03 18:03:23,098 - INFO - Epoch 629: train_loss=0.8401
2025-02-03 18:03:23,790 - INFO - Epoch 629: val_loss=2.5557, val_acc=33.33%
2025-02-03 18:03:23,795 - INFO - Epoch 629: EPOCH_AVG_TRAIN_LOSS=0.8401
2025-02-03 18:03:23,799 - INFO - ####################Training epoch 630####################
2025-02-03 18:03:24,086 - INFO - Epoch 630: train_loss=0.8396
2025-02-03 18:03:24,718 - INFO - Epoch 630: val_loss=2.5514, val_acc=33.33%
2025-02-03 18:03:24,723 - INFO - Epoch 630: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:03:24,732 - INFO - ####################Training epoch 631####################
2025-02-03 18:03:25,144 - INFO - Epoch 631: train_loss=0.8394
2025-02-03 18:03:25,766 - INFO - Epoch 631: val_loss=2.5525, val_acc=33.33%
2025-02-03 18:03:25,769 - INFO - Epoch 631: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:03:25,772 - INFO - ####################Training epoch 632####################
2025-02-03 18:03:26,156 - INFO - Epoch 632: train_loss=0.8381
2025-02-03 18:03:26,914 - INFO - Epoch 632: val_loss=2.5570, val_acc=33.33%
2025-02-03 18:03:26,917 - INFO - Epoch 632: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:03:26,919 - INFO - ####################Training epoch 633####################
2025-02-03 18:03:27,252 - INFO - Epoch 633: train_loss=0.8376
2025-02-03 18:03:27,906 - INFO - Epoch 633: val_loss=2.5532, val_acc=33.33%
2025-02-03 18:03:27,913 - INFO - Epoch 633: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:03:27,923 - INFO - ####################Training epoch 634####################
2025-02-03 18:03:28,236 - INFO - Epoch 634: train_loss=0.8380
2025-02-03 18:03:28,827 - INFO - Epoch 634: val_loss=2.5465, val_acc=33.33%
2025-02-03 18:03:28,832 - INFO - Epoch 634: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:03:28,844 - INFO - ####################Training epoch 635####################
2025-02-03 18:03:29,293 - INFO - Epoch 635: train_loss=0.8397
2025-02-03 18:03:29,969 - INFO - Epoch 635: val_loss=2.5542, val_acc=33.33%
2025-02-03 18:03:29,973 - INFO - Epoch 635: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 18:03:29,975 - INFO - ####################Training epoch 636####################
2025-02-03 18:03:30,398 - INFO - Epoch 636: train_loss=0.8385
2025-02-03 18:03:31,166 - INFO - Epoch 636: val_loss=2.5538, val_acc=33.33%
2025-02-03 18:03:31,169 - INFO - Epoch 636: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:03:31,172 - INFO - ####################Training epoch 637####################
2025-02-03 18:03:31,509 - INFO - Epoch 637: train_loss=0.8366
2025-02-03 18:03:32,164 - INFO - Epoch 637: val_loss=2.5477, val_acc=33.33%
2025-02-03 18:03:32,168 - INFO - Epoch 637: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 18:03:32,179 - INFO - ####################Training epoch 638####################
2025-02-03 18:03:32,495 - INFO - Epoch 638: train_loss=0.8384
2025-02-03 18:03:33,089 - INFO - Epoch 638: val_loss=2.5506, val_acc=33.33%
2025-02-03 18:03:33,094 - INFO - Epoch 638: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:03:33,106 - INFO - ####################Training epoch 639####################
2025-02-03 18:03:33,563 - INFO - Epoch 639: train_loss=0.8364
2025-02-03 18:03:34,225 - INFO - Epoch 639: val_loss=2.5494, val_acc=33.33%
2025-02-03 18:03:34,229 - INFO - Epoch 639: EPOCH_AVG_TRAIN_LOSS=0.8364
2025-02-03 18:03:34,231 - INFO - ####################Training epoch 640####################
2025-02-03 18:03:34,650 - INFO - Epoch 640: train_loss=0.8369
2025-02-03 18:03:35,420 - INFO - Epoch 640: val_loss=2.5557, val_acc=33.33%
2025-02-03 18:03:35,424 - INFO - Epoch 640: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:03:35,426 - INFO - ####################Training epoch 641####################
2025-02-03 18:03:35,764 - INFO - Epoch 641: train_loss=0.8380
2025-02-03 18:03:36,423 - INFO - Epoch 641: val_loss=2.5564, val_acc=33.33%
2025-02-03 18:03:36,428 - INFO - Epoch 641: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:03:36,438 - INFO - ####################Training epoch 642####################
2025-02-03 18:03:36,751 - INFO - Epoch 642: train_loss=0.8395
2025-02-03 18:03:37,348 - INFO - Epoch 642: val_loss=2.5470, val_acc=33.33%
2025-02-03 18:03:37,353 - INFO - Epoch 642: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:03:37,364 - INFO - ####################Training epoch 643####################
2025-02-03 18:03:37,812 - INFO - Epoch 643: train_loss=0.8378
2025-02-03 18:03:38,489 - INFO - Epoch 643: val_loss=2.5463, val_acc=33.33%
2025-02-03 18:03:38,493 - INFO - Epoch 643: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:03:38,495 - INFO - ####################Training epoch 644####################
2025-02-03 18:03:38,919 - INFO - Epoch 644: train_loss=0.8368
2025-02-03 18:03:39,690 - INFO - Epoch 644: val_loss=2.5581, val_acc=33.33%
2025-02-03 18:03:39,694 - INFO - Epoch 644: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:03:39,696 - INFO - ####################Training epoch 645####################
2025-02-03 18:03:40,030 - INFO - Epoch 645: train_loss=0.8390
2025-02-03 18:03:40,686 - INFO - Epoch 645: val_loss=2.5561, val_acc=33.33%
2025-02-03 18:03:40,691 - INFO - Epoch 645: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:03:40,701 - INFO - ####################Training epoch 646####################
2025-02-03 18:03:41,016 - INFO - Epoch 646: train_loss=0.8370
2025-02-03 18:03:41,522 - INFO - Epoch 646: val_loss=2.5495, val_acc=33.33%
2025-02-03 18:03:41,525 - INFO - Epoch 646: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:03:41,528 - INFO - ####################Training epoch 647####################
2025-02-03 18:03:42,016 - INFO - Epoch 647: train_loss=0.8381
2025-02-03 18:03:42,679 - INFO - Epoch 647: val_loss=2.5578, val_acc=33.33%
2025-02-03 18:03:42,682 - INFO - Epoch 647: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:03:42,684 - INFO - ####################Training epoch 648####################
2025-02-03 18:03:42,989 - INFO - Epoch 648: train_loss=0.8383
2025-02-03 18:03:43,707 - INFO - Epoch 648: val_loss=2.5600, val_acc=33.33%
2025-02-03 18:03:43,711 - INFO - Epoch 648: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:03:43,722 - INFO - ####################Training epoch 649####################
2025-02-03 18:03:44,009 - INFO - Epoch 649: train_loss=0.8376
2025-02-03 18:03:44,603 - INFO - Epoch 649: val_loss=2.5513, val_acc=33.33%
2025-02-03 18:03:44,608 - INFO - Epoch 649: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:03:44,617 - INFO - ####################Training epoch 650####################
2025-02-03 18:03:45,044 - INFO - Epoch 650: train_loss=0.8386
2025-02-03 18:03:45,674 - INFO - Epoch 650: val_loss=2.5587, val_acc=33.33%
2025-02-03 18:03:45,678 - INFO - Epoch 650: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:03:45,680 - INFO - ####################Training epoch 651####################
2025-02-03 18:03:46,106 - INFO - Epoch 651: train_loss=0.8372
2025-02-03 18:03:46,837 - INFO - Epoch 651: val_loss=2.5573, val_acc=33.33%
2025-02-03 18:03:46,841 - INFO - Epoch 651: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:03:46,844 - INFO - ####################Training epoch 652####################
2025-02-03 18:03:47,152 - INFO - Epoch 652: train_loss=0.8393
2025-02-03 18:03:47,835 - INFO - Epoch 652: val_loss=2.5527, val_acc=33.33%
2025-02-03 18:03:47,839 - INFO - Epoch 652: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:03:47,850 - INFO - ####################Training epoch 653####################
2025-02-03 18:03:48,140 - INFO - Epoch 653: train_loss=0.8379
2025-02-03 18:03:48,732 - INFO - Epoch 653: val_loss=2.5502, val_acc=33.33%
2025-02-03 18:03:48,736 - INFO - Epoch 653: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:03:48,747 - INFO - ####################Training epoch 654####################
2025-02-03 18:03:49,188 - INFO - Epoch 654: train_loss=0.8395
2025-02-03 18:03:49,857 - INFO - Epoch 654: val_loss=2.5526, val_acc=33.33%
2025-02-03 18:03:49,860 - INFO - Epoch 654: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:03:49,863 - INFO - ####################Training epoch 655####################
2025-02-03 18:03:50,287 - INFO - Epoch 655: train_loss=0.8385
2025-02-03 18:03:51,061 - INFO - Epoch 655: val_loss=2.5558, val_acc=33.33%
2025-02-03 18:03:51,065 - INFO - Epoch 655: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:03:51,067 - INFO - ####################Training epoch 656####################
2025-02-03 18:03:51,412 - INFO - Epoch 656: train_loss=0.8377
2025-02-03 18:03:52,067 - INFO - Epoch 656: val_loss=2.5562, val_acc=33.33%
2025-02-03 18:03:52,071 - INFO - Epoch 656: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:03:52,082 - INFO - ####################Training epoch 657####################
2025-02-03 18:03:52,400 - INFO - Epoch 657: train_loss=0.8385
2025-02-03 18:03:52,982 - INFO - Epoch 657: val_loss=2.5514, val_acc=33.33%
2025-02-03 18:03:52,986 - INFO - Epoch 657: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:03:52,995 - INFO - ####################Training epoch 658####################
2025-02-03 18:03:53,462 - INFO - Epoch 658: train_loss=0.8390
2025-02-03 18:03:54,140 - INFO - Epoch 658: val_loss=2.5575, val_acc=33.33%
2025-02-03 18:03:54,144 - INFO - Epoch 658: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:03:54,147 - INFO - ####################Training epoch 659####################
2025-02-03 18:03:54,570 - INFO - Epoch 659: train_loss=0.8386
2025-02-03 18:03:55,341 - INFO - Epoch 659: val_loss=2.5557, val_acc=33.33%
2025-02-03 18:03:55,345 - INFO - Epoch 659: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:03:55,347 - INFO - ####################Training epoch 660####################
2025-02-03 18:03:55,687 - INFO - Epoch 660: train_loss=0.8408
2025-02-03 18:03:56,337 - INFO - Epoch 660: val_loss=2.5541, val_acc=33.33%
2025-02-03 18:03:56,342 - INFO - Epoch 660: EPOCH_AVG_TRAIN_LOSS=0.8408
2025-02-03 18:03:56,352 - INFO - ####################Training epoch 661####################
2025-02-03 18:03:56,677 - INFO - Epoch 661: train_loss=0.8379
2025-02-03 18:03:57,254 - INFO - Epoch 661: val_loss=2.5567, val_acc=33.33%
2025-02-03 18:03:57,259 - INFO - Epoch 661: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:03:57,268 - INFO - ####################Training epoch 662####################
2025-02-03 18:03:57,735 - INFO - Epoch 662: train_loss=0.8361
2025-02-03 18:03:58,415 - INFO - Epoch 662: val_loss=2.5565, val_acc=33.33%
2025-02-03 18:03:58,418 - INFO - Epoch 662: EPOCH_AVG_TRAIN_LOSS=0.8361
2025-02-03 18:03:58,420 - INFO - ####################Training epoch 663####################
2025-02-03 18:03:58,849 - INFO - Epoch 663: train_loss=0.8374
2025-02-03 18:03:59,622 - INFO - Epoch 663: val_loss=2.5548, val_acc=33.33%
2025-02-03 18:03:59,626 - INFO - Epoch 663: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:03:59,628 - INFO - ####################Training epoch 664####################
2025-02-03 18:03:59,962 - INFO - Epoch 664: train_loss=0.8396
2025-02-03 18:04:00,631 - INFO - Epoch 664: val_loss=2.5548, val_acc=33.33%
2025-02-03 18:04:00,636 - INFO - Epoch 664: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:04:00,643 - INFO - ####################Training epoch 665####################
2025-02-03 18:04:00,950 - INFO - Epoch 665: train_loss=0.8382
2025-02-03 18:04:01,538 - INFO - Epoch 665: val_loss=2.5573, val_acc=33.33%
2025-02-03 18:04:01,544 - INFO - Epoch 665: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:04:01,554 - INFO - ####################Training epoch 666####################
2025-02-03 18:04:02,009 - INFO - Epoch 666: train_loss=0.8369
2025-02-03 18:04:02,677 - INFO - Epoch 666: val_loss=2.5548, val_acc=33.33%
2025-02-03 18:04:02,680 - INFO - Epoch 666: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:04:02,683 - INFO - ####################Training epoch 667####################
2025-02-03 18:04:03,101 - INFO - Epoch 667: train_loss=0.8387
2025-02-03 18:04:03,872 - INFO - Epoch 667: val_loss=2.5534, val_acc=33.33%
2025-02-03 18:04:03,875 - INFO - Epoch 667: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:04:03,878 - INFO - ####################Training epoch 668####################
2025-02-03 18:04:04,211 - INFO - Epoch 668: train_loss=0.8393
2025-02-03 18:04:04,865 - INFO - Epoch 668: val_loss=2.5560, val_acc=33.33%
2025-02-03 18:04:04,870 - INFO - Epoch 668: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:04:04,880 - INFO - ####################Training epoch 669####################
2025-02-03 18:04:05,200 - INFO - Epoch 669: train_loss=0.8393
2025-02-03 18:04:05,783 - INFO - Epoch 669: val_loss=2.5566, val_acc=33.33%
2025-02-03 18:04:05,787 - INFO - Epoch 669: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:04:05,795 - INFO - ####################Training epoch 670####################
2025-02-03 18:04:06,260 - INFO - Epoch 670: train_loss=0.8391
2025-02-03 18:04:06,935 - INFO - Epoch 670: val_loss=2.5536, val_acc=33.33%
2025-02-03 18:04:06,938 - INFO - Epoch 670: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:04:06,941 - INFO - ####################Training epoch 671####################
2025-02-03 18:04:07,369 - INFO - Epoch 671: train_loss=0.8382
2025-02-03 18:04:08,144 - INFO - Epoch 671: val_loss=2.5473, val_acc=33.33%
2025-02-03 18:04:08,148 - INFO - Epoch 671: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:04:08,151 - INFO - ####################Training epoch 672####################
2025-02-03 18:04:08,491 - INFO - Epoch 672: train_loss=0.8395
2025-02-03 18:04:09,144 - INFO - Epoch 672: val_loss=2.5475, val_acc=33.33%
2025-02-03 18:04:09,149 - INFO - Epoch 672: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:04:09,159 - INFO - ####################Training epoch 673####################
2025-02-03 18:04:09,478 - INFO - Epoch 673: train_loss=0.8384
2025-02-03 18:04:10,070 - INFO - Epoch 673: val_loss=2.5541, val_acc=33.33%
2025-02-03 18:04:10,075 - INFO - Epoch 673: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:04:10,086 - INFO - ####################Training epoch 674####################
2025-02-03 18:04:10,537 - INFO - Epoch 674: train_loss=0.8377
2025-02-03 18:04:11,215 - INFO - Epoch 674: val_loss=2.5547, val_acc=33.33%
2025-02-03 18:04:11,218 - INFO - Epoch 674: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:04:11,221 - INFO - ####################Training epoch 675####################
2025-02-03 18:04:11,643 - INFO - Epoch 675: train_loss=0.8403
2025-02-03 18:04:12,414 - INFO - Epoch 675: val_loss=2.5503, val_acc=33.33%
2025-02-03 18:04:12,418 - INFO - Epoch 675: EPOCH_AVG_TRAIN_LOSS=0.8403
2025-02-03 18:04:12,420 - INFO - ####################Training epoch 676####################
2025-02-03 18:04:12,756 - INFO - Epoch 676: train_loss=0.8395
2025-02-03 18:04:13,408 - INFO - Epoch 676: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:04:13,413 - INFO - Epoch 676: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:04:13,423 - INFO - ####################Training epoch 677####################
2025-02-03 18:04:13,746 - INFO - Epoch 677: train_loss=0.8401
2025-02-03 18:04:14,339 - INFO - Epoch 677: val_loss=2.5581, val_acc=33.33%
2025-02-03 18:04:14,345 - INFO - Epoch 677: EPOCH_AVG_TRAIN_LOSS=0.8401
2025-02-03 18:04:14,355 - INFO - ####################Training epoch 678####################
2025-02-03 18:04:14,806 - INFO - Epoch 678: train_loss=0.8385
2025-02-03 18:04:15,479 - INFO - Epoch 678: val_loss=2.5536, val_acc=33.33%
2025-02-03 18:04:15,483 - INFO - Epoch 678: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:04:15,485 - INFO - ####################Training epoch 679####################
2025-02-03 18:04:15,879 - INFO - Epoch 679: train_loss=0.8390
2025-02-03 18:04:16,645 - INFO - Epoch 679: val_loss=2.5495, val_acc=33.33%
2025-02-03 18:04:16,649 - INFO - Epoch 679: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:04:16,660 - INFO - ####################Training epoch 680####################
2025-02-03 18:04:16,986 - INFO - Epoch 680: train_loss=0.8375
2025-02-03 18:04:17,605 - INFO - Epoch 680: val_loss=2.5584, val_acc=33.33%
2025-02-03 18:04:17,609 - INFO - Epoch 680: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:04:17,619 - INFO - ####################Training epoch 681####################
2025-02-03 18:04:17,991 - INFO - Epoch 681: train_loss=0.8387
2025-02-03 18:04:18,503 - INFO - Epoch 681: val_loss=2.5461, val_acc=33.33%
2025-02-03 18:04:18,507 - INFO - Epoch 681: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:04:18,510 - INFO - ####################Training epoch 682####################
2025-02-03 18:04:18,954 - INFO - Epoch 682: train_loss=0.8368
2025-02-03 18:04:19,619 - INFO - Epoch 682: val_loss=2.5556, val_acc=33.33%
2025-02-03 18:04:19,622 - INFO - Epoch 682: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:04:19,625 - INFO - ####################Training epoch 683####################
2025-02-03 18:04:19,922 - INFO - Epoch 683: train_loss=0.8378
2025-02-03 18:04:20,628 - INFO - Epoch 683: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:04:20,633 - INFO - Epoch 683: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:04:20,639 - INFO - ####################Training epoch 684####################
2025-02-03 18:04:20,926 - INFO - Epoch 684: train_loss=0.8377
2025-02-03 18:04:21,529 - INFO - Epoch 684: val_loss=2.5482, val_acc=33.33%
2025-02-03 18:04:21,533 - INFO - Epoch 684: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:04:21,544 - INFO - ####################Training epoch 685####################
2025-02-03 18:04:21,974 - INFO - Epoch 685: train_loss=0.8382
2025-02-03 18:04:22,607 - INFO - Epoch 685: val_loss=2.5535, val_acc=33.33%
2025-02-03 18:04:22,611 - INFO - Epoch 685: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:04:22,613 - INFO - ####################Training epoch 686####################
2025-02-03 18:04:23,033 - INFO - Epoch 686: train_loss=0.8366
2025-02-03 18:04:23,766 - INFO - Epoch 686: val_loss=2.5517, val_acc=33.33%
2025-02-03 18:04:23,769 - INFO - Epoch 686: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 18:04:23,772 - INFO - ####################Training epoch 687####################
2025-02-03 18:04:24,079 - INFO - Epoch 687: train_loss=0.8388
2025-02-03 18:04:24,766 - INFO - Epoch 687: val_loss=2.5515, val_acc=33.33%
2025-02-03 18:04:24,771 - INFO - Epoch 687: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:04:24,781 - INFO - ####################Training epoch 688####################
2025-02-03 18:04:25,074 - INFO - Epoch 688: train_loss=0.8393
2025-02-03 18:04:25,655 - INFO - Epoch 688: val_loss=2.5496, val_acc=33.33%
2025-02-03 18:04:25,660 - INFO - Epoch 688: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:04:25,671 - INFO - ####################Training epoch 689####################
2025-02-03 18:04:26,113 - INFO - Epoch 689: train_loss=0.8404
2025-02-03 18:04:26,780 - INFO - Epoch 689: val_loss=2.5506, val_acc=33.33%
2025-02-03 18:04:26,783 - INFO - Epoch 689: EPOCH_AVG_TRAIN_LOSS=0.8404
2025-02-03 18:04:26,786 - INFO - ####################Training epoch 690####################
2025-02-03 18:04:27,209 - INFO - Epoch 690: train_loss=0.8379
2025-02-03 18:04:27,979 - INFO - Epoch 690: val_loss=2.5534, val_acc=33.33%
2025-02-03 18:04:27,983 - INFO - Epoch 690: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:04:27,985 - INFO - ####################Training epoch 691####################
2025-02-03 18:04:28,319 - INFO - Epoch 691: train_loss=0.8386
2025-02-03 18:04:28,970 - INFO - Epoch 691: val_loss=2.5523, val_acc=33.33%
2025-02-03 18:04:28,975 - INFO - Epoch 691: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:04:28,985 - INFO - ####################Training epoch 692####################
2025-02-03 18:04:29,307 - INFO - Epoch 692: train_loss=0.8371
2025-02-03 18:04:29,856 - INFO - Epoch 692: val_loss=2.5474, val_acc=33.33%
2025-02-03 18:04:29,861 - INFO - Epoch 692: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:04:29,871 - INFO - ####################Training epoch 693####################
2025-02-03 18:04:30,342 - INFO - Epoch 693: train_loss=0.8390
2025-02-03 18:04:31,020 - INFO - Epoch 693: val_loss=2.5541, val_acc=33.33%
2025-02-03 18:04:31,027 - INFO - Epoch 693: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:04:31,036 - INFO - ####################Training epoch 694####################
2025-02-03 18:04:31,398 - INFO - Epoch 694: train_loss=0.8370
2025-02-03 18:04:32,169 - INFO - Epoch 694: val_loss=2.5509, val_acc=33.33%
2025-02-03 18:04:32,173 - INFO - Epoch 694: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:04:32,184 - INFO - ####################Training epoch 695####################
2025-02-03 18:04:32,508 - INFO - Epoch 695: train_loss=0.8371
2025-02-03 18:04:33,167 - INFO - Epoch 695: val_loss=2.5452, val_acc=33.33%
2025-02-03 18:04:33,172 - INFO - Epoch 695: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:04:33,182 - INFO - ####################Training epoch 696####################
2025-02-03 18:04:33,520 - INFO - Epoch 696: train_loss=0.8399
2025-02-03 18:04:34,086 - INFO - Epoch 696: val_loss=2.5481, val_acc=33.33%
2025-02-03 18:04:34,090 - INFO - Epoch 696: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 18:04:34,101 - INFO - ####################Training epoch 697####################
2025-02-03 18:04:34,577 - INFO - Epoch 697: train_loss=0.8381
2025-02-03 18:04:35,254 - INFO - Epoch 697: val_loss=2.5526, val_acc=33.33%
2025-02-03 18:04:35,257 - INFO - Epoch 697: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:04:35,260 - INFO - ####################Training epoch 698####################
2025-02-03 18:04:35,683 - INFO - Epoch 698: train_loss=0.8396
2025-02-03 18:04:36,454 - INFO - Epoch 698: val_loss=2.5579, val_acc=33.33%
2025-02-03 18:04:36,458 - INFO - Epoch 698: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:04:36,460 - INFO - ####################Training epoch 699####################
2025-02-03 18:04:36,792 - INFO - Epoch 699: train_loss=0.8376
2025-02-03 18:04:37,461 - INFO - Epoch 699: val_loss=2.5553, val_acc=33.33%
2025-02-03 18:04:37,465 - INFO - Epoch 699: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:04:37,474 - INFO - ####################Training epoch 700####################
2025-02-03 18:04:37,785 - INFO - Epoch 700: train_loss=0.8377
2025-02-03 18:04:38,376 - INFO - Epoch 700: val_loss=2.5570, val_acc=33.33%
2025-02-03 18:04:38,381 - INFO - Epoch 700: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:04:38,392 - INFO - ####################Training epoch 701####################
2025-02-03 18:04:38,843 - INFO - Epoch 701: train_loss=0.8383
2025-02-03 18:04:39,516 - INFO - Epoch 701: val_loss=2.5571, val_acc=33.33%
2025-02-03 18:04:39,519 - INFO - Epoch 701: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:04:39,522 - INFO - ####################Training epoch 702####################
2025-02-03 18:04:39,947 - INFO - Epoch 702: train_loss=0.8396
2025-02-03 18:04:40,717 - INFO - Epoch 702: val_loss=2.5536, val_acc=33.33%
2025-02-03 18:04:40,720 - INFO - Epoch 702: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:04:40,723 - INFO - ####################Training epoch 703####################
2025-02-03 18:04:41,059 - INFO - Epoch 703: train_loss=0.8375
2025-02-03 18:04:41,739 - INFO - Epoch 703: val_loss=2.5584, val_acc=33.33%
2025-02-03 18:04:41,744 - INFO - Epoch 703: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:04:41,748 - INFO - ####################Training epoch 704####################
2025-02-03 18:04:42,050 - INFO - Epoch 704: train_loss=0.8380
2025-02-03 18:04:42,645 - INFO - Epoch 704: val_loss=2.5495, val_acc=33.33%
2025-02-03 18:04:42,649 - INFO - Epoch 704: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:04:42,660 - INFO - ####################Training epoch 705####################
2025-02-03 18:04:43,111 - INFO - Epoch 705: train_loss=0.8378
2025-02-03 18:04:43,789 - INFO - Epoch 705: val_loss=2.5529, val_acc=33.33%
2025-02-03 18:04:43,793 - INFO - Epoch 705: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:04:43,795 - INFO - ####################Training epoch 706####################
2025-02-03 18:04:44,219 - INFO - Epoch 706: train_loss=0.8406
2025-02-03 18:04:44,990 - INFO - Epoch 706: val_loss=2.5574, val_acc=33.33%
2025-02-03 18:04:44,993 - INFO - Epoch 706: EPOCH_AVG_TRAIN_LOSS=0.8406
2025-02-03 18:04:44,996 - INFO - ####################Training epoch 707####################
2025-02-03 18:04:45,328 - INFO - Epoch 707: train_loss=0.8385
2025-02-03 18:04:45,981 - INFO - Epoch 707: val_loss=2.5547, val_acc=33.33%
2025-02-03 18:04:45,986 - INFO - Epoch 707: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:04:45,996 - INFO - ####################Training epoch 708####################
2025-02-03 18:04:46,319 - INFO - Epoch 708: train_loss=0.8368
2025-02-03 18:04:46,916 - INFO - Epoch 708: val_loss=2.5518, val_acc=33.33%
2025-02-03 18:04:46,920 - INFO - Epoch 708: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:04:46,930 - INFO - ####################Training epoch 709####################
2025-02-03 18:04:47,386 - INFO - Epoch 709: train_loss=0.8376
2025-02-03 18:04:48,062 - INFO - Epoch 709: val_loss=2.5541, val_acc=33.33%
2025-02-03 18:04:48,065 - INFO - Epoch 709: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:04:48,068 - INFO - ####################Training epoch 710####################
2025-02-03 18:04:48,490 - INFO - Epoch 710: train_loss=0.8374
2025-02-03 18:04:49,262 - INFO - Epoch 710: val_loss=2.5579, val_acc=33.33%
2025-02-03 18:04:49,266 - INFO - Epoch 710: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:04:49,268 - INFO - ####################Training epoch 711####################
2025-02-03 18:04:49,605 - INFO - Epoch 711: train_loss=0.8381
2025-02-03 18:04:50,285 - INFO - Epoch 711: val_loss=2.5535, val_acc=33.33%
2025-02-03 18:04:50,291 - INFO - Epoch 711: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:04:50,300 - INFO - ####################Training epoch 712####################
2025-02-03 18:04:50,601 - INFO - Epoch 712: train_loss=0.8388
2025-02-03 18:04:51,188 - INFO - Epoch 712: val_loss=2.5496, val_acc=33.33%
2025-02-03 18:04:51,192 - INFO - Epoch 712: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:04:51,203 - INFO - ####################Training epoch 713####################
2025-02-03 18:04:51,655 - INFO - Epoch 713: train_loss=0.8383
2025-02-03 18:04:52,330 - INFO - Epoch 713: val_loss=2.5525, val_acc=33.33%
2025-02-03 18:04:52,333 - INFO - Epoch 713: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:04:52,336 - INFO - ####################Training epoch 714####################
2025-02-03 18:04:52,758 - INFO - Epoch 714: train_loss=0.8395
2025-02-03 18:04:53,528 - INFO - Epoch 714: val_loss=2.5531, val_acc=33.33%
2025-02-03 18:04:53,532 - INFO - Epoch 714: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:04:53,534 - INFO - ####################Training epoch 715####################
2025-02-03 18:04:53,865 - INFO - Epoch 715: train_loss=0.8370
2025-02-03 18:04:54,516 - INFO - Epoch 715: val_loss=2.5546, val_acc=33.33%
2025-02-03 18:04:54,521 - INFO - Epoch 715: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:04:54,531 - INFO - ####################Training epoch 716####################
2025-02-03 18:04:54,855 - INFO - Epoch 716: train_loss=0.8360
2025-02-03 18:04:55,449 - INFO - Epoch 716: val_loss=2.5472, val_acc=33.33%
2025-02-03 18:04:55,454 - INFO - Epoch 716: EPOCH_AVG_TRAIN_LOSS=0.8360
2025-02-03 18:04:55,465 - INFO - ####################Training epoch 717####################
2025-02-03 18:04:55,916 - INFO - Epoch 717: train_loss=0.8403
2025-02-03 18:04:56,592 - INFO - Epoch 717: val_loss=2.5502, val_acc=33.33%
2025-02-03 18:04:56,595 - INFO - Epoch 717: EPOCH_AVG_TRAIN_LOSS=0.8403
2025-02-03 18:04:56,598 - INFO - ####################Training epoch 718####################
2025-02-03 18:04:57,020 - INFO - Epoch 718: train_loss=0.8389
2025-02-03 18:04:57,789 - INFO - Epoch 718: val_loss=2.5564, val_acc=33.33%
2025-02-03 18:04:57,793 - INFO - Epoch 718: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:04:57,795 - INFO - ####################Training epoch 719####################
2025-02-03 18:04:58,129 - INFO - Epoch 719: train_loss=0.8371
2025-02-03 18:04:58,807 - INFO - Epoch 719: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:04:58,813 - INFO - Epoch 719: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:04:58,817 - INFO - ####################Training epoch 720####################
2025-02-03 18:04:59,120 - INFO - Epoch 720: train_loss=0.8380
2025-02-03 18:04:59,715 - INFO - Epoch 720: val_loss=2.5545, val_acc=33.33%
2025-02-03 18:04:59,719 - INFO - Epoch 720: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:04:59,726 - INFO - ####################Training epoch 721####################
2025-02-03 18:05:00,166 - INFO - Epoch 721: train_loss=0.8367
2025-02-03 18:05:00,841 - INFO - Epoch 721: val_loss=2.5526, val_acc=33.33%
2025-02-03 18:05:00,844 - INFO - Epoch 721: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:05:00,846 - INFO - ####################Training epoch 722####################
2025-02-03 18:05:01,267 - INFO - Epoch 722: train_loss=0.8383
2025-02-03 18:05:02,041 - INFO - Epoch 722: val_loss=2.5583, val_acc=33.33%
2025-02-03 18:05:02,045 - INFO - Epoch 722: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:05:02,047 - INFO - ####################Training epoch 723####################
2025-02-03 18:05:02,386 - INFO - Epoch 723: train_loss=0.8390
2025-02-03 18:05:03,038 - INFO - Epoch 723: val_loss=2.5540, val_acc=33.33%
2025-02-03 18:05:03,043 - INFO - Epoch 723: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:05:03,053 - INFO - ####################Training epoch 724####################
2025-02-03 18:05:03,375 - INFO - Epoch 724: train_loss=0.8376
2025-02-03 18:05:03,970 - INFO - Epoch 724: val_loss=2.5502, val_acc=33.33%
2025-02-03 18:05:03,975 - INFO - Epoch 724: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:05:03,986 - INFO - ####################Training epoch 725####################
2025-02-03 18:05:04,441 - INFO - Epoch 725: train_loss=0.8390
2025-02-03 18:05:05,112 - INFO - Epoch 725: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:05:05,116 - INFO - Epoch 725: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:05:05,118 - INFO - ####################Training epoch 726####################
2025-02-03 18:05:05,538 - INFO - Epoch 726: train_loss=0.8384
2025-02-03 18:05:06,309 - INFO - Epoch 726: val_loss=2.5536, val_acc=33.33%
2025-02-03 18:05:06,312 - INFO - Epoch 726: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:05:06,315 - INFO - ####################Training epoch 727####################
2025-02-03 18:05:06,649 - INFO - Epoch 727: train_loss=0.8396
2025-02-03 18:05:07,311 - INFO - Epoch 727: val_loss=2.5515, val_acc=33.33%
2025-02-03 18:05:07,315 - INFO - Epoch 727: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:05:07,331 - INFO - ####################Training epoch 728####################
2025-02-03 18:05:07,654 - INFO - Epoch 728: train_loss=0.8382
2025-02-03 18:05:08,240 - INFO - Epoch 728: val_loss=2.5527, val_acc=33.33%
2025-02-03 18:05:08,245 - INFO - Epoch 728: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:05:08,256 - INFO - ####################Training epoch 729####################
2025-02-03 18:05:08,695 - INFO - Epoch 729: train_loss=0.8383
2025-02-03 18:05:09,371 - INFO - Epoch 729: val_loss=2.5485, val_acc=33.33%
2025-02-03 18:05:09,375 - INFO - Epoch 729: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:05:09,377 - INFO - ####################Training epoch 730####################
2025-02-03 18:05:09,801 - INFO - Epoch 730: train_loss=0.8377
2025-02-03 18:05:10,572 - INFO - Epoch 730: val_loss=2.5544, val_acc=33.33%
2025-02-03 18:05:10,576 - INFO - Epoch 730: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:05:10,578 - INFO - ####################Training epoch 731####################
2025-02-03 18:05:10,916 - INFO - Epoch 731: train_loss=0.8395
2025-02-03 18:05:11,571 - INFO - Epoch 731: val_loss=2.5549, val_acc=33.33%
2025-02-03 18:05:11,575 - INFO - Epoch 731: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:05:11,586 - INFO - ####################Training epoch 732####################
2025-02-03 18:05:11,906 - INFO - Epoch 732: train_loss=0.8399
2025-02-03 18:05:12,451 - INFO - Epoch 732: val_loss=2.5537, val_acc=33.33%
2025-02-03 18:05:12,457 - INFO - Epoch 732: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 18:05:12,468 - INFO - ####################Training epoch 733####################
2025-02-03 18:05:12,946 - INFO - Epoch 733: train_loss=0.8391
2025-02-03 18:05:13,627 - INFO - Epoch 733: val_loss=2.5529, val_acc=33.33%
2025-02-03 18:05:13,634 - INFO - Epoch 733: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:05:13,643 - INFO - ####################Training epoch 734####################
2025-02-03 18:05:14,006 - INFO - Epoch 734: train_loss=0.8373
2025-02-03 18:05:14,774 - INFO - Epoch 734: val_loss=2.5584, val_acc=33.33%
2025-02-03 18:05:14,779 - INFO - Epoch 734: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:05:14,789 - INFO - ####################Training epoch 735####################
2025-02-03 18:05:15,112 - INFO - Epoch 735: train_loss=0.8372
2025-02-03 18:05:15,731 - INFO - Epoch 735: val_loss=2.5537, val_acc=33.33%
2025-02-03 18:05:15,735 - INFO - Epoch 735: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:05:15,745 - INFO - ####################Training epoch 736####################
2025-02-03 18:05:16,122 - INFO - Epoch 736: train_loss=0.8360
2025-02-03 18:05:16,658 - INFO - Epoch 736: val_loss=2.5589, val_acc=33.33%
2025-02-03 18:05:16,664 - INFO - Epoch 736: EPOCH_AVG_TRAIN_LOSS=0.8360
2025-02-03 18:05:16,675 - INFO - ####################Training epoch 737####################
2025-02-03 18:05:17,154 - INFO - Epoch 737: train_loss=0.8395
2025-02-03 18:05:17,835 - INFO - Epoch 737: val_loss=2.5533, val_acc=33.33%
2025-02-03 18:05:17,841 - INFO - Epoch 737: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:05:17,849 - INFO - ####################Training epoch 738####################
2025-02-03 18:05:18,212 - INFO - Epoch 738: train_loss=0.8363
2025-02-03 18:05:18,942 - INFO - Epoch 738: val_loss=2.5532, val_acc=33.33%
2025-02-03 18:05:18,947 - INFO - Epoch 738: EPOCH_AVG_TRAIN_LOSS=0.8363
2025-02-03 18:05:18,957 - INFO - ####################Training epoch 739####################
2025-02-03 18:05:19,260 - INFO - Epoch 739: train_loss=0.8382
2025-02-03 18:05:19,850 - INFO - Epoch 739: val_loss=2.5539, val_acc=33.33%
2025-02-03 18:05:19,855 - INFO - Epoch 739: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:05:19,865 - INFO - ####################Training epoch 740####################
2025-02-03 18:05:20,281 - INFO - Epoch 740: train_loss=0.8390
2025-02-03 18:05:20,814 - INFO - Epoch 740: val_loss=2.5508, val_acc=33.33%
2025-02-03 18:05:20,818 - INFO - Epoch 740: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:05:20,821 - INFO - ####################Training epoch 741####################
2025-02-03 18:05:21,284 - INFO - Epoch 741: train_loss=0.8384
2025-02-03 18:05:21,944 - INFO - Epoch 741: val_loss=2.5549, val_acc=33.33%
2025-02-03 18:05:21,947 - INFO - Epoch 741: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:05:21,950 - INFO - ####################Training epoch 742####################
2025-02-03 18:05:22,248 - INFO - Epoch 742: train_loss=0.8370
2025-02-03 18:05:22,954 - INFO - Epoch 742: val_loss=2.5533, val_acc=33.33%
2025-02-03 18:05:22,960 - INFO - Epoch 742: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:05:22,965 - INFO - ####################Training epoch 743####################
2025-02-03 18:05:23,254 - INFO - Epoch 743: train_loss=0.8372
2025-02-03 18:05:23,829 - INFO - Epoch 743: val_loss=2.5582, val_acc=33.33%
2025-02-03 18:05:23,834 - INFO - Epoch 743: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:05:23,844 - INFO - ####################Training epoch 744####################
2025-02-03 18:05:24,273 - INFO - Epoch 744: train_loss=0.8392
2025-02-03 18:05:24,960 - INFO - Epoch 744: val_loss=2.5565, val_acc=33.33%
2025-02-03 18:05:24,963 - INFO - Epoch 744: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:05:24,966 - INFO - ####################Training epoch 745####################
2025-02-03 18:05:25,388 - INFO - Epoch 745: train_loss=0.8386
2025-02-03 18:05:26,159 - INFO - Epoch 745: val_loss=2.5471, val_acc=33.33%
2025-02-03 18:05:26,163 - INFO - Epoch 745: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:05:26,165 - INFO - ####################Training epoch 746####################
2025-02-03 18:05:26,500 - INFO - Epoch 746: train_loss=0.8380
2025-02-03 18:05:27,154 - INFO - Epoch 746: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:05:27,159 - INFO - Epoch 746: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:05:27,169 - INFO - ####################Training epoch 747####################
2025-02-03 18:05:27,490 - INFO - Epoch 747: train_loss=0.8387
2025-02-03 18:05:28,056 - INFO - Epoch 747: val_loss=2.5536, val_acc=33.33%
2025-02-03 18:05:28,060 - INFO - Epoch 747: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:05:28,071 - INFO - ####################Training epoch 748####################
2025-02-03 18:05:28,528 - INFO - Epoch 748: train_loss=0.8379
2025-02-03 18:05:29,211 - INFO - Epoch 748: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:05:29,216 - INFO - Epoch 748: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:05:29,221 - INFO - ####################Training epoch 749####################
2025-02-03 18:05:29,581 - INFO - Epoch 749: train_loss=0.8359
2025-02-03 18:05:30,348 - INFO - Epoch 749: val_loss=2.5519, val_acc=33.33%
2025-02-03 18:05:30,353 - INFO - Epoch 749: EPOCH_AVG_TRAIN_LOSS=0.8359
2025-02-03 18:05:30,363 - INFO - ####################Training epoch 750####################
2025-02-03 18:05:30,674 - INFO - Epoch 750: train_loss=0.8367
2025-02-03 18:05:31,255 - INFO - Epoch 750: val_loss=2.5555, val_acc=33.33%
2025-02-03 18:05:31,260 - INFO - Epoch 750: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:05:31,270 - INFO - ####################Training epoch 751####################
2025-02-03 18:05:31,689 - INFO - Epoch 751: train_loss=0.8388
2025-02-03 18:05:32,226 - INFO - Epoch 751: val_loss=2.5561, val_acc=33.33%
2025-02-03 18:05:32,230 - INFO - Epoch 751: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:05:32,233 - INFO - ####################Training epoch 752####################
2025-02-03 18:05:32,693 - INFO - Epoch 752: train_loss=0.8381
2025-02-03 18:05:33,363 - INFO - Epoch 752: val_loss=2.5537, val_acc=33.33%
2025-02-03 18:05:33,366 - INFO - Epoch 752: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:05:33,368 - INFO - ####################Training epoch 753####################
2025-02-03 18:05:33,675 - INFO - Epoch 753: train_loss=0.8375
2025-02-03 18:05:34,390 - INFO - Epoch 753: val_loss=2.5493, val_acc=33.33%
2025-02-03 18:05:34,397 - INFO - Epoch 753: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:05:34,407 - INFO - ####################Training epoch 754####################
2025-02-03 18:05:34,696 - INFO - Epoch 754: train_loss=0.8389
2025-02-03 18:05:35,292 - INFO - Epoch 754: val_loss=2.5567, val_acc=33.33%
2025-02-03 18:05:35,297 - INFO - Epoch 754: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:05:35,307 - INFO - ####################Training epoch 755####################
2025-02-03 18:05:35,719 - INFO - Epoch 755: train_loss=0.8369
2025-02-03 18:05:36,350 - INFO - Epoch 755: val_loss=2.5494, val_acc=33.33%
2025-02-03 18:05:36,354 - INFO - Epoch 755: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:05:36,356 - INFO - ####################Training epoch 756####################
2025-02-03 18:05:36,777 - INFO - Epoch 756: train_loss=0.8392
2025-02-03 18:05:37,508 - INFO - Epoch 756: val_loss=2.5472, val_acc=33.33%
2025-02-03 18:05:37,512 - INFO - Epoch 756: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:05:37,514 - INFO - ####################Training epoch 757####################
2025-02-03 18:05:37,822 - INFO - Epoch 757: train_loss=0.8389
2025-02-03 18:05:38,507 - INFO - Epoch 757: val_loss=2.5550, val_acc=33.33%
2025-02-03 18:05:38,512 - INFO - Epoch 757: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:05:38,522 - INFO - ####################Training epoch 758####################
2025-02-03 18:05:38,816 - INFO - Epoch 758: train_loss=0.8371
2025-02-03 18:05:39,402 - INFO - Epoch 758: val_loss=2.5571, val_acc=33.33%
2025-02-03 18:05:39,408 - INFO - Epoch 758: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:05:39,418 - INFO - ####################Training epoch 759####################
2025-02-03 18:05:39,858 - INFO - Epoch 759: train_loss=0.8373
2025-02-03 18:05:40,531 - INFO - Epoch 759: val_loss=2.5549, val_acc=33.33%
2025-02-03 18:05:40,535 - INFO - Epoch 759: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:05:40,537 - INFO - ####################Training epoch 760####################
2025-02-03 18:05:40,964 - INFO - Epoch 760: train_loss=0.8394
2025-02-03 18:05:41,768 - INFO - Epoch 760: val_loss=2.5542, val_acc=33.33%
2025-02-03 18:05:41,772 - INFO - Epoch 760: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:05:41,774 - INFO - ####################Training epoch 761####################
2025-02-03 18:05:42,091 - INFO - Epoch 761: train_loss=0.8383
2025-02-03 18:05:42,765 - INFO - Epoch 761: val_loss=2.5486, val_acc=33.33%
2025-02-03 18:05:42,770 - INFO - Epoch 761: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:05:42,775 - INFO - ####################Training epoch 762####################
2025-02-03 18:05:43,077 - INFO - Epoch 762: train_loss=0.8373
2025-02-03 18:05:43,664 - INFO - Epoch 762: val_loss=2.5470, val_acc=33.33%
2025-02-03 18:05:43,670 - INFO - Epoch 762: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:05:43,680 - INFO - ####################Training epoch 763####################
2025-02-03 18:05:44,131 - INFO - Epoch 763: train_loss=0.8380
2025-02-03 18:05:44,806 - INFO - Epoch 763: val_loss=2.5550, val_acc=33.33%
2025-02-03 18:05:44,810 - INFO - Epoch 763: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:05:44,812 - INFO - ####################Training epoch 764####################
2025-02-03 18:05:45,239 - INFO - Epoch 764: train_loss=0.8372
2025-02-03 18:05:46,008 - INFO - Epoch 764: val_loss=2.5562, val_acc=33.33%
2025-02-03 18:05:46,012 - INFO - Epoch 764: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:05:46,014 - INFO - ####################Training epoch 765####################
2025-02-03 18:05:46,350 - INFO - Epoch 765: train_loss=0.8393
2025-02-03 18:05:47,004 - INFO - Epoch 765: val_loss=2.5553, val_acc=33.33%
2025-02-03 18:05:47,009 - INFO - Epoch 765: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:05:47,019 - INFO - ####################Training epoch 766####################
2025-02-03 18:05:47,344 - INFO - Epoch 766: train_loss=0.8368
2025-02-03 18:05:47,941 - INFO - Epoch 766: val_loss=2.5538, val_acc=33.33%
2025-02-03 18:05:47,946 - INFO - Epoch 766: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:05:47,957 - INFO - ####################Training epoch 767####################
2025-02-03 18:05:48,406 - INFO - Epoch 767: train_loss=0.8378
2025-02-03 18:05:49,083 - INFO - Epoch 767: val_loss=2.5529, val_acc=33.33%
2025-02-03 18:05:49,087 - INFO - Epoch 767: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:05:49,090 - INFO - ####################Training epoch 768####################
2025-02-03 18:05:49,514 - INFO - Epoch 768: train_loss=0.8370
2025-02-03 18:05:50,292 - INFO - Epoch 768: val_loss=2.5495, val_acc=33.33%
2025-02-03 18:05:50,296 - INFO - Epoch 768: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:05:50,298 - INFO - ####################Training epoch 769####################
2025-02-03 18:05:50,678 - INFO - Epoch 769: train_loss=0.8390
2025-02-03 18:05:51,334 - INFO - Epoch 769: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:05:51,338 - INFO - Epoch 769: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:05:51,349 - INFO - ####################Training epoch 770####################
2025-02-03 18:05:51,667 - INFO - Epoch 770: train_loss=0.8373
2025-02-03 18:05:52,260 - INFO - Epoch 770: val_loss=2.5506, val_acc=33.33%
2025-02-03 18:05:52,265 - INFO - Epoch 770: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:05:52,276 - INFO - ####################Training epoch 771####################
2025-02-03 18:05:52,727 - INFO - Epoch 771: train_loss=0.8379
2025-02-03 18:05:53,400 - INFO - Epoch 771: val_loss=2.5502, val_acc=33.33%
2025-02-03 18:05:53,404 - INFO - Epoch 771: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:05:53,407 - INFO - ####################Training epoch 772####################
2025-02-03 18:05:53,833 - INFO - Epoch 772: train_loss=0.8384
2025-02-03 18:05:54,605 - INFO - Epoch 772: val_loss=2.5527, val_acc=33.33%
2025-02-03 18:05:54,608 - INFO - Epoch 772: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:05:54,611 - INFO - ####################Training epoch 773####################
2025-02-03 18:05:54,952 - INFO - Epoch 773: train_loss=0.8384
2025-02-03 18:05:55,598 - INFO - Epoch 773: val_loss=2.5458, val_acc=33.33%
2025-02-03 18:05:55,602 - INFO - Epoch 773: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:05:55,613 - INFO - ####################Training epoch 774####################
2025-02-03 18:05:55,941 - INFO - Epoch 774: train_loss=0.8391
2025-02-03 18:05:56,512 - INFO - Epoch 774: val_loss=2.5542, val_acc=33.33%
2025-02-03 18:05:56,517 - INFO - Epoch 774: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:05:56,527 - INFO - ####################Training epoch 775####################
2025-02-03 18:05:56,999 - INFO - Epoch 775: train_loss=0.8383
2025-02-03 18:05:57,675 - INFO - Epoch 775: val_loss=2.5509, val_acc=33.33%
2025-02-03 18:05:57,679 - INFO - Epoch 775: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:05:57,682 - INFO - ####################Training epoch 776####################
2025-02-03 18:05:58,106 - INFO - Epoch 776: train_loss=0.8400
2025-02-03 18:05:58,894 - INFO - Epoch 776: val_loss=2.5594, val_acc=33.33%
2025-02-03 18:05:58,898 - INFO - Epoch 776: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 18:05:58,901 - INFO - ####################Training epoch 777####################
2025-02-03 18:05:59,232 - INFO - Epoch 777: train_loss=0.8375
2025-02-03 18:05:59,910 - INFO - Epoch 777: val_loss=2.5511, val_acc=33.33%
2025-02-03 18:05:59,915 - INFO - Epoch 777: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:05:59,922 - INFO - ####################Training epoch 778####################
2025-02-03 18:06:00,220 - INFO - Epoch 778: train_loss=0.8383
2025-02-03 18:06:00,804 - INFO - Epoch 778: val_loss=2.5513, val_acc=33.33%
2025-02-03 18:06:00,809 - INFO - Epoch 778: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:06:00,819 - INFO - ####################Training epoch 779####################
2025-02-03 18:06:01,268 - INFO - Epoch 779: train_loss=0.8369
2025-02-03 18:06:01,940 - INFO - Epoch 779: val_loss=2.5517, val_acc=33.33%
2025-02-03 18:06:01,943 - INFO - Epoch 779: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:06:01,946 - INFO - ####################Training epoch 780####################
2025-02-03 18:06:02,366 - INFO - Epoch 780: train_loss=0.8400
2025-02-03 18:06:03,137 - INFO - Epoch 780: val_loss=2.5497, val_acc=33.33%
2025-02-03 18:06:03,140 - INFO - Epoch 780: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 18:06:03,143 - INFO - ####################Training epoch 781####################
2025-02-03 18:06:03,477 - INFO - Epoch 781: train_loss=0.8372
2025-02-03 18:06:04,134 - INFO - Epoch 781: val_loss=2.5539, val_acc=33.33%
2025-02-03 18:06:04,139 - INFO - Epoch 781: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:06:04,149 - INFO - ####################Training epoch 782####################
2025-02-03 18:06:04,466 - INFO - Epoch 782: train_loss=0.8372
2025-02-03 18:06:05,038 - INFO - Epoch 782: val_loss=2.5547, val_acc=33.33%
2025-02-03 18:06:05,042 - INFO - Epoch 782: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:06:05,053 - INFO - ####################Training epoch 783####################
2025-02-03 18:06:05,526 - INFO - Epoch 783: train_loss=0.8368
2025-02-03 18:06:06,200 - INFO - Epoch 783: val_loss=2.5554, val_acc=33.33%
2025-02-03 18:06:06,204 - INFO - Epoch 783: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:06:06,206 - INFO - ####################Training epoch 784####################
2025-02-03 18:06:06,633 - INFO - Epoch 784: train_loss=0.8371
2025-02-03 18:06:07,427 - INFO - Epoch 784: val_loss=2.5555, val_acc=33.33%
2025-02-03 18:06:07,431 - INFO - Epoch 784: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:06:07,434 - INFO - ####################Training epoch 785####################
2025-02-03 18:06:07,760 - INFO - Epoch 785: train_loss=0.8382
2025-02-03 18:06:08,427 - INFO - Epoch 785: val_loss=2.5571, val_acc=33.33%
2025-02-03 18:06:08,432 - INFO - Epoch 785: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:06:08,440 - INFO - ####################Training epoch 786####################
2025-02-03 18:06:08,749 - INFO - Epoch 786: train_loss=0.8384
2025-02-03 18:06:09,339 - INFO - Epoch 786: val_loss=2.5512, val_acc=33.33%
2025-02-03 18:06:09,343 - INFO - Epoch 786: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:06:09,354 - INFO - ####################Training epoch 787####################
2025-02-03 18:06:09,809 - INFO - Epoch 787: train_loss=0.8379
2025-02-03 18:06:10,480 - INFO - Epoch 787: val_loss=2.5522, val_acc=33.33%
2025-02-03 18:06:10,483 - INFO - Epoch 787: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:06:10,486 - INFO - ####################Training epoch 788####################
2025-02-03 18:06:10,912 - INFO - Epoch 788: train_loss=0.8377
2025-02-03 18:06:11,681 - INFO - Epoch 788: val_loss=2.5545, val_acc=33.33%
2025-02-03 18:06:11,684 - INFO - Epoch 788: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:06:11,687 - INFO - ####################Training epoch 789####################
2025-02-03 18:06:12,026 - INFO - Epoch 789: train_loss=0.8390
2025-02-03 18:06:12,677 - INFO - Epoch 789: val_loss=2.5494, val_acc=33.33%
2025-02-03 18:06:12,681 - INFO - Epoch 789: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:06:12,692 - INFO - ####################Training epoch 790####################
2025-02-03 18:06:13,016 - INFO - Epoch 790: train_loss=0.8364
2025-02-03 18:06:13,598 - INFO - Epoch 790: val_loss=2.5528, val_acc=33.33%
2025-02-03 18:06:13,602 - INFO - Epoch 790: EPOCH_AVG_TRAIN_LOSS=0.8364
2025-02-03 18:06:13,611 - INFO - ####################Training epoch 791####################
2025-02-03 18:06:14,078 - INFO - Epoch 791: train_loss=0.8377
2025-02-03 18:06:14,753 - INFO - Epoch 791: val_loss=2.5512, val_acc=33.33%
2025-02-03 18:06:14,757 - INFO - Epoch 791: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:06:14,759 - INFO - ####################Training epoch 792####################
2025-02-03 18:06:15,182 - INFO - Epoch 792: train_loss=0.8383
2025-02-03 18:06:15,961 - INFO - Epoch 792: val_loss=2.5519, val_acc=33.33%
2025-02-03 18:06:15,964 - INFO - Epoch 792: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:06:15,967 - INFO - ####################Training epoch 793####################
2025-02-03 18:06:16,294 - INFO - Epoch 793: train_loss=0.8384
2025-02-03 18:06:16,954 - INFO - Epoch 793: val_loss=2.5500, val_acc=33.33%
2025-02-03 18:06:16,959 - INFO - Epoch 793: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:06:16,969 - INFO - ####################Training epoch 794####################
2025-02-03 18:06:17,285 - INFO - Epoch 794: train_loss=0.8384
2025-02-03 18:06:17,872 - INFO - Epoch 794: val_loss=2.5529, val_acc=33.33%
2025-02-03 18:06:17,877 - INFO - Epoch 794: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:06:17,882 - INFO - ####################Training epoch 795####################
2025-02-03 18:06:18,347 - INFO - Epoch 795: train_loss=0.8379
2025-02-03 18:06:19,023 - INFO - Epoch 795: val_loss=2.5527, val_acc=33.33%
2025-02-03 18:06:19,026 - INFO - Epoch 795: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:06:19,029 - INFO - ####################Training epoch 796####################
2025-02-03 18:06:19,454 - INFO - Epoch 796: train_loss=0.8398
2025-02-03 18:06:20,224 - INFO - Epoch 796: val_loss=2.5513, val_acc=33.33%
2025-02-03 18:06:20,227 - INFO - Epoch 796: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:06:20,230 - INFO - ####################Training epoch 797####################
2025-02-03 18:06:20,560 - INFO - Epoch 797: train_loss=0.8363
2025-02-03 18:06:21,220 - INFO - Epoch 797: val_loss=2.5470, val_acc=33.33%
2025-02-03 18:06:21,224 - INFO - Epoch 797: EPOCH_AVG_TRAIN_LOSS=0.8363
2025-02-03 18:06:21,235 - INFO - ####################Training epoch 798####################
2025-02-03 18:06:21,550 - INFO - Epoch 798: train_loss=0.8394
2025-02-03 18:06:22,120 - INFO - Epoch 798: val_loss=2.5561, val_acc=33.33%
2025-02-03 18:06:22,125 - INFO - Epoch 798: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:06:22,135 - INFO - ####################Training epoch 799####################
2025-02-03 18:06:22,610 - INFO - Epoch 799: train_loss=0.8367
2025-02-03 18:06:23,288 - INFO - Epoch 799: val_loss=2.5501, val_acc=33.33%
2025-02-03 18:06:23,291 - INFO - Epoch 799: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:06:23,294 - INFO - ####################Training epoch 800####################
2025-02-03 18:06:23,722 - INFO - Epoch 800: train_loss=0.8379
2025-02-03 18:06:24,496 - INFO - Epoch 800: val_loss=2.5526, val_acc=33.33%
2025-02-03 18:06:24,500 - INFO - Epoch 800: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:06:24,502 - INFO - ####################Training epoch 801####################
2025-02-03 18:06:24,835 - INFO - Epoch 801: train_loss=0.8395
2025-02-03 18:06:25,495 - INFO - Epoch 801: val_loss=2.5595, val_acc=33.33%
2025-02-03 18:06:25,500 - INFO - Epoch 801: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:06:25,510 - INFO - ####################Training epoch 802####################
2025-02-03 18:06:25,825 - INFO - Epoch 802: train_loss=0.8400
2025-02-03 18:06:26,420 - INFO - Epoch 802: val_loss=2.5533, val_acc=33.33%
2025-02-03 18:06:26,425 - INFO - Epoch 802: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 18:06:26,437 - INFO - ####################Training epoch 803####################
2025-02-03 18:06:26,885 - INFO - Epoch 803: train_loss=0.8366
2025-02-03 18:06:27,561 - INFO - Epoch 803: val_loss=2.5575, val_acc=33.33%
2025-02-03 18:06:27,565 - INFO - Epoch 803: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 18:06:27,567 - INFO - ####################Training epoch 804####################
2025-02-03 18:06:27,988 - INFO - Epoch 804: train_loss=0.8374
2025-02-03 18:06:28,760 - INFO - Epoch 804: val_loss=2.5537, val_acc=33.33%
2025-02-03 18:06:28,764 - INFO - Epoch 804: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:06:28,766 - INFO - ####################Training epoch 805####################
2025-02-03 18:06:29,098 - INFO - Epoch 805: train_loss=0.8386
2025-02-03 18:06:29,749 - INFO - Epoch 805: val_loss=2.5569, val_acc=33.33%
2025-02-03 18:06:29,753 - INFO - Epoch 805: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:06:29,764 - INFO - ####################Training epoch 806####################
2025-02-03 18:06:30,089 - INFO - Epoch 806: train_loss=0.8388
2025-02-03 18:06:30,675 - INFO - Epoch 806: val_loss=2.5544, val_acc=33.33%
2025-02-03 18:06:30,680 - INFO - Epoch 806: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:06:30,683 - INFO - ####################Training epoch 807####################
2025-02-03 18:06:31,150 - INFO - Epoch 807: train_loss=0.8387
2025-02-03 18:06:31,824 - INFO - Epoch 807: val_loss=2.5519, val_acc=33.33%
2025-02-03 18:06:31,828 - INFO - Epoch 807: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:06:31,831 - INFO - ####################Training epoch 808####################
2025-02-03 18:06:32,260 - INFO - Epoch 808: train_loss=0.8397
2025-02-03 18:06:33,040 - INFO - Epoch 808: val_loss=2.5498, val_acc=33.33%
2025-02-03 18:06:33,044 - INFO - Epoch 808: EPOCH_AVG_TRAIN_LOSS=0.8397
2025-02-03 18:06:33,047 - INFO - ####################Training epoch 809####################
2025-02-03 18:06:33,388 - INFO - Epoch 809: train_loss=0.8360
2025-02-03 18:06:34,040 - INFO - Epoch 809: val_loss=2.5585, val_acc=33.33%
2025-02-03 18:06:34,044 - INFO - Epoch 809: EPOCH_AVG_TRAIN_LOSS=0.8360
2025-02-03 18:06:34,055 - INFO - ####################Training epoch 810####################
2025-02-03 18:06:34,377 - INFO - Epoch 810: train_loss=0.8361
2025-02-03 18:06:34,973 - INFO - Epoch 810: val_loss=2.5522, val_acc=33.33%
2025-02-03 18:06:34,977 - INFO - Epoch 810: EPOCH_AVG_TRAIN_LOSS=0.8361
2025-02-03 18:06:34,989 - INFO - ####################Training epoch 811####################
2025-02-03 18:06:35,440 - INFO - Epoch 811: train_loss=0.8387
2025-02-03 18:06:36,111 - INFO - Epoch 811: val_loss=2.5475, val_acc=33.33%
2025-02-03 18:06:36,115 - INFO - Epoch 811: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:06:36,117 - INFO - ####################Training epoch 812####################
2025-02-03 18:06:36,541 - INFO - Epoch 812: train_loss=0.8418
2025-02-03 18:06:37,311 - INFO - Epoch 812: val_loss=2.5539, val_acc=33.33%
2025-02-03 18:06:37,315 - INFO - Epoch 812: EPOCH_AVG_TRAIN_LOSS=0.8418
2025-02-03 18:06:37,317 - INFO - ####################Training epoch 813####################
2025-02-03 18:06:37,648 - INFO - Epoch 813: train_loss=0.8385
2025-02-03 18:06:38,310 - INFO - Epoch 813: val_loss=2.5525, val_acc=33.33%
2025-02-03 18:06:38,315 - INFO - Epoch 813: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:06:38,325 - INFO - ####################Training epoch 814####################
2025-02-03 18:06:38,637 - INFO - Epoch 814: train_loss=0.8365
2025-02-03 18:06:39,217 - INFO - Epoch 814: val_loss=2.5494, val_acc=33.33%
2025-02-03 18:06:39,222 - INFO - Epoch 814: EPOCH_AVG_TRAIN_LOSS=0.8365
2025-02-03 18:06:39,231 - INFO - ####################Training epoch 815####################
2025-02-03 18:06:39,696 - INFO - Epoch 815: train_loss=0.8392
2025-02-03 18:06:40,372 - INFO - Epoch 815: val_loss=2.5553, val_acc=33.33%
2025-02-03 18:06:40,375 - INFO - Epoch 815: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:06:40,378 - INFO - ####################Training epoch 816####################
2025-02-03 18:06:40,799 - INFO - Epoch 816: train_loss=0.8385
2025-02-03 18:06:41,572 - INFO - Epoch 816: val_loss=2.5597, val_acc=33.33%
2025-02-03 18:06:41,576 - INFO - Epoch 816: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:06:41,578 - INFO - ####################Training epoch 817####################
2025-02-03 18:06:41,912 - INFO - Epoch 817: train_loss=0.8380
2025-02-03 18:06:42,568 - INFO - Epoch 817: val_loss=2.5562, val_acc=33.33%
2025-02-03 18:06:42,573 - INFO - Epoch 817: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:06:42,583 - INFO - ####################Training epoch 818####################
2025-02-03 18:06:42,901 - INFO - Epoch 818: train_loss=0.8377
2025-02-03 18:06:43,480 - INFO - Epoch 818: val_loss=2.5515, val_acc=33.33%
2025-02-03 18:06:43,485 - INFO - Epoch 818: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:06:43,495 - INFO - ####################Training epoch 819####################
2025-02-03 18:06:43,966 - INFO - Epoch 819: train_loss=0.8370
2025-02-03 18:06:44,642 - INFO - Epoch 819: val_loss=2.5507, val_acc=33.33%
2025-02-03 18:06:44,645 - INFO - Epoch 819: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:06:44,648 - INFO - ####################Training epoch 820####################
2025-02-03 18:06:45,073 - INFO - Epoch 820: train_loss=0.8362
2025-02-03 18:06:45,844 - INFO - Epoch 820: val_loss=2.5510, val_acc=33.33%
2025-02-03 18:06:45,848 - INFO - Epoch 820: EPOCH_AVG_TRAIN_LOSS=0.8362
2025-02-03 18:06:45,851 - INFO - ####################Training epoch 821####################
2025-02-03 18:06:46,185 - INFO - Epoch 821: train_loss=0.8380
2025-02-03 18:06:46,839 - INFO - Epoch 821: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:06:46,844 - INFO - Epoch 821: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:06:46,854 - INFO - ####################Training epoch 822####################
2025-02-03 18:06:47,175 - INFO - Epoch 822: train_loss=0.8400
2025-02-03 18:06:47,770 - INFO - Epoch 822: val_loss=2.5593, val_acc=33.33%
2025-02-03 18:06:47,775 - INFO - Epoch 822: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 18:06:47,787 - INFO - ####################Training epoch 823####################
2025-02-03 18:06:48,238 - INFO - Epoch 823: train_loss=0.8359
2025-02-03 18:06:48,909 - INFO - Epoch 823: val_loss=2.5528, val_acc=33.33%
2025-02-03 18:06:48,912 - INFO - Epoch 823: EPOCH_AVG_TRAIN_LOSS=0.8359
2025-02-03 18:06:48,915 - INFO - ####################Training epoch 824####################
2025-02-03 18:06:49,336 - INFO - Epoch 824: train_loss=0.8364
2025-02-03 18:06:50,120 - INFO - Epoch 824: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:06:50,124 - INFO - Epoch 824: EPOCH_AVG_TRAIN_LOSS=0.8364
2025-02-03 18:06:50,126 - INFO - ####################Training epoch 825####################
2025-02-03 18:06:50,459 - INFO - Epoch 825: train_loss=0.8384
2025-02-03 18:06:51,120 - INFO - Epoch 825: val_loss=2.5522, val_acc=33.33%
2025-02-03 18:06:51,125 - INFO - Epoch 825: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:06:51,135 - INFO - ####################Training epoch 826####################
2025-02-03 18:06:51,451 - INFO - Epoch 826: train_loss=0.8355
2025-02-03 18:06:52,027 - INFO - Epoch 826: val_loss=2.5483, val_acc=33.33%
2025-02-03 18:06:52,031 - INFO - Epoch 826: EPOCH_AVG_TRAIN_LOSS=0.8355
2025-02-03 18:06:52,041 - INFO - ####################Training epoch 827####################
2025-02-03 18:06:52,507 - INFO - Epoch 827: train_loss=0.8383
2025-02-03 18:06:53,180 - INFO - Epoch 827: val_loss=2.5414, val_acc=33.33%
2025-02-03 18:06:53,184 - INFO - Epoch 827: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:06:53,195 - INFO - ####################Training epoch 828####################
2025-02-03 18:06:53,568 - INFO - Epoch 828: train_loss=0.8382
2025-02-03 18:06:54,342 - INFO - Epoch 828: val_loss=2.5594, val_acc=33.33%
2025-02-03 18:06:54,347 - INFO - Epoch 828: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:06:54,357 - INFO - ####################Training epoch 829####################
2025-02-03 18:06:54,684 - INFO - Epoch 829: train_loss=0.8363
2025-02-03 18:06:55,298 - INFO - Epoch 829: val_loss=2.5582, val_acc=33.33%
2025-02-03 18:06:55,302 - INFO - Epoch 829: EPOCH_AVG_TRAIN_LOSS=0.8363
2025-02-03 18:06:55,312 - INFO - ####################Training epoch 830####################
2025-02-03 18:06:55,693 - INFO - Epoch 830: train_loss=0.8384
2025-02-03 18:06:56,218 - INFO - Epoch 830: val_loss=2.5519, val_acc=33.33%
2025-02-03 18:06:56,224 - INFO - Epoch 830: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:06:56,234 - INFO - ####################Training epoch 831####################
2025-02-03 18:06:56,722 - INFO - Epoch 831: train_loss=0.8391
2025-02-03 18:06:57,390 - INFO - Epoch 831: val_loss=2.5544, val_acc=33.33%
2025-02-03 18:06:57,393 - INFO - Epoch 831: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:06:57,396 - INFO - ####################Training epoch 832####################
2025-02-03 18:06:57,752 - INFO - Epoch 832: train_loss=0.8360
2025-02-03 18:06:58,501 - INFO - Epoch 832: val_loss=2.5527, val_acc=33.33%
2025-02-03 18:06:58,507 - INFO - Epoch 832: EPOCH_AVG_TRAIN_LOSS=0.8360
2025-02-03 18:06:58,517 - INFO - ####################Training epoch 833####################
2025-02-03 18:06:58,820 - INFO - Epoch 833: train_loss=0.8374
2025-02-03 18:06:59,411 - INFO - Epoch 833: val_loss=2.5546, val_acc=33.33%
2025-02-03 18:06:59,416 - INFO - Epoch 833: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:06:59,426 - INFO - ####################Training epoch 834####################
2025-02-03 18:06:59,846 - INFO - Epoch 834: train_loss=0.8384
2025-02-03 18:07:00,376 - INFO - Epoch 834: val_loss=2.5506, val_acc=33.33%
2025-02-03 18:07:00,380 - INFO - Epoch 834: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:07:00,383 - INFO - ####################Training epoch 835####################
2025-02-03 18:07:00,844 - INFO - Epoch 835: train_loss=0.8388
2025-02-03 18:07:01,508 - INFO - Epoch 835: val_loss=2.5523, val_acc=33.33%
2025-02-03 18:07:01,511 - INFO - Epoch 835: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:07:01,514 - INFO - ####################Training epoch 836####################
2025-02-03 18:07:01,815 - INFO - Epoch 836: train_loss=0.8399
2025-02-03 18:07:02,521 - INFO - Epoch 836: val_loss=2.5485, val_acc=33.33%
2025-02-03 18:07:02,526 - INFO - Epoch 836: EPOCH_AVG_TRAIN_LOSS=0.8399
2025-02-03 18:07:02,532 - INFO - ####################Training epoch 837####################
2025-02-03 18:07:02,820 - INFO - Epoch 837: train_loss=0.8375
2025-02-03 18:07:03,396 - INFO - Epoch 837: val_loss=2.5517, val_acc=33.33%
2025-02-03 18:07:03,402 - INFO - Epoch 837: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:07:03,412 - INFO - ####################Training epoch 838####################
2025-02-03 18:07:03,851 - INFO - Epoch 838: train_loss=0.8377
2025-02-03 18:07:04,520 - INFO - Epoch 838: val_loss=2.5528, val_acc=33.33%
2025-02-03 18:07:04,524 - INFO - Epoch 838: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:07:04,526 - INFO - ####################Training epoch 839####################
2025-02-03 18:07:04,945 - INFO - Epoch 839: train_loss=0.8363
2025-02-03 18:07:05,719 - INFO - Epoch 839: val_loss=2.5500, val_acc=33.33%
2025-02-03 18:07:05,722 - INFO - Epoch 839: EPOCH_AVG_TRAIN_LOSS=0.8363
2025-02-03 18:07:05,725 - INFO - ####################Training epoch 840####################
2025-02-03 18:07:06,056 - INFO - Epoch 840: train_loss=0.8373
2025-02-03 18:07:06,701 - INFO - Epoch 840: val_loss=2.5502, val_acc=33.33%
2025-02-03 18:07:06,706 - INFO - Epoch 840: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:07:06,716 - INFO - ####################Training epoch 841####################
2025-02-03 18:07:07,064 - INFO - Epoch 841: train_loss=0.8382
2025-02-03 18:07:07,660 - INFO - Epoch 841: val_loss=2.5429, val_acc=33.33%
2025-02-03 18:07:07,664 - INFO - Epoch 841: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:07:07,669 - INFO - ####################Training epoch 842####################
2025-02-03 18:07:08,111 - INFO - Epoch 842: train_loss=0.8377
2025-02-03 18:07:08,784 - INFO - Epoch 842: val_loss=2.5496, val_acc=33.33%
2025-02-03 18:07:08,787 - INFO - Epoch 842: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:07:08,790 - INFO - ####################Training epoch 843####################
2025-02-03 18:07:09,213 - INFO - Epoch 843: train_loss=0.8377
2025-02-03 18:07:09,983 - INFO - Epoch 843: val_loss=2.5554, val_acc=33.33%
2025-02-03 18:07:09,987 - INFO - Epoch 843: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:07:09,989 - INFO - ####################Training epoch 844####################
2025-02-03 18:07:10,327 - INFO - Epoch 844: train_loss=0.8383
2025-02-03 18:07:10,984 - INFO - Epoch 844: val_loss=2.5546, val_acc=33.33%
2025-02-03 18:07:10,988 - INFO - Epoch 844: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:07:10,999 - INFO - ####################Training epoch 845####################
2025-02-03 18:07:11,315 - INFO - Epoch 845: train_loss=0.8386
2025-02-03 18:07:11,909 - INFO - Epoch 845: val_loss=2.5574, val_acc=33.33%
2025-02-03 18:07:11,914 - INFO - Epoch 845: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:07:11,925 - INFO - ####################Training epoch 846####################
2025-02-03 18:07:12,374 - INFO - Epoch 846: train_loss=0.8377
2025-02-03 18:07:13,049 - INFO - Epoch 846: val_loss=2.5542, val_acc=33.33%
2025-02-03 18:07:13,053 - INFO - Epoch 846: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:07:13,055 - INFO - ####################Training epoch 847####################
2025-02-03 18:07:13,479 - INFO - Epoch 847: train_loss=0.8372
2025-02-03 18:07:14,250 - INFO - Epoch 847: val_loss=2.5567, val_acc=33.33%
2025-02-03 18:07:14,253 - INFO - Epoch 847: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:07:14,256 - INFO - ####################Training epoch 848####################
2025-02-03 18:07:14,588 - INFO - Epoch 848: train_loss=0.8386
2025-02-03 18:07:15,255 - INFO - Epoch 848: val_loss=2.5518, val_acc=33.33%
2025-02-03 18:07:15,260 - INFO - Epoch 848: EPOCH_AVG_TRAIN_LOSS=0.8386
2025-02-03 18:07:15,269 - INFO - ####################Training epoch 849####################
2025-02-03 18:07:15,602 - INFO - Epoch 849: train_loss=0.8374
2025-02-03 18:07:16,185 - INFO - Epoch 849: val_loss=2.5529, val_acc=33.33%
2025-02-03 18:07:16,189 - INFO - Epoch 849: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:07:16,200 - INFO - ####################Training epoch 850####################
2025-02-03 18:07:16,644 - INFO - Epoch 850: train_loss=0.8412
2025-02-03 18:07:17,310 - INFO - Epoch 850: val_loss=2.5564, val_acc=33.33%
2025-02-03 18:07:17,314 - INFO - Epoch 850: EPOCH_AVG_TRAIN_LOSS=0.8412
2025-02-03 18:07:17,317 - INFO - ####################Training epoch 851####################
2025-02-03 18:07:17,750 - INFO - Epoch 851: train_loss=0.8369
2025-02-03 18:07:18,509 - INFO - Epoch 851: val_loss=2.5518, val_acc=33.33%
2025-02-03 18:07:18,513 - INFO - Epoch 851: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:07:18,515 - INFO - ####################Training epoch 852####################
2025-02-03 18:07:18,845 - INFO - Epoch 852: train_loss=0.8393
2025-02-03 18:07:19,506 - INFO - Epoch 852: val_loss=2.5497, val_acc=33.33%
2025-02-03 18:07:19,510 - INFO - Epoch 852: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:07:19,521 - INFO - ####################Training epoch 853####################
2025-02-03 18:07:19,836 - INFO - Epoch 853: train_loss=0.8380
2025-02-03 18:07:20,428 - INFO - Epoch 853: val_loss=2.5531, val_acc=33.33%
2025-02-03 18:07:20,432 - INFO - Epoch 853: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:07:20,443 - INFO - ####################Training epoch 854####################
2025-02-03 18:07:20,902 - INFO - Epoch 854: train_loss=0.8353
2025-02-03 18:07:21,568 - INFO - Epoch 854: val_loss=2.5575, val_acc=33.33%
2025-02-03 18:07:21,572 - INFO - Epoch 854: EPOCH_AVG_TRAIN_LOSS=0.8353
2025-02-03 18:07:21,574 - INFO - ####################Training epoch 855####################
2025-02-03 18:07:22,002 - INFO - Epoch 855: train_loss=0.8347
2025-02-03 18:07:22,774 - INFO - Epoch 855: val_loss=2.5555, val_acc=33.33%
2025-02-03 18:07:22,777 - INFO - Epoch 855: EPOCH_AVG_TRAIN_LOSS=0.8347
2025-02-03 18:07:22,780 - INFO - ####################Training epoch 856####################
2025-02-03 18:07:23,117 - INFO - Epoch 856: train_loss=0.8377
2025-02-03 18:07:23,773 - INFO - Epoch 856: val_loss=2.5591, val_acc=33.33%
2025-02-03 18:07:23,778 - INFO - Epoch 856: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:07:23,788 - INFO - ####################Training epoch 857####################
2025-02-03 18:07:24,126 - INFO - Epoch 857: train_loss=0.8383
2025-02-03 18:07:24,720 - INFO - Epoch 857: val_loss=2.5513, val_acc=33.33%
2025-02-03 18:07:24,725 - INFO - Epoch 857: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:07:24,735 - INFO - ####################Training epoch 858####################
2025-02-03 18:07:25,173 - INFO - Epoch 858: train_loss=0.8382
2025-02-03 18:07:25,843 - INFO - Epoch 858: val_loss=2.5540, val_acc=33.33%
2025-02-03 18:07:25,847 - INFO - Epoch 858: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:07:25,849 - INFO - ####################Training epoch 859####################
2025-02-03 18:07:26,274 - INFO - Epoch 859: train_loss=0.8389
2025-02-03 18:07:27,045 - INFO - Epoch 859: val_loss=2.5477, val_acc=33.33%
2025-02-03 18:07:27,049 - INFO - Epoch 859: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:07:27,051 - INFO - ####################Training epoch 860####################
2025-02-03 18:07:27,383 - INFO - Epoch 860: train_loss=0.8373
2025-02-03 18:07:28,034 - INFO - Epoch 860: val_loss=2.5573, val_acc=33.33%
2025-02-03 18:07:28,039 - INFO - Epoch 860: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:07:28,049 - INFO - ####################Training epoch 861####################
2025-02-03 18:07:28,371 - INFO - Epoch 861: train_loss=0.8376
2025-02-03 18:07:28,934 - INFO - Epoch 861: val_loss=2.5592, val_acc=33.33%
2025-02-03 18:07:28,939 - INFO - Epoch 861: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:07:28,949 - INFO - ####################Training epoch 862####################
2025-02-03 18:07:29,426 - INFO - Epoch 862: train_loss=0.8402
2025-02-03 18:07:30,111 - INFO - Epoch 862: val_loss=2.5505, val_acc=33.33%
2025-02-03 18:07:30,115 - INFO - Epoch 862: EPOCH_AVG_TRAIN_LOSS=0.8402
2025-02-03 18:07:30,117 - INFO - ####################Training epoch 863####################
2025-02-03 18:07:30,544 - INFO - Epoch 863: train_loss=0.8372
2025-02-03 18:07:31,316 - INFO - Epoch 863: val_loss=2.5563, val_acc=33.33%
2025-02-03 18:07:31,319 - INFO - Epoch 863: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:07:31,322 - INFO - ####################Training epoch 864####################
2025-02-03 18:07:31,655 - INFO - Epoch 864: train_loss=0.8364
2025-02-03 18:07:32,309 - INFO - Epoch 864: val_loss=2.5582, val_acc=33.33%
2025-02-03 18:07:32,314 - INFO - Epoch 864: EPOCH_AVG_TRAIN_LOSS=0.8364
2025-02-03 18:07:32,325 - INFO - ####################Training epoch 865####################
2025-02-03 18:07:32,662 - INFO - Epoch 865: train_loss=0.8352
2025-02-03 18:07:33,259 - INFO - Epoch 865: val_loss=2.5585, val_acc=33.33%
2025-02-03 18:07:33,263 - INFO - Epoch 865: EPOCH_AVG_TRAIN_LOSS=0.8352
2025-02-03 18:07:33,268 - INFO - ####################Training epoch 866####################
2025-02-03 18:07:33,716 - INFO - Epoch 866: train_loss=0.8388
2025-02-03 18:07:34,384 - INFO - Epoch 866: val_loss=2.5571, val_acc=33.33%
2025-02-03 18:07:34,388 - INFO - Epoch 866: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:07:34,390 - INFO - ####################Training epoch 867####################
2025-02-03 18:07:34,816 - INFO - Epoch 867: train_loss=0.8376
2025-02-03 18:07:35,588 - INFO - Epoch 867: val_loss=2.5530, val_acc=33.33%
2025-02-03 18:07:35,592 - INFO - Epoch 867: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:07:35,594 - INFO - ####################Training epoch 868####################
2025-02-03 18:07:35,928 - INFO - Epoch 868: train_loss=0.8355
2025-02-03 18:07:36,596 - INFO - Epoch 868: val_loss=2.5489, val_acc=33.33%
2025-02-03 18:07:36,600 - INFO - Epoch 868: EPOCH_AVG_TRAIN_LOSS=0.8355
2025-02-03 18:07:36,607 - INFO - ####################Training epoch 869####################
2025-02-03 18:07:36,918 - INFO - Epoch 869: train_loss=0.8394
2025-02-03 18:07:37,508 - INFO - Epoch 869: val_loss=2.5528, val_acc=33.33%
2025-02-03 18:07:37,513 - INFO - Epoch 869: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:07:37,523 - INFO - ####################Training epoch 870####################
2025-02-03 18:07:37,975 - INFO - Epoch 870: train_loss=0.8352
2025-02-03 18:07:38,654 - INFO - Epoch 870: val_loss=2.5508, val_acc=33.33%
2025-02-03 18:07:38,657 - INFO - Epoch 870: EPOCH_AVG_TRAIN_LOSS=0.8352
2025-02-03 18:07:38,660 - INFO - ####################Training epoch 871####################
2025-02-03 18:07:39,083 - INFO - Epoch 871: train_loss=0.8391
2025-02-03 18:07:39,854 - INFO - Epoch 871: val_loss=2.5568, val_acc=33.33%
2025-02-03 18:07:39,858 - INFO - Epoch 871: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:07:39,860 - INFO - ####################Training epoch 872####################
2025-02-03 18:07:40,194 - INFO - Epoch 872: train_loss=0.8366
2025-02-03 18:07:40,843 - INFO - Epoch 872: val_loss=2.5544, val_acc=33.33%
2025-02-03 18:07:40,848 - INFO - Epoch 872: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 18:07:40,858 - INFO - ####################Training epoch 873####################
2025-02-03 18:07:41,207 - INFO - Epoch 873: train_loss=0.8388
2025-02-03 18:07:41,766 - INFO - Epoch 873: val_loss=2.5588, val_acc=33.33%
2025-02-03 18:07:41,771 - INFO - Epoch 873: EPOCH_AVG_TRAIN_LOSS=0.8388
2025-02-03 18:07:41,781 - INFO - ####################Training epoch 874####################
2025-02-03 18:07:42,239 - INFO - Epoch 874: train_loss=0.8371
2025-02-03 18:07:42,916 - INFO - Epoch 874: val_loss=2.5563, val_acc=33.33%
2025-02-03 18:07:42,920 - INFO - Epoch 874: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:07:42,926 - INFO - ####################Training epoch 875####################
2025-02-03 18:07:43,283 - INFO - Epoch 875: train_loss=0.8365
2025-02-03 18:07:44,053 - INFO - Epoch 875: val_loss=2.5530, val_acc=33.33%
2025-02-03 18:07:44,057 - INFO - Epoch 875: EPOCH_AVG_TRAIN_LOSS=0.8365
2025-02-03 18:07:44,068 - INFO - ####################Training epoch 876####################
2025-02-03 18:07:44,389 - INFO - Epoch 876: train_loss=0.8398
2025-02-03 18:07:45,004 - INFO - Epoch 876: val_loss=2.5480, val_acc=33.33%
2025-02-03 18:07:45,008 - INFO - Epoch 876: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:07:45,018 - INFO - ####################Training epoch 877####################
2025-02-03 18:07:45,389 - INFO - Epoch 877: train_loss=0.8377
2025-02-03 18:07:45,927 - INFO - Epoch 877: val_loss=2.5602, val_acc=33.33%
2025-02-03 18:07:45,934 - INFO - Epoch 877: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:07:45,944 - INFO - ####################Training epoch 878####################
2025-02-03 18:07:46,422 - INFO - Epoch 878: train_loss=0.8367
2025-02-03 18:07:47,100 - INFO - Epoch 878: val_loss=2.5488, val_acc=33.33%
2025-02-03 18:07:47,106 - INFO - Epoch 878: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:07:47,115 - INFO - ####################Training epoch 879####################
2025-02-03 18:07:47,482 - INFO - Epoch 879: train_loss=0.8372
2025-02-03 18:07:48,252 - INFO - Epoch 879: val_loss=2.5511, val_acc=33.33%
2025-02-03 18:07:48,257 - INFO - Epoch 879: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:07:48,267 - INFO - ####################Training epoch 880####################
2025-02-03 18:07:48,588 - INFO - Epoch 880: train_loss=0.8373
2025-02-03 18:07:49,206 - INFO - Epoch 880: val_loss=2.5514, val_acc=33.33%
2025-02-03 18:07:49,211 - INFO - Epoch 880: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:07:49,221 - INFO - ####################Training epoch 881####################
2025-02-03 18:07:49,597 - INFO - Epoch 881: train_loss=0.8374
2025-02-03 18:07:50,118 - INFO - Epoch 881: val_loss=2.5523, val_acc=33.33%
2025-02-03 18:07:50,123 - INFO - Epoch 881: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:07:50,135 - INFO - ####################Training epoch 882####################
2025-02-03 18:07:50,625 - INFO - Epoch 882: train_loss=0.8376
2025-02-03 18:07:51,290 - INFO - Epoch 882: val_loss=2.5502, val_acc=33.33%
2025-02-03 18:07:51,294 - INFO - Epoch 882: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:07:51,296 - INFO - ####################Training epoch 883####################
2025-02-03 18:07:51,656 - INFO - Epoch 883: train_loss=0.8391
2025-02-03 18:07:52,384 - INFO - Epoch 883: val_loss=2.5545, val_acc=33.33%
2025-02-03 18:07:52,388 - INFO - Epoch 883: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:07:52,399 - INFO - ####################Training epoch 884####################
2025-02-03 18:07:52,704 - INFO - Epoch 884: train_loss=0.8389
2025-02-03 18:07:53,290 - INFO - Epoch 884: val_loss=2.5518, val_acc=33.33%
2025-02-03 18:07:53,295 - INFO - Epoch 884: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:07:53,305 - INFO - ####################Training epoch 885####################
2025-02-03 18:07:53,721 - INFO - Epoch 885: train_loss=0.8393
2025-02-03 18:07:54,253 - INFO - Epoch 885: val_loss=2.5492, val_acc=33.33%
2025-02-03 18:07:54,257 - INFO - Epoch 885: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:07:54,259 - INFO - ####################Training epoch 886####################
2025-02-03 18:07:54,720 - INFO - Epoch 886: train_loss=0.8369
2025-02-03 18:07:55,386 - INFO - Epoch 886: val_loss=2.5547, val_acc=33.33%
2025-02-03 18:07:55,390 - INFO - Epoch 886: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:07:55,393 - INFO - ####################Training epoch 887####################
2025-02-03 18:07:55,699 - INFO - Epoch 887: train_loss=0.8377
2025-02-03 18:07:56,418 - INFO - Epoch 887: val_loss=2.5495, val_acc=33.33%
2025-02-03 18:07:56,424 - INFO - Epoch 887: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:07:56,434 - INFO - ####################Training epoch 888####################
2025-02-03 18:07:56,726 - INFO - Epoch 888: train_loss=0.8385
2025-02-03 18:07:57,312 - INFO - Epoch 888: val_loss=2.5557, val_acc=33.33%
2025-02-03 18:07:57,316 - INFO - Epoch 888: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:07:57,326 - INFO - ####################Training epoch 889####################
2025-02-03 18:07:57,753 - INFO - Epoch 889: train_loss=0.8372
2025-02-03 18:07:58,419 - INFO - Epoch 889: val_loss=2.5523, val_acc=33.33%
2025-02-03 18:07:58,423 - INFO - Epoch 889: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:07:58,425 - INFO - ####################Training epoch 890####################
2025-02-03 18:07:58,828 - INFO - Epoch 890: train_loss=0.8391
2025-02-03 18:07:59,589 - INFO - Epoch 890: val_loss=2.5529, val_acc=33.33%
2025-02-03 18:07:59,593 - INFO - Epoch 890: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:07:59,595 - INFO - ####################Training epoch 891####################
2025-02-03 18:07:59,932 - INFO - Epoch 891: train_loss=0.8378
2025-02-03 18:08:00,583 - INFO - Epoch 891: val_loss=2.5485, val_acc=33.33%
2025-02-03 18:08:00,590 - INFO - Epoch 891: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:08:00,601 - INFO - ####################Training epoch 892####################
2025-02-03 18:08:00,924 - INFO - Epoch 892: train_loss=0.8377
2025-02-03 18:08:01,521 - INFO - Epoch 892: val_loss=2.5545, val_acc=33.33%
2025-02-03 18:08:01,526 - INFO - Epoch 892: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:08:01,537 - INFO - ####################Training epoch 893####################
2025-02-03 18:08:01,988 - INFO - Epoch 893: train_loss=0.8375
2025-02-03 18:08:02,666 - INFO - Epoch 893: val_loss=2.5534, val_acc=33.33%
2025-02-03 18:08:02,670 - INFO - Epoch 893: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:08:02,672 - INFO - ####################Training epoch 894####################
2025-02-03 18:08:03,099 - INFO - Epoch 894: train_loss=0.8360
2025-02-03 18:08:03,870 - INFO - Epoch 894: val_loss=2.5507, val_acc=33.33%
2025-02-03 18:08:03,874 - INFO - Epoch 894: EPOCH_AVG_TRAIN_LOSS=0.8360
2025-02-03 18:08:03,876 - INFO - ####################Training epoch 895####################
2025-02-03 18:08:04,216 - INFO - Epoch 895: train_loss=0.8368
2025-02-03 18:08:04,873 - INFO - Epoch 895: val_loss=2.5518, val_acc=33.33%
2025-02-03 18:08:04,878 - INFO - Epoch 895: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:08:04,888 - INFO - ####################Training epoch 896####################
2025-02-03 18:08:05,207 - INFO - Epoch 896: train_loss=0.8380
2025-02-03 18:08:05,809 - INFO - Epoch 896: val_loss=2.5460, val_acc=33.33%
2025-02-03 18:08:05,814 - INFO - Epoch 896: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:08:05,825 - INFO - ####################Training epoch 897####################
2025-02-03 18:08:06,277 - INFO - Epoch 897: train_loss=0.8395
2025-02-03 18:08:06,969 - INFO - Epoch 897: val_loss=2.5471, val_acc=33.33%
2025-02-03 18:08:06,974 - INFO - Epoch 897: EPOCH_AVG_TRAIN_LOSS=0.8395
2025-02-03 18:08:06,981 - INFO - ####################Training epoch 898####################
2025-02-03 18:08:07,355 - INFO - Epoch 898: train_loss=0.8381
2025-02-03 18:08:08,120 - INFO - Epoch 898: val_loss=2.5548, val_acc=33.33%
2025-02-03 18:08:08,124 - INFO - Epoch 898: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:08:08,135 - INFO - ####################Training epoch 899####################
2025-02-03 18:08:08,458 - INFO - Epoch 899: train_loss=0.8363
2025-02-03 18:08:09,076 - INFO - Epoch 899: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:08:09,080 - INFO - Epoch 899: EPOCH_AVG_TRAIN_LOSS=0.8363
2025-02-03 18:08:09,090 - INFO - ####################Training epoch 900####################
2025-02-03 18:08:09,472 - INFO - Epoch 900: train_loss=0.8390
2025-02-03 18:08:10,001 - INFO - Epoch 900: val_loss=2.5569, val_acc=33.33%
2025-02-03 18:08:10,004 - INFO - Epoch 900: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:08:10,007 - INFO - ####################Training epoch 901####################
2025-02-03 18:08:10,470 - INFO - Epoch 901: train_loss=0.8377
2025-02-03 18:08:11,134 - INFO - Epoch 901: val_loss=2.5470, val_acc=33.33%
2025-02-03 18:08:11,138 - INFO - Epoch 901: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:08:11,140 - INFO - ####################Training epoch 902####################
2025-02-03 18:08:11,447 - INFO - Epoch 902: train_loss=0.8379
2025-02-03 18:08:12,162 - INFO - Epoch 902: val_loss=2.5517, val_acc=33.33%
2025-02-03 18:08:12,166 - INFO - Epoch 902: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:08:12,177 - INFO - ####################Training epoch 903####################
2025-02-03 18:08:12,470 - INFO - Epoch 903: train_loss=0.8374
2025-02-03 18:08:13,072 - INFO - Epoch 903: val_loss=2.5550, val_acc=33.33%
2025-02-03 18:08:13,077 - INFO - Epoch 903: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:08:13,088 - INFO - ####################Training epoch 904####################
2025-02-03 18:08:13,498 - INFO - Epoch 904: train_loss=0.8391
2025-02-03 18:08:14,131 - INFO - Epoch 904: val_loss=2.5550, val_acc=33.33%
2025-02-03 18:08:14,135 - INFO - Epoch 904: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:08:14,137 - INFO - ####################Training epoch 905####################
2025-02-03 18:08:14,561 - INFO - Epoch 905: train_loss=0.8381
2025-02-03 18:08:15,350 - INFO - Epoch 905: val_loss=2.5521, val_acc=33.33%
2025-02-03 18:08:15,354 - INFO - Epoch 905: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:08:15,356 - INFO - ####################Training epoch 906####################
2025-02-03 18:08:15,682 - INFO - Epoch 906: train_loss=0.8370
2025-02-03 18:08:16,388 - INFO - Epoch 906: val_loss=2.5481, val_acc=33.33%
2025-02-03 18:08:16,392 - INFO - Epoch 906: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:08:16,400 - INFO - ####################Training epoch 907####################
2025-02-03 18:08:16,696 - INFO - Epoch 907: train_loss=0.8381
2025-02-03 18:08:17,273 - INFO - Epoch 907: val_loss=2.5539, val_acc=33.33%
2025-02-03 18:08:17,278 - INFO - Epoch 907: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:08:17,288 - INFO - ####################Training epoch 908####################
2025-02-03 18:08:17,715 - INFO - Epoch 908: train_loss=0.8368
2025-02-03 18:08:18,388 - INFO - Epoch 908: val_loss=2.5575, val_acc=33.33%
2025-02-03 18:08:18,392 - INFO - Epoch 908: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:08:18,394 - INFO - ####################Training epoch 909####################
2025-02-03 18:08:18,815 - INFO - Epoch 909: train_loss=0.8377
2025-02-03 18:08:19,587 - INFO - Epoch 909: val_loss=2.5530, val_acc=33.33%
2025-02-03 18:08:19,591 - INFO - Epoch 909: EPOCH_AVG_TRAIN_LOSS=0.8377
2025-02-03 18:08:19,594 - INFO - ####################Training epoch 910####################
2025-02-03 18:08:19,927 - INFO - Epoch 910: train_loss=0.8367
2025-02-03 18:08:20,581 - INFO - Epoch 910: val_loss=2.5499, val_acc=33.33%
2025-02-03 18:08:20,586 - INFO - Epoch 910: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:08:20,596 - INFO - ####################Training epoch 911####################
2025-02-03 18:08:20,916 - INFO - Epoch 911: train_loss=0.8381
2025-02-03 18:08:21,512 - INFO - Epoch 911: val_loss=2.5530, val_acc=33.33%
2025-02-03 18:08:21,517 - INFO - Epoch 911: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:08:21,528 - INFO - ####################Training epoch 912####################
2025-02-03 18:08:21,977 - INFO - Epoch 912: train_loss=0.8404
2025-02-03 18:08:22,653 - INFO - Epoch 912: val_loss=2.5556, val_acc=33.33%
2025-02-03 18:08:22,656 - INFO - Epoch 912: EPOCH_AVG_TRAIN_LOSS=0.8404
2025-02-03 18:08:22,659 - INFO - ####################Training epoch 913####################
2025-02-03 18:08:23,082 - INFO - Epoch 913: train_loss=0.8396
2025-02-03 18:08:23,871 - INFO - Epoch 913: val_loss=2.5549, val_acc=33.33%
2025-02-03 18:08:23,875 - INFO - Epoch 913: EPOCH_AVG_TRAIN_LOSS=0.8396
2025-02-03 18:08:23,877 - INFO - ####################Training epoch 914####################
2025-02-03 18:08:24,212 - INFO - Epoch 914: train_loss=0.8363
2025-02-03 18:08:24,882 - INFO - Epoch 914: val_loss=2.5536, val_acc=33.33%
2025-02-03 18:08:24,887 - INFO - Epoch 914: EPOCH_AVG_TRAIN_LOSS=0.8363
2025-02-03 18:08:24,893 - INFO - ####################Training epoch 915####################
2025-02-03 18:08:25,200 - INFO - Epoch 915: train_loss=0.8367
2025-02-03 18:08:25,801 - INFO - Epoch 915: val_loss=2.5519, val_acc=33.33%
2025-02-03 18:08:25,805 - INFO - Epoch 915: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:08:25,810 - INFO - ####################Training epoch 916####################
2025-02-03 18:08:26,256 - INFO - Epoch 916: train_loss=0.8391
2025-02-03 18:08:26,926 - INFO - Epoch 916: val_loss=2.5522, val_acc=33.33%
2025-02-03 18:08:26,930 - INFO - Epoch 916: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:08:26,932 - INFO - ####################Training epoch 917####################
2025-02-03 18:08:27,353 - INFO - Epoch 917: train_loss=0.8383
2025-02-03 18:08:28,124 - INFO - Epoch 917: val_loss=2.5485, val_acc=33.33%
2025-02-03 18:08:28,127 - INFO - Epoch 917: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:08:28,130 - INFO - ####################Training epoch 918####################
2025-02-03 18:08:28,464 - INFO - Epoch 918: train_loss=0.8382
2025-02-03 18:08:29,122 - INFO - Epoch 918: val_loss=2.5522, val_acc=33.33%
2025-02-03 18:08:29,126 - INFO - Epoch 918: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:08:29,137 - INFO - ####################Training epoch 919####################
2025-02-03 18:08:29,453 - INFO - Epoch 919: train_loss=0.8368
2025-02-03 18:08:30,048 - INFO - Epoch 919: val_loss=2.5523, val_acc=33.33%
2025-02-03 18:08:30,054 - INFO - Epoch 919: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:08:30,064 - INFO - ####################Training epoch 920####################
2025-02-03 18:08:30,513 - INFO - Epoch 920: train_loss=0.8362
2025-02-03 18:08:31,189 - INFO - Epoch 920: val_loss=2.5560, val_acc=33.33%
2025-02-03 18:08:31,193 - INFO - Epoch 920: EPOCH_AVG_TRAIN_LOSS=0.8362
2025-02-03 18:08:31,195 - INFO - ####################Training epoch 921####################
2025-02-03 18:08:31,619 - INFO - Epoch 921: train_loss=0.8392
2025-02-03 18:08:32,400 - INFO - Epoch 921: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:08:32,404 - INFO - Epoch 921: EPOCH_AVG_TRAIN_LOSS=0.8392
2025-02-03 18:08:32,406 - INFO - ####################Training epoch 922####################
2025-02-03 18:08:32,742 - INFO - Epoch 922: train_loss=0.8398
2025-02-03 18:08:33,412 - INFO - Epoch 922: val_loss=2.5494, val_acc=33.33%
2025-02-03 18:08:33,417 - INFO - Epoch 922: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:08:33,426 - INFO - ####################Training epoch 923####################
2025-02-03 18:08:33,736 - INFO - Epoch 923: train_loss=0.8368
2025-02-03 18:08:34,322 - INFO - Epoch 923: val_loss=2.5541, val_acc=33.33%
2025-02-03 18:08:34,327 - INFO - Epoch 923: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:08:34,336 - INFO - ####################Training epoch 924####################
2025-02-03 18:08:34,787 - INFO - Epoch 924: train_loss=0.8385
2025-02-03 18:08:35,468 - INFO - Epoch 924: val_loss=2.5509, val_acc=33.33%
2025-02-03 18:08:35,472 - INFO - Epoch 924: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:08:35,474 - INFO - ####################Training epoch 925####################
2025-02-03 18:08:35,900 - INFO - Epoch 925: train_loss=0.8381
2025-02-03 18:08:36,672 - INFO - Epoch 925: val_loss=2.5464, val_acc=33.33%
2025-02-03 18:08:36,676 - INFO - Epoch 925: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:08:36,678 - INFO - ####################Training epoch 926####################
2025-02-03 18:08:37,014 - INFO - Epoch 926: train_loss=0.8366
2025-02-03 18:08:37,661 - INFO - Epoch 926: val_loss=2.5533, val_acc=33.33%
2025-02-03 18:08:37,666 - INFO - Epoch 926: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 18:08:37,676 - INFO - ####################Training epoch 927####################
2025-02-03 18:08:38,008 - INFO - Epoch 927: train_loss=0.8411
2025-02-03 18:08:38,606 - INFO - Epoch 927: val_loss=2.5537, val_acc=33.33%
2025-02-03 18:08:38,612 - INFO - Epoch 927: EPOCH_AVG_TRAIN_LOSS=0.8411
2025-02-03 18:08:38,624 - INFO - ####################Training epoch 928####################
2025-02-03 18:08:39,075 - INFO - Epoch 928: train_loss=0.8368
2025-02-03 18:08:39,755 - INFO - Epoch 928: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:08:39,759 - INFO - Epoch 928: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:08:39,762 - INFO - ####################Training epoch 929####################
2025-02-03 18:08:40,329 - INFO - Epoch 929: train_loss=0.8367
2025-02-03 18:08:41,044 - INFO - Epoch 929: val_loss=2.5525, val_acc=33.33%
2025-02-03 18:08:41,047 - INFO - Epoch 929: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:08:41,050 - INFO - ####################Training epoch 930####################
2025-02-03 18:08:41,365 - INFO - Epoch 930: train_loss=0.8409
2025-02-03 18:08:42,073 - INFO - Epoch 930: val_loss=2.5544, val_acc=33.33%
2025-02-03 18:08:42,078 - INFO - Epoch 930: EPOCH_AVG_TRAIN_LOSS=0.8409
2025-02-03 18:08:42,086 - INFO - ####################Training epoch 931####################
2025-02-03 18:08:42,382 - INFO - Epoch 931: train_loss=0.8383
2025-02-03 18:08:43,077 - INFO - Epoch 931: val_loss=2.5515, val_acc=33.33%
2025-02-03 18:08:43,082 - INFO - Epoch 931: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:08:43,094 - INFO - ####################Training epoch 932####################
2025-02-03 18:08:43,496 - INFO - Epoch 932: train_loss=0.8382
2025-02-03 18:08:44,134 - INFO - Epoch 932: val_loss=2.5539, val_acc=33.33%
2025-02-03 18:08:44,138 - INFO - Epoch 932: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:08:44,140 - INFO - ####################Training epoch 933####################
2025-02-03 18:08:44,564 - INFO - Epoch 933: train_loss=0.8375
2025-02-03 18:08:45,299 - INFO - Epoch 933: val_loss=2.5581, val_acc=33.33%
2025-02-03 18:08:45,303 - INFO - Epoch 933: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:08:45,305 - INFO - ####################Training epoch 934####################
2025-02-03 18:08:45,610 - INFO - Epoch 934: train_loss=0.8370
2025-02-03 18:08:46,295 - INFO - Epoch 934: val_loss=2.5499, val_acc=33.33%
2025-02-03 18:08:46,300 - INFO - Epoch 934: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:08:46,311 - INFO - ####################Training epoch 935####################
2025-02-03 18:08:46,605 - INFO - Epoch 935: train_loss=0.8379
2025-02-03 18:08:47,198 - INFO - Epoch 935: val_loss=2.5479, val_acc=33.33%
2025-02-03 18:08:47,205 - INFO - Epoch 935: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:08:47,215 - INFO - ####################Training epoch 936####################
2025-02-03 18:08:47,654 - INFO - Epoch 936: train_loss=0.8379
2025-02-03 18:08:48,325 - INFO - Epoch 936: val_loss=2.5553, val_acc=33.33%
2025-02-03 18:08:48,329 - INFO - Epoch 936: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:08:48,331 - INFO - ####################Training epoch 937####################
2025-02-03 18:08:48,757 - INFO - Epoch 937: train_loss=0.8372
2025-02-03 18:08:49,530 - INFO - Epoch 937: val_loss=2.5467, val_acc=33.33%
2025-02-03 18:08:49,534 - INFO - Epoch 937: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:08:49,537 - INFO - ####################Training epoch 938####################
2025-02-03 18:08:49,870 - INFO - Epoch 938: train_loss=0.8391
2025-02-03 18:08:50,535 - INFO - Epoch 938: val_loss=2.5532, val_acc=33.33%
2025-02-03 18:08:50,540 - INFO - Epoch 938: EPOCH_AVG_TRAIN_LOSS=0.8391
2025-02-03 18:08:50,549 - INFO - ####################Training epoch 939####################
2025-02-03 18:08:50,855 - INFO - Epoch 939: train_loss=0.8381
2025-02-03 18:08:51,428 - INFO - Epoch 939: val_loss=2.5568, val_acc=33.33%
2025-02-03 18:08:51,432 - INFO - Epoch 939: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:08:51,439 - INFO - ####################Training epoch 940####################
2025-02-03 18:08:51,938 - INFO - Epoch 940: train_loss=0.8361
2025-02-03 18:08:52,605 - INFO - Epoch 940: val_loss=2.5536, val_acc=33.33%
2025-02-03 18:08:52,609 - INFO - Epoch 940: EPOCH_AVG_TRAIN_LOSS=0.8361
2025-02-03 18:08:52,612 - INFO - ####################Training epoch 941####################
2025-02-03 18:08:52,970 - INFO - Epoch 941: train_loss=0.8374
2025-02-03 18:08:53,686 - INFO - Epoch 941: val_loss=2.5506, val_acc=33.33%
2025-02-03 18:08:53,691 - INFO - Epoch 941: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:08:53,695 - INFO - ####################Training epoch 942####################
2025-02-03 18:08:53,985 - INFO - Epoch 942: train_loss=0.8385
2025-02-03 18:08:54,565 - INFO - Epoch 942: val_loss=2.5593, val_acc=33.33%
2025-02-03 18:08:54,569 - INFO - Epoch 942: EPOCH_AVG_TRAIN_LOSS=0.8385
2025-02-03 18:08:54,580 - INFO - ####################Training epoch 943####################
2025-02-03 18:08:54,967 - INFO - Epoch 943: train_loss=0.8384
2025-02-03 18:08:55,598 - INFO - Epoch 943: val_loss=2.5557, val_acc=33.33%
2025-02-03 18:08:55,602 - INFO - Epoch 943: EPOCH_AVG_TRAIN_LOSS=0.8384
2025-02-03 18:08:55,604 - INFO - ####################Training epoch 944####################
2025-02-03 18:08:55,985 - INFO - Epoch 944: train_loss=0.8375
2025-02-03 18:08:56,744 - INFO - Epoch 944: val_loss=2.5563, val_acc=33.33%
2025-02-03 18:08:56,748 - INFO - Epoch 944: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:08:56,750 - INFO - ####################Training epoch 945####################
2025-02-03 18:08:57,084 - INFO - Epoch 945: train_loss=0.8407
2025-02-03 18:08:57,739 - INFO - Epoch 945: val_loss=2.5460, val_acc=33.33%
2025-02-03 18:08:57,743 - INFO - Epoch 945: EPOCH_AVG_TRAIN_LOSS=0.8407
2025-02-03 18:08:57,754 - INFO - ####################Training epoch 946####################
2025-02-03 18:08:58,075 - INFO - Epoch 946: train_loss=0.8394
2025-02-03 18:08:58,674 - INFO - Epoch 946: val_loss=2.5500, val_acc=33.33%
2025-02-03 18:08:58,680 - INFO - Epoch 946: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:08:58,690 - INFO - ####################Training epoch 947####################
2025-02-03 18:08:59,141 - INFO - Epoch 947: train_loss=0.8390
2025-02-03 18:08:59,841 - INFO - Epoch 947: val_loss=2.5469, val_acc=33.33%
2025-02-03 18:08:59,845 - INFO - Epoch 947: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:08:59,847 - INFO - ####################Training epoch 948####################
2025-02-03 18:09:00,301 - INFO - Epoch 948: train_loss=0.8380
2025-02-03 18:09:01,072 - INFO - Epoch 948: val_loss=2.5535, val_acc=33.33%
2025-02-03 18:09:01,076 - INFO - Epoch 948: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:09:01,078 - INFO - ####################Training epoch 949####################
2025-02-03 18:09:01,422 - INFO - Epoch 949: train_loss=0.8378
2025-02-03 18:09:02,078 - INFO - Epoch 949: val_loss=2.5504, val_acc=33.33%
2025-02-03 18:09:02,083 - INFO - Epoch 949: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:09:02,093 - INFO - ####################Training epoch 950####################
2025-02-03 18:09:02,411 - INFO - Epoch 950: train_loss=0.8367
2025-02-03 18:09:02,983 - INFO - Epoch 950: val_loss=2.5541, val_acc=33.33%
2025-02-03 18:09:02,988 - INFO - Epoch 950: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-03 18:09:02,998 - INFO - ####################Training epoch 951####################
2025-02-03 18:09:03,472 - INFO - Epoch 951: train_loss=0.8379
2025-02-03 18:09:04,148 - INFO - Epoch 951: val_loss=2.5585, val_acc=33.33%
2025-02-03 18:09:04,152 - INFO - Epoch 951: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:09:04,154 - INFO - ####################Training epoch 952####################
2025-02-03 18:09:04,578 - INFO - Epoch 952: train_loss=0.8381
2025-02-03 18:09:05,349 - INFO - Epoch 952: val_loss=2.5521, val_acc=33.33%
2025-02-03 18:09:05,352 - INFO - Epoch 952: EPOCH_AVG_TRAIN_LOSS=0.8381
2025-02-03 18:09:05,354 - INFO - ####################Training epoch 953####################
2025-02-03 18:09:05,690 - INFO - Epoch 953: train_loss=0.8375
2025-02-03 18:09:06,353 - INFO - Epoch 953: val_loss=2.5567, val_acc=33.33%
2025-02-03 18:09:06,357 - INFO - Epoch 953: EPOCH_AVG_TRAIN_LOSS=0.8375
2025-02-03 18:09:06,367 - INFO - ####################Training epoch 954####################
2025-02-03 18:09:06,680 - INFO - Epoch 954: train_loss=0.8398
2025-02-03 18:09:07,268 - INFO - Epoch 954: val_loss=2.5565, val_acc=33.33%
2025-02-03 18:09:07,273 - INFO - Epoch 954: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-03 18:09:07,283 - INFO - ####################Training epoch 955####################
2025-02-03 18:09:07,733 - INFO - Epoch 955: train_loss=0.8364
2025-02-03 18:09:08,432 - INFO - Epoch 955: val_loss=2.5506, val_acc=33.33%
2025-02-03 18:09:08,435 - INFO - Epoch 955: EPOCH_AVG_TRAIN_LOSS=0.8364
2025-02-03 18:09:08,437 - INFO - ####################Training epoch 956####################
2025-02-03 18:09:08,888 - INFO - Epoch 956: train_loss=0.8372
2025-02-03 18:09:09,659 - INFO - Epoch 956: val_loss=2.5484, val_acc=33.33%
2025-02-03 18:09:09,663 - INFO - Epoch 956: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:09:09,665 - INFO - ####################Training epoch 957####################
2025-02-03 18:09:09,999 - INFO - Epoch 957: train_loss=0.8354
2025-02-03 18:09:10,649 - INFO - Epoch 957: val_loss=2.5586, val_acc=33.33%
2025-02-03 18:09:10,654 - INFO - Epoch 957: EPOCH_AVG_TRAIN_LOSS=0.8354
2025-02-03 18:09:10,664 - INFO - ####################Training epoch 958####################
2025-02-03 18:09:10,990 - INFO - Epoch 958: train_loss=0.8376
2025-02-03 18:09:11,570 - INFO - Epoch 958: val_loss=2.5605, val_acc=33.33%
2025-02-03 18:09:11,574 - INFO - Epoch 958: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:09:11,585 - INFO - ####################Training epoch 959####################
2025-02-03 18:09:12,055 - INFO - Epoch 959: train_loss=0.8383
2025-02-03 18:09:12,735 - INFO - Epoch 959: val_loss=2.5516, val_acc=33.33%
2025-02-03 18:09:12,738 - INFO - Epoch 959: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:09:12,740 - INFO - ####################Training epoch 960####################
2025-02-03 18:09:13,159 - INFO - Epoch 960: train_loss=0.8371
2025-02-03 18:09:13,930 - INFO - Epoch 960: val_loss=2.5604, val_acc=33.33%
2025-02-03 18:09:13,933 - INFO - Epoch 960: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:09:13,936 - INFO - ####################Training epoch 961####################
2025-02-03 18:09:14,269 - INFO - Epoch 961: train_loss=0.8371
2025-02-03 18:09:14,938 - INFO - Epoch 961: val_loss=2.5503, val_acc=33.33%
2025-02-03 18:09:14,943 - INFO - Epoch 961: EPOCH_AVG_TRAIN_LOSS=0.8371
2025-02-03 18:09:14,950 - INFO - ####################Training epoch 962####################
2025-02-03 18:09:15,258 - INFO - Epoch 962: train_loss=0.8363
2025-02-03 18:09:15,843 - INFO - Epoch 962: val_loss=2.5531, val_acc=33.33%
2025-02-03 18:09:15,849 - INFO - Epoch 962: EPOCH_AVG_TRAIN_LOSS=0.8363
2025-02-03 18:09:15,858 - INFO - ####################Training epoch 963####################
2025-02-03 18:09:16,309 - INFO - Epoch 963: train_loss=0.8368
2025-02-03 18:09:17,026 - INFO - Epoch 963: val_loss=2.5539, val_acc=33.33%
2025-02-03 18:09:17,030 - INFO - Epoch 963: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:09:17,032 - INFO - ####################Training epoch 964####################
2025-02-03 18:09:17,460 - INFO - Epoch 964: train_loss=0.8374
2025-02-03 18:09:18,231 - INFO - Epoch 964: val_loss=2.5532, val_acc=33.33%
2025-02-03 18:09:18,234 - INFO - Epoch 964: EPOCH_AVG_TRAIN_LOSS=0.8374
2025-02-03 18:09:18,236 - INFO - ####################Training epoch 965####################
2025-02-03 18:09:18,567 - INFO - Epoch 965: train_loss=0.8376
2025-02-03 18:09:19,239 - INFO - Epoch 965: val_loss=2.5484, val_acc=33.33%
2025-02-03 18:09:19,243 - INFO - Epoch 965: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:09:19,248 - INFO - ####################Training epoch 966####################
2025-02-03 18:09:19,555 - INFO - Epoch 966: train_loss=0.8365
2025-02-03 18:09:20,141 - INFO - Epoch 966: val_loss=2.5531, val_acc=33.33%
2025-02-03 18:09:20,146 - INFO - Epoch 966: EPOCH_AVG_TRAIN_LOSS=0.8365
2025-02-03 18:09:20,157 - INFO - ####################Training epoch 967####################
2025-02-03 18:09:20,606 - INFO - Epoch 967: train_loss=0.8389
2025-02-03 18:09:21,282 - INFO - Epoch 967: val_loss=2.5505, val_acc=33.33%
2025-02-03 18:09:21,286 - INFO - Epoch 967: EPOCH_AVG_TRAIN_LOSS=0.8389
2025-02-03 18:09:21,288 - INFO - ####################Training epoch 968####################
2025-02-03 18:09:21,713 - INFO - Epoch 968: train_loss=0.8380
2025-02-03 18:09:22,483 - INFO - Epoch 968: val_loss=2.5531, val_acc=33.33%
2025-02-03 18:09:22,488 - INFO - Epoch 968: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:09:22,491 - INFO - ####################Training epoch 969####################
2025-02-03 18:09:22,826 - INFO - Epoch 969: train_loss=0.8373
2025-02-03 18:09:23,490 - INFO - Epoch 969: val_loss=2.5514, val_acc=33.33%
2025-02-03 18:09:23,495 - INFO - Epoch 969: EPOCH_AVG_TRAIN_LOSS=0.8373
2025-02-03 18:09:23,505 - INFO - ####################Training epoch 970####################
2025-02-03 18:09:23,813 - INFO - Epoch 970: train_loss=0.8380
2025-02-03 18:09:24,400 - INFO - Epoch 970: val_loss=2.5505, val_acc=33.33%
2025-02-03 18:09:24,405 - INFO - Epoch 970: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:09:24,415 - INFO - ####################Training epoch 971####################
2025-02-03 18:09:24,865 - INFO - Epoch 971: train_loss=0.8393
2025-02-03 18:09:25,565 - INFO - Epoch 971: val_loss=2.5462, val_acc=33.33%
2025-02-03 18:09:25,568 - INFO - Epoch 971: EPOCH_AVG_TRAIN_LOSS=0.8393
2025-02-03 18:09:25,571 - INFO - ####################Training epoch 972####################
2025-02-03 18:09:25,990 - INFO - Epoch 972: train_loss=0.8379
2025-02-03 18:09:26,762 - INFO - Epoch 972: val_loss=2.5507, val_acc=33.33%
2025-02-03 18:09:26,766 - INFO - Epoch 972: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:09:26,768 - INFO - ####################Training epoch 973####################
2025-02-03 18:09:27,101 - INFO - Epoch 973: train_loss=0.8379
2025-02-03 18:09:27,758 - INFO - Epoch 973: val_loss=2.5562, val_acc=33.33%
2025-02-03 18:09:27,763 - INFO - Epoch 973: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:09:27,773 - INFO - ####################Training epoch 974####################
2025-02-03 18:09:28,092 - INFO - Epoch 974: train_loss=0.8378
2025-02-03 18:09:28,640 - INFO - Epoch 974: val_loss=2.5579, val_acc=33.33%
2025-02-03 18:09:28,645 - INFO - Epoch 974: EPOCH_AVG_TRAIN_LOSS=0.8378
2025-02-03 18:09:28,655 - INFO - ####################Training epoch 975####################
2025-02-03 18:09:29,127 - INFO - Epoch 975: train_loss=0.8368
2025-02-03 18:09:29,810 - INFO - Epoch 975: val_loss=2.5576, val_acc=33.33%
2025-02-03 18:09:29,816 - INFO - Epoch 975: EPOCH_AVG_TRAIN_LOSS=0.8368
2025-02-03 18:09:29,823 - INFO - ####################Training epoch 976####################
2025-02-03 18:09:30,190 - INFO - Epoch 976: train_loss=0.8364
2025-02-03 18:09:30,955 - INFO - Epoch 976: val_loss=2.5561, val_acc=33.33%
2025-02-03 18:09:30,960 - INFO - Epoch 976: EPOCH_AVG_TRAIN_LOSS=0.8364
2025-02-03 18:09:30,970 - INFO - ####################Training epoch 977####################
2025-02-03 18:09:31,292 - INFO - Epoch 977: train_loss=0.8355
2025-02-03 18:09:31,918 - INFO - Epoch 977: val_loss=2.5523, val_acc=33.33%
2025-02-03 18:09:31,923 - INFO - Epoch 977: EPOCH_AVG_TRAIN_LOSS=0.8355
2025-02-03 18:09:31,933 - INFO - ####################Training epoch 978####################
2025-02-03 18:09:32,295 - INFO - Epoch 978: train_loss=0.8366
2025-02-03 18:09:32,872 - INFO - Epoch 978: val_loss=2.5551, val_acc=33.33%
2025-02-03 18:09:32,877 - INFO - Epoch 978: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 18:09:32,886 - INFO - ####################Training epoch 979####################
2025-02-03 18:09:33,355 - INFO - Epoch 979: train_loss=0.8390
2025-02-03 18:09:34,051 - INFO - Epoch 979: val_loss=2.5489, val_acc=33.33%
2025-02-03 18:09:34,055 - INFO - Epoch 979: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:09:34,058 - INFO - ####################Training epoch 980####################
2025-02-03 18:09:34,488 - INFO - Epoch 980: train_loss=0.8366
2025-02-03 18:09:35,258 - INFO - Epoch 980: val_loss=2.5528, val_acc=33.33%
2025-02-03 18:09:35,262 - INFO - Epoch 980: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 18:09:35,264 - INFO - ####################Training epoch 981####################
2025-02-03 18:09:35,607 - INFO - Epoch 981: train_loss=0.8383
2025-02-03 18:09:36,262 - INFO - Epoch 981: val_loss=2.5560, val_acc=33.33%
2025-02-03 18:09:36,267 - INFO - Epoch 981: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:09:36,277 - INFO - ####################Training epoch 982####################
2025-02-03 18:09:36,598 - INFO - Epoch 982: train_loss=0.8383
2025-02-03 18:09:37,178 - INFO - Epoch 982: val_loss=2.5514, val_acc=33.33%
2025-02-03 18:09:37,182 - INFO - Epoch 982: EPOCH_AVG_TRAIN_LOSS=0.8383
2025-02-03 18:09:37,192 - INFO - ####################Training epoch 983####################
2025-02-03 18:09:37,658 - INFO - Epoch 983: train_loss=0.8354
2025-02-03 18:09:38,339 - INFO - Epoch 983: val_loss=2.5561, val_acc=33.33%
2025-02-03 18:09:38,343 - INFO - Epoch 983: EPOCH_AVG_TRAIN_LOSS=0.8354
2025-02-03 18:09:38,345 - INFO - ####################Training epoch 984####################
2025-02-03 18:09:38,772 - INFO - Epoch 984: train_loss=0.8394
2025-02-03 18:09:39,544 - INFO - Epoch 984: val_loss=2.5514, val_acc=33.33%
2025-02-03 18:09:39,548 - INFO - Epoch 984: EPOCH_AVG_TRAIN_LOSS=0.8394
2025-02-03 18:09:39,550 - INFO - ####################Training epoch 985####################
2025-02-03 18:09:39,886 - INFO - Epoch 985: train_loss=0.8387
2025-02-03 18:09:40,539 - INFO - Epoch 985: val_loss=2.5581, val_acc=33.33%
2025-02-03 18:09:40,544 - INFO - Epoch 985: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:09:40,554 - INFO - ####################Training epoch 986####################
2025-02-03 18:09:40,878 - INFO - Epoch 986: train_loss=0.8369
2025-02-03 18:09:41,451 - INFO - Epoch 986: val_loss=2.5543, val_acc=33.33%
2025-02-03 18:09:41,455 - INFO - Epoch 986: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:09:41,466 - INFO - ####################Training epoch 987####################
2025-02-03 18:09:41,938 - INFO - Epoch 987: train_loss=0.8338
2025-02-03 18:09:42,616 - INFO - Epoch 987: val_loss=2.5530, val_acc=33.33%
2025-02-03 18:09:42,621 - INFO - Epoch 987: EPOCH_AVG_TRAIN_LOSS=0.8338
2025-02-03 18:09:42,625 - INFO - ####################Training epoch 988####################
2025-02-03 18:09:42,985 - INFO - Epoch 988: train_loss=0.8380
2025-02-03 18:09:43,752 - INFO - Epoch 988: val_loss=2.5553, val_acc=33.33%
2025-02-03 18:09:43,757 - INFO - Epoch 988: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:09:43,767 - INFO - ####################Training epoch 989####################
2025-02-03 18:09:44,093 - INFO - Epoch 989: train_loss=0.8372
2025-02-03 18:09:44,715 - INFO - Epoch 989: val_loss=2.5547, val_acc=33.33%
2025-02-03 18:09:44,720 - INFO - Epoch 989: EPOCH_AVG_TRAIN_LOSS=0.8372
2025-02-03 18:09:44,730 - INFO - ####################Training epoch 990####################
2025-02-03 18:09:45,097 - INFO - Epoch 990: train_loss=0.8376
2025-02-03 18:09:45,642 - INFO - Epoch 990: val_loss=2.5520, val_acc=33.33%
2025-02-03 18:09:45,648 - INFO - Epoch 990: EPOCH_AVG_TRAIN_LOSS=0.8376
2025-02-03 18:09:45,658 - INFO - ####################Training epoch 991####################
2025-02-03 18:09:46,137 - INFO - Epoch 991: train_loss=0.8379
2025-02-03 18:09:46,819 - INFO - Epoch 991: val_loss=2.5519, val_acc=33.33%
2025-02-03 18:09:46,824 - INFO - Epoch 991: EPOCH_AVG_TRAIN_LOSS=0.8379
2025-02-03 18:09:46,833 - INFO - ####################Training epoch 992####################
2025-02-03 18:09:47,200 - INFO - Epoch 992: train_loss=0.8380
2025-02-03 18:09:47,967 - INFO - Epoch 992: val_loss=2.5509, val_acc=33.33%
2025-02-03 18:09:47,971 - INFO - Epoch 992: EPOCH_AVG_TRAIN_LOSS=0.8380
2025-02-03 18:09:47,981 - INFO - ####################Training epoch 993####################
2025-02-03 18:09:48,308 - INFO - Epoch 993: train_loss=0.8400
2025-02-03 18:09:48,930 - INFO - Epoch 993: val_loss=2.5468, val_acc=33.33%
2025-02-03 18:09:48,934 - INFO - Epoch 993: EPOCH_AVG_TRAIN_LOSS=0.8400
2025-02-03 18:09:48,944 - INFO - ####################Training epoch 994####################
2025-02-03 18:09:49,307 - INFO - Epoch 994: train_loss=0.8390
2025-02-03 18:09:49,884 - INFO - Epoch 994: val_loss=2.5594, val_acc=33.33%
2025-02-03 18:09:49,889 - INFO - Epoch 994: EPOCH_AVG_TRAIN_LOSS=0.8390
2025-02-03 18:09:49,899 - INFO - ####################Training epoch 995####################
2025-02-03 18:09:50,362 - INFO - Epoch 995: train_loss=0.8366
2025-02-03 18:09:51,057 - INFO - Epoch 995: val_loss=2.5457, val_acc=33.33%
2025-02-03 18:09:51,064 - INFO - Epoch 995: EPOCH_AVG_TRAIN_LOSS=0.8366
2025-02-03 18:09:51,067 - INFO - ####################Training epoch 996####################
2025-02-03 18:09:51,443 - INFO - Epoch 996: train_loss=0.8369
2025-02-03 18:09:52,221 - INFO - Epoch 996: val_loss=2.5524, val_acc=33.33%
2025-02-03 18:09:52,226 - INFO - Epoch 996: EPOCH_AVG_TRAIN_LOSS=0.8369
2025-02-03 18:09:52,236 - INFO - ####################Training epoch 997####################
2025-02-03 18:09:52,565 - INFO - Epoch 997: train_loss=0.8370
2025-02-03 18:09:53,184 - INFO - Epoch 997: val_loss=2.5536, val_acc=33.33%
2025-02-03 18:09:53,189 - INFO - Epoch 997: EPOCH_AVG_TRAIN_LOSS=0.8370
2025-02-03 18:09:53,199 - INFO - ####################Training epoch 998####################
2025-02-03 18:09:53,571 - INFO - Epoch 998: train_loss=0.8387
2025-02-03 18:09:54,174 - INFO - Epoch 998: val_loss=2.5501, val_acc=33.33%
2025-02-03 18:09:54,179 - INFO - Epoch 998: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-03 18:09:54,190 - INFO - ####################Training epoch 999####################
2025-02-03 18:09:54,640 - INFO - Epoch 999: train_loss=0.8382
2025-02-03 18:09:55,316 - INFO - Epoch 999: val_loss=2.5556, val_acc=33.33%
2025-02-03 18:09:55,320 - INFO - Epoch 999: EPOCH_AVG_TRAIN_LOSS=0.8382
2025-02-03 18:09:55,519 - INFO - Model saved.
