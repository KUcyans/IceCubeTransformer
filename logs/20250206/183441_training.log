2025-02-06 18:34:48,840 - INFO - Starting training with the following parameters:
2025-02-06 18:34:48,840 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product|
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.001          |
| epochs          | 200            |
| batch_size      | 16             |

2025-02-06 18:34:49,488 - INFO - Epoch 0: val_loss=1.2098, val_acc=0.00%
2025-02-06 18:34:49,630 - INFO - #################### Training epoch 0 ####################
2025-02-06 18:34:49,630 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:34:49,875 - INFO - Epoch 0: train_loss=1.1008
2025-02-06 18:34:50,233 - INFO - Epoch 0: train_loss=1.4746
2025-02-06 18:34:50,533 - INFO - Epoch 0: val_loss=1.1532, val_acc=0.00%
2025-02-06 18:34:50,550 - INFO - Epoch 0: EPOCH_AVG_TRAIN_LOSS=1.1008
2025-02-06 18:34:50,579 - INFO - #################### Training epoch 1 ####################
2025-02-06 18:34:50,579 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:34:50,982 - INFO - Epoch 1: train_loss=1.0745
2025-02-06 18:34:51,273 - INFO - Epoch 1: train_loss=1.1584
2025-02-06 18:34:51,599 - INFO - Epoch 1: val_loss=1.1097, val_acc=33.33%
2025-02-06 18:34:51,603 - INFO - Epoch 1: EPOCH_AVG_TRAIN_LOSS=1.0745
2025-02-06 18:34:51,628 - INFO - #################### Training epoch 2 ####################
2025-02-06 18:34:51,628 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:34:52,039 - INFO - Epoch 2: train_loss=1.0371
2025-02-06 18:34:52,331 - INFO - Epoch 2: train_loss=1.0786
2025-02-06 18:34:52,652 - INFO - Epoch 2: val_loss=1.0761, val_acc=33.33%
2025-02-06 18:34:52,656 - INFO - Epoch 2: EPOCH_AVG_TRAIN_LOSS=1.0371
2025-02-06 18:34:52,682 - INFO - #################### Training epoch 3 ####################
2025-02-06 18:34:52,682 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:34:53,095 - INFO - Epoch 3: train_loss=1.0081
2025-02-06 18:34:53,387 - INFO - Epoch 3: train_loss=1.1432
2025-02-06 18:34:53,707 - INFO - Epoch 3: val_loss=1.0431, val_acc=33.33%
2025-02-06 18:34:53,710 - INFO - Epoch 3: EPOCH_AVG_TRAIN_LOSS=1.0081
2025-02-06 18:34:53,738 - INFO - #################### Training epoch 4 ####################
2025-02-06 18:34:53,738 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:34:54,149 - INFO - Epoch 4: train_loss=1.0191
2025-02-06 18:34:54,440 - INFO - Epoch 4: train_loss=0.9426
2025-02-06 18:34:54,769 - INFO - Epoch 4: val_loss=1.1250, val_acc=0.00%
2025-02-06 18:34:54,773 - INFO - Epoch 4: EPOCH_AVG_TRAIN_LOSS=0.9426
2025-02-06 18:34:54,775 - INFO - #################### Training epoch 5 ####################
2025-02-06 18:34:54,775 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:34:55,185 - INFO - Epoch 5: train_loss=0.9599
2025-02-06 18:34:55,477 - INFO - Epoch 5: train_loss=0.9011
2025-02-06 18:34:55,805 - INFO - Epoch 5: val_loss=1.1574, val_acc=33.33%
2025-02-06 18:34:55,809 - INFO - Epoch 5: EPOCH_AVG_TRAIN_LOSS=0.9011
2025-02-06 18:34:55,811 - INFO - #################### Training epoch 6 ####################
2025-02-06 18:34:55,811 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:34:56,224 - INFO - Epoch 6: train_loss=0.9556
2025-02-06 18:34:56,515 - INFO - Epoch 6: train_loss=0.9659
2025-02-06 18:34:56,841 - INFO - Epoch 6: val_loss=1.1576, val_acc=0.00%
2025-02-06 18:34:56,844 - INFO - Epoch 6: EPOCH_AVG_TRAIN_LOSS=0.9556
2025-02-06 18:34:56,847 - INFO - #################### Training epoch 7 ####################
2025-02-06 18:34:56,847 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:34:57,256 - INFO - Epoch 7: train_loss=0.8955
2025-02-06 18:34:57,547 - INFO - Epoch 7: train_loss=0.8855
2025-02-06 18:34:57,878 - INFO - Epoch 7: val_loss=1.0743, val_acc=0.00%
2025-02-06 18:34:57,882 - INFO - Epoch 7: EPOCH_AVG_TRAIN_LOSS=0.8855
2025-02-06 18:34:57,910 - INFO - #################### Training epoch 8 ####################
2025-02-06 18:34:57,910 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:34:58,319 - INFO - Epoch 8: train_loss=0.8221
2025-02-06 18:34:58,611 - INFO - Epoch 8: train_loss=0.8915
2025-02-06 18:34:58,931 - INFO - Epoch 8: val_loss=1.0725, val_acc=0.00%
2025-02-06 18:34:58,935 - INFO - Epoch 8: EPOCH_AVG_TRAIN_LOSS=0.8221
2025-02-06 18:34:58,963 - INFO - #################### Training epoch 9 ####################
2025-02-06 18:34:58,963 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:34:59,374 - INFO - Epoch 9: train_loss=0.9161
2025-02-06 18:34:59,665 - INFO - Epoch 9: train_loss=0.7530
2025-02-06 18:34:59,989 - INFO - Epoch 9: val_loss=1.3324, val_acc=0.00%
2025-02-06 18:34:59,993 - INFO - Epoch 9: EPOCH_AVG_TRAIN_LOSS=0.7530
2025-02-06 18:34:59,995 - INFO - #################### Training epoch 10 ####################
2025-02-06 18:34:59,995 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:00,406 - INFO - Epoch 10: train_loss=0.8400
2025-02-06 18:35:00,697 - INFO - Epoch 10: train_loss=0.7320
2025-02-06 18:35:01,023 - INFO - Epoch 10: val_loss=1.4754, val_acc=0.00%
2025-02-06 18:35:01,027 - INFO - Epoch 10: EPOCH_AVG_TRAIN_LOSS=0.7320
2025-02-06 18:35:01,030 - INFO - #################### Training epoch 11 ####################
2025-02-06 18:35:01,030 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:01,440 - INFO - Epoch 11: train_loss=0.7691
2025-02-06 18:35:01,731 - INFO - Epoch 11: train_loss=1.1272
2025-02-06 18:35:02,058 - INFO - Epoch 11: val_loss=1.5811, val_acc=0.00%
2025-02-06 18:35:02,061 - INFO - Epoch 11: EPOCH_AVG_TRAIN_LOSS=0.7691
2025-02-06 18:35:02,064 - INFO - #################### Training epoch 12 ####################
2025-02-06 18:35:02,064 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:02,476 - INFO - Epoch 12: train_loss=0.8840
2025-02-06 18:35:02,767 - INFO - Epoch 12: train_loss=0.6523
2025-02-06 18:35:03,096 - INFO - Epoch 12: val_loss=1.6992, val_acc=0.00%
2025-02-06 18:35:03,100 - INFO - Epoch 12: EPOCH_AVG_TRAIN_LOSS=0.6523
2025-02-06 18:35:03,102 - INFO - #################### Training epoch 13 ####################
2025-02-06 18:35:03,102 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:03,511 - INFO - Epoch 13: train_loss=0.7100
2025-02-06 18:35:03,803 - INFO - Epoch 13: train_loss=1.0381
2025-02-06 18:35:04,130 - INFO - Epoch 13: val_loss=1.7171, val_acc=0.00%
2025-02-06 18:35:04,134 - INFO - Epoch 13: EPOCH_AVG_TRAIN_LOSS=0.7100
2025-02-06 18:35:04,136 - INFO - #################### Training epoch 14 ####################
2025-02-06 18:35:04,136 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:04,548 - INFO - Epoch 14: train_loss=0.8640
2025-02-06 18:35:04,839 - INFO - Epoch 14: train_loss=0.6329
2025-02-06 18:35:05,166 - INFO - Epoch 14: val_loss=1.6985, val_acc=0.00%
2025-02-06 18:35:05,169 - INFO - Epoch 14: EPOCH_AVG_TRAIN_LOSS=0.6329
2025-02-06 18:35:05,172 - INFO - #################### Training epoch 15 ####################
2025-02-06 18:35:05,172 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:05,586 - INFO - Epoch 15: train_loss=0.7370
2025-02-06 18:35:05,877 - INFO - Epoch 15: train_loss=0.6744
2025-02-06 18:35:06,202 - INFO - Epoch 15: val_loss=1.6362, val_acc=0.00%
2025-02-06 18:35:06,205 - INFO - Epoch 15: EPOCH_AVG_TRAIN_LOSS=0.6744
2025-02-06 18:35:06,208 - INFO - #################### Training epoch 16 ####################
2025-02-06 18:35:06,208 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:06,620 - INFO - Epoch 16: train_loss=0.6202
2025-02-06 18:35:06,911 - INFO - Epoch 16: train_loss=0.7434
2025-02-06 18:35:07,237 - INFO - Epoch 16: val_loss=1.6225, val_acc=0.00%
2025-02-06 18:35:07,241 - INFO - Epoch 16: EPOCH_AVG_TRAIN_LOSS=0.6202
2025-02-06 18:35:07,243 - INFO - #################### Training epoch 17 ####################
2025-02-06 18:35:07,243 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:07,655 - INFO - Epoch 17: train_loss=0.7280
2025-02-06 18:35:07,946 - INFO - Epoch 17: train_loss=0.4750
2025-02-06 18:35:08,269 - INFO - Epoch 17: val_loss=1.5605, val_acc=0.00%
2025-02-06 18:35:08,273 - INFO - Epoch 17: EPOCH_AVG_TRAIN_LOSS=0.4750
2025-02-06 18:35:08,275 - INFO - #################### Training epoch 18 ####################
2025-02-06 18:35:08,275 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:08,686 - INFO - Epoch 18: train_loss=0.6336
2025-02-06 18:35:08,977 - INFO - Epoch 18: train_loss=0.5863
2025-02-06 18:35:09,305 - INFO - Epoch 18: val_loss=2.3546, val_acc=0.00%
2025-02-06 18:35:09,309 - INFO - Epoch 18: EPOCH_AVG_TRAIN_LOSS=0.5863
2025-02-06 18:35:09,311 - INFO - #################### Training epoch 19 ####################
2025-02-06 18:35:09,312 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:09,723 - INFO - Epoch 19: train_loss=0.5061
2025-02-06 18:35:10,013 - INFO - Epoch 19: train_loss=1.2100
2025-02-06 18:35:10,342 - INFO - Epoch 19: val_loss=1.6506, val_acc=33.33%
2025-02-06 18:35:10,346 - INFO - Epoch 19: EPOCH_AVG_TRAIN_LOSS=0.5061
2025-02-06 18:35:10,348 - INFO - #################### Training epoch 20 ####################
2025-02-06 18:35:10,348 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:10,759 - INFO - Epoch 20: train_loss=0.9299
2025-02-06 18:35:11,050 - INFO - Epoch 20: train_loss=1.2013
2025-02-06 18:35:11,378 - INFO - Epoch 20: val_loss=1.6661, val_acc=33.33%
2025-02-06 18:35:11,381 - INFO - Epoch 20: EPOCH_AVG_TRAIN_LOSS=0.9299
2025-02-06 18:35:11,384 - INFO - #################### Training epoch 21 ####################
2025-02-06 18:35:11,384 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:11,795 - INFO - Epoch 21: train_loss=1.0504
2025-02-06 18:35:12,086 - INFO - Epoch 21: train_loss=1.4655
2025-02-06 18:35:12,415 - INFO - Epoch 21: val_loss=1.7051, val_acc=33.33%
2025-02-06 18:35:12,419 - INFO - Epoch 21: EPOCH_AVG_TRAIN_LOSS=1.0504
2025-02-06 18:35:12,422 - INFO - #################### Training epoch 22 ####################
2025-02-06 18:35:12,422 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:12,834 - INFO - Epoch 22: train_loss=1.5041
2025-02-06 18:35:13,126 - INFO - Epoch 22: train_loss=1.0188
2025-02-06 18:35:13,451 - INFO - Epoch 22: val_loss=1.7100, val_acc=33.33%
2025-02-06 18:35:13,455 - INFO - Epoch 22: EPOCH_AVG_TRAIN_LOSS=1.0188
2025-02-06 18:35:13,457 - INFO - #################### Training epoch 23 ####################
2025-02-06 18:35:13,457 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:13,870 - INFO - Epoch 23: train_loss=1.1929
2025-02-06 18:35:14,163 - INFO - Epoch 23: train_loss=1.5193
2025-02-06 18:35:14,490 - INFO - Epoch 23: val_loss=1.6845, val_acc=33.33%
2025-02-06 18:35:14,494 - INFO - Epoch 23: EPOCH_AVG_TRAIN_LOSS=1.1929
2025-02-06 18:35:14,497 - INFO - #################### Training epoch 24 ####################
2025-02-06 18:35:14,497 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:14,906 - INFO - Epoch 24: train_loss=1.2306
2025-02-06 18:35:15,197 - INFO - Epoch 24: train_loss=1.5854
2025-02-06 18:35:15,526 - INFO - Epoch 24: val_loss=1.6977, val_acc=33.33%
2025-02-06 18:35:15,529 - INFO - Epoch 24: EPOCH_AVG_TRAIN_LOSS=1.2306
2025-02-06 18:35:15,532 - INFO - #################### Training epoch 25 ####################
2025-02-06 18:35:15,532 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:15,941 - INFO - Epoch 25: train_loss=1.3628
2025-02-06 18:35:16,232 - INFO - Epoch 25: train_loss=1.3000
2025-02-06 18:35:16,560 - INFO - Epoch 25: val_loss=1.6913, val_acc=33.33%
2025-02-06 18:35:16,565 - INFO - Epoch 25: EPOCH_AVG_TRAIN_LOSS=1.3000
2025-02-06 18:35:16,568 - INFO - #################### Training epoch 26 ####################
2025-02-06 18:35:16,568 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:16,978 - INFO - Epoch 26: train_loss=1.3667
2025-02-06 18:35:17,269 - INFO - Epoch 26: train_loss=1.2418
2025-02-06 18:35:17,594 - INFO - Epoch 26: val_loss=1.6923, val_acc=33.33%
2025-02-06 18:35:17,598 - INFO - Epoch 26: EPOCH_AVG_TRAIN_LOSS=1.2418
2025-02-06 18:35:17,600 - INFO - #################### Training epoch 27 ####################
2025-02-06 18:35:17,600 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:18,008 - INFO - Epoch 27: train_loss=1.0751
2025-02-06 18:35:18,299 - INFO - Epoch 27: train_loss=1.8356
2025-02-06 18:35:18,625 - INFO - Epoch 27: val_loss=1.7196, val_acc=33.33%
2025-02-06 18:35:18,629 - INFO - Epoch 27: EPOCH_AVG_TRAIN_LOSS=1.0751
2025-02-06 18:35:18,631 - INFO - #################### Training epoch 28 ####################
2025-02-06 18:35:18,632 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:19,042 - INFO - Epoch 28: train_loss=1.1053
2025-02-06 18:35:19,333 - INFO - Epoch 28: train_loss=1.8940
2025-02-06 18:35:19,658 - INFO - Epoch 28: val_loss=1.7144, val_acc=33.33%
2025-02-06 18:35:19,661 - INFO - Epoch 28: EPOCH_AVG_TRAIN_LOSS=1.1053
2025-02-06 18:35:19,664 - INFO - #################### Training epoch 29 ####################
2025-02-06 18:35:19,664 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:20,074 - INFO - Epoch 29: train_loss=1.2825
2025-02-06 18:35:20,365 - INFO - Epoch 29: train_loss=1.4706
2025-02-06 18:35:20,689 - INFO - Epoch 29: val_loss=1.6959, val_acc=33.33%
2025-02-06 18:35:20,693 - INFO - Epoch 29: EPOCH_AVG_TRAIN_LOSS=1.2825
2025-02-06 18:35:20,695 - INFO - #################### Training epoch 30 ####################
2025-02-06 18:35:20,695 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:21,104 - INFO - Epoch 30: train_loss=1.3534
2025-02-06 18:35:21,396 - INFO - Epoch 30: train_loss=1.3370
2025-02-06 18:35:21,722 - INFO - Epoch 30: val_loss=1.7027, val_acc=33.33%
2025-02-06 18:35:21,726 - INFO - Epoch 30: EPOCH_AVG_TRAIN_LOSS=1.3370
2025-02-06 18:35:21,728 - INFO - #################### Training epoch 31 ####################
2025-02-06 18:35:21,729 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:22,140 - INFO - Epoch 31: train_loss=1.5771
2025-02-06 18:35:22,432 - INFO - Epoch 31: train_loss=0.8559
2025-02-06 18:35:22,761 - INFO - Epoch 31: val_loss=1.7283, val_acc=33.33%
2025-02-06 18:35:22,765 - INFO - Epoch 31: EPOCH_AVG_TRAIN_LOSS=0.8559
2025-02-06 18:35:22,767 - INFO - #################### Training epoch 32 ####################
2025-02-06 18:35:22,767 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:23,176 - INFO - Epoch 32: train_loss=1.1989
2025-02-06 18:35:23,467 - INFO - Epoch 32: train_loss=1.4042
2025-02-06 18:35:23,795 - INFO - Epoch 32: val_loss=1.6953, val_acc=33.33%
2025-02-06 18:35:23,799 - INFO - Epoch 32: EPOCH_AVG_TRAIN_LOSS=1.1989
2025-02-06 18:35:23,801 - INFO - #################### Training epoch 33 ####################
2025-02-06 18:35:23,801 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:24,211 - INFO - Epoch 33: train_loss=1.3742
2025-02-06 18:35:24,503 - INFO - Epoch 33: train_loss=1.1383
2025-02-06 18:35:24,828 - INFO - Epoch 33: val_loss=1.6923, val_acc=33.33%
2025-02-06 18:35:24,832 - INFO - Epoch 33: EPOCH_AVG_TRAIN_LOSS=1.1383
2025-02-06 18:35:24,834 - INFO - #################### Training epoch 34 ####################
2025-02-06 18:35:24,834 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:25,245 - INFO - Epoch 34: train_loss=1.6336
2025-02-06 18:35:25,535 - INFO - Epoch 34: train_loss=0.6037
2025-02-06 18:35:25,865 - INFO - Epoch 34: val_loss=1.6784, val_acc=33.33%
2025-02-06 18:35:25,869 - INFO - Epoch 34: EPOCH_AVG_TRAIN_LOSS=0.6037
2025-02-06 18:35:25,871 - INFO - #################### Training epoch 35 ####################
2025-02-06 18:35:25,871 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:26,281 - INFO - Epoch 35: train_loss=1.2894
2025-02-06 18:35:26,572 - INFO - Epoch 35: train_loss=1.2084
2025-02-06 18:35:26,897 - INFO - Epoch 35: val_loss=1.6507, val_acc=33.33%
2025-02-06 18:35:26,901 - INFO - Epoch 35: EPOCH_AVG_TRAIN_LOSS=1.2084
2025-02-06 18:35:26,903 - INFO - #################### Training epoch 36 ####################
2025-02-06 18:35:26,903 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:27,312 - INFO - Epoch 36: train_loss=1.1834
2025-02-06 18:35:27,603 - INFO - Epoch 36: train_loss=1.3779
2025-02-06 18:35:27,928 - INFO - Epoch 36: val_loss=1.6318, val_acc=33.33%
2025-02-06 18:35:27,932 - INFO - Epoch 36: EPOCH_AVG_TRAIN_LOSS=1.1834
2025-02-06 18:35:27,934 - INFO - #################### Training epoch 37 ####################
2025-02-06 18:35:27,934 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:28,342 - INFO - Epoch 37: train_loss=1.2710
2025-02-06 18:35:28,633 - INFO - Epoch 37: train_loss=1.1102
2025-02-06 18:35:28,958 - INFO - Epoch 37: val_loss=1.6316, val_acc=33.33%
2025-02-06 18:35:28,962 - INFO - Epoch 37: EPOCH_AVG_TRAIN_LOSS=1.1102
2025-02-06 18:35:28,964 - INFO - #################### Training epoch 38 ####################
2025-02-06 18:35:28,964 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:35:29,370 - INFO - Epoch 38: train_loss=1.4687
2025-02-06 18:35:29,661 - INFO - Epoch 38: train_loss=0.6969
2025-02-06 18:35:29,989 - INFO - Epoch 38: val_loss=1.6265, val_acc=33.33%
2025-02-06 18:35:29,993 - INFO - Epoch 38: EPOCH_AVG_TRAIN_LOSS=0.6969
2025-02-06 18:35:29,995 - INFO - #################### Training epoch 39 ####################
2025-02-06 18:35:29,995 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:30,407 - INFO - Epoch 39: train_loss=1.3453
2025-02-06 18:35:30,699 - INFO - Epoch 39: train_loss=1.0016
2025-02-06 18:35:31,019 - INFO - Epoch 39: val_loss=1.6341, val_acc=33.33%
2025-02-06 18:35:31,022 - INFO - Epoch 39: EPOCH_AVG_TRAIN_LOSS=1.0016
2025-02-06 18:35:31,025 - INFO - #################### Training epoch 40 ####################
2025-02-06 18:35:31,025 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:31,435 - INFO - Epoch 40: train_loss=1.1657
2025-02-06 18:35:31,726 - INFO - Epoch 40: train_loss=1.2187
2025-02-06 18:35:32,051 - INFO - Epoch 40: val_loss=1.6065, val_acc=33.33%
2025-02-06 18:35:32,055 - INFO - Epoch 40: EPOCH_AVG_TRAIN_LOSS=1.1657
2025-02-06 18:35:32,057 - INFO - #################### Training epoch 41 ####################
2025-02-06 18:35:32,057 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:32,466 - INFO - Epoch 41: train_loss=1.2495
2025-02-06 18:35:32,758 - INFO - Epoch 41: train_loss=1.0973
2025-02-06 18:35:33,081 - INFO - Epoch 41: val_loss=1.6136, val_acc=33.33%
2025-02-06 18:35:33,085 - INFO - Epoch 41: EPOCH_AVG_TRAIN_LOSS=1.0973
2025-02-06 18:35:33,087 - INFO - #################### Training epoch 42 ####################
2025-02-06 18:35:33,087 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:33,495 - INFO - Epoch 42: train_loss=1.1691
2025-02-06 18:35:33,787 - INFO - Epoch 42: train_loss=1.1567
2025-02-06 18:35:34,114 - INFO - Epoch 42: val_loss=1.6592, val_acc=33.33%
2025-02-06 18:35:34,117 - INFO - Epoch 42: EPOCH_AVG_TRAIN_LOSS=1.1567
2025-02-06 18:35:34,119 - INFO - #################### Training epoch 43 ####################
2025-02-06 18:35:34,119 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:34,529 - INFO - Epoch 43: train_loss=1.1668
2025-02-06 18:35:34,820 - INFO - Epoch 43: train_loss=1.3632
2025-02-06 18:35:35,146 - INFO - Epoch 43: val_loss=1.6025, val_acc=33.33%
2025-02-06 18:35:35,150 - INFO - Epoch 43: EPOCH_AVG_TRAIN_LOSS=1.1668
2025-02-06 18:35:35,152 - INFO - #################### Training epoch 44 ####################
2025-02-06 18:35:35,152 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:35,562 - INFO - Epoch 44: train_loss=1.3112
2025-02-06 18:35:35,853 - INFO - Epoch 44: train_loss=0.8818
2025-02-06 18:35:36,177 - INFO - Epoch 44: val_loss=1.6015, val_acc=33.33%
2025-02-06 18:35:36,181 - INFO - Epoch 44: EPOCH_AVG_TRAIN_LOSS=0.8818
2025-02-06 18:35:36,183 - INFO - #################### Training epoch 45 ####################
2025-02-06 18:35:36,183 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:36,591 - INFO - Epoch 45: train_loss=1.2684
2025-02-06 18:35:36,882 - INFO - Epoch 45: train_loss=0.8795
2025-02-06 18:35:37,207 - INFO - Epoch 45: val_loss=1.6112, val_acc=33.33%
2025-02-06 18:35:37,210 - INFO - Epoch 45: EPOCH_AVG_TRAIN_LOSS=0.8795
2025-02-06 18:35:37,213 - INFO - #################### Training epoch 46 ####################
2025-02-06 18:35:37,213 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:37,621 - INFO - Epoch 46: train_loss=1.1855
2025-02-06 18:35:37,913 - INFO - Epoch 46: train_loss=1.2119
2025-02-06 18:35:38,235 - INFO - Epoch 46: val_loss=1.5191, val_acc=33.33%
2025-02-06 18:35:38,239 - INFO - Epoch 46: EPOCH_AVG_TRAIN_LOSS=1.1855
2025-02-06 18:35:38,241 - INFO - #################### Training epoch 47 ####################
2025-02-06 18:35:38,241 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:38,652 - INFO - Epoch 47: train_loss=1.0322
2025-02-06 18:35:38,942 - INFO - Epoch 47: train_loss=1.2116
2025-02-06 18:35:39,270 - INFO - Epoch 47: val_loss=1.5530, val_acc=33.33%
2025-02-06 18:35:39,274 - INFO - Epoch 47: EPOCH_AVG_TRAIN_LOSS=1.0322
2025-02-06 18:35:39,276 - INFO - #################### Training epoch 48 ####################
2025-02-06 18:35:39,276 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:39,682 - INFO - Epoch 48: train_loss=1.0455
2025-02-06 18:35:39,974 - INFO - Epoch 48: train_loss=1.4294
2025-02-06 18:35:40,299 - INFO - Epoch 48: val_loss=1.5197, val_acc=33.33%
2025-02-06 18:35:40,303 - INFO - Epoch 48: EPOCH_AVG_TRAIN_LOSS=1.0455
2025-02-06 18:35:40,305 - INFO - #################### Training epoch 49 ####################
2025-02-06 18:35:40,305 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:40,714 - INFO - Epoch 49: train_loss=1.2636
2025-02-06 18:35:41,005 - INFO - Epoch 49: train_loss=0.8691
2025-02-06 18:35:41,331 - INFO - Epoch 49: val_loss=1.5716, val_acc=33.33%
2025-02-06 18:35:41,335 - INFO - Epoch 49: EPOCH_AVG_TRAIN_LOSS=0.8691
2025-02-06 18:35:41,337 - INFO - #################### Training epoch 50 ####################
2025-02-06 18:35:41,337 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:41,745 - INFO - Epoch 50: train_loss=1.2925
2025-02-06 18:35:42,036 - INFO - Epoch 50: train_loss=0.7717
2025-02-06 18:35:42,362 - INFO - Epoch 50: val_loss=1.6191, val_acc=33.33%
2025-02-06 18:35:42,365 - INFO - Epoch 50: EPOCH_AVG_TRAIN_LOSS=0.7717
2025-02-06 18:35:42,368 - INFO - #################### Training epoch 51 ####################
2025-02-06 18:35:42,368 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:42,777 - INFO - Epoch 51: train_loss=1.0990
2025-02-06 18:35:43,069 - INFO - Epoch 51: train_loss=1.0593
2025-02-06 18:35:43,387 - INFO - Epoch 51: val_loss=1.6192, val_acc=33.33%
2025-02-06 18:35:43,391 - INFO - Epoch 51: EPOCH_AVG_TRAIN_LOSS=1.0593
2025-02-06 18:35:43,393 - INFO - #################### Training epoch 52 ####################
2025-02-06 18:35:43,393 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:43,803 - INFO - Epoch 52: train_loss=1.1283
2025-02-06 18:35:44,095 - INFO - Epoch 52: train_loss=1.0121
2025-02-06 18:35:44,420 - INFO - Epoch 52: val_loss=1.5325, val_acc=33.33%
2025-02-06 18:35:44,423 - INFO - Epoch 52: EPOCH_AVG_TRAIN_LOSS=1.0121
2025-02-06 18:35:44,425 - INFO - #################### Training epoch 53 ####################
2025-02-06 18:35:44,425 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:44,835 - INFO - Epoch 53: train_loss=0.9866
2025-02-06 18:35:45,126 - INFO - Epoch 53: train_loss=1.2338
2025-02-06 18:35:45,451 - INFO - Epoch 53: val_loss=1.6272, val_acc=33.33%
2025-02-06 18:35:45,454 - INFO - Epoch 53: EPOCH_AVG_TRAIN_LOSS=0.9866
2025-02-06 18:35:45,456 - INFO - #################### Training epoch 54 ####################
2025-02-06 18:35:45,457 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:45,866 - INFO - Epoch 54: train_loss=1.0469
2025-02-06 18:35:46,157 - INFO - Epoch 54: train_loss=0.9710
2025-02-06 18:35:46,487 - INFO - Epoch 54: val_loss=1.6327, val_acc=33.33%
2025-02-06 18:35:46,490 - INFO - Epoch 54: EPOCH_AVG_TRAIN_LOSS=0.9710
2025-02-06 18:35:46,492 - INFO - #################### Training epoch 55 ####################
2025-02-06 18:35:46,492 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:46,900 - INFO - Epoch 55: train_loss=0.8251
2025-02-06 18:35:47,192 - INFO - Epoch 55: train_loss=1.3719
2025-02-06 18:35:47,515 - INFO - Epoch 55: val_loss=1.5747, val_acc=33.33%
2025-02-06 18:35:47,519 - INFO - Epoch 55: EPOCH_AVG_TRAIN_LOSS=0.8251
2025-02-06 18:35:47,521 - INFO - #################### Training epoch 56 ####################
2025-02-06 18:35:47,521 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:47,931 - INFO - Epoch 56: train_loss=0.8274
2025-02-06 18:35:48,223 - INFO - Epoch 56: train_loss=1.2928
2025-02-06 18:35:48,550 - INFO - Epoch 56: val_loss=1.5781, val_acc=0.00%
2025-02-06 18:35:48,554 - INFO - Epoch 56: EPOCH_AVG_TRAIN_LOSS=0.8274
2025-02-06 18:35:48,556 - INFO - #################### Training epoch 57 ####################
2025-02-06 18:35:48,556 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:48,967 - INFO - Epoch 57: train_loss=0.9885
2025-02-06 18:35:49,259 - INFO - Epoch 57: train_loss=0.8881
2025-02-06 18:35:49,587 - INFO - Epoch 57: val_loss=1.5652, val_acc=0.00%
2025-02-06 18:35:49,591 - INFO - Epoch 57: EPOCH_AVG_TRAIN_LOSS=0.8881
2025-02-06 18:35:49,593 - INFO - #################### Training epoch 58 ####################
2025-02-06 18:35:49,593 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:50,006 - INFO - Epoch 58: train_loss=1.1491
2025-02-06 18:35:50,300 - INFO - Epoch 58: train_loss=0.4865
2025-02-06 18:35:50,623 - INFO - Epoch 58: val_loss=1.5271, val_acc=0.00%
2025-02-06 18:35:50,627 - INFO - Epoch 58: EPOCH_AVG_TRAIN_LOSS=0.4865
2025-02-06 18:35:50,629 - INFO - #################### Training epoch 59 ####################
2025-02-06 18:35:50,629 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:35:51,039 - INFO - Epoch 59: train_loss=0.8726
2025-02-06 18:35:51,331 - INFO - Epoch 59: train_loss=1.0148
2025-02-06 18:35:51,659 - INFO - Epoch 59: val_loss=1.5994, val_acc=0.00%
2025-02-06 18:35:51,663 - INFO - Epoch 59: EPOCH_AVG_TRAIN_LOSS=0.8726
2025-02-06 18:35:51,665 - INFO - #################### Training epoch 60 ####################
2025-02-06 18:35:51,665 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:35:52,074 - INFO - Epoch 60: train_loss=0.7104
2025-02-06 18:35:52,364 - INFO - Epoch 60: train_loss=1.3941
2025-02-06 18:35:52,691 - INFO - Epoch 60: val_loss=1.5461, val_acc=0.00%
2025-02-06 18:35:52,694 - INFO - Epoch 60: EPOCH_AVG_TRAIN_LOSS=0.7104
2025-02-06 18:35:52,697 - INFO - #################### Training epoch 61 ####################
2025-02-06 18:35:52,697 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:35:53,103 - INFO - Epoch 61: train_loss=1.0688
2025-02-06 18:35:53,395 - INFO - Epoch 61: train_loss=0.6704
2025-02-06 18:35:53,724 - INFO - Epoch 61: val_loss=1.5628, val_acc=0.00%
2025-02-06 18:35:53,727 - INFO - Epoch 61: EPOCH_AVG_TRAIN_LOSS=0.6704
2025-02-06 18:35:53,730 - INFO - #################### Training epoch 62 ####################
2025-02-06 18:35:53,730 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:35:54,143 - INFO - Epoch 62: train_loss=0.7979
2025-02-06 18:35:54,433 - INFO - Epoch 62: train_loss=1.1927
2025-02-06 18:35:54,759 - INFO - Epoch 62: val_loss=1.5545, val_acc=0.00%
2025-02-06 18:35:54,763 - INFO - Epoch 62: EPOCH_AVG_TRAIN_LOSS=0.7979
2025-02-06 18:35:54,765 - INFO - #################### Training epoch 63 ####################
2025-02-06 18:35:54,765 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:35:55,176 - INFO - Epoch 63: train_loss=1.0324
2025-02-06 18:35:55,468 - INFO - Epoch 63: train_loss=0.6139
2025-02-06 18:35:55,791 - INFO - Epoch 63: val_loss=1.4915, val_acc=0.00%
2025-02-06 18:35:55,794 - INFO - Epoch 63: EPOCH_AVG_TRAIN_LOSS=0.6139
2025-02-06 18:35:55,796 - INFO - #################### Training epoch 64 ####################
2025-02-06 18:35:55,797 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:35:56,210 - INFO - Epoch 64: train_loss=0.9506
2025-02-06 18:35:56,500 - INFO - Epoch 64: train_loss=0.7943
2025-02-06 18:35:56,825 - INFO - Epoch 64: val_loss=1.5184, val_acc=0.00%
2025-02-06 18:35:56,829 - INFO - Epoch 64: EPOCH_AVG_TRAIN_LOSS=0.7943
2025-02-06 18:35:56,831 - INFO - #################### Training epoch 65 ####################
2025-02-06 18:35:56,831 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:35:57,242 - INFO - Epoch 65: train_loss=0.8401
2025-02-06 18:35:57,533 - INFO - Epoch 65: train_loss=1.2872
2025-02-06 18:35:57,860 - INFO - Epoch 65: val_loss=1.5640, val_acc=0.00%
2025-02-06 18:35:57,864 - INFO - Epoch 65: EPOCH_AVG_TRAIN_LOSS=0.8401
2025-02-06 18:35:57,866 - INFO - #################### Training epoch 66 ####################
2025-02-06 18:35:57,866 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:35:58,274 - INFO - Epoch 66: train_loss=1.1481
2025-02-06 18:35:58,565 - INFO - Epoch 66: train_loss=0.5527
2025-02-06 18:35:58,892 - INFO - Epoch 66: val_loss=1.5608, val_acc=0.00%
2025-02-06 18:35:58,896 - INFO - Epoch 66: EPOCH_AVG_TRAIN_LOSS=0.5527
2025-02-06 18:35:58,898 - INFO - #################### Training epoch 67 ####################
2025-02-06 18:35:58,898 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:35:59,308 - INFO - Epoch 67: train_loss=0.9632
2025-02-06 18:35:59,599 - INFO - Epoch 67: train_loss=0.9330
2025-02-06 18:35:59,923 - INFO - Epoch 67: val_loss=1.5251, val_acc=0.00%
2025-02-06 18:35:59,927 - INFO - Epoch 67: EPOCH_AVG_TRAIN_LOSS=0.9330
2025-02-06 18:35:59,929 - INFO - #################### Training epoch 68 ####################
2025-02-06 18:35:59,929 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:00,339 - INFO - Epoch 68: train_loss=0.8064
2025-02-06 18:36:00,630 - INFO - Epoch 68: train_loss=1.1289
2025-02-06 18:36:00,955 - INFO - Epoch 68: val_loss=1.5885, val_acc=0.00%
2025-02-06 18:36:00,958 - INFO - Epoch 68: EPOCH_AVG_TRAIN_LOSS=0.8064
2025-02-06 18:36:00,961 - INFO - #################### Training epoch 69 ####################
2025-02-06 18:36:00,961 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:01,372 - INFO - Epoch 69: train_loss=0.8798
2025-02-06 18:36:01,662 - INFO - Epoch 69: train_loss=1.0327
2025-02-06 18:36:01,985 - INFO - Epoch 69: val_loss=1.5718, val_acc=0.00%
2025-02-06 18:36:01,989 - INFO - Epoch 69: EPOCH_AVG_TRAIN_LOSS=0.8798
2025-02-06 18:36:01,991 - INFO - #################### Training epoch 70 ####################
2025-02-06 18:36:01,991 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:02,401 - INFO - Epoch 70: train_loss=1.0817
2025-02-06 18:36:02,692 - INFO - Epoch 70: train_loss=0.7701
2025-02-06 18:36:03,015 - INFO - Epoch 70: val_loss=1.6149, val_acc=0.00%
2025-02-06 18:36:03,019 - INFO - Epoch 70: EPOCH_AVG_TRAIN_LOSS=0.7701
2025-02-06 18:36:03,021 - INFO - #################### Training epoch 71 ####################
2025-02-06 18:36:03,021 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:03,426 - INFO - Epoch 71: train_loss=0.7755
2025-02-06 18:36:03,716 - INFO - Epoch 71: train_loss=1.1266
2025-02-06 18:36:04,044 - INFO - Epoch 71: val_loss=1.5446, val_acc=0.00%
2025-02-06 18:36:04,047 - INFO - Epoch 71: EPOCH_AVG_TRAIN_LOSS=0.7755
2025-02-06 18:36:04,049 - INFO - #################### Training epoch 72 ####################
2025-02-06 18:36:04,049 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:04,458 - INFO - Epoch 72: train_loss=0.9899
2025-02-06 18:36:04,749 - INFO - Epoch 72: train_loss=0.8481
2025-02-06 18:36:05,076 - INFO - Epoch 72: val_loss=1.5610, val_acc=0.00%
2025-02-06 18:36:05,080 - INFO - Epoch 72: EPOCH_AVG_TRAIN_LOSS=0.8481
2025-02-06 18:36:05,082 - INFO - #################### Training epoch 73 ####################
2025-02-06 18:36:05,082 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:05,490 - INFO - Epoch 73: train_loss=0.9507
2025-02-06 18:36:05,781 - INFO - Epoch 73: train_loss=0.7967
2025-02-06 18:36:06,106 - INFO - Epoch 73: val_loss=1.5568, val_acc=0.00%
2025-02-06 18:36:06,110 - INFO - Epoch 73: EPOCH_AVG_TRAIN_LOSS=0.7967
2025-02-06 18:36:06,112 - INFO - #################### Training epoch 74 ####################
2025-02-06 18:36:06,112 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:06,518 - INFO - Epoch 74: train_loss=1.1237
2025-02-06 18:36:06,809 - INFO - Epoch 74: train_loss=0.5231
2025-02-06 18:36:07,135 - INFO - Epoch 74: val_loss=1.6064, val_acc=0.00%
2025-02-06 18:36:07,139 - INFO - Epoch 74: EPOCH_AVG_TRAIN_LOSS=0.5231
2025-02-06 18:36:07,141 - INFO - #################### Training epoch 75 ####################
2025-02-06 18:36:07,141 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:07,551 - INFO - Epoch 75: train_loss=0.8910
2025-02-06 18:36:07,843 - INFO - Epoch 75: train_loss=0.8989
2025-02-06 18:36:08,165 - INFO - Epoch 75: val_loss=1.5592, val_acc=0.00%
2025-02-06 18:36:08,169 - INFO - Epoch 75: EPOCH_AVG_TRAIN_LOSS=0.8910
2025-02-06 18:36:08,171 - INFO - #################### Training epoch 76 ####################
2025-02-06 18:36:08,171 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:08,580 - INFO - Epoch 76: train_loss=0.8641
2025-02-06 18:36:08,871 - INFO - Epoch 76: train_loss=1.0823
2025-02-06 18:36:09,196 - INFO - Epoch 76: val_loss=1.6075, val_acc=0.00%
2025-02-06 18:36:09,200 - INFO - Epoch 76: EPOCH_AVG_TRAIN_LOSS=0.8641
2025-02-06 18:36:09,202 - INFO - #################### Training epoch 77 ####################
2025-02-06 18:36:09,202 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:09,613 - INFO - Epoch 77: train_loss=0.9533
2025-02-06 18:36:09,904 - INFO - Epoch 77: train_loss=0.8529
2025-02-06 18:36:10,230 - INFO - Epoch 77: val_loss=1.5507, val_acc=0.00%
2025-02-06 18:36:10,234 - INFO - Epoch 77: EPOCH_AVG_TRAIN_LOSS=0.8529
2025-02-06 18:36:10,236 - INFO - #################### Training epoch 78 ####################
2025-02-06 18:36:10,236 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:10,648 - INFO - Epoch 78: train_loss=1.1546
2025-02-06 18:36:10,939 - INFO - Epoch 78: train_loss=0.5585
2025-02-06 18:36:11,265 - INFO - Epoch 78: val_loss=1.6055, val_acc=0.00%
2025-02-06 18:36:11,268 - INFO - Epoch 78: EPOCH_AVG_TRAIN_LOSS=0.5585
2025-02-06 18:36:11,271 - INFO - #################### Training epoch 79 ####################
2025-02-06 18:36:11,271 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:11,682 - INFO - Epoch 79: train_loss=0.9997
2025-02-06 18:36:11,972 - INFO - Epoch 79: train_loss=0.7937
2025-02-06 18:36:12,302 - INFO - Epoch 79: val_loss=1.5315, val_acc=0.00%
2025-02-06 18:36:12,306 - INFO - Epoch 79: EPOCH_AVG_TRAIN_LOSS=0.7937
2025-02-06 18:36:12,308 - INFO - #################### Training epoch 80 ####################
2025-02-06 18:36:12,308 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:36:12,719 - INFO - Epoch 80: train_loss=0.9670
2025-02-06 18:36:13,010 - INFO - Epoch 80: train_loss=0.8798
2025-02-06 18:36:13,335 - INFO - Epoch 80: val_loss=1.5347, val_acc=0.00%
2025-02-06 18:36:13,338 - INFO - Epoch 80: EPOCH_AVG_TRAIN_LOSS=0.8798
2025-02-06 18:36:13,341 - INFO - #################### Training epoch 81 ####################
2025-02-06 18:36:13,341 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:13,749 - INFO - Epoch 81: train_loss=1.1342
2025-02-06 18:36:14,040 - INFO - Epoch 81: train_loss=0.5858
2025-02-06 18:36:14,371 - INFO - Epoch 81: val_loss=1.6127, val_acc=0.00%
2025-02-06 18:36:14,375 - INFO - Epoch 81: EPOCH_AVG_TRAIN_LOSS=0.5858
2025-02-06 18:36:14,377 - INFO - #################### Training epoch 82 ####################
2025-02-06 18:36:14,377 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:14,785 - INFO - Epoch 82: train_loss=0.8998
2025-02-06 18:36:15,076 - INFO - Epoch 82: train_loss=0.9552
2025-02-06 18:36:15,398 - INFO - Epoch 82: val_loss=1.5419, val_acc=0.00%
2025-02-06 18:36:15,402 - INFO - Epoch 82: EPOCH_AVG_TRAIN_LOSS=0.8998
2025-02-06 18:36:15,404 - INFO - #################### Training epoch 83 ####################
2025-02-06 18:36:15,404 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:15,812 - INFO - Epoch 83: train_loss=0.8387
2025-02-06 18:36:16,104 - INFO - Epoch 83: train_loss=1.1392
2025-02-06 18:36:16,423 - INFO - Epoch 83: val_loss=1.6177, val_acc=0.00%
2025-02-06 18:36:16,427 - INFO - Epoch 83: EPOCH_AVG_TRAIN_LOSS=0.8387
2025-02-06 18:36:16,429 - INFO - #################### Training epoch 84 ####################
2025-02-06 18:36:16,429 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:16,842 - INFO - Epoch 84: train_loss=0.9312
2025-02-06 18:36:17,133 - INFO - Epoch 84: train_loss=0.8331
2025-02-06 18:36:17,458 - INFO - Epoch 84: val_loss=1.5290, val_acc=0.00%
2025-02-06 18:36:17,462 - INFO - Epoch 84: EPOCH_AVG_TRAIN_LOSS=0.8331
2025-02-06 18:36:17,464 - INFO - #################### Training epoch 85 ####################
2025-02-06 18:36:17,464 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:17,874 - INFO - Epoch 85: train_loss=0.6656
2025-02-06 18:36:18,166 - INFO - Epoch 85: train_loss=1.3468
2025-02-06 18:36:18,493 - INFO - Epoch 85: val_loss=1.6160, val_acc=0.00%
2025-02-06 18:36:18,497 - INFO - Epoch 85: EPOCH_AVG_TRAIN_LOSS=0.6656
2025-02-06 18:36:18,499 - INFO - #################### Training epoch 86 ####################
2025-02-06 18:36:18,499 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:18,910 - INFO - Epoch 86: train_loss=0.7770
2025-02-06 18:36:19,202 - INFO - Epoch 86: train_loss=1.0869
2025-02-06 18:36:19,525 - INFO - Epoch 86: val_loss=1.5683, val_acc=0.00%
2025-02-06 18:36:19,529 - INFO - Epoch 86: EPOCH_AVG_TRAIN_LOSS=0.7770
2025-02-06 18:36:19,531 - INFO - #################### Training epoch 87 ####################
2025-02-06 18:36:19,531 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:19,945 - INFO - Epoch 87: train_loss=0.8813
2025-02-06 18:36:20,237 - INFO - Epoch 87: train_loss=1.0236
2025-02-06 18:36:20,562 - INFO - Epoch 87: val_loss=1.6189, val_acc=0.00%
2025-02-06 18:36:20,566 - INFO - Epoch 87: EPOCH_AVG_TRAIN_LOSS=0.8813
2025-02-06 18:36:20,568 - INFO - #################### Training epoch 88 ####################
2025-02-06 18:36:20,568 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:20,981 - INFO - Epoch 88: train_loss=0.8720
2025-02-06 18:36:21,272 - INFO - Epoch 88: train_loss=1.0322
2025-02-06 18:36:21,599 - INFO - Epoch 88: val_loss=1.6247, val_acc=0.00%
2025-02-06 18:36:21,603 - INFO - Epoch 88: EPOCH_AVG_TRAIN_LOSS=0.8720
2025-02-06 18:36:21,605 - INFO - #################### Training epoch 89 ####################
2025-02-06 18:36:21,605 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:22,014 - INFO - Epoch 89: train_loss=0.8672
2025-02-06 18:36:22,305 - INFO - Epoch 89: train_loss=0.9678
2025-02-06 18:36:22,633 - INFO - Epoch 89: val_loss=1.6195, val_acc=0.00%
2025-02-06 18:36:22,636 - INFO - Epoch 89: EPOCH_AVG_TRAIN_LOSS=0.8672
2025-02-06 18:36:22,639 - INFO - #################### Training epoch 90 ####################
2025-02-06 18:36:22,639 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:23,045 - INFO - Epoch 90: train_loss=0.9127
2025-02-06 18:36:23,336 - INFO - Epoch 90: train_loss=0.9443
2025-02-06 18:36:23,659 - INFO - Epoch 90: val_loss=1.5275, val_acc=0.00%
2025-02-06 18:36:23,663 - INFO - Epoch 90: EPOCH_AVG_TRAIN_LOSS=0.9127
2025-02-06 18:36:23,665 - INFO - #################### Training epoch 91 ####################
2025-02-06 18:36:23,665 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:24,075 - INFO - Epoch 91: train_loss=0.9038
2025-02-06 18:36:24,366 - INFO - Epoch 91: train_loss=0.9450
2025-02-06 18:36:24,693 - INFO - Epoch 91: val_loss=1.5871, val_acc=0.00%
2025-02-06 18:36:24,696 - INFO - Epoch 91: EPOCH_AVG_TRAIN_LOSS=0.9038
2025-02-06 18:36:24,699 - INFO - #################### Training epoch 92 ####################
2025-02-06 18:36:24,699 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:25,109 - INFO - Epoch 92: train_loss=0.8529
2025-02-06 18:36:25,400 - INFO - Epoch 92: train_loss=0.8066
2025-02-06 18:36:25,724 - INFO - Epoch 92: val_loss=1.5750, val_acc=0.00%
2025-02-06 18:36:25,728 - INFO - Epoch 92: EPOCH_AVG_TRAIN_LOSS=0.8066
2025-02-06 18:36:25,730 - INFO - #################### Training epoch 93 ####################
2025-02-06 18:36:25,730 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:26,138 - INFO - Epoch 93: train_loss=0.9505
2025-02-06 18:36:26,429 - INFO - Epoch 93: train_loss=0.8929
2025-02-06 18:36:26,752 - INFO - Epoch 93: val_loss=1.5180, val_acc=0.00%
2025-02-06 18:36:26,756 - INFO - Epoch 93: EPOCH_AVG_TRAIN_LOSS=0.8929
2025-02-06 18:36:26,758 - INFO - #################### Training epoch 94 ####################
2025-02-06 18:36:26,758 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:27,170 - INFO - Epoch 94: train_loss=0.9543
2025-02-06 18:36:27,462 - INFO - Epoch 94: train_loss=0.8512
2025-02-06 18:36:27,788 - INFO - Epoch 94: val_loss=1.6480, val_acc=0.00%
2025-02-06 18:36:27,792 - INFO - Epoch 94: EPOCH_AVG_TRAIN_LOSS=0.8512
2025-02-06 18:36:27,794 - INFO - #################### Training epoch 95 ####################
2025-02-06 18:36:27,794 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:28,206 - INFO - Epoch 95: train_loss=0.6861
2025-02-06 18:36:28,497 - INFO - Epoch 95: train_loss=1.3250
2025-02-06 18:36:28,825 - INFO - Epoch 95: val_loss=1.6036, val_acc=0.00%
2025-02-06 18:36:28,828 - INFO - Epoch 95: EPOCH_AVG_TRAIN_LOSS=0.6861
2025-02-06 18:36:28,831 - INFO - #################### Training epoch 96 ####################
2025-02-06 18:36:28,831 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:29,241 - INFO - Epoch 96: train_loss=1.1927
2025-02-06 18:36:29,532 - INFO - Epoch 96: train_loss=0.3703
2025-02-06 18:36:29,862 - INFO - Epoch 96: val_loss=1.5749, val_acc=0.00%
2025-02-06 18:36:29,866 - INFO - Epoch 96: EPOCH_AVG_TRAIN_LOSS=0.3703
2025-02-06 18:36:29,868 - INFO - #################### Training epoch 97 ####################
2025-02-06 18:36:29,868 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:30,277 - INFO - Epoch 97: train_loss=0.8940
2025-02-06 18:36:30,568 - INFO - Epoch 97: train_loss=0.9334
2025-02-06 18:36:30,892 - INFO - Epoch 97: val_loss=1.5960, val_acc=0.00%
2025-02-06 18:36:30,896 - INFO - Epoch 97: EPOCH_AVG_TRAIN_LOSS=0.8940
2025-02-06 18:36:30,898 - INFO - #################### Training epoch 98 ####################
2025-02-06 18:36:30,898 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:31,307 - INFO - Epoch 98: train_loss=1.0741
2025-02-06 18:36:31,599 - INFO - Epoch 98: train_loss=0.5052
2025-02-06 18:36:31,924 - INFO - Epoch 98: val_loss=1.6467, val_acc=0.00%
2025-02-06 18:36:31,928 - INFO - Epoch 98: EPOCH_AVG_TRAIN_LOSS=0.5052
2025-02-06 18:36:31,930 - INFO - #################### Training epoch 99 ####################
2025-02-06 18:36:31,930 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:32,341 - INFO - Epoch 99: train_loss=0.8750
2025-02-06 18:36:32,633 - INFO - Epoch 99: train_loss=1.0000
2025-02-06 18:36:32,955 - INFO - Epoch 99: val_loss=1.5434, val_acc=0.00%
2025-02-06 18:36:32,958 - INFO - Epoch 99: EPOCH_AVG_TRAIN_LOSS=0.8750
2025-02-06 18:36:32,961 - INFO - #################### Training epoch 100 ####################
2025-02-06 18:36:32,961 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:33,369 - INFO - Epoch 100: train_loss=0.5900
2025-02-06 18:36:33,660 - INFO - Epoch 100: train_loss=1.5316
2025-02-06 18:36:33,988 - INFO - Epoch 100: val_loss=1.4926, val_acc=0.00%
2025-02-06 18:36:33,992 - INFO - Epoch 100: EPOCH_AVG_TRAIN_LOSS=0.5900
2025-02-06 18:36:33,994 - INFO - #################### Training epoch 101 ####################
2025-02-06 18:36:33,994 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:34,404 - INFO - Epoch 101: train_loss=0.8510
2025-02-06 18:36:34,695 - INFO - Epoch 101: train_loss=1.0821
2025-02-06 18:36:35,021 - INFO - Epoch 101: val_loss=1.5411, val_acc=0.00%
2025-02-06 18:36:35,025 - INFO - Epoch 101: EPOCH_AVG_TRAIN_LOSS=0.8510
2025-02-06 18:36:35,027 - INFO - #################### Training epoch 102 ####################
2025-02-06 18:36:35,027 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:35,435 - INFO - Epoch 102: train_loss=0.9333
2025-02-06 18:36:35,726 - INFO - Epoch 102: train_loss=0.7816
2025-02-06 18:36:36,053 - INFO - Epoch 102: val_loss=1.6033, val_acc=0.00%
2025-02-06 18:36:36,056 - INFO - Epoch 102: EPOCH_AVG_TRAIN_LOSS=0.7816
2025-02-06 18:36:36,059 - INFO - #################### Training epoch 103 ####################
2025-02-06 18:36:36,059 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:36,468 - INFO - Epoch 103: train_loss=0.9409
2025-02-06 18:36:36,759 - INFO - Epoch 103: train_loss=0.8282
2025-02-06 18:36:37,090 - INFO - Epoch 103: val_loss=1.5683, val_acc=0.00%
2025-02-06 18:36:37,094 - INFO - Epoch 103: EPOCH_AVG_TRAIN_LOSS=0.8282
2025-02-06 18:36:37,096 - INFO - #################### Training epoch 104 ####################
2025-02-06 18:36:37,096 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:37,507 - INFO - Epoch 104: train_loss=0.9573
2025-02-06 18:36:37,798 - INFO - Epoch 104: train_loss=0.8111
2025-02-06 18:36:38,125 - INFO - Epoch 104: val_loss=1.6163, val_acc=0.00%
2025-02-06 18:36:38,129 - INFO - Epoch 104: EPOCH_AVG_TRAIN_LOSS=0.8111
2025-02-06 18:36:38,131 - INFO - #################### Training epoch 105 ####################
2025-02-06 18:36:38,131 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:38,544 - INFO - Epoch 105: train_loss=0.8990
2025-02-06 18:36:38,836 - INFO - Epoch 105: train_loss=0.9855
2025-02-06 18:36:39,164 - INFO - Epoch 105: val_loss=1.5425, val_acc=0.00%
2025-02-06 18:36:39,168 - INFO - Epoch 105: EPOCH_AVG_TRAIN_LOSS=0.8990
2025-02-06 18:36:39,170 - INFO - #################### Training epoch 106 ####################
2025-02-06 18:36:39,170 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:39,583 - INFO - Epoch 106: train_loss=0.9265
2025-02-06 18:36:39,875 - INFO - Epoch 106: train_loss=0.8956
2025-02-06 18:36:40,202 - INFO - Epoch 106: val_loss=1.5600, val_acc=0.00%
2025-02-06 18:36:40,206 - INFO - Epoch 106: EPOCH_AVG_TRAIN_LOSS=0.8956
2025-02-06 18:36:40,208 - INFO - #################### Training epoch 107 ####################
2025-02-06 18:36:40,208 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:40,619 - INFO - Epoch 107: train_loss=1.0497
2025-02-06 18:36:40,910 - INFO - Epoch 107: train_loss=0.5499
2025-02-06 18:36:41,236 - INFO - Epoch 107: val_loss=1.5391, val_acc=0.00%
2025-02-06 18:36:41,240 - INFO - Epoch 107: EPOCH_AVG_TRAIN_LOSS=0.5499
2025-02-06 18:36:41,243 - INFO - #################### Training epoch 108 ####################
2025-02-06 18:36:41,243 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:41,650 - INFO - Epoch 108: train_loss=0.8608
2025-02-06 18:36:41,942 - INFO - Epoch 108: train_loss=1.0277
2025-02-06 18:36:42,268 - INFO - Epoch 108: val_loss=1.5807, val_acc=0.00%
2025-02-06 18:36:42,272 - INFO - Epoch 108: EPOCH_AVG_TRAIN_LOSS=0.8608
2025-02-06 18:36:42,274 - INFO - #################### Training epoch 109 ####################
2025-02-06 18:36:42,274 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:42,687 - INFO - Epoch 109: train_loss=0.7831
2025-02-06 18:36:42,979 - INFO - Epoch 109: train_loss=1.0723
2025-02-06 18:36:43,301 - INFO - Epoch 109: val_loss=1.5568, val_acc=0.00%
2025-02-06 18:36:43,305 - INFO - Epoch 109: EPOCH_AVG_TRAIN_LOSS=0.7831
2025-02-06 18:36:43,307 - INFO - #################### Training epoch 110 ####################
2025-02-06 18:36:43,307 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:43,717 - INFO - Epoch 110: train_loss=0.7199
2025-02-06 18:36:44,008 - INFO - Epoch 110: train_loss=1.2915
2025-02-06 18:36:44,333 - INFO - Epoch 110: val_loss=1.6040, val_acc=0.00%
2025-02-06 18:36:44,337 - INFO - Epoch 110: EPOCH_AVG_TRAIN_LOSS=0.7199
2025-02-06 18:36:44,339 - INFO - #################### Training epoch 111 ####################
2025-02-06 18:36:44,339 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:44,749 - INFO - Epoch 111: train_loss=1.0426
2025-02-06 18:36:45,041 - INFO - Epoch 111: train_loss=0.6681
2025-02-06 18:36:45,365 - INFO - Epoch 111: val_loss=1.5574, val_acc=0.00%
2025-02-06 18:36:45,369 - INFO - Epoch 111: EPOCH_AVG_TRAIN_LOSS=0.6681
2025-02-06 18:36:45,371 - INFO - #################### Training epoch 112 ####################
2025-02-06 18:36:45,371 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:45,781 - INFO - Epoch 112: train_loss=0.6962
2025-02-06 18:36:46,072 - INFO - Epoch 112: train_loss=1.1424
2025-02-06 18:36:46,397 - INFO - Epoch 112: val_loss=1.6235, val_acc=0.00%
2025-02-06 18:36:46,401 - INFO - Epoch 112: EPOCH_AVG_TRAIN_LOSS=0.6962
2025-02-06 18:36:46,403 - INFO - #################### Training epoch 113 ####################
2025-02-06 18:36:46,403 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:46,814 - INFO - Epoch 113: train_loss=0.8156
2025-02-06 18:36:47,105 - INFO - Epoch 113: train_loss=0.9613
2025-02-06 18:36:47,435 - INFO - Epoch 113: val_loss=1.5305, val_acc=0.00%
2025-02-06 18:36:47,439 - INFO - Epoch 113: EPOCH_AVG_TRAIN_LOSS=0.8156
2025-02-06 18:36:47,441 - INFO - #################### Training epoch 114 ####################
2025-02-06 18:36:47,441 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:47,850 - INFO - Epoch 114: train_loss=0.8797
2025-02-06 18:36:48,143 - INFO - Epoch 114: train_loss=0.9443
2025-02-06 18:36:48,472 - INFO - Epoch 114: val_loss=1.4736, val_acc=0.00%
2025-02-06 18:36:48,476 - INFO - Epoch 114: EPOCH_AVG_TRAIN_LOSS=0.8797
2025-02-06 18:36:48,478 - INFO - #################### Training epoch 115 ####################
2025-02-06 18:36:48,478 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:48,888 - INFO - Epoch 115: train_loss=0.8796
2025-02-06 18:36:49,180 - INFO - Epoch 115: train_loss=1.0155
2025-02-06 18:36:49,503 - INFO - Epoch 115: val_loss=1.6573, val_acc=0.00%
2025-02-06 18:36:49,507 - INFO - Epoch 115: EPOCH_AVG_TRAIN_LOSS=0.8796
2025-02-06 18:36:49,509 - INFO - #################### Training epoch 116 ####################
2025-02-06 18:36:49,509 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:49,920 - INFO - Epoch 116: train_loss=0.8900
2025-02-06 18:36:50,212 - INFO - Epoch 116: train_loss=1.0408
2025-02-06 18:36:50,535 - INFO - Epoch 116: val_loss=1.4800, val_acc=0.00%
2025-02-06 18:36:50,539 - INFO - Epoch 116: EPOCH_AVG_TRAIN_LOSS=0.8900
2025-02-06 18:36:50,542 - INFO - #################### Training epoch 117 ####################
2025-02-06 18:36:50,542 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:36:50,953 - INFO - Epoch 117: train_loss=0.9895
2025-02-06 18:36:51,245 - INFO - Epoch 117: train_loss=0.7918
2025-02-06 18:36:51,570 - INFO - Epoch 117: val_loss=1.5706, val_acc=0.00%
2025-02-06 18:36:51,574 - INFO - Epoch 117: EPOCH_AVG_TRAIN_LOSS=0.7918
2025-02-06 18:36:51,576 - INFO - #################### Training epoch 118 ####################
2025-02-06 18:36:51,576 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:36:51,988 - INFO - Epoch 118: train_loss=0.7184
2025-02-06 18:36:52,279 - INFO - Epoch 118: train_loss=1.2907
2025-02-06 18:36:52,605 - INFO - Epoch 118: val_loss=1.5578, val_acc=0.00%
2025-02-06 18:36:52,609 - INFO - Epoch 118: EPOCH_AVG_TRAIN_LOSS=0.7184
2025-02-06 18:36:52,611 - INFO - #################### Training epoch 119 ####################
2025-02-06 18:36:52,611 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:36:53,023 - INFO - Epoch 119: train_loss=0.6921
2025-02-06 18:36:53,315 - INFO - Epoch 119: train_loss=1.2815
2025-02-06 18:36:53,640 - INFO - Epoch 119: val_loss=1.5864, val_acc=0.00%
2025-02-06 18:36:53,644 - INFO - Epoch 119: EPOCH_AVG_TRAIN_LOSS=0.6921
2025-02-06 18:36:53,646 - INFO - #################### Training epoch 120 ####################
2025-02-06 18:36:53,646 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:36:54,055 - INFO - Epoch 120: train_loss=0.6844
2025-02-06 18:36:54,346 - INFO - Epoch 120: train_loss=1.3148
2025-02-06 18:36:54,673 - INFO - Epoch 120: val_loss=1.6076, val_acc=0.00%
2025-02-06 18:36:54,676 - INFO - Epoch 120: EPOCH_AVG_TRAIN_LOSS=0.6844
2025-02-06 18:36:54,679 - INFO - #################### Training epoch 121 ####################
2025-02-06 18:36:54,679 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:36:55,088 - INFO - Epoch 121: train_loss=0.8810
2025-02-06 18:36:55,378 - INFO - Epoch 121: train_loss=0.9777
2025-02-06 18:36:55,704 - INFO - Epoch 121: val_loss=1.6068, val_acc=0.00%
2025-02-06 18:36:55,708 - INFO - Epoch 121: EPOCH_AVG_TRAIN_LOSS=0.8810
2025-02-06 18:36:55,710 - INFO - #################### Training epoch 122 ####################
2025-02-06 18:36:55,710 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:36:56,120 - INFO - Epoch 122: train_loss=0.8682
2025-02-06 18:36:56,412 - INFO - Epoch 122: train_loss=1.0119
2025-02-06 18:36:56,738 - INFO - Epoch 122: val_loss=1.6497, val_acc=0.00%
2025-02-06 18:36:56,742 - INFO - Epoch 122: EPOCH_AVG_TRAIN_LOSS=0.8682
2025-02-06 18:36:56,744 - INFO - #################### Training epoch 123 ####################
2025-02-06 18:36:56,744 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:36:57,156 - INFO - Epoch 123: train_loss=0.9720
2025-02-06 18:36:57,448 - INFO - Epoch 123: train_loss=0.7562
2025-02-06 18:36:57,773 - INFO - Epoch 123: val_loss=1.6085, val_acc=0.00%
2025-02-06 18:36:57,777 - INFO - Epoch 123: EPOCH_AVG_TRAIN_LOSS=0.7562
2025-02-06 18:36:57,779 - INFO - #################### Training epoch 124 ####################
2025-02-06 18:36:57,779 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:36:58,191 - INFO - Epoch 124: train_loss=0.9754
2025-02-06 18:36:58,482 - INFO - Epoch 124: train_loss=0.7387
2025-02-06 18:36:58,810 - INFO - Epoch 124: val_loss=1.5470, val_acc=0.00%
2025-02-06 18:36:58,814 - INFO - Epoch 124: EPOCH_AVG_TRAIN_LOSS=0.7387
2025-02-06 18:36:58,816 - INFO - #################### Training epoch 125 ####################
2025-02-06 18:36:58,816 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:36:59,226 - INFO - Epoch 125: train_loss=0.9756
2025-02-06 18:36:59,517 - INFO - Epoch 125: train_loss=0.8612
2025-02-06 18:36:59,843 - INFO - Epoch 125: val_loss=1.5774, val_acc=0.00%
2025-02-06 18:36:59,847 - INFO - Epoch 125: EPOCH_AVG_TRAIN_LOSS=0.8612
2025-02-06 18:36:59,850 - INFO - #################### Training epoch 126 ####################
2025-02-06 18:36:59,850 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:00,259 - INFO - Epoch 126: train_loss=0.9873
2025-02-06 18:37:00,551 - INFO - Epoch 126: train_loss=0.8203
2025-02-06 18:37:00,877 - INFO - Epoch 126: val_loss=1.6553, val_acc=0.00%
2025-02-06 18:37:00,881 - INFO - Epoch 126: EPOCH_AVG_TRAIN_LOSS=0.8203
2025-02-06 18:37:00,883 - INFO - #################### Training epoch 127 ####################
2025-02-06 18:37:00,883 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:01,296 - INFO - Epoch 127: train_loss=0.7899
2025-02-06 18:37:01,587 - INFO - Epoch 127: train_loss=1.1560
2025-02-06 18:37:01,911 - INFO - Epoch 127: val_loss=1.5149, val_acc=0.00%
2025-02-06 18:37:01,914 - INFO - Epoch 127: EPOCH_AVG_TRAIN_LOSS=0.7899
2025-02-06 18:37:01,917 - INFO - #################### Training epoch 128 ####################
2025-02-06 18:37:01,917 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:02,328 - INFO - Epoch 128: train_loss=1.0892
2025-02-06 18:37:02,620 - INFO - Epoch 128: train_loss=0.6399
2025-02-06 18:37:02,945 - INFO - Epoch 128: val_loss=1.6021, val_acc=0.00%
2025-02-06 18:37:02,949 - INFO - Epoch 128: EPOCH_AVG_TRAIN_LOSS=0.6399
2025-02-06 18:37:02,951 - INFO - #################### Training epoch 129 ####################
2025-02-06 18:37:02,951 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:03,364 - INFO - Epoch 129: train_loss=0.9287
2025-02-06 18:37:03,655 - INFO - Epoch 129: train_loss=0.8785
2025-02-06 18:37:03,983 - INFO - Epoch 129: val_loss=1.6112, val_acc=0.00%
2025-02-06 18:37:03,986 - INFO - Epoch 129: EPOCH_AVG_TRAIN_LOSS=0.8785
2025-02-06 18:37:03,988 - INFO - #################### Training epoch 130 ####################
2025-02-06 18:37:03,989 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:04,401 - INFO - Epoch 130: train_loss=0.8739
2025-02-06 18:37:04,693 - INFO - Epoch 130: train_loss=0.9374
2025-02-06 18:37:05,023 - INFO - Epoch 130: val_loss=1.6186, val_acc=0.00%
2025-02-06 18:37:05,026 - INFO - Epoch 130: EPOCH_AVG_TRAIN_LOSS=0.8739
2025-02-06 18:37:05,029 - INFO - #################### Training epoch 131 ####################
2025-02-06 18:37:05,029 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:05,436 - INFO - Epoch 131: train_loss=0.8853
2025-02-06 18:37:05,728 - INFO - Epoch 131: train_loss=1.0367
2025-02-06 18:37:06,053 - INFO - Epoch 131: val_loss=1.6266, val_acc=0.00%
2025-02-06 18:37:06,057 - INFO - Epoch 131: EPOCH_AVG_TRAIN_LOSS=0.8853
2025-02-06 18:37:06,059 - INFO - #################### Training epoch 132 ####################
2025-02-06 18:37:06,059 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:06,467 - INFO - Epoch 132: train_loss=0.9590
2025-02-06 18:37:06,758 - INFO - Epoch 132: train_loss=0.8651
2025-02-06 18:37:07,085 - INFO - Epoch 132: val_loss=1.5439, val_acc=0.00%
2025-02-06 18:37:07,089 - INFO - Epoch 132: EPOCH_AVG_TRAIN_LOSS=0.8651
2025-02-06 18:37:07,091 - INFO - #################### Training epoch 133 ####################
2025-02-06 18:37:07,091 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:07,503 - INFO - Epoch 133: train_loss=1.0073
2025-02-06 18:37:07,794 - INFO - Epoch 133: train_loss=0.8367
2025-02-06 18:37:08,122 - INFO - Epoch 133: val_loss=1.5960, val_acc=0.00%
2025-02-06 18:37:08,125 - INFO - Epoch 133: EPOCH_AVG_TRAIN_LOSS=0.8367
2025-02-06 18:37:08,128 - INFO - #################### Training epoch 134 ####################
2025-02-06 18:37:08,128 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:08,537 - INFO - Epoch 134: train_loss=0.9414
2025-02-06 18:37:08,829 - INFO - Epoch 134: train_loss=1.0283
2025-02-06 18:37:09,155 - INFO - Epoch 134: val_loss=1.5400, val_acc=0.00%
2025-02-06 18:37:09,159 - INFO - Epoch 134: EPOCH_AVG_TRAIN_LOSS=0.9414
2025-02-06 18:37:09,161 - INFO - #################### Training epoch 135 ####################
2025-02-06 18:37:09,161 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:09,572 - INFO - Epoch 135: train_loss=0.8648
2025-02-06 18:37:09,862 - INFO - Epoch 135: train_loss=1.0670
2025-02-06 18:37:10,182 - INFO - Epoch 135: val_loss=1.5963, val_acc=0.00%
2025-02-06 18:37:10,186 - INFO - Epoch 135: EPOCH_AVG_TRAIN_LOSS=0.8648
2025-02-06 18:37:10,188 - INFO - #################### Training epoch 136 ####################
2025-02-06 18:37:10,188 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:10,598 - INFO - Epoch 136: train_loss=0.9358
2025-02-06 18:37:10,889 - INFO - Epoch 136: train_loss=1.0678
2025-02-06 18:37:11,214 - INFO - Epoch 136: val_loss=1.5787, val_acc=0.00%
2025-02-06 18:37:11,218 - INFO - Epoch 136: EPOCH_AVG_TRAIN_LOSS=0.9358
2025-02-06 18:37:11,220 - INFO - #################### Training epoch 137 ####################
2025-02-06 18:37:11,220 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:11,630 - INFO - Epoch 137: train_loss=0.9097
2025-02-06 18:37:11,921 - INFO - Epoch 137: train_loss=1.0596
2025-02-06 18:37:12,246 - INFO - Epoch 137: val_loss=1.5756, val_acc=33.33%
2025-02-06 18:37:12,250 - INFO - Epoch 137: EPOCH_AVG_TRAIN_LOSS=0.9097
2025-02-06 18:37:12,252 - INFO - #################### Training epoch 138 ####################
2025-02-06 18:37:12,252 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:37:12,659 - INFO - Epoch 138: train_loss=0.7305
2025-02-06 18:37:12,951 - INFO - Epoch 138: train_loss=1.3545
2025-02-06 18:37:13,276 - INFO - Epoch 138: val_loss=1.5589, val_acc=33.33%
2025-02-06 18:37:13,280 - INFO - Epoch 138: EPOCH_AVG_TRAIN_LOSS=0.7305
2025-02-06 18:37:13,282 - INFO - #################### Training epoch 139 ####################
2025-02-06 18:37:13,282 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:13,692 - INFO - Epoch 139: train_loss=1.0135
2025-02-06 18:37:13,984 - INFO - Epoch 139: train_loss=0.8398
2025-02-06 18:37:14,309 - INFO - Epoch 139: val_loss=1.6150, val_acc=0.00%
2025-02-06 18:37:14,313 - INFO - Epoch 139: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-06 18:37:14,315 - INFO - #################### Training epoch 140 ####################
2025-02-06 18:37:14,315 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:14,727 - INFO - Epoch 140: train_loss=0.8426
2025-02-06 18:37:15,018 - INFO - Epoch 140: train_loss=1.2553
2025-02-06 18:37:15,342 - INFO - Epoch 140: val_loss=1.5375, val_acc=33.33%
2025-02-06 18:37:15,346 - INFO - Epoch 140: EPOCH_AVG_TRAIN_LOSS=0.8426
2025-02-06 18:37:15,348 - INFO - #################### Training epoch 141 ####################
2025-02-06 18:37:15,348 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:15,755 - INFO - Epoch 141: train_loss=0.9436
2025-02-06 18:37:16,046 - INFO - Epoch 141: train_loss=0.9564
2025-02-06 18:37:16,368 - INFO - Epoch 141: val_loss=1.5742, val_acc=0.00%
2025-02-06 18:37:16,371 - INFO - Epoch 141: EPOCH_AVG_TRAIN_LOSS=0.9436
2025-02-06 18:37:16,373 - INFO - #################### Training epoch 142 ####################
2025-02-06 18:37:16,374 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:16,782 - INFO - Epoch 142: train_loss=1.0515
2025-02-06 18:37:17,073 - INFO - Epoch 142: train_loss=0.8743
2025-02-06 18:37:17,397 - INFO - Epoch 142: val_loss=1.5937, val_acc=0.00%
2025-02-06 18:37:17,400 - INFO - Epoch 142: EPOCH_AVG_TRAIN_LOSS=0.8743
2025-02-06 18:37:17,403 - INFO - #################### Training epoch 143 ####################
2025-02-06 18:37:17,403 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:17,812 - INFO - Epoch 143: train_loss=0.8358
2025-02-06 18:37:18,104 - INFO - Epoch 143: train_loss=1.3338
2025-02-06 18:37:18,426 - INFO - Epoch 143: val_loss=1.6193, val_acc=0.00%
2025-02-06 18:37:18,430 - INFO - Epoch 143: EPOCH_AVG_TRAIN_LOSS=0.8358
2025-02-06 18:37:18,432 - INFO - #################### Training epoch 144 ####################
2025-02-06 18:37:18,432 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:18,842 - INFO - Epoch 144: train_loss=1.0834
2025-02-06 18:37:19,133 - INFO - Epoch 144: train_loss=0.7002
2025-02-06 18:37:19,458 - INFO - Epoch 144: val_loss=1.5236, val_acc=33.33%
2025-02-06 18:37:19,462 - INFO - Epoch 144: EPOCH_AVG_TRAIN_LOSS=0.7002
2025-02-06 18:37:19,464 - INFO - #################### Training epoch 145 ####################
2025-02-06 18:37:19,464 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:19,877 - INFO - Epoch 145: train_loss=1.0535
2025-02-06 18:37:20,168 - INFO - Epoch 145: train_loss=0.7356
2025-02-06 18:37:20,488 - INFO - Epoch 145: val_loss=1.5085, val_acc=33.33%
2025-02-06 18:37:20,492 - INFO - Epoch 145: EPOCH_AVG_TRAIN_LOSS=0.7356
2025-02-06 18:37:20,494 - INFO - #################### Training epoch 146 ####################
2025-02-06 18:37:20,494 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:20,903 - INFO - Epoch 146: train_loss=0.8870
2025-02-06 18:37:21,194 - INFO - Epoch 146: train_loss=1.0005
2025-02-06 18:37:21,516 - INFO - Epoch 146: val_loss=1.5441, val_acc=33.33%
2025-02-06 18:37:21,519 - INFO - Epoch 146: EPOCH_AVG_TRAIN_LOSS=0.8870
2025-02-06 18:37:21,522 - INFO - #################### Training epoch 147 ####################
2025-02-06 18:37:21,522 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:21,930 - INFO - Epoch 147: train_loss=0.8408
2025-02-06 18:37:22,222 - INFO - Epoch 147: train_loss=1.1007
2025-02-06 18:37:22,545 - INFO - Epoch 147: val_loss=1.6311, val_acc=0.00%
2025-02-06 18:37:22,549 - INFO - Epoch 147: EPOCH_AVG_TRAIN_LOSS=0.8408
2025-02-06 18:37:22,551 - INFO - #################### Training epoch 148 ####################
2025-02-06 18:37:22,551 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:22,960 - INFO - Epoch 148: train_loss=0.9991
2025-02-06 18:37:23,251 - INFO - Epoch 148: train_loss=0.8702
2025-02-06 18:37:23,575 - INFO - Epoch 148: val_loss=1.5485, val_acc=0.00%
2025-02-06 18:37:23,579 - INFO - Epoch 148: EPOCH_AVG_TRAIN_LOSS=0.8702
2025-02-06 18:37:23,581 - INFO - #################### Training epoch 149 ####################
2025-02-06 18:37:23,581 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:23,988 - INFO - Epoch 149: train_loss=0.9430
2025-02-06 18:37:24,280 - INFO - Epoch 149: train_loss=1.0619
2025-02-06 18:37:24,604 - INFO - Epoch 149: val_loss=1.6130, val_acc=0.00%
2025-02-06 18:37:24,608 - INFO - Epoch 149: EPOCH_AVG_TRAIN_LOSS=0.9430
2025-02-06 18:37:24,610 - INFO - #################### Training epoch 150 ####################
2025-02-06 18:37:24,610 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:25,019 - INFO - Epoch 150: train_loss=0.9473
2025-02-06 18:37:25,310 - INFO - Epoch 150: train_loss=0.9968
2025-02-06 18:37:25,638 - INFO - Epoch 150: val_loss=1.5925, val_acc=0.00%
2025-02-06 18:37:25,642 - INFO - Epoch 150: EPOCH_AVG_TRAIN_LOSS=0.9473
2025-02-06 18:37:25,644 - INFO - #################### Training epoch 151 ####################
2025-02-06 18:37:25,644 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:26,053 - INFO - Epoch 151: train_loss=0.7793
2025-02-06 18:37:26,345 - INFO - Epoch 151: train_loss=1.2071
2025-02-06 18:37:26,671 - INFO - Epoch 151: val_loss=1.5842, val_acc=0.00%
2025-02-06 18:37:26,674 - INFO - Epoch 151: EPOCH_AVG_TRAIN_LOSS=0.7793
2025-02-06 18:37:26,677 - INFO - #################### Training epoch 152 ####################
2025-02-06 18:37:26,677 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:27,087 - INFO - Epoch 152: train_loss=1.0262
2025-02-06 18:37:27,378 - INFO - Epoch 152: train_loss=0.9069
2025-02-06 18:37:27,699 - INFO - Epoch 152: val_loss=1.5507, val_acc=33.33%
2025-02-06 18:37:27,703 - INFO - Epoch 152: EPOCH_AVG_TRAIN_LOSS=0.9069
2025-02-06 18:37:27,705 - INFO - #################### Training epoch 153 ####################
2025-02-06 18:37:27,705 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:28,115 - INFO - Epoch 153: train_loss=0.8494
2025-02-06 18:37:28,406 - INFO - Epoch 153: train_loss=1.0538
2025-02-06 18:37:28,729 - INFO - Epoch 153: val_loss=1.5205, val_acc=33.33%
2025-02-06 18:37:28,732 - INFO - Epoch 153: EPOCH_AVG_TRAIN_LOSS=0.8494
2025-02-06 18:37:28,735 - INFO - #################### Training epoch 154 ####################
2025-02-06 18:37:28,735 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:29,141 - INFO - Epoch 154: train_loss=0.7729
2025-02-06 18:37:29,432 - INFO - Epoch 154: train_loss=1.2162
2025-02-06 18:37:29,758 - INFO - Epoch 154: val_loss=1.5635, val_acc=0.00%
2025-02-06 18:37:29,762 - INFO - Epoch 154: EPOCH_AVG_TRAIN_LOSS=0.7729
2025-02-06 18:37:29,764 - INFO - #################### Training epoch 155 ####################
2025-02-06 18:37:29,764 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:30,171 - INFO - Epoch 155: train_loss=0.9131
2025-02-06 18:37:30,462 - INFO - Epoch 155: train_loss=0.9910
2025-02-06 18:37:30,784 - INFO - Epoch 155: val_loss=1.5394, val_acc=33.33%
2025-02-06 18:37:30,788 - INFO - Epoch 155: EPOCH_AVG_TRAIN_LOSS=0.9131
2025-02-06 18:37:30,790 - INFO - #################### Training epoch 156 ####################
2025-02-06 18:37:30,790 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:31,199 - INFO - Epoch 156: train_loss=0.8787
2025-02-06 18:37:31,491 - INFO - Epoch 156: train_loss=1.0559
2025-02-06 18:37:31,816 - INFO - Epoch 156: val_loss=1.5533, val_acc=0.00%
2025-02-06 18:37:31,819 - INFO - Epoch 156: EPOCH_AVG_TRAIN_LOSS=0.8787
2025-02-06 18:37:31,822 - INFO - #################### Training epoch 157 ####################
2025-02-06 18:37:31,822 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:32,231 - INFO - Epoch 157: train_loss=0.7683
2025-02-06 18:37:32,523 - INFO - Epoch 157: train_loss=1.3362
2025-02-06 18:37:32,845 - INFO - Epoch 157: val_loss=1.5568, val_acc=0.00%
2025-02-06 18:37:32,849 - INFO - Epoch 157: EPOCH_AVG_TRAIN_LOSS=0.7683
2025-02-06 18:37:32,851 - INFO - #################### Training epoch 158 ####################
2025-02-06 18:37:32,851 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:33,259 - INFO - Epoch 158: train_loss=1.0650
2025-02-06 18:37:33,550 - INFO - Epoch 158: train_loss=0.6842
2025-02-06 18:37:33,875 - INFO - Epoch 158: val_loss=1.5128, val_acc=0.00%
2025-02-06 18:37:33,879 - INFO - Epoch 158: EPOCH_AVG_TRAIN_LOSS=0.6842
2025-02-06 18:37:33,881 - INFO - #################### Training epoch 159 ####################
2025-02-06 18:37:33,881 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:37:34,292 - INFO - Epoch 159: train_loss=0.7133
2025-02-06 18:37:34,584 - INFO - Epoch 159: train_loss=1.3911
2025-02-06 18:37:34,905 - INFO - Epoch 159: val_loss=1.6128, val_acc=0.00%
2025-02-06 18:37:34,909 - INFO - Epoch 159: EPOCH_AVG_TRAIN_LOSS=0.7133
2025-02-06 18:37:34,911 - INFO - #################### Training epoch 160 ####################
2025-02-06 18:37:34,911 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:35,320 - INFO - Epoch 160: train_loss=1.0435
2025-02-06 18:37:35,611 - INFO - Epoch 160: train_loss=0.6339
2025-02-06 18:37:35,936 - INFO - Epoch 160: val_loss=1.5704, val_acc=0.00%
2025-02-06 18:37:35,940 - INFO - Epoch 160: EPOCH_AVG_TRAIN_LOSS=0.6339
2025-02-06 18:37:35,942 - INFO - #################### Training epoch 161 ####################
2025-02-06 18:37:35,942 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:36,353 - INFO - Epoch 161: train_loss=1.0832
2025-02-06 18:37:36,644 - INFO - Epoch 161: train_loss=0.6737
2025-02-06 18:37:36,966 - INFO - Epoch 161: val_loss=1.5376, val_acc=0.00%
2025-02-06 18:37:36,970 - INFO - Epoch 161: EPOCH_AVG_TRAIN_LOSS=0.6737
2025-02-06 18:37:36,972 - INFO - #################### Training epoch 162 ####################
2025-02-06 18:37:36,972 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:37,381 - INFO - Epoch 162: train_loss=1.1249
2025-02-06 18:37:37,672 - INFO - Epoch 162: train_loss=0.6202
2025-02-06 18:37:37,994 - INFO - Epoch 162: val_loss=1.5339, val_acc=33.33%
2025-02-06 18:37:37,997 - INFO - Epoch 162: EPOCH_AVG_TRAIN_LOSS=0.6202
2025-02-06 18:37:38,000 - INFO - #################### Training epoch 163 ####################
2025-02-06 18:37:38,000 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:38,409 - INFO - Epoch 163: train_loss=0.9378
2025-02-06 18:37:38,701 - INFO - Epoch 163: train_loss=0.7874
2025-02-06 18:37:39,024 - INFO - Epoch 163: val_loss=1.5875, val_acc=0.00%
2025-02-06 18:37:39,028 - INFO - Epoch 163: EPOCH_AVG_TRAIN_LOSS=0.7874
2025-02-06 18:37:39,030 - INFO - #################### Training epoch 164 ####################
2025-02-06 18:37:39,030 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:39,442 - INFO - Epoch 164: train_loss=1.0410
2025-02-06 18:37:39,733 - INFO - Epoch 164: train_loss=0.7451
2025-02-06 18:37:40,055 - INFO - Epoch 164: val_loss=1.5388, val_acc=33.33%
2025-02-06 18:37:40,058 - INFO - Epoch 164: EPOCH_AVG_TRAIN_LOSS=0.7451
2025-02-06 18:37:40,061 - INFO - #################### Training epoch 165 ####################
2025-02-06 18:37:40,061 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:40,469 - INFO - Epoch 165: train_loss=1.0664
2025-02-06 18:37:40,761 - INFO - Epoch 165: train_loss=0.6428
2025-02-06 18:37:41,087 - INFO - Epoch 165: val_loss=1.5218, val_acc=0.00%
2025-02-06 18:37:41,091 - INFO - Epoch 165: EPOCH_AVG_TRAIN_LOSS=0.6428
2025-02-06 18:37:41,093 - INFO - #################### Training epoch 166 ####################
2025-02-06 18:37:41,093 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:41,500 - INFO - Epoch 166: train_loss=0.7149
2025-02-06 18:37:41,791 - INFO - Epoch 166: train_loss=1.3466
2025-02-06 18:37:42,116 - INFO - Epoch 166: val_loss=1.5424, val_acc=0.00%
2025-02-06 18:37:42,120 - INFO - Epoch 166: EPOCH_AVG_TRAIN_LOSS=0.7149
2025-02-06 18:37:42,122 - INFO - #################### Training epoch 167 ####################
2025-02-06 18:37:42,122 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:42,526 - INFO - Epoch 167: train_loss=0.7641
2025-02-06 18:37:42,817 - INFO - Epoch 167: train_loss=1.3261
2025-02-06 18:37:43,145 - INFO - Epoch 167: val_loss=1.5305, val_acc=0.00%
2025-02-06 18:37:43,148 - INFO - Epoch 167: EPOCH_AVG_TRAIN_LOSS=0.7641
2025-02-06 18:37:43,151 - INFO - #################### Training epoch 168 ####################
2025-02-06 18:37:43,151 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:43,561 - INFO - Epoch 168: train_loss=0.7774
2025-02-06 18:37:43,852 - INFO - Epoch 168: train_loss=1.2427
2025-02-06 18:37:44,175 - INFO - Epoch 168: val_loss=1.5757, val_acc=0.00%
2025-02-06 18:37:44,179 - INFO - Epoch 168: EPOCH_AVG_TRAIN_LOSS=0.7774
2025-02-06 18:37:44,181 - INFO - #################### Training epoch 169 ####################
2025-02-06 18:37:44,181 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:44,591 - INFO - Epoch 169: train_loss=1.0635
2025-02-06 18:37:44,882 - INFO - Epoch 169: train_loss=0.6341
2025-02-06 18:37:45,205 - INFO - Epoch 169: val_loss=1.5950, val_acc=0.00%
2025-02-06 18:37:45,209 - INFO - Epoch 169: EPOCH_AVG_TRAIN_LOSS=0.6341
2025-02-06 18:37:45,211 - INFO - #################### Training epoch 170 ####################
2025-02-06 18:37:45,211 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:45,620 - INFO - Epoch 170: train_loss=1.0731
2025-02-06 18:37:45,912 - INFO - Epoch 170: train_loss=0.7481
2025-02-06 18:37:46,237 - INFO - Epoch 170: val_loss=1.6341, val_acc=0.00%
2025-02-06 18:37:46,241 - INFO - Epoch 170: EPOCH_AVG_TRAIN_LOSS=0.7481
2025-02-06 18:37:46,243 - INFO - #################### Training epoch 171 ####################
2025-02-06 18:37:46,243 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:46,656 - INFO - Epoch 171: train_loss=1.1034
2025-02-06 18:37:46,946 - INFO - Epoch 171: train_loss=0.6185
2025-02-06 18:37:47,269 - INFO - Epoch 171: val_loss=1.5207, val_acc=33.33%
2025-02-06 18:37:47,273 - INFO - Epoch 171: EPOCH_AVG_TRAIN_LOSS=0.6185
2025-02-06 18:37:47,275 - INFO - #################### Training epoch 172 ####################
2025-02-06 18:37:47,275 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:47,687 - INFO - Epoch 172: train_loss=0.8904
2025-02-06 18:37:47,978 - INFO - Epoch 172: train_loss=1.0269
2025-02-06 18:37:48,302 - INFO - Epoch 172: val_loss=1.5781, val_acc=0.00%
2025-02-06 18:37:48,306 - INFO - Epoch 172: EPOCH_AVG_TRAIN_LOSS=0.8904
2025-02-06 18:37:48,308 - INFO - #################### Training epoch 173 ####################
2025-02-06 18:37:48,308 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:48,719 - INFO - Epoch 173: train_loss=0.8737
2025-02-06 18:37:49,010 - INFO - Epoch 173: train_loss=1.0270
2025-02-06 18:37:49,334 - INFO - Epoch 173: val_loss=1.5456, val_acc=0.00%
2025-02-06 18:37:49,337 - INFO - Epoch 173: EPOCH_AVG_TRAIN_LOSS=0.8737
2025-02-06 18:37:49,339 - INFO - #################### Training epoch 174 ####################
2025-02-06 18:37:49,340 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:49,750 - INFO - Epoch 174: train_loss=0.8087
2025-02-06 18:37:50,041 - INFO - Epoch 174: train_loss=1.2364
2025-02-06 18:37:50,363 - INFO - Epoch 174: val_loss=1.5749, val_acc=0.00%
2025-02-06 18:37:50,367 - INFO - Epoch 174: EPOCH_AVG_TRAIN_LOSS=0.8087
2025-02-06 18:37:50,369 - INFO - #################### Training epoch 175 ####################
2025-02-06 18:37:50,369 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:50,780 - INFO - Epoch 175: train_loss=0.9084
2025-02-06 18:37:51,071 - INFO - Epoch 175: train_loss=1.0047
2025-02-06 18:37:51,395 - INFO - Epoch 175: val_loss=1.5538, val_acc=0.00%
2025-02-06 18:37:51,399 - INFO - Epoch 175: EPOCH_AVG_TRAIN_LOSS=0.9084
2025-02-06 18:37:51,401 - INFO - #################### Training epoch 176 ####################
2025-02-06 18:37:51,401 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:51,811 - INFO - Epoch 176: train_loss=1.0382
2025-02-06 18:37:52,102 - INFO - Epoch 176: train_loss=0.6948
2025-02-06 18:37:52,426 - INFO - Epoch 176: val_loss=1.5299, val_acc=0.00%
2025-02-06 18:37:52,429 - INFO - Epoch 176: EPOCH_AVG_TRAIN_LOSS=0.6948
2025-02-06 18:37:52,432 - INFO - #################### Training epoch 177 ####################
2025-02-06 18:37:52,432 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:52,841 - INFO - Epoch 177: train_loss=0.8587
2025-02-06 18:37:53,133 - INFO - Epoch 177: train_loss=1.0567
2025-02-06 18:37:53,457 - INFO - Epoch 177: val_loss=1.5815, val_acc=0.00%
2025-02-06 18:37:53,461 - INFO - Epoch 177: EPOCH_AVG_TRAIN_LOSS=0.8587
2025-02-06 18:37:53,463 - INFO - #################### Training epoch 178 ####################
2025-02-06 18:37:53,463 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:53,875 - INFO - Epoch 178: train_loss=0.6863
2025-02-06 18:37:54,166 - INFO - Epoch 178: train_loss=1.4355
2025-02-06 18:37:54,491 - INFO - Epoch 178: val_loss=1.6152, val_acc=0.00%
2025-02-06 18:37:54,494 - INFO - Epoch 178: EPOCH_AVG_TRAIN_LOSS=0.6863
2025-02-06 18:37:54,497 - INFO - #################### Training epoch 179 ####################
2025-02-06 18:37:54,497 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:54,905 - INFO - Epoch 179: train_loss=1.0195
2025-02-06 18:37:55,196 - INFO - Epoch 179: train_loss=0.7683
2025-02-06 18:37:55,521 - INFO - Epoch 179: val_loss=1.5772, val_acc=0.00%
2025-02-06 18:37:55,525 - INFO - Epoch 179: EPOCH_AVG_TRAIN_LOSS=0.7683
2025-02-06 18:37:55,527 - INFO - #################### Training epoch 180 ####################
2025-02-06 18:37:55,527 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:37:55,940 - INFO - Epoch 180: train_loss=0.7203
2025-02-06 18:37:56,231 - INFO - Epoch 180: train_loss=1.2119
2025-02-06 18:37:56,558 - INFO - Epoch 180: val_loss=1.6058, val_acc=0.00%
2025-02-06 18:37:56,561 - INFO - Epoch 180: EPOCH_AVG_TRAIN_LOSS=0.7203
2025-02-06 18:37:56,563 - INFO - #################### Training epoch 181 ####################
2025-02-06 18:37:56,563 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:37:56,975 - INFO - Epoch 181: train_loss=0.9774
2025-02-06 18:37:57,266 - INFO - Epoch 181: train_loss=0.8291
2025-02-06 18:37:57,585 - INFO - Epoch 181: val_loss=1.5179, val_acc=0.00%
2025-02-06 18:37:57,589 - INFO - Epoch 181: EPOCH_AVG_TRAIN_LOSS=0.8291
2025-02-06 18:37:57,591 - INFO - #################### Training epoch 182 ####################
2025-02-06 18:37:57,591 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:37:58,000 - INFO - Epoch 182: train_loss=0.8986
2025-02-06 18:37:58,291 - INFO - Epoch 182: train_loss=1.1519
2025-02-06 18:37:58,615 - INFO - Epoch 182: val_loss=1.5918, val_acc=0.00%
2025-02-06 18:37:58,618 - INFO - Epoch 182: EPOCH_AVG_TRAIN_LOSS=0.8986
2025-02-06 18:37:58,621 - INFO - #################### Training epoch 183 ####################
2025-02-06 18:37:58,621 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:37:59,032 - INFO - Epoch 183: train_loss=0.9788
2025-02-06 18:37:59,324 - INFO - Epoch 183: train_loss=0.9239
2025-02-06 18:37:59,649 - INFO - Epoch 183: val_loss=1.5895, val_acc=0.00%
2025-02-06 18:37:59,653 - INFO - Epoch 183: EPOCH_AVG_TRAIN_LOSS=0.9239
2025-02-06 18:37:59,655 - INFO - #################### Training epoch 184 ####################
2025-02-06 18:37:59,655 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:00,062 - INFO - Epoch 184: train_loss=0.9207
2025-02-06 18:38:00,353 - INFO - Epoch 184: train_loss=0.9522
2025-02-06 18:38:00,678 - INFO - Epoch 184: val_loss=1.5771, val_acc=0.00%
2025-02-06 18:38:00,682 - INFO - Epoch 184: EPOCH_AVG_TRAIN_LOSS=0.9207
2025-02-06 18:38:00,684 - INFO - #################### Training epoch 185 ####################
2025-02-06 18:38:00,684 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:01,092 - INFO - Epoch 185: train_loss=0.9615
2025-02-06 18:38:01,384 - INFO - Epoch 185: train_loss=0.8620
2025-02-06 18:38:01,706 - INFO - Epoch 185: val_loss=1.6290, val_acc=0.00%
2025-02-06 18:38:01,709 - INFO - Epoch 185: EPOCH_AVG_TRAIN_LOSS=0.8620
2025-02-06 18:38:01,712 - INFO - #################### Training epoch 186 ####################
2025-02-06 18:38:01,712 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:02,123 - INFO - Epoch 186: train_loss=0.8616
2025-02-06 18:38:02,414 - INFO - Epoch 186: train_loss=1.1775
2025-02-06 18:38:02,739 - INFO - Epoch 186: val_loss=1.5968, val_acc=0.00%
2025-02-06 18:38:02,742 - INFO - Epoch 186: EPOCH_AVG_TRAIN_LOSS=0.8616
2025-02-06 18:38:02,744 - INFO - #################### Training epoch 187 ####################
2025-02-06 18:38:02,745 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:03,155 - INFO - Epoch 187: train_loss=0.8909
2025-02-06 18:38:03,446 - INFO - Epoch 187: train_loss=1.0532
2025-02-06 18:38:03,767 - INFO - Epoch 187: val_loss=1.5007, val_acc=33.33%
2025-02-06 18:38:03,771 - INFO - Epoch 187: EPOCH_AVG_TRAIN_LOSS=0.8909
2025-02-06 18:38:03,773 - INFO - #################### Training epoch 188 ####################
2025-02-06 18:38:03,773 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:04,184 - INFO - Epoch 188: train_loss=0.7530
2025-02-06 18:38:04,475 - INFO - Epoch 188: train_loss=1.2793
2025-02-06 18:38:04,803 - INFO - Epoch 188: val_loss=1.6390, val_acc=0.00%
2025-02-06 18:38:04,807 - INFO - Epoch 188: EPOCH_AVG_TRAIN_LOSS=0.7530
2025-02-06 18:38:04,809 - INFO - #################### Training epoch 189 ####################
2025-02-06 18:38:04,809 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:05,216 - INFO - Epoch 189: train_loss=0.8484
2025-02-06 18:38:05,507 - INFO - Epoch 189: train_loss=1.1344
2025-02-06 18:38:05,836 - INFO - Epoch 189: val_loss=1.5502, val_acc=0.00%
2025-02-06 18:38:05,840 - INFO - Epoch 189: EPOCH_AVG_TRAIN_LOSS=0.8484
2025-02-06 18:38:05,842 - INFO - #################### Training epoch 190 ####################
2025-02-06 18:38:05,842 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:06,255 - INFO - Epoch 190: train_loss=0.7149
2025-02-06 18:38:06,547 - INFO - Epoch 190: train_loss=1.4156
2025-02-06 18:38:06,873 - INFO - Epoch 190: val_loss=1.5742, val_acc=0.00%
2025-02-06 18:38:06,877 - INFO - Epoch 190: EPOCH_AVG_TRAIN_LOSS=0.7149
2025-02-06 18:38:06,879 - INFO - #################### Training epoch 191 ####################
2025-02-06 18:38:06,879 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:07,286 - INFO - Epoch 191: train_loss=1.0510
2025-02-06 18:38:07,577 - INFO - Epoch 191: train_loss=0.6492
2025-02-06 18:38:07,900 - INFO - Epoch 191: val_loss=1.6060, val_acc=0.00%
2025-02-06 18:38:07,904 - INFO - Epoch 191: EPOCH_AVG_TRAIN_LOSS=0.6492
2025-02-06 18:38:07,906 - INFO - #################### Training epoch 192 ####################
2025-02-06 18:38:07,906 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:08,315 - INFO - Epoch 192: train_loss=0.9874
2025-02-06 18:38:08,606 - INFO - Epoch 192: train_loss=0.9081
2025-02-06 18:38:08,932 - INFO - Epoch 192: val_loss=1.6121, val_acc=0.00%
2025-02-06 18:38:08,935 - INFO - Epoch 192: EPOCH_AVG_TRAIN_LOSS=0.9081
2025-02-06 18:38:08,938 - INFO - #################### Training epoch 193 ####################
2025-02-06 18:38:08,938 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:09,352 - INFO - Epoch 193: train_loss=1.0123
2025-02-06 18:38:09,644 - INFO - Epoch 193: train_loss=0.8550
2025-02-06 18:38:09,967 - INFO - Epoch 193: val_loss=1.6137, val_acc=0.00%
2025-02-06 18:38:09,971 - INFO - Epoch 193: EPOCH_AVG_TRAIN_LOSS=0.8550
2025-02-06 18:38:09,973 - INFO - #################### Training epoch 194 ####################
2025-02-06 18:38:09,973 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:10,382 - INFO - Epoch 194: train_loss=0.8018
2025-02-06 18:38:10,674 - INFO - Epoch 194: train_loss=1.2325
2025-02-06 18:38:11,002 - INFO - Epoch 194: val_loss=1.5967, val_acc=0.00%
2025-02-06 18:38:11,006 - INFO - Epoch 194: EPOCH_AVG_TRAIN_LOSS=0.8018
2025-02-06 18:38:11,008 - INFO - #################### Training epoch 195 ####################
2025-02-06 18:38:11,008 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:11,416 - INFO - Epoch 195: train_loss=0.9929
2025-02-06 18:38:11,708 - INFO - Epoch 195: train_loss=0.9178
2025-02-06 18:38:12,035 - INFO - Epoch 195: val_loss=1.4818, val_acc=33.33%
2025-02-06 18:38:12,039 - INFO - Epoch 195: EPOCH_AVG_TRAIN_LOSS=0.9178
2025-02-06 18:38:12,041 - INFO - #################### Training epoch 196 ####################
2025-02-06 18:38:12,041 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:12,451 - INFO - Epoch 196: train_loss=0.9967
2025-02-06 18:38:12,743 - INFO - Epoch 196: train_loss=0.7883
2025-02-06 18:38:13,067 - INFO - Epoch 196: val_loss=1.5567, val_acc=0.00%
2025-02-06 18:38:13,070 - INFO - Epoch 196: EPOCH_AVG_TRAIN_LOSS=0.7883
2025-02-06 18:38:13,073 - INFO - #################### Training epoch 197 ####################
2025-02-06 18:38:13,073 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:13,479 - INFO - Epoch 197: train_loss=0.8572
2025-02-06 18:38:13,772 - INFO - Epoch 197: train_loss=1.1985
2025-02-06 18:38:14,095 - INFO - Epoch 197: val_loss=1.6450, val_acc=0.00%
2025-02-06 18:38:14,099 - INFO - Epoch 197: EPOCH_AVG_TRAIN_LOSS=0.8572
2025-02-06 18:38:14,101 - INFO - #################### Training epoch 198 ####################
2025-02-06 18:38:14,101 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:14,511 - INFO - Epoch 198: train_loss=0.7870
2025-02-06 18:38:14,802 - INFO - Epoch 198: train_loss=1.2936
2025-02-06 18:38:15,125 - INFO - Epoch 198: val_loss=1.6060, val_acc=0.00%
2025-02-06 18:38:15,129 - INFO - Epoch 198: EPOCH_AVG_TRAIN_LOSS=0.7870
2025-02-06 18:38:15,131 - INFO - #################### Training epoch 199 ####################
2025-02-06 18:38:15,131 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:38:15,541 - INFO - Epoch 199: train_loss=1.1747
2025-02-06 18:38:15,833 - INFO - Epoch 199: train_loss=0.4960
2025-02-06 18:38:16,153 - INFO - Epoch 199: val_loss=1.5586, val_acc=0.00%
2025-02-06 18:38:16,157 - INFO - Epoch 199: EPOCH_AVG_TRAIN_LOSS=0.4960
2025-02-06 18:38:16,333 - INFO - Model saved.
