2025-02-06 18:01:26,865 - INFO - Starting training with the following parameters:
2025-02-06 18:01:26,866 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product|
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.001          |
| epochs          | 200            |
| batch_size      | 16             |

2025-02-06 18:01:27,473 - INFO - Epoch 0: val_loss=1.0943, val_acc=33.33%
2025-02-06 18:01:27,613 - INFO - #################### Training epoch 0 ####################
2025-02-06 18:01:27,613 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:27,859 - INFO - Epoch 0: train_loss=1.1141
2025-02-06 18:01:28,215 - INFO - Epoch 0: train_loss=1.0583
2025-02-06 18:01:28,515 - INFO - Epoch 0: val_loss=1.0424, val_acc=33.33%
2025-02-06 18:01:28,532 - INFO - Epoch 0: EPOCH_AVG_TRAIN_LOSS=1.0583
2025-02-06 18:01:28,562 - INFO - #################### Training epoch 1 ####################
2025-02-06 18:01:28,563 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:28,963 - INFO - Epoch 1: train_loss=1.1089
2025-02-06 18:01:29,253 - INFO - Epoch 1: train_loss=1.0246
2025-02-06 18:01:29,570 - INFO - Epoch 1: val_loss=1.1426, val_acc=0.00%
2025-02-06 18:01:29,574 - INFO - Epoch 1: EPOCH_AVG_TRAIN_LOSS=1.0246
2025-02-06 18:01:29,600 - INFO - #################### Training epoch 2 ####################
2025-02-06 18:01:29,600 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:30,007 - INFO - Epoch 2: train_loss=1.0059
2025-02-06 18:01:30,297 - INFO - Epoch 2: train_loss=1.0835
2025-02-06 18:01:30,620 - INFO - Epoch 2: val_loss=1.0668, val_acc=33.33%
2025-02-06 18:01:30,624 - INFO - Epoch 2: EPOCH_AVG_TRAIN_LOSS=1.0059
2025-02-06 18:01:30,674 - INFO - #################### Training epoch 3 ####################
2025-02-06 18:01:30,674 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:31,079 - INFO - Epoch 3: train_loss=0.9778
2025-02-06 18:01:31,369 - INFO - Epoch 3: train_loss=1.1055
2025-02-06 18:01:31,689 - INFO - Epoch 3: val_loss=0.9999, val_acc=33.33%
2025-02-06 18:01:31,693 - INFO - Epoch 3: EPOCH_AVG_TRAIN_LOSS=0.9778
2025-02-06 18:01:31,721 - INFO - #################### Training epoch 4 ####################
2025-02-06 18:01:31,721 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:32,127 - INFO - Epoch 4: train_loss=0.9596
2025-02-06 18:01:32,417 - INFO - Epoch 4: train_loss=0.9912
2025-02-06 18:01:32,742 - INFO - Epoch 4: val_loss=1.0138, val_acc=33.33%
2025-02-06 18:01:32,746 - INFO - Epoch 4: EPOCH_AVG_TRAIN_LOSS=0.9596
2025-02-06 18:01:32,775 - INFO - #################### Training epoch 5 ####################
2025-02-06 18:01:32,775 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:33,174 - INFO - Epoch 5: train_loss=0.9651
2025-02-06 18:01:33,466 - INFO - Epoch 5: train_loss=0.9121
2025-02-06 18:01:33,783 - INFO - Epoch 5: val_loss=1.0191, val_acc=33.33%
2025-02-06 18:01:33,787 - INFO - Epoch 5: EPOCH_AVG_TRAIN_LOSS=0.9121
2025-02-06 18:01:33,840 - INFO - #################### Training epoch 6 ####################
2025-02-06 18:01:33,840 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:34,246 - INFO - Epoch 6: train_loss=1.0074
2025-02-06 18:01:34,535 - INFO - Epoch 6: train_loss=0.8340
2025-02-06 18:01:34,855 - INFO - Epoch 6: val_loss=1.1863, val_acc=0.00%
2025-02-06 18:01:34,858 - INFO - Epoch 6: EPOCH_AVG_TRAIN_LOSS=0.8340
2025-02-06 18:01:34,861 - INFO - #################### Training epoch 7 ####################
2025-02-06 18:01:34,861 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:35,266 - INFO - Epoch 7: train_loss=0.8807
2025-02-06 18:01:35,555 - INFO - Epoch 7: train_loss=0.8252
2025-02-06 18:01:35,877 - INFO - Epoch 7: val_loss=1.2642, val_acc=0.00%
2025-02-06 18:01:35,880 - INFO - Epoch 7: EPOCH_AVG_TRAIN_LOSS=0.8252
2025-02-06 18:01:35,883 - INFO - #################### Training epoch 8 ####################
2025-02-06 18:01:35,883 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:36,287 - INFO - Epoch 8: train_loss=0.8483
2025-02-06 18:01:36,576 - INFO - Epoch 8: train_loss=0.8101
2025-02-06 18:01:36,899 - INFO - Epoch 8: val_loss=1.3119, val_acc=0.00%
2025-02-06 18:01:36,902 - INFO - Epoch 8: EPOCH_AVG_TRAIN_LOSS=0.8101
2025-02-06 18:01:36,905 - INFO - #################### Training epoch 9 ####################
2025-02-06 18:01:36,905 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:37,316 - INFO - Epoch 9: train_loss=0.8630
2025-02-06 18:01:37,606 - INFO - Epoch 9: train_loss=0.6663
2025-02-06 18:01:37,932 - INFO - Epoch 9: val_loss=1.3420, val_acc=0.00%
2025-02-06 18:01:37,935 - INFO - Epoch 9: EPOCH_AVG_TRAIN_LOSS=0.6663
2025-02-06 18:01:37,938 - INFO - #################### Training epoch 10 ####################
2025-02-06 18:01:37,938 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:38,346 - INFO - Epoch 10: train_loss=0.5983
2025-02-06 18:01:38,636 - INFO - Epoch 10: train_loss=1.0989
2025-02-06 18:01:38,961 - INFO - Epoch 10: val_loss=1.4163, val_acc=0.00%
2025-02-06 18:01:38,965 - INFO - Epoch 10: EPOCH_AVG_TRAIN_LOSS=0.5983
2025-02-06 18:01:38,967 - INFO - #################### Training epoch 11 ####################
2025-02-06 18:01:38,967 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:39,375 - INFO - Epoch 11: train_loss=0.6626
2025-02-06 18:01:39,666 - INFO - Epoch 11: train_loss=0.8420
2025-02-06 18:01:39,986 - INFO - Epoch 11: val_loss=1.4057, val_acc=33.33%
2025-02-06 18:01:39,989 - INFO - Epoch 11: EPOCH_AVG_TRAIN_LOSS=0.6626
2025-02-06 18:01:39,992 - INFO - #################### Training epoch 12 ####################
2025-02-06 18:01:39,992 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:40,401 - INFO - Epoch 12: train_loss=0.7485
2025-02-06 18:01:40,691 - INFO - Epoch 12: train_loss=0.5650
2025-02-06 18:01:41,014 - INFO - Epoch 12: val_loss=1.4574, val_acc=33.33%
2025-02-06 18:01:41,017 - INFO - Epoch 12: EPOCH_AVG_TRAIN_LOSS=0.5650
2025-02-06 18:01:41,020 - INFO - #################### Training epoch 13 ####################
2025-02-06 18:01:41,020 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:41,425 - INFO - Epoch 13: train_loss=0.7661
2025-02-06 18:01:41,715 - INFO - Epoch 13: train_loss=0.7526
2025-02-06 18:01:42,036 - INFO - Epoch 13: val_loss=1.4800, val_acc=33.33%
2025-02-06 18:01:42,040 - INFO - Epoch 13: EPOCH_AVG_TRAIN_LOSS=0.7526
2025-02-06 18:01:42,042 - INFO - #################### Training epoch 14 ####################
2025-02-06 18:01:42,042 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:42,449 - INFO - Epoch 14: train_loss=0.7101
2025-02-06 18:01:42,740 - INFO - Epoch 14: train_loss=0.4907
2025-02-06 18:01:43,064 - INFO - Epoch 14: val_loss=1.5216, val_acc=33.33%
2025-02-06 18:01:43,068 - INFO - Epoch 14: EPOCH_AVG_TRAIN_LOSS=0.4907
2025-02-06 18:01:43,070 - INFO - #################### Training epoch 15 ####################
2025-02-06 18:01:43,070 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:43,479 - INFO - Epoch 15: train_loss=0.5706
2025-02-06 18:01:43,770 - INFO - Epoch 15: train_loss=0.7130
2025-02-06 18:01:44,093 - INFO - Epoch 15: val_loss=1.4209, val_acc=0.00%
2025-02-06 18:01:44,097 - INFO - Epoch 15: EPOCH_AVG_TRAIN_LOSS=0.5706
2025-02-06 18:01:44,099 - INFO - #################### Training epoch 16 ####################
2025-02-06 18:01:44,099 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:44,505 - INFO - Epoch 16: train_loss=0.6674
2025-02-06 18:01:44,795 - INFO - Epoch 16: train_loss=0.6566
2025-02-06 18:01:45,119 - INFO - Epoch 16: val_loss=1.3144, val_acc=33.33%
2025-02-06 18:01:45,123 - INFO - Epoch 16: EPOCH_AVG_TRAIN_LOSS=0.6566
2025-02-06 18:01:45,125 - INFO - #################### Training epoch 17 ####################
2025-02-06 18:01:45,125 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:45,537 - INFO - Epoch 17: train_loss=0.7718
2025-02-06 18:01:45,829 - INFO - Epoch 17: train_loss=1.0147
2025-02-06 18:01:46,152 - INFO - Epoch 17: val_loss=1.3812, val_acc=33.33%
2025-02-06 18:01:46,156 - INFO - Epoch 17: EPOCH_AVG_TRAIN_LOSS=0.7718
2025-02-06 18:01:46,159 - INFO - #################### Training epoch 18 ####################
2025-02-06 18:01:46,159 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:01:46,567 - INFO - Epoch 18: train_loss=0.8624
2025-02-06 18:01:46,858 - INFO - Epoch 18: train_loss=1.5007
2025-02-06 18:01:47,176 - INFO - Epoch 18: val_loss=1.4457, val_acc=33.33%
2025-02-06 18:01:47,179 - INFO - Epoch 18: EPOCH_AVG_TRAIN_LOSS=0.8624
2025-02-06 18:01:47,182 - INFO - #################### Training epoch 19 ####################
2025-02-06 18:01:47,182 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:01:47,589 - INFO - Epoch 19: train_loss=1.3301
2025-02-06 18:01:47,880 - INFO - Epoch 19: train_loss=1.0280
2025-02-06 18:01:48,204 - INFO - Epoch 19: val_loss=1.5081, val_acc=33.33%
2025-02-06 18:01:48,208 - INFO - Epoch 19: EPOCH_AVG_TRAIN_LOSS=1.0280
2025-02-06 18:01:48,210 - INFO - #################### Training epoch 20 ####################
2025-02-06 18:01:48,210 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:01:48,616 - INFO - Epoch 20: train_loss=1.2969
2025-02-06 18:01:48,907 - INFO - Epoch 20: train_loss=1.2708
2025-02-06 18:01:49,229 - INFO - Epoch 20: val_loss=1.5228, val_acc=33.33%
2025-02-06 18:01:49,233 - INFO - Epoch 20: EPOCH_AVG_TRAIN_LOSS=1.2708
2025-02-06 18:01:49,235 - INFO - #################### Training epoch 21 ####################
2025-02-06 18:01:49,235 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:01:49,643 - INFO - Epoch 21: train_loss=1.3080
2025-02-06 18:01:49,934 - INFO - Epoch 21: train_loss=1.1960
2025-02-06 18:01:50,258 - INFO - Epoch 21: val_loss=1.5350, val_acc=33.33%
2025-02-06 18:01:50,262 - INFO - Epoch 21: EPOCH_AVG_TRAIN_LOSS=1.1960
2025-02-06 18:01:50,264 - INFO - #################### Training epoch 22 ####################
2025-02-06 18:01:50,264 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:01:50,673 - INFO - Epoch 22: train_loss=1.5116
2025-02-06 18:01:50,964 - INFO - Epoch 22: train_loss=1.1518
2025-02-06 18:01:51,285 - INFO - Epoch 22: val_loss=1.5428, val_acc=33.33%
2025-02-06 18:01:51,289 - INFO - Epoch 22: EPOCH_AVG_TRAIN_LOSS=1.1518
2025-02-06 18:01:51,291 - INFO - #################### Training epoch 23 ####################
2025-02-06 18:01:51,291 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:01:51,698 - INFO - Epoch 23: train_loss=1.3726
2025-02-06 18:01:51,989 - INFO - Epoch 23: train_loss=1.3131
2025-02-06 18:01:52,311 - INFO - Epoch 23: val_loss=1.5903, val_acc=33.33%
2025-02-06 18:01:52,315 - INFO - Epoch 23: EPOCH_AVG_TRAIN_LOSS=1.3131
2025-02-06 18:01:52,317 - INFO - #################### Training epoch 24 ####################
2025-02-06 18:01:52,317 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:01:52,728 - INFO - Epoch 24: train_loss=1.0588
2025-02-06 18:01:53,019 - INFO - Epoch 24: train_loss=1.9602
2025-02-06 18:01:53,339 - INFO - Epoch 24: val_loss=1.5661, val_acc=33.33%
2025-02-06 18:01:53,343 - INFO - Epoch 24: EPOCH_AVG_TRAIN_LOSS=1.0588
2025-02-06 18:01:53,345 - INFO - #################### Training epoch 25 ####################
2025-02-06 18:01:53,345 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:01:53,750 - INFO - Epoch 25: train_loss=1.2377
2025-02-06 18:01:54,041 - INFO - Epoch 25: train_loss=1.8289
2025-02-06 18:01:54,363 - INFO - Epoch 25: val_loss=1.5802, val_acc=33.33%
2025-02-06 18:01:54,367 - INFO - Epoch 25: EPOCH_AVG_TRAIN_LOSS=1.2377
2025-02-06 18:01:54,369 - INFO - #################### Training epoch 26 ####################
2025-02-06 18:01:54,369 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:01:54,777 - INFO - Epoch 26: train_loss=1.3386
2025-02-06 18:01:55,068 - INFO - Epoch 26: train_loss=1.5734
2025-02-06 18:01:55,390 - INFO - Epoch 26: val_loss=1.5799, val_acc=33.33%
2025-02-06 18:01:55,394 - INFO - Epoch 26: EPOCH_AVG_TRAIN_LOSS=1.3386
2025-02-06 18:01:55,396 - INFO - #################### Training epoch 27 ####################
2025-02-06 18:01:55,397 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:01:55,803 - INFO - Epoch 27: train_loss=1.5009
2025-02-06 18:01:56,094 - INFO - Epoch 27: train_loss=1.1405
2025-02-06 18:01:56,413 - INFO - Epoch 27: val_loss=1.5748, val_acc=33.33%
2025-02-06 18:01:56,417 - INFO - Epoch 27: EPOCH_AVG_TRAIN_LOSS=1.1405
2025-02-06 18:01:56,419 - INFO - #################### Training epoch 28 ####################
2025-02-06 18:01:56,419 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:01:56,823 - INFO - Epoch 28: train_loss=1.2249
2025-02-06 18:01:57,114 - INFO - Epoch 28: train_loss=1.8309
2025-02-06 18:01:57,437 - INFO - Epoch 28: val_loss=1.5718, val_acc=33.33%
2025-02-06 18:01:57,441 - INFO - Epoch 28: EPOCH_AVG_TRAIN_LOSS=1.2249
2025-02-06 18:01:57,443 - INFO - #################### Training epoch 29 ####################
2025-02-06 18:01:57,443 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:01:57,850 - INFO - Epoch 29: train_loss=1.5656
2025-02-06 18:01:58,141 - INFO - Epoch 29: train_loss=1.1595
2025-02-06 18:01:58,465 - INFO - Epoch 29: val_loss=1.5736, val_acc=33.33%
2025-02-06 18:01:58,468 - INFO - Epoch 29: EPOCH_AVG_TRAIN_LOSS=1.1595
2025-02-06 18:01:58,471 - INFO - #################### Training epoch 30 ####################
2025-02-06 18:01:58,471 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:01:58,879 - INFO - Epoch 30: train_loss=1.3927
2025-02-06 18:01:59,170 - INFO - Epoch 30: train_loss=1.4109
2025-02-06 18:01:59,491 - INFO - Epoch 30: val_loss=1.5902, val_acc=33.33%
2025-02-06 18:01:59,495 - INFO - Epoch 30: EPOCH_AVG_TRAIN_LOSS=1.3927
2025-02-06 18:01:59,497 - INFO - #################### Training epoch 31 ####################
2025-02-06 18:01:59,497 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:01:59,906 - INFO - Epoch 31: train_loss=1.2994
2025-02-06 18:02:00,197 - INFO - Epoch 31: train_loss=1.6600
2025-02-06 18:02:00,522 - INFO - Epoch 31: val_loss=1.5733, val_acc=33.33%
2025-02-06 18:02:00,525 - INFO - Epoch 31: EPOCH_AVG_TRAIN_LOSS=1.2994
2025-02-06 18:02:00,528 - INFO - #################### Training epoch 32 ####################
2025-02-06 18:02:00,528 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:02:00,934 - INFO - Epoch 32: train_loss=1.3665
2025-02-06 18:02:01,225 - INFO - Epoch 32: train_loss=1.4978
2025-02-06 18:02:01,546 - INFO - Epoch 32: val_loss=1.5809, val_acc=33.33%
2025-02-06 18:02:01,550 - INFO - Epoch 32: EPOCH_AVG_TRAIN_LOSS=1.3665
2025-02-06 18:02:01,552 - INFO - #################### Training epoch 33 ####################
2025-02-06 18:02:01,552 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:02:01,960 - INFO - Epoch 33: train_loss=1.4719
2025-02-06 18:02:02,251 - INFO - Epoch 33: train_loss=1.3352
2025-02-06 18:02:02,574 - INFO - Epoch 33: val_loss=1.5719, val_acc=33.33%
2025-02-06 18:02:02,578 - INFO - Epoch 33: EPOCH_AVG_TRAIN_LOSS=1.3352
2025-02-06 18:02:02,580 - INFO - #################### Training epoch 34 ####################
2025-02-06 18:02:02,580 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:02:02,985 - INFO - Epoch 34: train_loss=1.4950
2025-02-06 18:02:03,276 - INFO - Epoch 34: train_loss=1.2531
2025-02-06 18:02:03,598 - INFO - Epoch 34: val_loss=1.5676, val_acc=33.33%
2025-02-06 18:02:03,601 - INFO - Epoch 34: EPOCH_AVG_TRAIN_LOSS=1.2531
2025-02-06 18:02:03,604 - INFO - #################### Training epoch 35 ####################
2025-02-06 18:02:03,604 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:02:04,012 - INFO - Epoch 35: train_loss=1.3691
2025-02-06 18:02:04,303 - INFO - Epoch 35: train_loss=1.4817
2025-02-06 18:02:04,624 - INFO - Epoch 35: val_loss=1.5775, val_acc=33.33%
2025-02-06 18:02:04,628 - INFO - Epoch 35: EPOCH_AVG_TRAIN_LOSS=1.3691
2025-02-06 18:02:04,630 - INFO - #################### Training epoch 36 ####################
2025-02-06 18:02:04,630 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:02:05,036 - INFO - Epoch 36: train_loss=1.1694
2025-02-06 18:02:05,327 - INFO - Epoch 36: train_loss=2.0471
2025-02-06 18:02:05,647 - INFO - Epoch 36: val_loss=1.5756, val_acc=33.33%
2025-02-06 18:02:05,651 - INFO - Epoch 36: EPOCH_AVG_TRAIN_LOSS=1.1694
2025-02-06 18:02:05,653 - INFO - #################### Training epoch 37 ####################
2025-02-06 18:02:05,653 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:02:06,061 - INFO - Epoch 37: train_loss=1.1881
2025-02-06 18:02:06,352 - INFO - Epoch 37: train_loss=1.9730
2025-02-06 18:02:06,672 - INFO - Epoch 37: val_loss=1.5922, val_acc=33.33%
2025-02-06 18:02:06,676 - INFO - Epoch 37: EPOCH_AVG_TRAIN_LOSS=1.1881
2025-02-06 18:02:06,678 - INFO - #################### Training epoch 38 ####################
2025-02-06 18:02:06,678 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:02:07,086 - INFO - Epoch 38: train_loss=1.5592
2025-02-06 18:02:07,377 - INFO - Epoch 38: train_loss=1.1484
2025-02-06 18:02:07,698 - INFO - Epoch 38: val_loss=1.5880, val_acc=33.33%
2025-02-06 18:02:07,702 - INFO - Epoch 38: EPOCH_AVG_TRAIN_LOSS=1.1484
2025-02-06 18:02:07,704 - INFO - #################### Training epoch 39 ####################
2025-02-06 18:02:07,704 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:02:08,111 - INFO - Epoch 39: train_loss=1.4602
2025-02-06 18:02:08,402 - INFO - Epoch 39: train_loss=1.3156
2025-02-06 18:02:08,724 - INFO - Epoch 39: val_loss=1.5768, val_acc=33.33%
2025-02-06 18:02:08,727 - INFO - Epoch 39: EPOCH_AVG_TRAIN_LOSS=1.3156
2025-02-06 18:02:08,730 - INFO - #################### Training epoch 40 ####################
2025-02-06 18:02:08,730 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:02:09,136 - INFO - Epoch 40: train_loss=1.6155
2025-02-06 18:02:09,426 - INFO - Epoch 40: train_loss=1.0451
2025-02-06 18:02:09,747 - INFO - Epoch 40: val_loss=1.5831, val_acc=33.33%
2025-02-06 18:02:09,751 - INFO - Epoch 40: EPOCH_AVG_TRAIN_LOSS=1.0451
2025-02-06 18:02:09,753 - INFO - #################### Training epoch 41 ####################
2025-02-06 18:02:09,753 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:02:10,160 - INFO - Epoch 41: train_loss=1.3231
2025-02-06 18:02:10,450 - INFO - Epoch 41: train_loss=1.6177
2025-02-06 18:02:10,770 - INFO - Epoch 41: val_loss=1.5825, val_acc=33.33%
2025-02-06 18:02:10,774 - INFO - Epoch 41: EPOCH_AVG_TRAIN_LOSS=1.3231
2025-02-06 18:02:10,776 - INFO - #################### Training epoch 42 ####################
2025-02-06 18:02:10,776 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:02:11,184 - INFO - Epoch 42: train_loss=1.3623
2025-02-06 18:02:11,475 - INFO - Epoch 42: train_loss=1.4782
2025-02-06 18:02:11,796 - INFO - Epoch 42: val_loss=1.5717, val_acc=33.33%
2025-02-06 18:02:11,800 - INFO - Epoch 42: EPOCH_AVG_TRAIN_LOSS=1.3623
2025-02-06 18:02:11,802 - INFO - #################### Training epoch 43 ####################
2025-02-06 18:02:11,802 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:02:12,212 - INFO - Epoch 43: train_loss=1.3491
2025-02-06 18:02:12,502 - INFO - Epoch 43: train_loss=1.5012
2025-02-06 18:02:12,824 - INFO - Epoch 43: val_loss=1.5895, val_acc=33.33%
2025-02-06 18:02:12,828 - INFO - Epoch 43: EPOCH_AVG_TRAIN_LOSS=1.3491
2025-02-06 18:02:12,830 - INFO - #################### Training epoch 44 ####################
2025-02-06 18:02:12,830 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:02:13,239 - INFO - Epoch 44: train_loss=1.2633
2025-02-06 18:02:13,530 - INFO - Epoch 44: train_loss=1.7417
2025-02-06 18:02:13,852 - INFO - Epoch 44: val_loss=1.5750, val_acc=33.33%
2025-02-06 18:02:13,856 - INFO - Epoch 44: EPOCH_AVG_TRAIN_LOSS=1.2633
2025-02-06 18:02:13,858 - INFO - #################### Training epoch 45 ####################
2025-02-06 18:02:13,858 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:02:14,265 - INFO - Epoch 45: train_loss=1.3917
2025-02-06 18:02:14,556 - INFO - Epoch 45: train_loss=1.4739
2025-02-06 18:02:14,878 - INFO - Epoch 45: val_loss=1.6008, val_acc=33.33%
2025-02-06 18:02:14,881 - INFO - Epoch 45: EPOCH_AVG_TRAIN_LOSS=1.3917
2025-02-06 18:02:14,883 - INFO - #################### Training epoch 46 ####################
2025-02-06 18:02:14,884 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:02:15,288 - INFO - Epoch 46: train_loss=1.4374
2025-02-06 18:02:15,579 - INFO - Epoch 46: train_loss=1.3351
2025-02-06 18:02:15,900 - INFO - Epoch 46: val_loss=1.5669, val_acc=33.33%
2025-02-06 18:02:15,904 - INFO - Epoch 46: EPOCH_AVG_TRAIN_LOSS=1.3351
2025-02-06 18:02:15,906 - INFO - #################### Training epoch 47 ####################
2025-02-06 18:02:15,906 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:02:16,313 - INFO - Epoch 47: train_loss=1.6467
2025-02-06 18:02:16,604 - INFO - Epoch 47: train_loss=0.9653
2025-02-06 18:02:16,927 - INFO - Epoch 47: val_loss=1.5623, val_acc=33.33%
2025-02-06 18:02:16,931 - INFO - Epoch 47: EPOCH_AVG_TRAIN_LOSS=0.9653
2025-02-06 18:02:16,933 - INFO - #################### Training epoch 48 ####################
2025-02-06 18:02:16,933 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:02:17,342 - INFO - Epoch 48: train_loss=1.4843
2025-02-06 18:02:17,633 - INFO - Epoch 48: train_loss=1.5470
2025-02-06 18:02:17,956 - INFO - Epoch 48: val_loss=1.5757, val_acc=33.33%
2025-02-06 18:02:17,960 - INFO - Epoch 48: EPOCH_AVG_TRAIN_LOSS=1.4843
2025-02-06 18:02:17,962 - INFO - #################### Training epoch 49 ####################
2025-02-06 18:02:17,962 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:02:18,371 - INFO - Epoch 49: train_loss=1.1967
2025-02-06 18:02:18,662 - INFO - Epoch 49: train_loss=1.8657
2025-02-06 18:02:18,981 - INFO - Epoch 49: val_loss=1.5804, val_acc=33.33%
2025-02-06 18:02:18,985 - INFO - Epoch 49: EPOCH_AVG_TRAIN_LOSS=1.1967
2025-02-06 18:02:18,987 - INFO - #################### Training epoch 50 ####################
2025-02-06 18:02:18,987 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:02:19,392 - INFO - Epoch 50: train_loss=1.4696
2025-02-06 18:02:19,683 - INFO - Epoch 50: train_loss=1.4259
2025-02-06 18:02:20,005 - INFO - Epoch 50: val_loss=1.5848, val_acc=33.33%
2025-02-06 18:02:20,009 - INFO - Epoch 50: EPOCH_AVG_TRAIN_LOSS=1.4259
2025-02-06 18:02:20,011 - INFO - #################### Training epoch 51 ####################
2025-02-06 18:02:20,011 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:02:20,417 - INFO - Epoch 51: train_loss=1.6427
2025-02-06 18:02:20,708 - INFO - Epoch 51: train_loss=0.9573
2025-02-06 18:02:21,030 - INFO - Epoch 51: val_loss=1.5775, val_acc=33.33%
2025-02-06 18:02:21,034 - INFO - Epoch 51: EPOCH_AVG_TRAIN_LOSS=0.9573
2025-02-06 18:02:21,036 - INFO - #################### Training epoch 52 ####################
2025-02-06 18:02:21,036 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:02:21,442 - INFO - Epoch 52: train_loss=1.4335
2025-02-06 18:02:21,733 - INFO - Epoch 52: train_loss=1.3715
2025-02-06 18:02:22,056 - INFO - Epoch 52: val_loss=1.5750, val_acc=33.33%
2025-02-06 18:02:22,060 - INFO - Epoch 52: EPOCH_AVG_TRAIN_LOSS=1.3715
2025-02-06 18:02:22,062 - INFO - #################### Training epoch 53 ####################
2025-02-06 18:02:22,062 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:02:22,467 - INFO - Epoch 53: train_loss=1.2713
2025-02-06 18:02:22,758 - INFO - Epoch 53: train_loss=1.6022
2025-02-06 18:02:23,080 - INFO - Epoch 53: val_loss=1.5820, val_acc=33.33%
2025-02-06 18:02:23,084 - INFO - Epoch 53: EPOCH_AVG_TRAIN_LOSS=1.2713
2025-02-06 18:02:23,087 - INFO - #################### Training epoch 54 ####################
2025-02-06 18:02:23,087 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:02:23,495 - INFO - Epoch 54: train_loss=1.7208
2025-02-06 18:02:23,785 - INFO - Epoch 54: train_loss=0.9389
2025-02-06 18:02:24,106 - INFO - Epoch 54: val_loss=1.5811, val_acc=33.33%
2025-02-06 18:02:24,110 - INFO - Epoch 54: EPOCH_AVG_TRAIN_LOSS=0.9389
2025-02-06 18:02:24,112 - INFO - #################### Training epoch 55 ####################
2025-02-06 18:02:24,112 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:02:24,520 - INFO - Epoch 55: train_loss=1.6487
2025-02-06 18:02:24,811 - INFO - Epoch 55: train_loss=1.0179
2025-02-06 18:02:25,134 - INFO - Epoch 55: val_loss=1.5817, val_acc=33.33%
2025-02-06 18:02:25,138 - INFO - Epoch 55: EPOCH_AVG_TRAIN_LOSS=1.0179
2025-02-06 18:02:25,140 - INFO - #################### Training epoch 56 ####################
2025-02-06 18:02:25,140 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:02:25,549 - INFO - Epoch 56: train_loss=1.6653
2025-02-06 18:02:25,840 - INFO - Epoch 56: train_loss=0.9441
2025-02-06 18:02:26,164 - INFO - Epoch 56: val_loss=1.5608, val_acc=33.33%
2025-02-06 18:02:26,168 - INFO - Epoch 56: EPOCH_AVG_TRAIN_LOSS=0.9441
2025-02-06 18:02:26,170 - INFO - #################### Training epoch 57 ####################
2025-02-06 18:02:26,171 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:02:26,575 - INFO - Epoch 57: train_loss=1.6103
2025-02-06 18:02:26,866 - INFO - Epoch 57: train_loss=1.0272
2025-02-06 18:02:27,187 - INFO - Epoch 57: val_loss=1.5754, val_acc=33.33%
2025-02-06 18:02:27,191 - INFO - Epoch 57: EPOCH_AVG_TRAIN_LOSS=1.0272
2025-02-06 18:02:27,193 - INFO - #################### Training epoch 58 ####################
2025-02-06 18:02:27,193 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:02:27,603 - INFO - Epoch 58: train_loss=1.6723
2025-02-06 18:02:27,894 - INFO - Epoch 58: train_loss=0.9751
2025-02-06 18:02:28,218 - INFO - Epoch 58: val_loss=1.5855, val_acc=33.33%
2025-02-06 18:02:28,222 - INFO - Epoch 58: EPOCH_AVG_TRAIN_LOSS=0.9751
2025-02-06 18:02:28,224 - INFO - #################### Training epoch 59 ####################
2025-02-06 18:02:28,224 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:02:28,631 - INFO - Epoch 59: train_loss=1.3929
2025-02-06 18:02:28,922 - INFO - Epoch 59: train_loss=1.4862
2025-02-06 18:02:29,245 - INFO - Epoch 59: val_loss=1.5678, val_acc=33.33%
2025-02-06 18:02:29,249 - INFO - Epoch 59: EPOCH_AVG_TRAIN_LOSS=1.3929
2025-02-06 18:02:29,251 - INFO - #################### Training epoch 60 ####################
2025-02-06 18:02:29,251 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:02:29,662 - INFO - Epoch 60: train_loss=1.2938
2025-02-06 18:02:29,954 - INFO - Epoch 60: train_loss=1.6394
2025-02-06 18:02:30,278 - INFO - Epoch 60: val_loss=1.5872, val_acc=33.33%
2025-02-06 18:02:30,282 - INFO - Epoch 60: EPOCH_AVG_TRAIN_LOSS=1.2938
2025-02-06 18:02:30,284 - INFO - #################### Training epoch 61 ####################
2025-02-06 18:02:30,284 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:02:30,689 - INFO - Epoch 61: train_loss=1.4283
2025-02-06 18:02:30,980 - INFO - Epoch 61: train_loss=1.4068
2025-02-06 18:02:31,303 - INFO - Epoch 61: val_loss=1.5761, val_acc=33.33%
2025-02-06 18:02:31,307 - INFO - Epoch 61: EPOCH_AVG_TRAIN_LOSS=1.4068
2025-02-06 18:02:31,309 - INFO - #################### Training epoch 62 ####################
2025-02-06 18:02:31,309 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:02:31,718 - INFO - Epoch 62: train_loss=1.5639
2025-02-06 18:02:32,009 - INFO - Epoch 62: train_loss=1.0467
2025-02-06 18:02:32,334 - INFO - Epoch 62: val_loss=1.5923, val_acc=33.33%
2025-02-06 18:02:32,337 - INFO - Epoch 62: EPOCH_AVG_TRAIN_LOSS=1.0467
2025-02-06 18:02:32,340 - INFO - #################### Training epoch 63 ####################
2025-02-06 18:02:32,340 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:02:32,748 - INFO - Epoch 63: train_loss=1.1137
2025-02-06 18:02:33,039 - INFO - Epoch 63: train_loss=1.9798
2025-02-06 18:02:33,362 - INFO - Epoch 63: val_loss=1.5902, val_acc=33.33%
2025-02-06 18:02:33,366 - INFO - Epoch 63: EPOCH_AVG_TRAIN_LOSS=1.1137
2025-02-06 18:02:33,368 - INFO - #################### Training epoch 64 ####################
2025-02-06 18:02:33,368 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:02:33,775 - INFO - Epoch 64: train_loss=1.3452
2025-02-06 18:02:34,066 - INFO - Epoch 64: train_loss=1.4525
2025-02-06 18:02:34,389 - INFO - Epoch 64: val_loss=1.5652, val_acc=33.33%
2025-02-06 18:02:34,393 - INFO - Epoch 64: EPOCH_AVG_TRAIN_LOSS=1.3452
2025-02-06 18:02:34,395 - INFO - #################### Training epoch 65 ####################
2025-02-06 18:02:34,395 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:02:34,800 - INFO - Epoch 65: train_loss=1.5302
2025-02-06 18:02:35,092 - INFO - Epoch 65: train_loss=1.3360
2025-02-06 18:02:35,414 - INFO - Epoch 65: val_loss=1.5781, val_acc=33.33%
2025-02-06 18:02:35,418 - INFO - Epoch 65: EPOCH_AVG_TRAIN_LOSS=1.3360
2025-02-06 18:02:35,420 - INFO - #################### Training epoch 66 ####################
2025-02-06 18:02:35,420 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:02:35,828 - INFO - Epoch 66: train_loss=1.5510
2025-02-06 18:02:36,119 - INFO - Epoch 66: train_loss=1.2489
2025-02-06 18:02:36,444 - INFO - Epoch 66: val_loss=1.5743, val_acc=33.33%
2025-02-06 18:02:36,448 - INFO - Epoch 66: EPOCH_AVG_TRAIN_LOSS=1.2489
2025-02-06 18:02:36,450 - INFO - #################### Training epoch 67 ####################
2025-02-06 18:02:36,450 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:02:36,858 - INFO - Epoch 67: train_loss=1.6307
2025-02-06 18:02:37,150 - INFO - Epoch 67: train_loss=1.1055
2025-02-06 18:02:37,471 - INFO - Epoch 67: val_loss=1.5858, val_acc=33.33%
2025-02-06 18:02:37,475 - INFO - Epoch 67: EPOCH_AVG_TRAIN_LOSS=1.1055
2025-02-06 18:02:37,477 - INFO - #################### Training epoch 68 ####################
2025-02-06 18:02:37,478 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:02:37,884 - INFO - Epoch 68: train_loss=1.2757
2025-02-06 18:02:38,174 - INFO - Epoch 68: train_loss=1.6240
2025-02-06 18:02:38,497 - INFO - Epoch 68: val_loss=1.5698, val_acc=33.33%
2025-02-06 18:02:38,501 - INFO - Epoch 68: EPOCH_AVG_TRAIN_LOSS=1.2757
2025-02-06 18:02:38,503 - INFO - #################### Training epoch 69 ####################
2025-02-06 18:02:38,503 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:02:38,912 - INFO - Epoch 69: train_loss=1.4242
2025-02-06 18:02:39,203 - INFO - Epoch 69: train_loss=1.4255
2025-02-06 18:02:39,530 - INFO - Epoch 69: val_loss=1.5820, val_acc=33.33%
2025-02-06 18:02:39,534 - INFO - Epoch 69: EPOCH_AVG_TRAIN_LOSS=1.4242
2025-02-06 18:02:39,536 - INFO - #################### Training epoch 70 ####################
2025-02-06 18:02:39,536 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:02:39,943 - INFO - Epoch 70: train_loss=1.3357
2025-02-06 18:02:40,235 - INFO - Epoch 70: train_loss=1.6333
2025-02-06 18:02:40,561 - INFO - Epoch 70: val_loss=1.5790, val_acc=33.33%
2025-02-06 18:02:40,564 - INFO - Epoch 70: EPOCH_AVG_TRAIN_LOSS=1.3357
2025-02-06 18:02:40,567 - INFO - #################### Training epoch 71 ####################
2025-02-06 18:02:40,567 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 18:02:40,974 - INFO - Epoch 71: train_loss=1.3795
2025-02-06 18:02:41,265 - INFO - Epoch 71: train_loss=1.5430
2025-02-06 18:02:41,587 - INFO - Epoch 71: val_loss=1.5805, val_acc=33.33%
2025-02-06 18:02:41,591 - INFO - Epoch 71: EPOCH_AVG_TRAIN_LOSS=1.3795
2025-02-06 18:02:41,593 - INFO - #################### Training epoch 72 ####################
2025-02-06 18:02:41,593 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 18:02:42,001 - INFO - Epoch 72: train_loss=1.4429
2025-02-06 18:02:42,293 - INFO - Epoch 72: train_loss=1.4384
2025-02-06 18:02:42,617 - INFO - Epoch 72: val_loss=1.5984, val_acc=33.33%
2025-02-06 18:02:42,621 - INFO - Epoch 72: EPOCH_AVG_TRAIN_LOSS=1.4384
2025-02-06 18:02:42,623 - INFO - #################### Training epoch 73 ####################
2025-02-06 18:02:42,623 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 18:02:43,031 - INFO - Epoch 73: train_loss=1.3906
2025-02-06 18:02:43,322 - INFO - Epoch 73: train_loss=1.4352
2025-02-06 18:02:43,645 - INFO - Epoch 73: val_loss=1.5801, val_acc=33.33%
2025-02-06 18:02:43,648 - INFO - Epoch 73: EPOCH_AVG_TRAIN_LOSS=1.3906
2025-02-06 18:02:43,651 - INFO - #################### Training epoch 74 ####################
2025-02-06 18:02:43,651 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 18:02:44,058 - INFO - Epoch 74: train_loss=1.1260
2025-02-06 18:02:44,349 - INFO - Epoch 74: train_loss=2.0967
2025-02-06 18:02:44,668 - INFO - Epoch 74: val_loss=1.5918, val_acc=33.33%
2025-02-06 18:02:44,672 - INFO - Epoch 74: EPOCH_AVG_TRAIN_LOSS=1.1260
2025-02-06 18:02:44,674 - INFO - #################### Training epoch 75 ####################
2025-02-06 18:02:44,674 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 18:02:45,082 - INFO - Epoch 75: train_loss=1.4036
2025-02-06 18:02:45,374 - INFO - Epoch 75: train_loss=1.4426
2025-02-06 18:02:45,702 - INFO - Epoch 75: val_loss=1.5855, val_acc=33.33%
2025-02-06 18:02:45,705 - INFO - Epoch 75: EPOCH_AVG_TRAIN_LOSS=1.4036
2025-02-06 18:02:45,708 - INFO - #################### Training epoch 76 ####################
2025-02-06 18:02:45,708 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 18:02:46,114 - INFO - Epoch 76: train_loss=1.4347
2025-02-06 18:02:46,406 - INFO - Epoch 76: train_loss=1.3202
2025-02-06 18:02:46,728 - INFO - Epoch 76: val_loss=1.5886, val_acc=33.33%
2025-02-06 18:02:46,731 - INFO - Epoch 76: EPOCH_AVG_TRAIN_LOSS=1.3202
2025-02-06 18:02:46,734 - INFO - #################### Training epoch 77 ####################
2025-02-06 18:02:46,734 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 18:02:47,142 - INFO - Epoch 77: train_loss=1.3339
2025-02-06 18:02:47,434 - INFO - Epoch 77: train_loss=1.7681
2025-02-06 18:02:47,761 - INFO - Epoch 77: val_loss=1.5751, val_acc=33.33%
2025-02-06 18:02:47,765 - INFO - Epoch 77: EPOCH_AVG_TRAIN_LOSS=1.3339
2025-02-06 18:02:47,767 - INFO - #################### Training epoch 78 ####################
2025-02-06 18:02:47,767 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 18:02:48,178 - INFO - Epoch 78: train_loss=1.3319
2025-02-06 18:02:48,471 - INFO - Epoch 78: train_loss=1.5156
2025-02-06 18:02:48,794 - INFO - Epoch 78: val_loss=1.5699, val_acc=33.33%
2025-02-06 18:02:48,798 - INFO - Epoch 78: EPOCH_AVG_TRAIN_LOSS=1.3319
2025-02-06 18:02:48,800 - INFO - #################### Training epoch 79 ####################
2025-02-06 18:02:48,800 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:49,207 - INFO - Epoch 79: train_loss=1.5354
2025-02-06 18:02:49,499 - INFO - Epoch 79: train_loss=1.1932
2025-02-06 18:02:49,823 - INFO - Epoch 79: val_loss=1.5787, val_acc=33.33%
2025-02-06 18:02:49,827 - INFO - Epoch 79: EPOCH_AVG_TRAIN_LOSS=1.1932
2025-02-06 18:02:49,829 - INFO - #################### Training epoch 80 ####################
2025-02-06 18:02:49,829 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:50,238 - INFO - Epoch 80: train_loss=1.4875
2025-02-06 18:02:50,531 - INFO - Epoch 80: train_loss=1.3379
2025-02-06 18:02:50,857 - INFO - Epoch 80: val_loss=1.5908, val_acc=33.33%
2025-02-06 18:02:50,860 - INFO - Epoch 80: EPOCH_AVG_TRAIN_LOSS=1.3379
2025-02-06 18:02:50,863 - INFO - #################### Training epoch 81 ####################
2025-02-06 18:02:50,863 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:51,270 - INFO - Epoch 81: train_loss=1.2547
2025-02-06 18:02:51,563 - INFO - Epoch 81: train_loss=1.8238
2025-02-06 18:02:51,886 - INFO - Epoch 81: val_loss=1.5883, val_acc=33.33%
2025-02-06 18:02:51,890 - INFO - Epoch 81: EPOCH_AVG_TRAIN_LOSS=1.2547
2025-02-06 18:02:51,892 - INFO - #################### Training epoch 82 ####################
2025-02-06 18:02:51,892 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:52,301 - INFO - Epoch 82: train_loss=1.3815
2025-02-06 18:02:52,594 - INFO - Epoch 82: train_loss=1.4583
2025-02-06 18:02:52,917 - INFO - Epoch 82: val_loss=1.5771, val_acc=33.33%
2025-02-06 18:02:52,920 - INFO - Epoch 82: EPOCH_AVG_TRAIN_LOSS=1.3815
2025-02-06 18:02:52,923 - INFO - #################### Training epoch 83 ####################
2025-02-06 18:02:52,923 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:53,333 - INFO - Epoch 83: train_loss=1.4674
2025-02-06 18:02:53,625 - INFO - Epoch 83: train_loss=1.3865
2025-02-06 18:02:53,944 - INFO - Epoch 83: val_loss=1.5801, val_acc=33.33%
2025-02-06 18:02:53,948 - INFO - Epoch 83: EPOCH_AVG_TRAIN_LOSS=1.3865
2025-02-06 18:02:53,950 - INFO - #################### Training epoch 84 ####################
2025-02-06 18:02:53,950 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:54,359 - INFO - Epoch 84: train_loss=1.5267
2025-02-06 18:02:54,651 - INFO - Epoch 84: train_loss=1.1064
2025-02-06 18:02:54,974 - INFO - Epoch 84: val_loss=1.5753, val_acc=33.33%
2025-02-06 18:02:54,978 - INFO - Epoch 84: EPOCH_AVG_TRAIN_LOSS=1.1064
2025-02-06 18:02:54,980 - INFO - #################### Training epoch 85 ####################
2025-02-06 18:02:54,980 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:55,388 - INFO - Epoch 85: train_loss=1.5557
2025-02-06 18:02:55,680 - INFO - Epoch 85: train_loss=1.2574
2025-02-06 18:02:56,007 - INFO - Epoch 85: val_loss=1.5825, val_acc=33.33%
2025-02-06 18:02:56,010 - INFO - Epoch 85: EPOCH_AVG_TRAIN_LOSS=1.2574
2025-02-06 18:02:56,012 - INFO - #################### Training epoch 86 ####################
2025-02-06 18:02:56,013 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:56,425 - INFO - Epoch 86: train_loss=1.3777
2025-02-06 18:02:56,718 - INFO - Epoch 86: train_loss=1.6045
2025-02-06 18:02:57,040 - INFO - Epoch 86: val_loss=1.5796, val_acc=33.33%
2025-02-06 18:02:57,044 - INFO - Epoch 86: EPOCH_AVG_TRAIN_LOSS=1.3777
2025-02-06 18:02:57,046 - INFO - #################### Training epoch 87 ####################
2025-02-06 18:02:57,046 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:57,452 - INFO - Epoch 87: train_loss=1.5717
2025-02-06 18:02:57,745 - INFO - Epoch 87: train_loss=1.1310
2025-02-06 18:02:58,070 - INFO - Epoch 87: val_loss=1.5761, val_acc=33.33%
2025-02-06 18:02:58,074 - INFO - Epoch 87: EPOCH_AVG_TRAIN_LOSS=1.1310
2025-02-06 18:02:58,076 - INFO - #################### Training epoch 88 ####################
2025-02-06 18:02:58,076 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:58,482 - INFO - Epoch 88: train_loss=1.5388
2025-02-06 18:02:58,774 - INFO - Epoch 88: train_loss=1.2244
2025-02-06 18:02:59,100 - INFO - Epoch 88: val_loss=1.5878, val_acc=33.33%
2025-02-06 18:02:59,103 - INFO - Epoch 88: EPOCH_AVG_TRAIN_LOSS=1.2244
2025-02-06 18:02:59,106 - INFO - #################### Training epoch 89 ####################
2025-02-06 18:02:59,106 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:02:59,515 - INFO - Epoch 89: train_loss=1.6294
2025-02-06 18:02:59,808 - INFO - Epoch 89: train_loss=0.8994
2025-02-06 18:03:00,130 - INFO - Epoch 89: val_loss=1.5763, val_acc=33.33%
2025-02-06 18:03:00,134 - INFO - Epoch 89: EPOCH_AVG_TRAIN_LOSS=0.8994
2025-02-06 18:03:00,136 - INFO - #################### Training epoch 90 ####################
2025-02-06 18:03:00,136 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:00,544 - INFO - Epoch 90: train_loss=1.0964
2025-02-06 18:03:00,836 - INFO - Epoch 90: train_loss=1.9153
2025-02-06 18:03:01,159 - INFO - Epoch 90: val_loss=1.5772, val_acc=33.33%
2025-02-06 18:03:01,163 - INFO - Epoch 90: EPOCH_AVG_TRAIN_LOSS=1.0964
2025-02-06 18:03:01,165 - INFO - #################### Training epoch 91 ####################
2025-02-06 18:03:01,165 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:01,572 - INFO - Epoch 91: train_loss=1.4918
2025-02-06 18:03:01,864 - INFO - Epoch 91: train_loss=1.2136
2025-02-06 18:03:02,189 - INFO - Epoch 91: val_loss=1.5838, val_acc=33.33%
2025-02-06 18:03:02,193 - INFO - Epoch 91: EPOCH_AVG_TRAIN_LOSS=1.2136
2025-02-06 18:03:02,196 - INFO - #################### Training epoch 92 ####################
2025-02-06 18:03:02,196 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:02,603 - INFO - Epoch 92: train_loss=1.3533
2025-02-06 18:03:02,895 - INFO - Epoch 92: train_loss=1.6044
2025-02-06 18:03:03,219 - INFO - Epoch 92: val_loss=1.5729, val_acc=33.33%
2025-02-06 18:03:03,223 - INFO - Epoch 92: EPOCH_AVG_TRAIN_LOSS=1.3533
2025-02-06 18:03:03,225 - INFO - #################### Training epoch 93 ####################
2025-02-06 18:03:03,225 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:03,633 - INFO - Epoch 93: train_loss=1.5350
2025-02-06 18:03:03,926 - INFO - Epoch 93: train_loss=1.1183
2025-02-06 18:03:04,251 - INFO - Epoch 93: val_loss=1.5803, val_acc=33.33%
2025-02-06 18:03:04,255 - INFO - Epoch 93: EPOCH_AVG_TRAIN_LOSS=1.1183
2025-02-06 18:03:04,257 - INFO - #################### Training epoch 94 ####################
2025-02-06 18:03:04,257 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:04,664 - INFO - Epoch 94: train_loss=1.2761
2025-02-06 18:03:04,956 - INFO - Epoch 94: train_loss=1.6780
2025-02-06 18:03:05,278 - INFO - Epoch 94: val_loss=1.5756, val_acc=33.33%
2025-02-06 18:03:05,282 - INFO - Epoch 94: EPOCH_AVG_TRAIN_LOSS=1.2761
2025-02-06 18:03:05,284 - INFO - #################### Training epoch 95 ####################
2025-02-06 18:03:05,284 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:05,689 - INFO - Epoch 95: train_loss=1.4346
2025-02-06 18:03:05,982 - INFO - Epoch 95: train_loss=1.2213
2025-02-06 18:03:06,304 - INFO - Epoch 95: val_loss=1.5672, val_acc=33.33%
2025-02-06 18:03:06,308 - INFO - Epoch 95: EPOCH_AVG_TRAIN_LOSS=1.2213
2025-02-06 18:03:06,310 - INFO - #################### Training epoch 96 ####################
2025-02-06 18:03:06,310 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:06,719 - INFO - Epoch 96: train_loss=1.4616
2025-02-06 18:03:07,011 - INFO - Epoch 96: train_loss=1.3924
2025-02-06 18:03:07,334 - INFO - Epoch 96: val_loss=1.5764, val_acc=33.33%
2025-02-06 18:03:07,338 - INFO - Epoch 96: EPOCH_AVG_TRAIN_LOSS=1.3924
2025-02-06 18:03:07,340 - INFO - #################### Training epoch 97 ####################
2025-02-06 18:03:07,340 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:07,750 - INFO - Epoch 97: train_loss=1.5503
2025-02-06 18:03:08,043 - INFO - Epoch 97: train_loss=1.1646
2025-02-06 18:03:08,364 - INFO - Epoch 97: val_loss=1.5803, val_acc=33.33%
2025-02-06 18:03:08,368 - INFO - Epoch 97: EPOCH_AVG_TRAIN_LOSS=1.1646
2025-02-06 18:03:08,370 - INFO - #################### Training epoch 98 ####################
2025-02-06 18:03:08,370 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:08,779 - INFO - Epoch 98: train_loss=1.4980
2025-02-06 18:03:09,071 - INFO - Epoch 98: train_loss=1.3250
2025-02-06 18:03:09,393 - INFO - Epoch 98: val_loss=1.5706, val_acc=33.33%
2025-02-06 18:03:09,397 - INFO - Epoch 98: EPOCH_AVG_TRAIN_LOSS=1.3250
2025-02-06 18:03:09,399 - INFO - #################### Training epoch 99 ####################
2025-02-06 18:03:09,399 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:09,806 - INFO - Epoch 99: train_loss=1.6626
2025-02-06 18:03:10,099 - INFO - Epoch 99: train_loss=0.9985
2025-02-06 18:03:10,420 - INFO - Epoch 99: val_loss=1.5658, val_acc=33.33%
2025-02-06 18:03:10,423 - INFO - Epoch 99: EPOCH_AVG_TRAIN_LOSS=0.9985
2025-02-06 18:03:10,425 - INFO - #################### Training epoch 100 ####################
2025-02-06 18:03:10,426 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:10,831 - INFO - Epoch 100: train_loss=1.2823
2025-02-06 18:03:11,124 - INFO - Epoch 100: train_loss=1.6094
2025-02-06 18:03:11,444 - INFO - Epoch 100: val_loss=1.5792, val_acc=33.33%
2025-02-06 18:03:11,448 - INFO - Epoch 100: EPOCH_AVG_TRAIN_LOSS=1.2823
2025-02-06 18:03:11,450 - INFO - #################### Training epoch 101 ####################
2025-02-06 18:03:11,451 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:11,859 - INFO - Epoch 101: train_loss=1.4621
2025-02-06 18:03:12,151 - INFO - Epoch 101: train_loss=1.2823
2025-02-06 18:03:12,474 - INFO - Epoch 101: val_loss=1.5840, val_acc=33.33%
2025-02-06 18:03:12,477 - INFO - Epoch 101: EPOCH_AVG_TRAIN_LOSS=1.2823
2025-02-06 18:03:12,480 - INFO - #################### Training epoch 102 ####################
2025-02-06 18:03:12,480 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:12,888 - INFO - Epoch 102: train_loss=1.4320
2025-02-06 18:03:13,181 - INFO - Epoch 102: train_loss=1.5388
2025-02-06 18:03:13,506 - INFO - Epoch 102: val_loss=1.5892, val_acc=33.33%
2025-02-06 18:03:13,510 - INFO - Epoch 102: EPOCH_AVG_TRAIN_LOSS=1.4320
2025-02-06 18:03:13,512 - INFO - #################### Training epoch 103 ####################
2025-02-06 18:03:13,512 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:13,917 - INFO - Epoch 103: train_loss=1.2112
2025-02-06 18:03:14,209 - INFO - Epoch 103: train_loss=1.8691
2025-02-06 18:03:14,534 - INFO - Epoch 103: val_loss=1.5769, val_acc=33.33%
2025-02-06 18:03:14,537 - INFO - Epoch 103: EPOCH_AVG_TRAIN_LOSS=1.2112
2025-02-06 18:03:14,540 - INFO - #################### Training epoch 104 ####################
2025-02-06 18:03:14,540 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:14,950 - INFO - Epoch 104: train_loss=1.6727
2025-02-06 18:03:15,243 - INFO - Epoch 104: train_loss=0.9222
2025-02-06 18:03:15,569 - INFO - Epoch 104: val_loss=1.5921, val_acc=33.33%
2025-02-06 18:03:15,572 - INFO - Epoch 104: EPOCH_AVG_TRAIN_LOSS=0.9222
2025-02-06 18:03:15,575 - INFO - #################### Training epoch 105 ####################
2025-02-06 18:03:15,575 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:15,981 - INFO - Epoch 105: train_loss=1.7108
2025-02-06 18:03:16,273 - INFO - Epoch 105: train_loss=0.8398
2025-02-06 18:03:16,597 - INFO - Epoch 105: val_loss=1.5755, val_acc=33.33%
2025-02-06 18:03:16,600 - INFO - Epoch 105: EPOCH_AVG_TRAIN_LOSS=0.8398
2025-02-06 18:03:16,603 - INFO - #################### Training epoch 106 ####################
2025-02-06 18:03:16,603 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:17,014 - INFO - Epoch 106: train_loss=1.1176
2025-02-06 18:03:17,306 - INFO - Epoch 106: train_loss=2.1007
2025-02-06 18:03:17,633 - INFO - Epoch 106: val_loss=1.5815, val_acc=33.33%
2025-02-06 18:03:17,637 - INFO - Epoch 106: EPOCH_AVG_TRAIN_LOSS=1.1176
2025-02-06 18:03:17,639 - INFO - #################### Training epoch 107 ####################
2025-02-06 18:03:17,639 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:18,044 - INFO - Epoch 107: train_loss=1.3283
2025-02-06 18:03:18,336 - INFO - Epoch 107: train_loss=1.5880
2025-02-06 18:03:18,656 - INFO - Epoch 107: val_loss=1.5956, val_acc=33.33%
2025-02-06 18:03:18,660 - INFO - Epoch 107: EPOCH_AVG_TRAIN_LOSS=1.3283
2025-02-06 18:03:18,662 - INFO - #################### Training epoch 108 ####################
2025-02-06 18:03:18,663 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:19,072 - INFO - Epoch 108: train_loss=1.6423
2025-02-06 18:03:19,364 - INFO - Epoch 108: train_loss=1.0416
2025-02-06 18:03:19,689 - INFO - Epoch 108: val_loss=1.5808, val_acc=33.33%
2025-02-06 18:03:19,693 - INFO - Epoch 108: EPOCH_AVG_TRAIN_LOSS=1.0416
2025-02-06 18:03:19,695 - INFO - #################### Training epoch 109 ####################
2025-02-06 18:03:19,695 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:20,106 - INFO - Epoch 109: train_loss=1.3785
2025-02-06 18:03:20,398 - INFO - Epoch 109: train_loss=1.5807
2025-02-06 18:03:20,723 - INFO - Epoch 109: val_loss=1.5833, val_acc=33.33%
2025-02-06 18:03:20,727 - INFO - Epoch 109: EPOCH_AVG_TRAIN_LOSS=1.3785
2025-02-06 18:03:20,729 - INFO - #################### Training epoch 110 ####################
2025-02-06 18:03:20,729 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:21,139 - INFO - Epoch 110: train_loss=1.3959
2025-02-06 18:03:21,431 - INFO - Epoch 110: train_loss=1.5728
2025-02-06 18:03:21,757 - INFO - Epoch 110: val_loss=1.5818, val_acc=33.33%
2025-02-06 18:03:21,760 - INFO - Epoch 110: EPOCH_AVG_TRAIN_LOSS=1.3959
2025-02-06 18:03:21,763 - INFO - #################### Training epoch 111 ####################
2025-02-06 18:03:21,763 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:22,176 - INFO - Epoch 111: train_loss=1.5898
2025-02-06 18:03:22,468 - INFO - Epoch 111: train_loss=1.0055
2025-02-06 18:03:22,791 - INFO - Epoch 111: val_loss=1.5624, val_acc=33.33%
2025-02-06 18:03:22,795 - INFO - Epoch 111: EPOCH_AVG_TRAIN_LOSS=1.0055
2025-02-06 18:03:22,797 - INFO - #################### Training epoch 112 ####################
2025-02-06 18:03:22,797 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:23,205 - INFO - Epoch 112: train_loss=1.3490
2025-02-06 18:03:23,497 - INFO - Epoch 112: train_loss=1.5954
2025-02-06 18:03:23,821 - INFO - Epoch 112: val_loss=1.5931, val_acc=33.33%
2025-02-06 18:03:23,825 - INFO - Epoch 112: EPOCH_AVG_TRAIN_LOSS=1.3490
2025-02-06 18:03:23,827 - INFO - #################### Training epoch 113 ####################
2025-02-06 18:03:23,827 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:24,234 - INFO - Epoch 113: train_loss=1.3580
2025-02-06 18:03:24,526 - INFO - Epoch 113: train_loss=1.4445
2025-02-06 18:03:24,849 - INFO - Epoch 113: val_loss=1.5785, val_acc=33.33%
2025-02-06 18:03:24,853 - INFO - Epoch 113: EPOCH_AVG_TRAIN_LOSS=1.3580
2025-02-06 18:03:24,856 - INFO - #################### Training epoch 114 ####################
2025-02-06 18:03:24,856 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:25,264 - INFO - Epoch 114: train_loss=1.4275
2025-02-06 18:03:25,556 - INFO - Epoch 114: train_loss=1.3683
2025-02-06 18:03:25,878 - INFO - Epoch 114: val_loss=1.5711, val_acc=33.33%
2025-02-06 18:03:25,882 - INFO - Epoch 114: EPOCH_AVG_TRAIN_LOSS=1.3683
2025-02-06 18:03:25,884 - INFO - #################### Training epoch 115 ####################
2025-02-06 18:03:25,884 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:26,292 - INFO - Epoch 115: train_loss=1.5392
2025-02-06 18:03:26,584 - INFO - Epoch 115: train_loss=1.3053
2025-02-06 18:03:26,908 - INFO - Epoch 115: val_loss=1.5942, val_acc=33.33%
2025-02-06 18:03:26,912 - INFO - Epoch 115: EPOCH_AVG_TRAIN_LOSS=1.3053
2025-02-06 18:03:26,914 - INFO - #################### Training epoch 116 ####################
2025-02-06 18:03:26,914 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:27,325 - INFO - Epoch 116: train_loss=1.2890
2025-02-06 18:03:27,618 - INFO - Epoch 116: train_loss=1.6329
2025-02-06 18:03:27,940 - INFO - Epoch 116: val_loss=1.5743, val_acc=33.33%
2025-02-06 18:03:27,943 - INFO - Epoch 116: EPOCH_AVG_TRAIN_LOSS=1.2890
2025-02-06 18:03:27,945 - INFO - #################### Training epoch 117 ####################
2025-02-06 18:03:27,945 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:28,356 - INFO - Epoch 117: train_loss=1.2082
2025-02-06 18:03:28,648 - INFO - Epoch 117: train_loss=1.7678
2025-02-06 18:03:28,973 - INFO - Epoch 117: val_loss=1.5682, val_acc=33.33%
2025-02-06 18:03:28,976 - INFO - Epoch 117: EPOCH_AVG_TRAIN_LOSS=1.2082
2025-02-06 18:03:28,979 - INFO - #################### Training epoch 118 ####################
2025-02-06 18:03:28,979 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:29,387 - INFO - Epoch 118: train_loss=1.4012
2025-02-06 18:03:29,679 - INFO - Epoch 118: train_loss=1.3124
2025-02-06 18:03:30,002 - INFO - Epoch 118: val_loss=1.5914, val_acc=33.33%
2025-02-06 18:03:30,006 - INFO - Epoch 118: EPOCH_AVG_TRAIN_LOSS=1.3124
2025-02-06 18:03:30,008 - INFO - #################### Training epoch 119 ####################
2025-02-06 18:03:30,008 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:30,417 - INFO - Epoch 119: train_loss=1.3205
2025-02-06 18:03:30,709 - INFO - Epoch 119: train_loss=1.6322
2025-02-06 18:03:31,033 - INFO - Epoch 119: val_loss=1.5753, val_acc=33.33%
2025-02-06 18:03:31,037 - INFO - Epoch 119: EPOCH_AVG_TRAIN_LOSS=1.3205
2025-02-06 18:03:31,039 - INFO - #################### Training epoch 120 ####################
2025-02-06 18:03:31,039 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:31,449 - INFO - Epoch 120: train_loss=1.4247
2025-02-06 18:03:31,742 - INFO - Epoch 120: train_loss=1.4396
2025-02-06 18:03:32,067 - INFO - Epoch 120: val_loss=1.5654, val_acc=33.33%
2025-02-06 18:03:32,070 - INFO - Epoch 120: EPOCH_AVG_TRAIN_LOSS=1.4247
2025-02-06 18:03:32,072 - INFO - #################### Training epoch 121 ####################
2025-02-06 18:03:32,073 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:32,479 - INFO - Epoch 121: train_loss=1.6268
2025-02-06 18:03:32,771 - INFO - Epoch 121: train_loss=1.0692
2025-02-06 18:03:33,091 - INFO - Epoch 121: val_loss=1.5860, val_acc=33.33%
2025-02-06 18:03:33,095 - INFO - Epoch 121: EPOCH_AVG_TRAIN_LOSS=1.0692
2025-02-06 18:03:33,097 - INFO - #################### Training epoch 122 ####################
2025-02-06 18:03:33,097 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:33,508 - INFO - Epoch 122: train_loss=1.3363
2025-02-06 18:03:33,800 - INFO - Epoch 122: train_loss=1.5312
2025-02-06 18:03:34,124 - INFO - Epoch 122: val_loss=1.5730, val_acc=33.33%
2025-02-06 18:03:34,128 - INFO - Epoch 122: EPOCH_AVG_TRAIN_LOSS=1.3363
2025-02-06 18:03:34,130 - INFO - #################### Training epoch 123 ####################
2025-02-06 18:03:34,130 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:34,539 - INFO - Epoch 123: train_loss=1.7337
2025-02-06 18:03:34,831 - INFO - Epoch 123: train_loss=0.7834
2025-02-06 18:03:35,150 - INFO - Epoch 123: val_loss=1.5672, val_acc=33.33%
2025-02-06 18:03:35,154 - INFO - Epoch 123: EPOCH_AVG_TRAIN_LOSS=0.7834
2025-02-06 18:03:35,156 - INFO - #################### Training epoch 124 ####################
2025-02-06 18:03:35,156 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:35,562 - INFO - Epoch 124: train_loss=1.4951
2025-02-06 18:03:35,855 - INFO - Epoch 124: train_loss=1.2972
2025-02-06 18:03:36,177 - INFO - Epoch 124: val_loss=1.5769, val_acc=33.33%
2025-02-06 18:03:36,181 - INFO - Epoch 124: EPOCH_AVG_TRAIN_LOSS=1.2972
2025-02-06 18:03:36,183 - INFO - #################### Training epoch 125 ####################
2025-02-06 18:03:36,183 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:36,592 - INFO - Epoch 125: train_loss=1.3737
2025-02-06 18:03:36,884 - INFO - Epoch 125: train_loss=1.4386
2025-02-06 18:03:37,205 - INFO - Epoch 125: val_loss=1.5787, val_acc=33.33%
2025-02-06 18:03:37,209 - INFO - Epoch 125: EPOCH_AVG_TRAIN_LOSS=1.3737
2025-02-06 18:03:37,211 - INFO - #################### Training epoch 126 ####################
2025-02-06 18:03:37,211 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:37,617 - INFO - Epoch 126: train_loss=1.2801
2025-02-06 18:03:37,909 - INFO - Epoch 126: train_loss=1.6530
2025-02-06 18:03:38,232 - INFO - Epoch 126: val_loss=1.5835, val_acc=33.33%
2025-02-06 18:03:38,236 - INFO - Epoch 126: EPOCH_AVG_TRAIN_LOSS=1.2801
2025-02-06 18:03:38,238 - INFO - #################### Training epoch 127 ####################
2025-02-06 18:03:38,238 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:38,645 - INFO - Epoch 127: train_loss=1.5215
2025-02-06 18:03:38,937 - INFO - Epoch 127: train_loss=1.1945
2025-02-06 18:03:39,263 - INFO - Epoch 127: val_loss=1.5914, val_acc=33.33%
2025-02-06 18:03:39,267 - INFO - Epoch 127: EPOCH_AVG_TRAIN_LOSS=1.1945
2025-02-06 18:03:39,269 - INFO - #################### Training epoch 128 ####################
2025-02-06 18:03:39,269 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:39,674 - INFO - Epoch 128: train_loss=1.4972
2025-02-06 18:03:39,966 - INFO - Epoch 128: train_loss=1.3019
2025-02-06 18:03:40,292 - INFO - Epoch 128: val_loss=1.5624, val_acc=33.33%
2025-02-06 18:03:40,296 - INFO - Epoch 128: EPOCH_AVG_TRAIN_LOSS=1.3019
2025-02-06 18:03:40,298 - INFO - #################### Training epoch 129 ####################
2025-02-06 18:03:40,298 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:40,706 - INFO - Epoch 129: train_loss=1.1895
2025-02-06 18:03:40,998 - INFO - Epoch 129: train_loss=1.9082
2025-02-06 18:03:41,323 - INFO - Epoch 129: val_loss=1.5868, val_acc=33.33%
2025-02-06 18:03:41,327 - INFO - Epoch 129: EPOCH_AVG_TRAIN_LOSS=1.1895
2025-02-06 18:03:41,329 - INFO - #################### Training epoch 130 ####################
2025-02-06 18:03:41,329 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:41,737 - INFO - Epoch 130: train_loss=1.7405
2025-02-06 18:03:42,028 - INFO - Epoch 130: train_loss=0.8107
2025-02-06 18:03:42,350 - INFO - Epoch 130: val_loss=1.5892, val_acc=33.33%
2025-02-06 18:03:42,354 - INFO - Epoch 130: EPOCH_AVG_TRAIN_LOSS=0.8107
2025-02-06 18:03:42,356 - INFO - #################### Training epoch 131 ####################
2025-02-06 18:03:42,356 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:42,765 - INFO - Epoch 131: train_loss=1.3840
2025-02-06 18:03:43,058 - INFO - Epoch 131: train_loss=1.6005
2025-02-06 18:03:43,379 - INFO - Epoch 131: val_loss=1.5875, val_acc=33.33%
2025-02-06 18:03:43,383 - INFO - Epoch 131: EPOCH_AVG_TRAIN_LOSS=1.3840
2025-02-06 18:03:43,385 - INFO - #################### Training epoch 132 ####################
2025-02-06 18:03:43,385 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:43,792 - INFO - Epoch 132: train_loss=1.5168
2025-02-06 18:03:44,084 - INFO - Epoch 132: train_loss=1.2655
2025-02-06 18:03:44,408 - INFO - Epoch 132: val_loss=1.5992, val_acc=33.33%
2025-02-06 18:03:44,412 - INFO - Epoch 132: EPOCH_AVG_TRAIN_LOSS=1.2655
2025-02-06 18:03:44,414 - INFO - #################### Training epoch 133 ####################
2025-02-06 18:03:44,414 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:44,823 - INFO - Epoch 133: train_loss=1.5867
2025-02-06 18:03:45,115 - INFO - Epoch 133: train_loss=1.1166
2025-02-06 18:03:45,439 - INFO - Epoch 133: val_loss=1.5772, val_acc=33.33%
2025-02-06 18:03:45,443 - INFO - Epoch 133: EPOCH_AVG_TRAIN_LOSS=1.1166
2025-02-06 18:03:45,445 - INFO - #################### Training epoch 134 ####################
2025-02-06 18:03:45,445 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:45,855 - INFO - Epoch 134: train_loss=1.2252
2025-02-06 18:03:46,146 - INFO - Epoch 134: train_loss=1.7696
2025-02-06 18:03:46,472 - INFO - Epoch 134: val_loss=1.5772, val_acc=33.33%
2025-02-06 18:03:46,476 - INFO - Epoch 134: EPOCH_AVG_TRAIN_LOSS=1.2252
2025-02-06 18:03:46,478 - INFO - #################### Training epoch 135 ####################
2025-02-06 18:03:46,478 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:46,887 - INFO - Epoch 135: train_loss=1.4378
2025-02-06 18:03:47,179 - INFO - Epoch 135: train_loss=1.4730
2025-02-06 18:03:47,505 - INFO - Epoch 135: val_loss=1.6037, val_acc=33.33%
2025-02-06 18:03:47,509 - INFO - Epoch 135: EPOCH_AVG_TRAIN_LOSS=1.4378
2025-02-06 18:03:47,511 - INFO - #################### Training epoch 136 ####################
2025-02-06 18:03:47,511 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:47,917 - INFO - Epoch 136: train_loss=1.7096
2025-02-06 18:03:48,209 - INFO - Epoch 136: train_loss=0.7832
2025-02-06 18:03:48,535 - INFO - Epoch 136: val_loss=1.5791, val_acc=33.33%
2025-02-06 18:03:48,539 - INFO - Epoch 136: EPOCH_AVG_TRAIN_LOSS=0.7832
2025-02-06 18:03:48,541 - INFO - #################### Training epoch 137 ####################
2025-02-06 18:03:48,541 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:48,947 - INFO - Epoch 137: train_loss=1.5275
2025-02-06 18:03:49,239 - INFO - Epoch 137: train_loss=1.1118
2025-02-06 18:03:49,565 - INFO - Epoch 137: val_loss=1.5887, val_acc=33.33%
2025-02-06 18:03:49,569 - INFO - Epoch 137: EPOCH_AVG_TRAIN_LOSS=1.1118
2025-02-06 18:03:49,571 - INFO - #################### Training epoch 138 ####################
2025-02-06 18:03:49,571 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:49,982 - INFO - Epoch 138: train_loss=1.4788
2025-02-06 18:03:50,273 - INFO - Epoch 138: train_loss=1.3858
2025-02-06 18:03:50,595 - INFO - Epoch 138: val_loss=1.5850, val_acc=33.33%
2025-02-06 18:03:50,599 - INFO - Epoch 138: EPOCH_AVG_TRAIN_LOSS=1.3858
2025-02-06 18:03:50,601 - INFO - #################### Training epoch 139 ####################
2025-02-06 18:03:50,601 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:51,010 - INFO - Epoch 139: train_loss=1.3720
2025-02-06 18:03:51,301 - INFO - Epoch 139: train_loss=1.6236
2025-02-06 18:03:51,626 - INFO - Epoch 139: val_loss=1.5516, val_acc=33.33%
2025-02-06 18:03:51,629 - INFO - Epoch 139: EPOCH_AVG_TRAIN_LOSS=1.3720
2025-02-06 18:03:51,632 - INFO - #################### Training epoch 140 ####################
2025-02-06 18:03:51,632 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:52,042 - INFO - Epoch 140: train_loss=1.3352
2025-02-06 18:03:52,334 - INFO - Epoch 140: train_loss=1.6241
2025-02-06 18:03:52,661 - INFO - Epoch 140: val_loss=1.5740, val_acc=33.33%
2025-02-06 18:03:52,665 - INFO - Epoch 140: EPOCH_AVG_TRAIN_LOSS=1.3352
2025-02-06 18:03:52,667 - INFO - #################### Training epoch 141 ####################
2025-02-06 18:03:52,667 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:53,075 - INFO - Epoch 141: train_loss=1.4827
2025-02-06 18:03:53,366 - INFO - Epoch 141: train_loss=1.3171
2025-02-06 18:03:53,689 - INFO - Epoch 141: val_loss=1.5764, val_acc=33.33%
2025-02-06 18:03:53,693 - INFO - Epoch 141: EPOCH_AVG_TRAIN_LOSS=1.3171
2025-02-06 18:03:53,695 - INFO - #################### Training epoch 142 ####################
2025-02-06 18:03:53,695 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:54,102 - INFO - Epoch 142: train_loss=1.4545
2025-02-06 18:03:54,394 - INFO - Epoch 142: train_loss=1.3309
2025-02-06 18:03:54,720 - INFO - Epoch 142: val_loss=1.5883, val_acc=33.33%
2025-02-06 18:03:54,724 - INFO - Epoch 142: EPOCH_AVG_TRAIN_LOSS=1.3309
2025-02-06 18:03:54,726 - INFO - #################### Training epoch 143 ####################
2025-02-06 18:03:54,726 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:55,134 - INFO - Epoch 143: train_loss=1.6424
2025-02-06 18:03:55,426 - INFO - Epoch 143: train_loss=1.0550
2025-02-06 18:03:55,753 - INFO - Epoch 143: val_loss=1.5689, val_acc=33.33%
2025-02-06 18:03:55,757 - INFO - Epoch 143: EPOCH_AVG_TRAIN_LOSS=1.0550
2025-02-06 18:03:55,759 - INFO - #################### Training epoch 144 ####################
2025-02-06 18:03:55,759 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:56,165 - INFO - Epoch 144: train_loss=1.4428
2025-02-06 18:03:56,457 - INFO - Epoch 144: train_loss=1.3508
2025-02-06 18:03:56,782 - INFO - Epoch 144: val_loss=1.5693, val_acc=33.33%
2025-02-06 18:03:56,785 - INFO - Epoch 144: EPOCH_AVG_TRAIN_LOSS=1.3508
2025-02-06 18:03:56,788 - INFO - #################### Training epoch 145 ####################
2025-02-06 18:03:56,788 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:57,194 - INFO - Epoch 145: train_loss=1.3149
2025-02-06 18:03:57,486 - INFO - Epoch 145: train_loss=1.5420
2025-02-06 18:03:57,806 - INFO - Epoch 145: val_loss=1.5796, val_acc=33.33%
2025-02-06 18:03:57,810 - INFO - Epoch 145: EPOCH_AVG_TRAIN_LOSS=1.3149
2025-02-06 18:03:57,812 - INFO - #################### Training epoch 146 ####################
2025-02-06 18:03:57,812 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:58,222 - INFO - Epoch 146: train_loss=1.1661
2025-02-06 18:03:58,514 - INFO - Epoch 146: train_loss=1.8565
2025-02-06 18:03:58,839 - INFO - Epoch 146: val_loss=1.5700, val_acc=33.33%
2025-02-06 18:03:58,843 - INFO - Epoch 146: EPOCH_AVG_TRAIN_LOSS=1.1661
2025-02-06 18:03:58,845 - INFO - #################### Training epoch 147 ####################
2025-02-06 18:03:58,845 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:03:59,254 - INFO - Epoch 147: train_loss=1.3733
2025-02-06 18:03:59,547 - INFO - Epoch 147: train_loss=1.6253
2025-02-06 18:03:59,871 - INFO - Epoch 147: val_loss=1.5876, val_acc=33.33%
2025-02-06 18:03:59,875 - INFO - Epoch 147: EPOCH_AVG_TRAIN_LOSS=1.3733
2025-02-06 18:03:59,877 - INFO - #################### Training epoch 148 ####################
2025-02-06 18:03:59,877 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:00,285 - INFO - Epoch 148: train_loss=1.3360
2025-02-06 18:04:00,578 - INFO - Epoch 148: train_loss=1.6182
2025-02-06 18:04:00,906 - INFO - Epoch 148: val_loss=1.6016, val_acc=33.33%
2025-02-06 18:04:00,910 - INFO - Epoch 148: EPOCH_AVG_TRAIN_LOSS=1.3360
2025-02-06 18:04:00,912 - INFO - #################### Training epoch 149 ####################
2025-02-06 18:04:00,912 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:01,319 - INFO - Epoch 149: train_loss=1.4986
2025-02-06 18:04:01,611 - INFO - Epoch 149: train_loss=1.2457
2025-02-06 18:04:01,936 - INFO - Epoch 149: val_loss=1.5828, val_acc=33.33%
2025-02-06 18:04:01,940 - INFO - Epoch 149: EPOCH_AVG_TRAIN_LOSS=1.2457
2025-02-06 18:04:01,942 - INFO - #################### Training epoch 150 ####################
2025-02-06 18:04:01,942 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:02,352 - INFO - Epoch 150: train_loss=1.4066
2025-02-06 18:04:02,644 - INFO - Epoch 150: train_loss=1.3653
2025-02-06 18:04:02,965 - INFO - Epoch 150: val_loss=1.5900, val_acc=33.33%
2025-02-06 18:04:02,969 - INFO - Epoch 150: EPOCH_AVG_TRAIN_LOSS=1.3653
2025-02-06 18:04:02,971 - INFO - #################### Training epoch 151 ####################
2025-02-06 18:04:02,971 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:03,380 - INFO - Epoch 151: train_loss=1.5129
2025-02-06 18:04:03,672 - INFO - Epoch 151: train_loss=1.0925
2025-02-06 18:04:03,999 - INFO - Epoch 151: val_loss=1.5971, val_acc=33.33%
2025-02-06 18:04:04,002 - INFO - Epoch 151: EPOCH_AVG_TRAIN_LOSS=1.0925
2025-02-06 18:04:04,005 - INFO - #################### Training epoch 152 ####################
2025-02-06 18:04:04,005 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:04,412 - INFO - Epoch 152: train_loss=1.2949
2025-02-06 18:04:04,704 - INFO - Epoch 152: train_loss=1.5048
2025-02-06 18:04:05,027 - INFO - Epoch 152: val_loss=1.5926, val_acc=33.33%
2025-02-06 18:04:05,031 - INFO - Epoch 152: EPOCH_AVG_TRAIN_LOSS=1.2949
2025-02-06 18:04:05,033 - INFO - #################### Training epoch 153 ####################
2025-02-06 18:04:05,033 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:05,441 - INFO - Epoch 153: train_loss=1.3297
2025-02-06 18:04:05,733 - INFO - Epoch 153: train_loss=1.5252
2025-02-06 18:04:06,059 - INFO - Epoch 153: val_loss=1.5692, val_acc=33.33%
2025-02-06 18:04:06,063 - INFO - Epoch 153: EPOCH_AVG_TRAIN_LOSS=1.3297
2025-02-06 18:04:06,065 - INFO - #################### Training epoch 154 ####################
2025-02-06 18:04:06,065 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:06,473 - INFO - Epoch 154: train_loss=1.2981
2025-02-06 18:04:06,767 - INFO - Epoch 154: train_loss=1.7316
2025-02-06 18:04:07,091 - INFO - Epoch 154: val_loss=1.5839, val_acc=33.33%
2025-02-06 18:04:07,095 - INFO - Epoch 154: EPOCH_AVG_TRAIN_LOSS=1.2981
2025-02-06 18:04:07,097 - INFO - #################### Training epoch 155 ####################
2025-02-06 18:04:07,097 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:07,505 - INFO - Epoch 155: train_loss=1.5389
2025-02-06 18:04:07,798 - INFO - Epoch 155: train_loss=1.1893
2025-02-06 18:04:08,121 - INFO - Epoch 155: val_loss=1.5779, val_acc=33.33%
2025-02-06 18:04:08,125 - INFO - Epoch 155: EPOCH_AVG_TRAIN_LOSS=1.1893
2025-02-06 18:04:08,127 - INFO - #################### Training epoch 156 ####################
2025-02-06 18:04:08,127 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:08,535 - INFO - Epoch 156: train_loss=1.4886
2025-02-06 18:04:08,827 - INFO - Epoch 156: train_loss=1.2126
2025-02-06 18:04:09,153 - INFO - Epoch 156: val_loss=1.5855, val_acc=33.33%
2025-02-06 18:04:09,157 - INFO - Epoch 156: EPOCH_AVG_TRAIN_LOSS=1.2126
2025-02-06 18:04:09,159 - INFO - #################### Training epoch 157 ####################
2025-02-06 18:04:09,159 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:09,567 - INFO - Epoch 157: train_loss=1.3650
2025-02-06 18:04:09,859 - INFO - Epoch 157: train_loss=1.5176
2025-02-06 18:04:10,182 - INFO - Epoch 157: val_loss=1.5842, val_acc=33.33%
2025-02-06 18:04:10,186 - INFO - Epoch 157: EPOCH_AVG_TRAIN_LOSS=1.3650
2025-02-06 18:04:10,188 - INFO - #################### Training epoch 158 ####################
2025-02-06 18:04:10,188 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:10,596 - INFO - Epoch 158: train_loss=1.8286
2025-02-06 18:04:10,888 - INFO - Epoch 158: train_loss=0.6453
2025-02-06 18:04:11,214 - INFO - Epoch 158: val_loss=1.5833, val_acc=33.33%
2025-02-06 18:04:11,218 - INFO - Epoch 158: EPOCH_AVG_TRAIN_LOSS=0.6453
2025-02-06 18:04:11,220 - INFO - #################### Training epoch 159 ####################
2025-02-06 18:04:11,220 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:11,627 - INFO - Epoch 159: train_loss=1.3718
2025-02-06 18:04:11,919 - INFO - Epoch 159: train_loss=1.3651
2025-02-06 18:04:12,242 - INFO - Epoch 159: val_loss=1.5924, val_acc=33.33%
2025-02-06 18:04:12,245 - INFO - Epoch 159: EPOCH_AVG_TRAIN_LOSS=1.3651
2025-02-06 18:04:12,248 - INFO - #################### Training epoch 160 ####################
2025-02-06 18:04:12,248 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:12,652 - INFO - Epoch 160: train_loss=1.6404
2025-02-06 18:04:12,945 - INFO - Epoch 160: train_loss=0.9657
2025-02-06 18:04:13,269 - INFO - Epoch 160: val_loss=1.5821, val_acc=33.33%
2025-02-06 18:04:13,273 - INFO - Epoch 160: EPOCH_AVG_TRAIN_LOSS=0.9657
2025-02-06 18:04:13,275 - INFO - #################### Training epoch 161 ####################
2025-02-06 18:04:13,275 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:13,687 - INFO - Epoch 161: train_loss=1.2813
2025-02-06 18:04:13,979 - INFO - Epoch 161: train_loss=1.6152
2025-02-06 18:04:14,303 - INFO - Epoch 161: val_loss=1.5844, val_acc=33.33%
2025-02-06 18:04:14,307 - INFO - Epoch 161: EPOCH_AVG_TRAIN_LOSS=1.2813
2025-02-06 18:04:14,309 - INFO - #################### Training epoch 162 ####################
2025-02-06 18:04:14,309 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:14,716 - INFO - Epoch 162: train_loss=1.2525
2025-02-06 18:04:15,009 - INFO - Epoch 162: train_loss=1.8810
2025-02-06 18:04:15,330 - INFO - Epoch 162: val_loss=1.5666, val_acc=33.33%
2025-02-06 18:04:15,334 - INFO - Epoch 162: EPOCH_AVG_TRAIN_LOSS=1.2525
2025-02-06 18:04:15,337 - INFO - #################### Training epoch 163 ####################
2025-02-06 18:04:15,337 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:15,745 - INFO - Epoch 163: train_loss=1.3139
2025-02-06 18:04:16,038 - INFO - Epoch 163: train_loss=1.6519
2025-02-06 18:04:16,363 - INFO - Epoch 163: val_loss=1.5856, val_acc=33.33%
2025-02-06 18:04:16,367 - INFO - Epoch 163: EPOCH_AVG_TRAIN_LOSS=1.3139
2025-02-06 18:04:16,369 - INFO - #################### Training epoch 164 ####################
2025-02-06 18:04:16,369 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:16,778 - INFO - Epoch 164: train_loss=1.2427
2025-02-06 18:04:17,072 - INFO - Epoch 164: train_loss=1.8473
2025-02-06 18:04:17,394 - INFO - Epoch 164: val_loss=1.5772, val_acc=33.33%
2025-02-06 18:04:17,398 - INFO - Epoch 164: EPOCH_AVG_TRAIN_LOSS=1.2427
2025-02-06 18:04:17,401 - INFO - #################### Training epoch 165 ####################
2025-02-06 18:04:17,401 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:17,810 - INFO - Epoch 165: train_loss=1.4795
2025-02-06 18:04:18,104 - INFO - Epoch 165: train_loss=1.4415
2025-02-06 18:04:18,424 - INFO - Epoch 165: val_loss=1.5920, val_acc=33.33%
2025-02-06 18:04:18,428 - INFO - Epoch 165: EPOCH_AVG_TRAIN_LOSS=1.4415
2025-02-06 18:04:18,430 - INFO - #################### Training epoch 166 ####################
2025-02-06 18:04:18,430 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:18,836 - INFO - Epoch 166: train_loss=1.2471
2025-02-06 18:04:19,128 - INFO - Epoch 166: train_loss=1.7186
2025-02-06 18:04:19,447 - INFO - Epoch 166: val_loss=1.5902, val_acc=33.33%
2025-02-06 18:04:19,451 - INFO - Epoch 166: EPOCH_AVG_TRAIN_LOSS=1.2471
2025-02-06 18:04:19,453 - INFO - #################### Training epoch 167 ####################
2025-02-06 18:04:19,453 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:19,862 - INFO - Epoch 167: train_loss=1.2622
2025-02-06 18:04:20,154 - INFO - Epoch 167: train_loss=1.7920
2025-02-06 18:04:20,473 - INFO - Epoch 167: val_loss=1.5754, val_acc=33.33%
2025-02-06 18:04:20,477 - INFO - Epoch 167: EPOCH_AVG_TRAIN_LOSS=1.2622
2025-02-06 18:04:20,479 - INFO - #################### Training epoch 168 ####################
2025-02-06 18:04:20,479 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:20,888 - INFO - Epoch 168: train_loss=1.4538
2025-02-06 18:04:21,181 - INFO - Epoch 168: train_loss=1.3220
2025-02-06 18:04:21,507 - INFO - Epoch 168: val_loss=1.5983, val_acc=33.33%
2025-02-06 18:04:21,511 - INFO - Epoch 168: EPOCH_AVG_TRAIN_LOSS=1.3220
2025-02-06 18:04:21,514 - INFO - #################### Training epoch 169 ####################
2025-02-06 18:04:21,514 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:21,920 - INFO - Epoch 169: train_loss=1.2499
2025-02-06 18:04:22,212 - INFO - Epoch 169: train_loss=1.6110
2025-02-06 18:04:22,533 - INFO - Epoch 169: val_loss=1.5647, val_acc=33.33%
2025-02-06 18:04:22,537 - INFO - Epoch 169: EPOCH_AVG_TRAIN_LOSS=1.2499
2025-02-06 18:04:22,539 - INFO - #################### Training epoch 170 ####################
2025-02-06 18:04:22,539 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:22,947 - INFO - Epoch 170: train_loss=1.5793
2025-02-06 18:04:23,240 - INFO - Epoch 170: train_loss=1.0642
2025-02-06 18:04:23,563 - INFO - Epoch 170: val_loss=1.5851, val_acc=33.33%
2025-02-06 18:04:23,567 - INFO - Epoch 170: EPOCH_AVG_TRAIN_LOSS=1.0642
2025-02-06 18:04:23,569 - INFO - #################### Training epoch 171 ####################
2025-02-06 18:04:23,569 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:23,977 - INFO - Epoch 171: train_loss=1.4221
2025-02-06 18:04:24,269 - INFO - Epoch 171: train_loss=1.4870
2025-02-06 18:04:24,591 - INFO - Epoch 171: val_loss=1.5917, val_acc=33.33%
2025-02-06 18:04:24,595 - INFO - Epoch 171: EPOCH_AVG_TRAIN_LOSS=1.4221
2025-02-06 18:04:24,597 - INFO - #################### Training epoch 172 ####################
2025-02-06 18:04:24,597 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:25,002 - INFO - Epoch 172: train_loss=1.1426
2025-02-06 18:04:25,294 - INFO - Epoch 172: train_loss=1.9376
2025-02-06 18:04:25,619 - INFO - Epoch 172: val_loss=1.5707, val_acc=33.33%
2025-02-06 18:04:25,622 - INFO - Epoch 172: EPOCH_AVG_TRAIN_LOSS=1.1426
2025-02-06 18:04:25,625 - INFO - #################### Training epoch 173 ####################
2025-02-06 18:04:25,625 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:26,035 - INFO - Epoch 173: train_loss=1.4909
2025-02-06 18:04:26,327 - INFO - Epoch 173: train_loss=1.2449
2025-02-06 18:04:26,651 - INFO - Epoch 173: val_loss=1.5667, val_acc=33.33%
2025-02-06 18:04:26,654 - INFO - Epoch 173: EPOCH_AVG_TRAIN_LOSS=1.2449
2025-02-06 18:04:26,657 - INFO - #################### Training epoch 174 ####################
2025-02-06 18:04:26,657 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:27,066 - INFO - Epoch 174: train_loss=1.6137
2025-02-06 18:04:27,359 - INFO - Epoch 174: train_loss=1.0516
2025-02-06 18:04:27,680 - INFO - Epoch 174: val_loss=1.5891, val_acc=33.33%
2025-02-06 18:04:27,684 - INFO - Epoch 174: EPOCH_AVG_TRAIN_LOSS=1.0516
2025-02-06 18:04:27,686 - INFO - #################### Training epoch 175 ####################
2025-02-06 18:04:27,686 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:28,092 - INFO - Epoch 175: train_loss=1.4691
2025-02-06 18:04:28,385 - INFO - Epoch 175: train_loss=1.2695
2025-02-06 18:04:28,709 - INFO - Epoch 175: val_loss=1.5896, val_acc=33.33%
2025-02-06 18:04:28,712 - INFO - Epoch 175: EPOCH_AVG_TRAIN_LOSS=1.2695
2025-02-06 18:04:28,715 - INFO - #################### Training epoch 176 ####################
2025-02-06 18:04:28,715 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:29,117 - INFO - Epoch 176: train_loss=1.5231
2025-02-06 18:04:29,409 - INFO - Epoch 176: train_loss=1.3136
2025-02-06 18:04:29,734 - INFO - Epoch 176: val_loss=1.5765, val_acc=33.33%
2025-02-06 18:04:29,737 - INFO - Epoch 176: EPOCH_AVG_TRAIN_LOSS=1.3136
2025-02-06 18:04:29,740 - INFO - #################### Training epoch 177 ####################
2025-02-06 18:04:29,740 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:30,148 - INFO - Epoch 177: train_loss=1.2788
2025-02-06 18:04:30,441 - INFO - Epoch 177: train_loss=1.7137
2025-02-06 18:04:30,767 - INFO - Epoch 177: val_loss=1.5772, val_acc=33.33%
2025-02-06 18:04:30,771 - INFO - Epoch 177: EPOCH_AVG_TRAIN_LOSS=1.2788
2025-02-06 18:04:30,773 - INFO - #################### Training epoch 178 ####################
2025-02-06 18:04:30,773 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:31,180 - INFO - Epoch 178: train_loss=1.3196
2025-02-06 18:04:31,473 - INFO - Epoch 178: train_loss=1.5886
2025-02-06 18:04:31,800 - INFO - Epoch 178: val_loss=1.5955, val_acc=33.33%
2025-02-06 18:04:31,804 - INFO - Epoch 178: EPOCH_AVG_TRAIN_LOSS=1.3196
2025-02-06 18:04:31,806 - INFO - #################### Training epoch 179 ####################
2025-02-06 18:04:31,806 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:32,214 - INFO - Epoch 179: train_loss=1.1281
2025-02-06 18:04:32,506 - INFO - Epoch 179: train_loss=1.9419
2025-02-06 18:04:32,829 - INFO - Epoch 179: val_loss=1.5789, val_acc=33.33%
2025-02-06 18:04:32,832 - INFO - Epoch 179: EPOCH_AVG_TRAIN_LOSS=1.1281
2025-02-06 18:04:32,834 - INFO - #################### Training epoch 180 ####################
2025-02-06 18:04:32,834 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:33,240 - INFO - Epoch 180: train_loss=1.6400
2025-02-06 18:04:33,532 - INFO - Epoch 180: train_loss=0.9791
2025-02-06 18:04:33,855 - INFO - Epoch 180: val_loss=1.5820, val_acc=33.33%
2025-02-06 18:04:33,859 - INFO - Epoch 180: EPOCH_AVG_TRAIN_LOSS=0.9791
2025-02-06 18:04:33,861 - INFO - #################### Training epoch 181 ####################
2025-02-06 18:04:33,861 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:34,271 - INFO - Epoch 181: train_loss=1.3503
2025-02-06 18:04:34,563 - INFO - Epoch 181: train_loss=1.5153
2025-02-06 18:04:34,881 - INFO - Epoch 181: val_loss=1.5737, val_acc=33.33%
2025-02-06 18:04:34,884 - INFO - Epoch 181: EPOCH_AVG_TRAIN_LOSS=1.3503
2025-02-06 18:04:34,887 - INFO - #################### Training epoch 182 ####################
2025-02-06 18:04:34,887 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:35,292 - INFO - Epoch 182: train_loss=1.3011
2025-02-06 18:04:35,584 - INFO - Epoch 182: train_loss=1.6344
2025-02-06 18:04:35,908 - INFO - Epoch 182: val_loss=1.5805, val_acc=33.33%
2025-02-06 18:04:35,911 - INFO - Epoch 182: EPOCH_AVG_TRAIN_LOSS=1.3011
2025-02-06 18:04:35,914 - INFO - #################### Training epoch 183 ####################
2025-02-06 18:04:35,914 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:36,324 - INFO - Epoch 183: train_loss=1.3474
2025-02-06 18:04:36,617 - INFO - Epoch 183: train_loss=1.5104
2025-02-06 18:04:36,942 - INFO - Epoch 183: val_loss=1.5862, val_acc=33.33%
2025-02-06 18:04:36,946 - INFO - Epoch 183: EPOCH_AVG_TRAIN_LOSS=1.3474
2025-02-06 18:04:36,948 - INFO - #################### Training epoch 184 ####################
2025-02-06 18:04:36,948 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:37,356 - INFO - Epoch 184: train_loss=1.3976
2025-02-06 18:04:37,648 - INFO - Epoch 184: train_loss=1.5560
2025-02-06 18:04:37,971 - INFO - Epoch 184: val_loss=1.5958, val_acc=33.33%
2025-02-06 18:04:37,975 - INFO - Epoch 184: EPOCH_AVG_TRAIN_LOSS=1.3976
2025-02-06 18:04:37,977 - INFO - #################### Training epoch 185 ####################
2025-02-06 18:04:37,977 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:38,385 - INFO - Epoch 185: train_loss=1.6892
2025-02-06 18:04:38,677 - INFO - Epoch 185: train_loss=0.9999
2025-02-06 18:04:39,003 - INFO - Epoch 185: val_loss=1.5810, val_acc=33.33%
2025-02-06 18:04:39,007 - INFO - Epoch 185: EPOCH_AVG_TRAIN_LOSS=0.9999
2025-02-06 18:04:39,009 - INFO - #################### Training epoch 186 ####################
2025-02-06 18:04:39,009 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:39,418 - INFO - Epoch 186: train_loss=1.5594
2025-02-06 18:04:39,710 - INFO - Epoch 186: train_loss=1.2025
2025-02-06 18:04:40,035 - INFO - Epoch 186: val_loss=1.5630, val_acc=33.33%
2025-02-06 18:04:40,038 - INFO - Epoch 186: EPOCH_AVG_TRAIN_LOSS=1.2025
2025-02-06 18:04:40,041 - INFO - #################### Training epoch 187 ####################
2025-02-06 18:04:40,041 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:40,445 - INFO - Epoch 187: train_loss=1.3072
2025-02-06 18:04:40,737 - INFO - Epoch 187: train_loss=1.6169
2025-02-06 18:04:41,059 - INFO - Epoch 187: val_loss=1.5567, val_acc=33.33%
2025-02-06 18:04:41,063 - INFO - Epoch 187: EPOCH_AVG_TRAIN_LOSS=1.3072
2025-02-06 18:04:41,065 - INFO - #################### Training epoch 188 ####################
2025-02-06 18:04:41,065 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:41,471 - INFO - Epoch 188: train_loss=1.2655
2025-02-06 18:04:41,763 - INFO - Epoch 188: train_loss=1.8078
2025-02-06 18:04:42,088 - INFO - Epoch 188: val_loss=1.5788, val_acc=33.33%
2025-02-06 18:04:42,092 - INFO - Epoch 188: EPOCH_AVG_TRAIN_LOSS=1.2655
2025-02-06 18:04:42,094 - INFO - #################### Training epoch 189 ####################
2025-02-06 18:04:42,094 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:42,503 - INFO - Epoch 189: train_loss=1.3696
2025-02-06 18:04:42,795 - INFO - Epoch 189: train_loss=1.4852
2025-02-06 18:04:43,115 - INFO - Epoch 189: val_loss=1.5757, val_acc=33.33%
2025-02-06 18:04:43,119 - INFO - Epoch 189: EPOCH_AVG_TRAIN_LOSS=1.3696
2025-02-06 18:04:43,121 - INFO - #################### Training epoch 190 ####################
2025-02-06 18:04:43,121 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:43,531 - INFO - Epoch 190: train_loss=1.5563
2025-02-06 18:04:43,823 - INFO - Epoch 190: train_loss=1.0858
2025-02-06 18:04:44,148 - INFO - Epoch 190: val_loss=1.5770, val_acc=33.33%
2025-02-06 18:04:44,152 - INFO - Epoch 190: EPOCH_AVG_TRAIN_LOSS=1.0858
2025-02-06 18:04:44,154 - INFO - #################### Training epoch 191 ####################
2025-02-06 18:04:44,154 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:44,562 - INFO - Epoch 191: train_loss=1.7219
2025-02-06 18:04:44,854 - INFO - Epoch 191: train_loss=0.8649
2025-02-06 18:04:45,175 - INFO - Epoch 191: val_loss=1.5817, val_acc=33.33%
2025-02-06 18:04:45,179 - INFO - Epoch 191: EPOCH_AVG_TRAIN_LOSS=0.8649
2025-02-06 18:04:45,181 - INFO - #################### Training epoch 192 ####################
2025-02-06 18:04:45,181 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:45,589 - INFO - Epoch 192: train_loss=1.4309
2025-02-06 18:04:45,880 - INFO - Epoch 192: train_loss=1.4201
2025-02-06 18:04:46,205 - INFO - Epoch 192: val_loss=1.5817, val_acc=33.33%
2025-02-06 18:04:46,209 - INFO - Epoch 192: EPOCH_AVG_TRAIN_LOSS=1.4201
2025-02-06 18:04:46,211 - INFO - #################### Training epoch 193 ####################
2025-02-06 18:04:46,211 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:46,619 - INFO - Epoch 193: train_loss=1.5660
2025-02-06 18:04:46,911 - INFO - Epoch 193: train_loss=1.2710
2025-02-06 18:04:47,232 - INFO - Epoch 193: val_loss=1.5731, val_acc=33.33%
2025-02-06 18:04:47,235 - INFO - Epoch 193: EPOCH_AVG_TRAIN_LOSS=1.2710
2025-02-06 18:04:47,238 - INFO - #################### Training epoch 194 ####################
2025-02-06 18:04:47,238 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:47,647 - INFO - Epoch 194: train_loss=1.2182
2025-02-06 18:04:47,938 - INFO - Epoch 194: train_loss=1.8396
2025-02-06 18:04:48,263 - INFO - Epoch 194: val_loss=1.5755, val_acc=33.33%
2025-02-06 18:04:48,267 - INFO - Epoch 194: EPOCH_AVG_TRAIN_LOSS=1.2182
2025-02-06 18:04:48,269 - INFO - #################### Training epoch 195 ####################
2025-02-06 18:04:48,269 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:48,676 - INFO - Epoch 195: train_loss=1.5491
2025-02-06 18:04:48,967 - INFO - Epoch 195: train_loss=1.2792
2025-02-06 18:04:49,292 - INFO - Epoch 195: val_loss=1.5851, val_acc=33.33%
2025-02-06 18:04:49,296 - INFO - Epoch 195: EPOCH_AVG_TRAIN_LOSS=1.2792
2025-02-06 18:04:49,298 - INFO - #################### Training epoch 196 ####################
2025-02-06 18:04:49,298 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:49,706 - INFO - Epoch 196: train_loss=1.4532
2025-02-06 18:04:49,998 - INFO - Epoch 196: train_loss=1.3532
2025-02-06 18:04:50,322 - INFO - Epoch 196: val_loss=1.5928, val_acc=33.33%
2025-02-06 18:04:50,326 - INFO - Epoch 196: EPOCH_AVG_TRAIN_LOSS=1.3532
2025-02-06 18:04:50,328 - INFO - #################### Training epoch 197 ####################
2025-02-06 18:04:50,328 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:50,737 - INFO - Epoch 197: train_loss=1.2003
2025-02-06 18:04:51,030 - INFO - Epoch 197: train_loss=1.8759
2025-02-06 18:04:51,356 - INFO - Epoch 197: val_loss=1.5787, val_acc=33.33%
2025-02-06 18:04:51,359 - INFO - Epoch 197: EPOCH_AVG_TRAIN_LOSS=1.2003
2025-02-06 18:04:51,362 - INFO - #################### Training epoch 198 ####################
2025-02-06 18:04:51,362 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:51,770 - INFO - Epoch 198: train_loss=1.3411
2025-02-06 18:04:52,062 - INFO - Epoch 198: train_loss=1.6189
2025-02-06 18:04:52,383 - INFO - Epoch 198: val_loss=1.5936, val_acc=33.33%
2025-02-06 18:04:52,387 - INFO - Epoch 198: EPOCH_AVG_TRAIN_LOSS=1.3411
2025-02-06 18:04:52,389 - INFO - #################### Training epoch 199 ####################
2025-02-06 18:04:52,389 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:04:52,793 - INFO - Epoch 199: train_loss=1.3256
2025-02-06 18:04:53,085 - INFO - Epoch 199: train_loss=1.6207
2025-02-06 18:04:53,409 - INFO - Epoch 199: val_loss=1.5868, val_acc=33.33%
2025-02-06 18:04:53,412 - INFO - Epoch 199: EPOCH_AVG_TRAIN_LOSS=1.3256
2025-02-06 18:04:53,584 - INFO - Model saved.
