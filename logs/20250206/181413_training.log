2025-02-06 18:14:23,248 - INFO - Starting training with the following parameters:
2025-02-06 18:14:23,249 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product|
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.001          |
| epochs          | 200            |
| batch_size      | 16             |

2025-02-06 18:14:23,858 - INFO - Epoch 0: val_loss=1.2144, val_acc=0.00%
2025-02-06 18:14:24,007 - INFO - #################### Training epoch 0 ####################
2025-02-06 18:14:24,007 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:24,251 - INFO - Epoch 0: train_loss=1.1016
2025-02-06 18:14:24,607 - INFO - Epoch 0: train_loss=1.2966
2025-02-06 18:14:24,916 - INFO - Epoch 0: val_loss=1.0884, val_acc=33.33%
2025-02-06 18:14:24,932 - INFO - Epoch 0: EPOCH_AVG_TRAIN_LOSS=1.1016
2025-02-06 18:14:24,961 - INFO - #################### Training epoch 1 ####################
2025-02-06 18:14:24,961 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:25,375 - INFO - Epoch 1: train_loss=1.0824
2025-02-06 18:14:25,666 - INFO - Epoch 1: train_loss=1.0268
2025-02-06 18:14:25,995 - INFO - Epoch 1: val_loss=1.0666, val_acc=66.67%
2025-02-06 18:14:25,998 - INFO - Epoch 1: EPOCH_AVG_TRAIN_LOSS=1.0268
2025-02-06 18:14:26,024 - INFO - #################### Training epoch 2 ####################
2025-02-06 18:14:26,024 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:26,444 - INFO - Epoch 2: train_loss=1.0398
2025-02-06 18:14:26,734 - INFO - Epoch 2: train_loss=1.0679
2025-02-06 18:14:27,069 - INFO - Epoch 2: val_loss=1.1225, val_acc=0.00%
2025-02-06 18:14:27,073 - INFO - Epoch 2: EPOCH_AVG_TRAIN_LOSS=1.0398
2025-02-06 18:14:27,099 - INFO - #################### Training epoch 3 ####################
2025-02-06 18:14:27,099 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:27,519 - INFO - Epoch 3: train_loss=0.9617
2025-02-06 18:14:27,810 - INFO - Epoch 3: train_loss=0.9732
2025-02-06 18:14:28,141 - INFO - Epoch 3: val_loss=1.0754, val_acc=0.00%
2025-02-06 18:14:28,144 - INFO - Epoch 3: EPOCH_AVG_TRAIN_LOSS=0.9617
2025-02-06 18:14:28,172 - INFO - #################### Training epoch 4 ####################
2025-02-06 18:14:28,172 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:28,591 - INFO - Epoch 4: train_loss=0.9533
2025-02-06 18:14:28,882 - INFO - Epoch 4: train_loss=1.0371
2025-02-06 18:14:29,220 - INFO - Epoch 4: val_loss=1.0267, val_acc=33.33%
2025-02-06 18:14:29,224 - INFO - Epoch 4: EPOCH_AVG_TRAIN_LOSS=0.9533
2025-02-06 18:14:29,251 - INFO - #################### Training epoch 5 ####################
2025-02-06 18:14:29,251 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:29,668 - INFO - Epoch 5: train_loss=1.0012
2025-02-06 18:14:29,959 - INFO - Epoch 5: train_loss=0.9168
2025-02-06 18:14:30,295 - INFO - Epoch 5: val_loss=1.1399, val_acc=0.00%
2025-02-06 18:14:30,299 - INFO - Epoch 5: EPOCH_AVG_TRAIN_LOSS=0.9168
2025-02-06 18:14:30,301 - INFO - #################### Training epoch 6 ####################
2025-02-06 18:14:30,301 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:30,720 - INFO - Epoch 6: train_loss=0.8969
2025-02-06 18:14:31,011 - INFO - Epoch 6: train_loss=1.0021
2025-02-06 18:14:31,352 - INFO - Epoch 6: val_loss=1.2862, val_acc=0.00%
2025-02-06 18:14:31,355 - INFO - Epoch 6: EPOCH_AVG_TRAIN_LOSS=0.8969
2025-02-06 18:14:31,358 - INFO - #################### Training epoch 7 ####################
2025-02-06 18:14:31,358 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:31,778 - INFO - Epoch 7: train_loss=0.8996
2025-02-06 18:14:32,069 - INFO - Epoch 7: train_loss=0.9452
2025-02-06 18:14:32,405 - INFO - Epoch 7: val_loss=1.1565, val_acc=0.00%
2025-02-06 18:14:32,409 - INFO - Epoch 7: EPOCH_AVG_TRAIN_LOSS=0.8996
2025-02-06 18:14:32,411 - INFO - #################### Training epoch 8 ####################
2025-02-06 18:14:32,411 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:32,831 - INFO - Epoch 8: train_loss=1.0107
2025-02-06 18:14:33,122 - INFO - Epoch 8: train_loss=0.6578
2025-02-06 18:14:33,455 - INFO - Epoch 8: val_loss=1.1407, val_acc=33.33%
2025-02-06 18:14:33,459 - INFO - Epoch 8: EPOCH_AVG_TRAIN_LOSS=0.6578
2025-02-06 18:14:33,461 - INFO - #################### Training epoch 9 ####################
2025-02-06 18:14:33,461 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:33,882 - INFO - Epoch 9: train_loss=0.8759
2025-02-06 18:14:34,172 - INFO - Epoch 9: train_loss=0.9606
2025-02-06 18:14:34,513 - INFO - Epoch 9: val_loss=1.1458, val_acc=0.00%
2025-02-06 18:14:34,517 - INFO - Epoch 9: EPOCH_AVG_TRAIN_LOSS=0.8759
2025-02-06 18:14:34,519 - INFO - #################### Training epoch 10 ####################
2025-02-06 18:14:34,519 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:34,938 - INFO - Epoch 10: train_loss=0.8499
2025-02-06 18:14:35,229 - INFO - Epoch 10: train_loss=0.7897
2025-02-06 18:14:35,567 - INFO - Epoch 10: val_loss=1.2759, val_acc=0.00%
2025-02-06 18:14:35,571 - INFO - Epoch 10: EPOCH_AVG_TRAIN_LOSS=0.7897
2025-02-06 18:14:35,573 - INFO - #################### Training epoch 11 ####################
2025-02-06 18:14:35,573 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:35,992 - INFO - Epoch 11: train_loss=0.8575
2025-02-06 18:14:36,282 - INFO - Epoch 11: train_loss=0.6661
2025-02-06 18:14:36,622 - INFO - Epoch 11: val_loss=1.3071, val_acc=33.33%
2025-02-06 18:14:36,625 - INFO - Epoch 11: EPOCH_AVG_TRAIN_LOSS=0.6661
2025-02-06 18:14:36,627 - INFO - #################### Training epoch 12 ####################
2025-02-06 18:14:36,627 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:37,044 - INFO - Epoch 12: train_loss=0.7562
2025-02-06 18:14:37,336 - INFO - Epoch 12: train_loss=0.9652
2025-02-06 18:14:37,672 - INFO - Epoch 12: val_loss=1.3188, val_acc=33.33%
2025-02-06 18:14:37,675 - INFO - Epoch 12: EPOCH_AVG_TRAIN_LOSS=0.7562
2025-02-06 18:14:37,677 - INFO - #################### Training epoch 13 ####################
2025-02-06 18:14:37,678 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:38,096 - INFO - Epoch 13: train_loss=0.8610
2025-02-06 18:14:38,387 - INFO - Epoch 13: train_loss=0.6332
2025-02-06 18:14:38,722 - INFO - Epoch 13: val_loss=1.2459, val_acc=33.33%
2025-02-06 18:14:38,725 - INFO - Epoch 13: EPOCH_AVG_TRAIN_LOSS=0.6332
2025-02-06 18:14:38,727 - INFO - #################### Training epoch 14 ####################
2025-02-06 18:14:38,728 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:39,148 - INFO - Epoch 14: train_loss=0.6972
2025-02-06 18:14:39,439 - INFO - Epoch 14: train_loss=0.8901
2025-02-06 18:14:39,775 - INFO - Epoch 14: val_loss=1.1818, val_acc=33.33%
2025-02-06 18:14:39,779 - INFO - Epoch 14: EPOCH_AVG_TRAIN_LOSS=0.6972
2025-02-06 18:14:39,781 - INFO - #################### Training epoch 15 ####################
2025-02-06 18:14:39,781 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:40,206 - INFO - Epoch 15: train_loss=0.8144
2025-02-06 18:14:40,498 - INFO - Epoch 15: train_loss=0.4108
2025-02-06 18:14:40,828 - INFO - Epoch 15: val_loss=1.2208, val_acc=33.33%
2025-02-06 18:14:40,832 - INFO - Epoch 15: EPOCH_AVG_TRAIN_LOSS=0.4108
2025-02-06 18:14:40,834 - INFO - #################### Training epoch 16 ####################
2025-02-06 18:14:40,834 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:41,255 - INFO - Epoch 16: train_loss=0.6880
2025-02-06 18:14:41,547 - INFO - Epoch 16: train_loss=0.7655
2025-02-06 18:14:41,881 - INFO - Epoch 16: val_loss=1.2159, val_acc=33.33%
2025-02-06 18:14:41,884 - INFO - Epoch 16: EPOCH_AVG_TRAIN_LOSS=0.6880
2025-02-06 18:14:41,886 - INFO - #################### Training epoch 17 ####################
2025-02-06 18:14:41,886 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:42,308 - INFO - Epoch 17: train_loss=0.6426
2025-02-06 18:14:42,599 - INFO - Epoch 17: train_loss=0.9190
2025-02-06 18:14:42,933 - INFO - Epoch 17: val_loss=1.2254, val_acc=33.33%
2025-02-06 18:14:42,937 - INFO - Epoch 17: EPOCH_AVG_TRAIN_LOSS=0.6426
2025-02-06 18:14:42,939 - INFO - #################### Training epoch 18 ####################
2025-02-06 18:14:42,939 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:43,358 - INFO - Epoch 18: train_loss=0.8324
2025-02-06 18:14:43,650 - INFO - Epoch 18: train_loss=0.5562
2025-02-06 18:14:43,982 - INFO - Epoch 18: val_loss=1.2424, val_acc=33.33%
2025-02-06 18:14:43,986 - INFO - Epoch 18: EPOCH_AVG_TRAIN_LOSS=0.5562
2025-02-06 18:14:43,988 - INFO - #################### Training epoch 19 ####################
2025-02-06 18:14:43,988 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:44,408 - INFO - Epoch 19: train_loss=0.7853
2025-02-06 18:14:44,699 - INFO - Epoch 19: train_loss=0.6323
2025-02-06 18:14:45,032 - INFO - Epoch 19: val_loss=1.2451, val_acc=33.33%
2025-02-06 18:14:45,036 - INFO - Epoch 19: EPOCH_AVG_TRAIN_LOSS=0.6323
2025-02-06 18:14:45,038 - INFO - #################### Training epoch 20 ####################
2025-02-06 18:14:45,038 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:45,456 - INFO - Epoch 20: train_loss=1.0092
2025-02-06 18:14:45,748 - INFO - Epoch 20: train_loss=0.2613
2025-02-06 18:14:46,079 - INFO - Epoch 20: val_loss=1.2500, val_acc=33.33%
2025-02-06 18:14:46,083 - INFO - Epoch 20: EPOCH_AVG_TRAIN_LOSS=0.2613
2025-02-06 18:14:46,085 - INFO - #################### Training epoch 21 ####################
2025-02-06 18:14:46,085 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:46,506 - INFO - Epoch 21: train_loss=0.6326
2025-02-06 18:14:46,797 - INFO - Epoch 21: train_loss=0.9502
2025-02-06 18:14:47,128 - INFO - Epoch 21: val_loss=1.2599, val_acc=33.33%
2025-02-06 18:14:47,132 - INFO - Epoch 21: EPOCH_AVG_TRAIN_LOSS=0.6326
2025-02-06 18:14:47,134 - INFO - #################### Training epoch 22 ####################
2025-02-06 18:14:47,134 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:47,553 - INFO - Epoch 22: train_loss=0.9324
2025-02-06 18:14:47,845 - INFO - Epoch 22: train_loss=0.3933
2025-02-06 18:14:48,175 - INFO - Epoch 22: val_loss=1.2807, val_acc=33.33%
2025-02-06 18:14:48,179 - INFO - Epoch 22: EPOCH_AVG_TRAIN_LOSS=0.3933
2025-02-06 18:14:48,181 - INFO - #################### Training epoch 23 ####################
2025-02-06 18:14:48,181 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:48,602 - INFO - Epoch 23: train_loss=0.8536
2025-02-06 18:14:48,894 - INFO - Epoch 23: train_loss=0.5296
2025-02-06 18:14:49,230 - INFO - Epoch 23: val_loss=1.2786, val_acc=33.33%
2025-02-06 18:14:49,233 - INFO - Epoch 23: EPOCH_AVG_TRAIN_LOSS=0.5296
2025-02-06 18:14:49,236 - INFO - #################### Training epoch 24 ####################
2025-02-06 18:14:49,236 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:49,656 - INFO - Epoch 24: train_loss=0.8446
2025-02-06 18:14:49,947 - INFO - Epoch 24: train_loss=0.6006
2025-02-06 18:14:50,280 - INFO - Epoch 24: val_loss=1.2831, val_acc=33.33%
2025-02-06 18:14:50,284 - INFO - Epoch 24: EPOCH_AVG_TRAIN_LOSS=0.6006
2025-02-06 18:14:50,286 - INFO - #################### Training epoch 25 ####################
2025-02-06 18:14:50,286 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:50,702 - INFO - Epoch 25: train_loss=0.6089
2025-02-06 18:14:50,994 - INFO - Epoch 25: train_loss=0.9882
2025-02-06 18:14:51,332 - INFO - Epoch 25: val_loss=1.3070, val_acc=33.33%
2025-02-06 18:14:51,336 - INFO - Epoch 25: EPOCH_AVG_TRAIN_LOSS=0.6089
2025-02-06 18:14:51,338 - INFO - #################### Training epoch 26 ####################
2025-02-06 18:14:51,338 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:51,751 - INFO - Epoch 26: train_loss=0.8135
2025-02-06 18:14:52,043 - INFO - Epoch 26: train_loss=0.6546
2025-02-06 18:14:52,375 - INFO - Epoch 26: val_loss=1.3133, val_acc=33.33%
2025-02-06 18:14:52,379 - INFO - Epoch 26: EPOCH_AVG_TRAIN_LOSS=0.6546
2025-02-06 18:14:52,381 - INFO - #################### Training epoch 27 ####################
2025-02-06 18:14:52,381 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:52,800 - INFO - Epoch 27: train_loss=0.7942
2025-02-06 18:14:53,092 - INFO - Epoch 27: train_loss=0.7321
2025-02-06 18:14:53,423 - INFO - Epoch 27: val_loss=1.3338, val_acc=33.33%
2025-02-06 18:14:53,427 - INFO - Epoch 27: EPOCH_AVG_TRAIN_LOSS=0.7321
2025-02-06 18:14:53,429 - INFO - #################### Training epoch 28 ####################
2025-02-06 18:14:53,429 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:53,847 - INFO - Epoch 28: train_loss=0.9122
2025-02-06 18:14:54,138 - INFO - Epoch 28: train_loss=0.4508
2025-02-06 18:14:54,473 - INFO - Epoch 28: val_loss=1.3349, val_acc=33.33%
2025-02-06 18:14:54,477 - INFO - Epoch 28: EPOCH_AVG_TRAIN_LOSS=0.4508
2025-02-06 18:14:54,479 - INFO - #################### Training epoch 29 ####################
2025-02-06 18:14:54,479 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:54,896 - INFO - Epoch 29: train_loss=0.7458
2025-02-06 18:14:55,188 - INFO - Epoch 29: train_loss=0.8094
2025-02-06 18:14:55,516 - INFO - Epoch 29: val_loss=1.3452, val_acc=33.33%
2025-02-06 18:14:55,520 - INFO - Epoch 29: EPOCH_AVG_TRAIN_LOSS=0.7458
2025-02-06 18:14:55,522 - INFO - #################### Training epoch 30 ####################
2025-02-06 18:14:55,522 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:55,940 - INFO - Epoch 30: train_loss=0.5820
2025-02-06 18:14:56,231 - INFO - Epoch 30: train_loss=1.2343
2025-02-06 18:14:56,564 - INFO - Epoch 30: val_loss=1.3470, val_acc=33.33%
2025-02-06 18:14:56,567 - INFO - Epoch 30: EPOCH_AVG_TRAIN_LOSS=0.5820
2025-02-06 18:14:56,570 - INFO - #################### Training epoch 31 ####################
2025-02-06 18:14:56,570 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:56,987 - INFO - Epoch 31: train_loss=0.9843
2025-02-06 18:14:57,279 - INFO - Epoch 31: train_loss=0.4495
2025-02-06 18:14:57,615 - INFO - Epoch 31: val_loss=1.3540, val_acc=33.33%
2025-02-06 18:14:57,619 - INFO - Epoch 31: EPOCH_AVG_TRAIN_LOSS=0.4495
2025-02-06 18:14:57,621 - INFO - #################### Training epoch 32 ####################
2025-02-06 18:14:57,621 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:58,040 - INFO - Epoch 32: train_loss=0.8601
2025-02-06 18:14:58,332 - INFO - Epoch 32: train_loss=0.7723
2025-02-06 18:14:58,668 - INFO - Epoch 32: val_loss=1.3828, val_acc=33.33%
2025-02-06 18:14:58,671 - INFO - Epoch 32: EPOCH_AVG_TRAIN_LOSS=0.7723
2025-02-06 18:14:58,674 - INFO - #################### Training epoch 33 ####################
2025-02-06 18:14:58,674 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:14:59,091 - INFO - Epoch 33: train_loss=0.5833
2025-02-06 18:14:59,383 - INFO - Epoch 33: train_loss=1.2848
2025-02-06 18:14:59,712 - INFO - Epoch 33: val_loss=1.3804, val_acc=33.33%
2025-02-06 18:14:59,716 - INFO - Epoch 33: EPOCH_AVG_TRAIN_LOSS=0.5833
2025-02-06 18:14:59,718 - INFO - #################### Training epoch 34 ####################
2025-02-06 18:14:59,718 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:15:00,133 - INFO - Epoch 34: train_loss=0.5228
2025-02-06 18:15:00,425 - INFO - Epoch 34: train_loss=1.4028
2025-02-06 18:15:00,756 - INFO - Epoch 34: val_loss=1.3872, val_acc=33.33%
2025-02-06 18:15:00,760 - INFO - Epoch 34: EPOCH_AVG_TRAIN_LOSS=0.5228
2025-02-06 18:15:00,762 - INFO - #################### Training epoch 35 ####################
2025-02-06 18:15:00,762 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:15:01,180 - INFO - Epoch 35: train_loss=0.8879
2025-02-06 18:15:01,472 - INFO - Epoch 35: train_loss=0.7319
2025-02-06 18:15:01,805 - INFO - Epoch 35: val_loss=1.3931, val_acc=33.33%
2025-02-06 18:15:01,809 - INFO - Epoch 35: EPOCH_AVG_TRAIN_LOSS=0.7319
2025-02-06 18:15:01,812 - INFO - #################### Training epoch 36 ####################
2025-02-06 18:15:01,812 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:15:02,230 - INFO - Epoch 36: train_loss=0.9756
2025-02-06 18:15:02,522 - INFO - Epoch 36: train_loss=0.5005
2025-02-06 18:15:02,856 - INFO - Epoch 36: val_loss=1.3861, val_acc=33.33%
2025-02-06 18:15:02,860 - INFO - Epoch 36: EPOCH_AVG_TRAIN_LOSS=0.5005
2025-02-06 18:15:02,862 - INFO - #################### Training epoch 37 ####################
2025-02-06 18:15:02,862 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:15:03,278 - INFO - Epoch 37: train_loss=0.6801
2025-02-06 18:15:03,570 - INFO - Epoch 37: train_loss=1.0900
2025-02-06 18:15:03,901 - INFO - Epoch 37: val_loss=1.3940, val_acc=33.33%
2025-02-06 18:15:03,905 - INFO - Epoch 37: EPOCH_AVG_TRAIN_LOSS=0.6801
2025-02-06 18:15:03,907 - INFO - #################### Training epoch 38 ####################
2025-02-06 18:15:03,907 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:15:04,322 - INFO - Epoch 38: train_loss=0.8703
2025-02-06 18:15:04,613 - INFO - Epoch 38: train_loss=0.6748
2025-02-06 18:15:04,948 - INFO - Epoch 38: val_loss=1.3931, val_acc=33.33%
2025-02-06 18:15:04,952 - INFO - Epoch 38: EPOCH_AVG_TRAIN_LOSS=0.6748
2025-02-06 18:15:04,954 - INFO - #################### Training epoch 39 ####################
2025-02-06 18:15:04,954 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:15:05,372 - INFO - Epoch 39: train_loss=0.9059
2025-02-06 18:15:05,665 - INFO - Epoch 39: train_loss=0.5986
2025-02-06 18:15:05,997 - INFO - Epoch 39: val_loss=1.4030, val_acc=33.33%
2025-02-06 18:15:06,001 - INFO - Epoch 39: EPOCH_AVG_TRAIN_LOSS=0.5986
2025-02-06 18:15:06,003 - INFO - #################### Training epoch 40 ####################
2025-02-06 18:15:06,003 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:15:06,421 - INFO - Epoch 40: train_loss=0.7617
2025-02-06 18:15:06,712 - INFO - Epoch 40: train_loss=0.9306
2025-02-06 18:15:07,044 - INFO - Epoch 40: val_loss=1.4139, val_acc=33.33%
2025-02-06 18:15:07,047 - INFO - Epoch 40: EPOCH_AVG_TRAIN_LOSS=0.7617
2025-02-06 18:15:07,050 - INFO - #################### Training epoch 41 ####################
2025-02-06 18:15:07,050 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:15:07,465 - INFO - Epoch 41: train_loss=0.8133
2025-02-06 18:15:07,756 - INFO - Epoch 41: train_loss=0.7408
2025-02-06 18:15:08,086 - INFO - Epoch 41: val_loss=1.4227, val_acc=33.33%
2025-02-06 18:15:08,090 - INFO - Epoch 41: EPOCH_AVG_TRAIN_LOSS=0.7408
2025-02-06 18:15:08,093 - INFO - #################### Training epoch 42 ####################
2025-02-06 18:15:08,093 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:08,512 - INFO - Epoch 42: train_loss=0.9909
2025-02-06 18:15:08,804 - INFO - Epoch 42: train_loss=0.4974
2025-02-06 18:15:09,132 - INFO - Epoch 42: val_loss=1.4297, val_acc=33.33%
2025-02-06 18:15:09,135 - INFO - Epoch 42: EPOCH_AVG_TRAIN_LOSS=0.4974
2025-02-06 18:15:09,137 - INFO - #################### Training epoch 43 ####################
2025-02-06 18:15:09,137 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:09,558 - INFO - Epoch 43: train_loss=0.8672
2025-02-06 18:15:09,850 - INFO - Epoch 43: train_loss=0.6880
2025-02-06 18:15:10,182 - INFO - Epoch 43: val_loss=1.4237, val_acc=33.33%
2025-02-06 18:15:10,185 - INFO - Epoch 43: EPOCH_AVG_TRAIN_LOSS=0.6880
2025-02-06 18:15:10,187 - INFO - #################### Training epoch 44 ####################
2025-02-06 18:15:10,187 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:10,599 - INFO - Epoch 44: train_loss=0.9488
2025-02-06 18:15:10,890 - INFO - Epoch 44: train_loss=0.5329
2025-02-06 18:15:11,222 - INFO - Epoch 44: val_loss=1.4303, val_acc=33.33%
2025-02-06 18:15:11,226 - INFO - Epoch 44: EPOCH_AVG_TRAIN_LOSS=0.5329
2025-02-06 18:15:11,228 - INFO - #################### Training epoch 45 ####################
2025-02-06 18:15:11,228 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:11,648 - INFO - Epoch 45: train_loss=0.9613
2025-02-06 18:15:11,939 - INFO - Epoch 45: train_loss=0.4585
2025-02-06 18:15:12,273 - INFO - Epoch 45: val_loss=1.4291, val_acc=33.33%
2025-02-06 18:15:12,277 - INFO - Epoch 45: EPOCH_AVG_TRAIN_LOSS=0.4585
2025-02-06 18:15:12,279 - INFO - #################### Training epoch 46 ####################
2025-02-06 18:15:12,279 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:12,695 - INFO - Epoch 46: train_loss=0.8760
2025-02-06 18:15:12,988 - INFO - Epoch 46: train_loss=0.5586
2025-02-06 18:15:13,321 - INFO - Epoch 46: val_loss=1.4393, val_acc=33.33%
2025-02-06 18:15:13,324 - INFO - Epoch 46: EPOCH_AVG_TRAIN_LOSS=0.5586
2025-02-06 18:15:13,327 - INFO - #################### Training epoch 47 ####################
2025-02-06 18:15:13,327 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:13,744 - INFO - Epoch 47: train_loss=0.9230
2025-02-06 18:15:14,036 - INFO - Epoch 47: train_loss=0.4865
2025-02-06 18:15:14,371 - INFO - Epoch 47: val_loss=1.4276, val_acc=33.33%
2025-02-06 18:15:14,375 - INFO - Epoch 47: EPOCH_AVG_TRAIN_LOSS=0.4865
2025-02-06 18:15:14,377 - INFO - #################### Training epoch 48 ####################
2025-02-06 18:15:14,377 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:14,794 - INFO - Epoch 48: train_loss=0.6519
2025-02-06 18:15:15,087 - INFO - Epoch 48: train_loss=0.9003
2025-02-06 18:15:15,420 - INFO - Epoch 48: val_loss=1.4292, val_acc=33.33%
2025-02-06 18:15:15,423 - INFO - Epoch 48: EPOCH_AVG_TRAIN_LOSS=0.6519
2025-02-06 18:15:15,426 - INFO - #################### Training epoch 49 ####################
2025-02-06 18:15:15,426 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:15,843 - INFO - Epoch 49: train_loss=0.7454
2025-02-06 18:15:16,135 - INFO - Epoch 49: train_loss=0.7602
2025-02-06 18:15:16,472 - INFO - Epoch 49: val_loss=1.4303, val_acc=33.33%
2025-02-06 18:15:16,476 - INFO - Epoch 49: EPOCH_AVG_TRAIN_LOSS=0.7454
2025-02-06 18:15:16,478 - INFO - #################### Training epoch 50 ####################
2025-02-06 18:15:16,478 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:16,898 - INFO - Epoch 50: train_loss=0.7439
2025-02-06 18:15:17,190 - INFO - Epoch 50: train_loss=0.7326
2025-02-06 18:15:17,528 - INFO - Epoch 50: val_loss=1.4215, val_acc=33.33%
2025-02-06 18:15:17,532 - INFO - Epoch 50: EPOCH_AVG_TRAIN_LOSS=0.7326
2025-02-06 18:15:17,534 - INFO - #################### Training epoch 51 ####################
2025-02-06 18:15:17,534 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:17,953 - INFO - Epoch 51: train_loss=0.5182
2025-02-06 18:15:18,245 - INFO - Epoch 51: train_loss=1.1979
2025-02-06 18:15:18,581 - INFO - Epoch 51: val_loss=1.4324, val_acc=33.33%
2025-02-06 18:15:18,585 - INFO - Epoch 51: EPOCH_AVG_TRAIN_LOSS=0.5182
2025-02-06 18:15:18,587 - INFO - #################### Training epoch 52 ####################
2025-02-06 18:15:18,587 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:19,004 - INFO - Epoch 52: train_loss=0.7633
2025-02-06 18:15:19,297 - INFO - Epoch 52: train_loss=0.7835
2025-02-06 18:15:19,632 - INFO - Epoch 52: val_loss=1.4242, val_acc=33.33%
2025-02-06 18:15:19,636 - INFO - Epoch 52: EPOCH_AVG_TRAIN_LOSS=0.7633
2025-02-06 18:15:19,638 - INFO - #################### Training epoch 53 ####################
2025-02-06 18:15:19,638 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:20,056 - INFO - Epoch 53: train_loss=0.8051
2025-02-06 18:15:20,348 - INFO - Epoch 53: train_loss=0.5956
2025-02-06 18:15:20,683 - INFO - Epoch 53: val_loss=1.4271, val_acc=33.33%
2025-02-06 18:15:20,687 - INFO - Epoch 53: EPOCH_AVG_TRAIN_LOSS=0.5956
2025-02-06 18:15:20,689 - INFO - #################### Training epoch 54 ####################
2025-02-06 18:15:20,689 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:21,109 - INFO - Epoch 54: train_loss=0.6692
2025-02-06 18:15:21,401 - INFO - Epoch 54: train_loss=0.7215
2025-02-06 18:15:21,738 - INFO - Epoch 54: val_loss=1.4263, val_acc=33.33%
2025-02-06 18:15:21,742 - INFO - Epoch 54: EPOCH_AVG_TRAIN_LOSS=0.6692
2025-02-06 18:15:21,745 - INFO - #################### Training epoch 55 ####################
2025-02-06 18:15:21,745 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:22,164 - INFO - Epoch 55: train_loss=0.6878
2025-02-06 18:15:22,457 - INFO - Epoch 55: train_loss=0.7536
2025-02-06 18:15:22,788 - INFO - Epoch 55: val_loss=1.4148, val_acc=33.33%
2025-02-06 18:15:22,791 - INFO - Epoch 55: EPOCH_AVG_TRAIN_LOSS=0.6878
2025-02-06 18:15:22,794 - INFO - #################### Training epoch 56 ####################
2025-02-06 18:15:22,794 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:23,211 - INFO - Epoch 56: train_loss=0.8857
2025-02-06 18:15:23,503 - INFO - Epoch 56: train_loss=0.3111
2025-02-06 18:15:23,836 - INFO - Epoch 56: val_loss=1.4257, val_acc=33.33%
2025-02-06 18:15:23,840 - INFO - Epoch 56: EPOCH_AVG_TRAIN_LOSS=0.3111
2025-02-06 18:15:23,842 - INFO - #################### Training epoch 57 ####################
2025-02-06 18:15:23,842 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:24,260 - INFO - Epoch 57: train_loss=0.5528
2025-02-06 18:15:24,551 - INFO - Epoch 57: train_loss=0.9694
2025-02-06 18:15:24,885 - INFO - Epoch 57: val_loss=1.4314, val_acc=33.33%
2025-02-06 18:15:24,889 - INFO - Epoch 57: EPOCH_AVG_TRAIN_LOSS=0.5528
2025-02-06 18:15:24,891 - INFO - #################### Training epoch 58 ####################
2025-02-06 18:15:24,891 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:25,309 - INFO - Epoch 58: train_loss=0.6687
2025-02-06 18:15:25,601 - INFO - Epoch 58: train_loss=0.7250
2025-02-06 18:15:25,933 - INFO - Epoch 58: val_loss=1.4336, val_acc=33.33%
2025-02-06 18:15:25,937 - INFO - Epoch 58: EPOCH_AVG_TRAIN_LOSS=0.6687
2025-02-06 18:15:25,939 - INFO - #################### Training epoch 59 ####################
2025-02-06 18:15:25,939 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:26,357 - INFO - Epoch 59: train_loss=0.6243
2025-02-06 18:15:26,649 - INFO - Epoch 59: train_loss=0.8113
2025-02-06 18:15:26,979 - INFO - Epoch 59: val_loss=1.4397, val_acc=33.33%
2025-02-06 18:15:26,983 - INFO - Epoch 59: EPOCH_AVG_TRAIN_LOSS=0.6243
2025-02-06 18:15:26,985 - INFO - #################### Training epoch 60 ####################
2025-02-06 18:15:26,985 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:27,404 - INFO - Epoch 60: train_loss=0.6515
2025-02-06 18:15:27,696 - INFO - Epoch 60: train_loss=0.6605
2025-02-06 18:15:28,027 - INFO - Epoch 60: val_loss=1.4390, val_acc=33.33%
2025-02-06 18:15:28,031 - INFO - Epoch 60: EPOCH_AVG_TRAIN_LOSS=0.6515
2025-02-06 18:15:28,033 - INFO - #################### Training epoch 61 ####################
2025-02-06 18:15:28,033 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:28,452 - INFO - Epoch 61: train_loss=0.6117
2025-02-06 18:15:28,744 - INFO - Epoch 61: train_loss=0.7719
2025-02-06 18:15:29,078 - INFO - Epoch 61: val_loss=1.4340, val_acc=33.33%
2025-02-06 18:15:29,081 - INFO - Epoch 61: EPOCH_AVG_TRAIN_LOSS=0.6117
2025-02-06 18:15:29,084 - INFO - #################### Training epoch 62 ####################
2025-02-06 18:15:29,084 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:15:29,503 - INFO - Epoch 62: train_loss=0.6303
2025-02-06 18:15:29,795 - INFO - Epoch 62: train_loss=0.7152
2025-02-06 18:15:30,130 - INFO - Epoch 62: val_loss=1.4391, val_acc=33.33%
2025-02-06 18:15:30,134 - INFO - Epoch 62: EPOCH_AVG_TRAIN_LOSS=0.6303
2025-02-06 18:15:30,136 - INFO - #################### Training epoch 63 ####################
2025-02-06 18:15:30,136 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:30,552 - INFO - Epoch 63: train_loss=0.6595
2025-02-06 18:15:30,844 - INFO - Epoch 63: train_loss=0.7258
2025-02-06 18:15:31,176 - INFO - Epoch 63: val_loss=1.4281, val_acc=33.33%
2025-02-06 18:15:31,180 - INFO - Epoch 63: EPOCH_AVG_TRAIN_LOSS=0.6595
2025-02-06 18:15:31,182 - INFO - #################### Training epoch 64 ####################
2025-02-06 18:15:31,182 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:31,599 - INFO - Epoch 64: train_loss=0.4874
2025-02-06 18:15:31,891 - INFO - Epoch 64: train_loss=0.9018
2025-02-06 18:15:32,224 - INFO - Epoch 64: val_loss=1.4327, val_acc=33.33%
2025-02-06 18:15:32,228 - INFO - Epoch 64: EPOCH_AVG_TRAIN_LOSS=0.4874
2025-02-06 18:15:32,230 - INFO - #################### Training epoch 65 ####################
2025-02-06 18:15:32,230 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:32,649 - INFO - Epoch 65: train_loss=0.4781
2025-02-06 18:15:32,941 - INFO - Epoch 65: train_loss=0.9278
2025-02-06 18:15:33,273 - INFO - Epoch 65: val_loss=1.4387, val_acc=33.33%
2025-02-06 18:15:33,277 - INFO - Epoch 65: EPOCH_AVG_TRAIN_LOSS=0.4781
2025-02-06 18:15:33,279 - INFO - #################### Training epoch 66 ####################
2025-02-06 18:15:33,279 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:33,700 - INFO - Epoch 66: train_loss=0.5353
2025-02-06 18:15:33,992 - INFO - Epoch 66: train_loss=0.8909
2025-02-06 18:15:34,322 - INFO - Epoch 66: val_loss=1.4435, val_acc=33.33%
2025-02-06 18:15:34,326 - INFO - Epoch 66: EPOCH_AVG_TRAIN_LOSS=0.5353
2025-02-06 18:15:34,328 - INFO - #################### Training epoch 67 ####################
2025-02-06 18:15:34,328 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:34,747 - INFO - Epoch 67: train_loss=0.6867
2025-02-06 18:15:35,039 - INFO - Epoch 67: train_loss=0.5774
2025-02-06 18:15:35,368 - INFO - Epoch 67: val_loss=1.4547, val_acc=33.33%
2025-02-06 18:15:35,372 - INFO - Epoch 67: EPOCH_AVG_TRAIN_LOSS=0.5774
2025-02-06 18:15:35,374 - INFO - #################### Training epoch 68 ####################
2025-02-06 18:15:35,374 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:35,790 - INFO - Epoch 68: train_loss=0.5976
2025-02-06 18:15:36,082 - INFO - Epoch 68: train_loss=0.7606
2025-02-06 18:15:36,415 - INFO - Epoch 68: val_loss=1.4451, val_acc=33.33%
2025-02-06 18:15:36,419 - INFO - Epoch 68: EPOCH_AVG_TRAIN_LOSS=0.5976
2025-02-06 18:15:36,421 - INFO - #################### Training epoch 69 ####################
2025-02-06 18:15:36,421 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:36,843 - INFO - Epoch 69: train_loss=0.7008
2025-02-06 18:15:37,134 - INFO - Epoch 69: train_loss=0.5974
2025-02-06 18:15:37,469 - INFO - Epoch 69: val_loss=1.4464, val_acc=33.33%
2025-02-06 18:15:37,473 - INFO - Epoch 69: EPOCH_AVG_TRAIN_LOSS=0.5974
2025-02-06 18:15:37,475 - INFO - #################### Training epoch 70 ####################
2025-02-06 18:15:37,475 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:37,888 - INFO - Epoch 70: train_loss=0.5527
2025-02-06 18:15:38,181 - INFO - Epoch 70: train_loss=0.8773
2025-02-06 18:15:38,516 - INFO - Epoch 70: val_loss=1.4274, val_acc=33.33%
2025-02-06 18:15:38,520 - INFO - Epoch 70: EPOCH_AVG_TRAIN_LOSS=0.5527
2025-02-06 18:15:38,522 - INFO - #################### Training epoch 71 ####################
2025-02-06 18:15:38,522 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:38,942 - INFO - Epoch 71: train_loss=0.8160
2025-02-06 18:15:39,234 - INFO - Epoch 71: train_loss=0.2474
2025-02-06 18:15:39,569 - INFO - Epoch 71: val_loss=1.4280, val_acc=33.33%
2025-02-06 18:15:39,573 - INFO - Epoch 71: EPOCH_AVG_TRAIN_LOSS=0.2474
2025-02-06 18:15:39,575 - INFO - #################### Training epoch 72 ####################
2025-02-06 18:15:39,575 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:39,997 - INFO - Epoch 72: train_loss=0.5712
2025-02-06 18:15:40,288 - INFO - Epoch 72: train_loss=0.7349
2025-02-06 18:15:40,620 - INFO - Epoch 72: val_loss=1.4345, val_acc=33.33%
2025-02-06 18:15:40,623 - INFO - Epoch 72: EPOCH_AVG_TRAIN_LOSS=0.5712
2025-02-06 18:15:40,626 - INFO - #################### Training epoch 73 ####################
2025-02-06 18:15:40,626 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:41,042 - INFO - Epoch 73: train_loss=0.6588
2025-02-06 18:15:41,334 - INFO - Epoch 73: train_loss=0.6208
2025-02-06 18:15:41,668 - INFO - Epoch 73: val_loss=1.4276, val_acc=33.33%
2025-02-06 18:15:41,672 - INFO - Epoch 73: EPOCH_AVG_TRAIN_LOSS=0.6208
2025-02-06 18:15:41,674 - INFO - #################### Training epoch 74 ####################
2025-02-06 18:15:41,674 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:42,094 - INFO - Epoch 74: train_loss=0.6616
2025-02-06 18:15:42,385 - INFO - Epoch 74: train_loss=0.6259
2025-02-06 18:15:42,716 - INFO - Epoch 74: val_loss=1.4132, val_acc=33.33%
2025-02-06 18:15:42,720 - INFO - Epoch 74: EPOCH_AVG_TRAIN_LOSS=0.6259
2025-02-06 18:15:42,722 - INFO - #################### Training epoch 75 ####################
2025-02-06 18:15:42,722 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:43,137 - INFO - Epoch 75: train_loss=0.5875
2025-02-06 18:15:43,429 - INFO - Epoch 75: train_loss=0.7804
2025-02-06 18:15:43,761 - INFO - Epoch 75: val_loss=1.4320, val_acc=33.33%
2025-02-06 18:15:43,764 - INFO - Epoch 75: EPOCH_AVG_TRAIN_LOSS=0.5875
2025-02-06 18:15:43,767 - INFO - #################### Training epoch 76 ####################
2025-02-06 18:15:43,767 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:44,183 - INFO - Epoch 76: train_loss=0.6154
2025-02-06 18:15:44,475 - INFO - Epoch 76: train_loss=0.7134
2025-02-06 18:15:44,806 - INFO - Epoch 76: val_loss=1.4227, val_acc=33.33%
2025-02-06 18:15:44,810 - INFO - Epoch 76: EPOCH_AVG_TRAIN_LOSS=0.6154
2025-02-06 18:15:44,812 - INFO - #################### Training epoch 77 ####################
2025-02-06 18:15:44,812 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:45,231 - INFO - Epoch 77: train_loss=0.6773
2025-02-06 18:15:45,522 - INFO - Epoch 77: train_loss=0.5897
2025-02-06 18:15:45,852 - INFO - Epoch 77: val_loss=1.4142, val_acc=33.33%
2025-02-06 18:15:45,856 - INFO - Epoch 77: EPOCH_AVG_TRAIN_LOSS=0.5897
2025-02-06 18:15:45,858 - INFO - #################### Training epoch 78 ####################
2025-02-06 18:15:45,858 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:46,274 - INFO - Epoch 78: train_loss=0.4344
2025-02-06 18:15:46,565 - INFO - Epoch 78: train_loss=1.1388
2025-02-06 18:15:46,898 - INFO - Epoch 78: val_loss=1.4296, val_acc=33.33%
2025-02-06 18:15:46,902 - INFO - Epoch 78: EPOCH_AVG_TRAIN_LOSS=0.4344
2025-02-06 18:15:46,904 - INFO - #################### Training epoch 79 ####################
2025-02-06 18:15:46,904 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:47,323 - INFO - Epoch 79: train_loss=0.5140
2025-02-06 18:15:47,615 - INFO - Epoch 79: train_loss=0.9123
2025-02-06 18:15:47,943 - INFO - Epoch 79: val_loss=1.4170, val_acc=33.33%
2025-02-06 18:15:47,947 - INFO - Epoch 79: EPOCH_AVG_TRAIN_LOSS=0.5140
2025-02-06 18:15:47,949 - INFO - #################### Training epoch 80 ####################
2025-02-06 18:15:47,949 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:48,368 - INFO - Epoch 80: train_loss=0.6022
2025-02-06 18:15:48,659 - INFO - Epoch 80: train_loss=0.7270
2025-02-06 18:15:48,991 - INFO - Epoch 80: val_loss=1.4437, val_acc=33.33%
2025-02-06 18:15:48,995 - INFO - Epoch 80: EPOCH_AVG_TRAIN_LOSS=0.6022
2025-02-06 18:15:48,997 - INFO - #################### Training epoch 81 ####################
2025-02-06 18:15:48,997 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:49,417 - INFO - Epoch 81: train_loss=0.6705
2025-02-06 18:15:49,709 - INFO - Epoch 81: train_loss=0.5012
2025-02-06 18:15:50,044 - INFO - Epoch 81: val_loss=1.4259, val_acc=33.33%
2025-02-06 18:15:50,048 - INFO - Epoch 81: EPOCH_AVG_TRAIN_LOSS=0.5012
2025-02-06 18:15:50,051 - INFO - #################### Training epoch 82 ####################
2025-02-06 18:15:50,051 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:50,471 - INFO - Epoch 82: train_loss=0.7182
2025-02-06 18:15:50,763 - INFO - Epoch 82: train_loss=0.4834
2025-02-06 18:15:51,099 - INFO - Epoch 82: val_loss=1.4166, val_acc=33.33%
2025-02-06 18:15:51,103 - INFO - Epoch 82: EPOCH_AVG_TRAIN_LOSS=0.4834
2025-02-06 18:15:51,105 - INFO - #################### Training epoch 83 ####################
2025-02-06 18:15:51,105 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:15:51,525 - INFO - Epoch 83: train_loss=0.5935
