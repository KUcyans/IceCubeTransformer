2025-02-06 18:10:35,769 - INFO - Starting training with the following parameters:
2025-02-06 18:10:35,770 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product|
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.001          |
| epochs          | 200            |
| batch_size      | 16             |

2025-02-06 18:10:36,380 - INFO - Epoch 0: val_loss=1.1364, val_acc=66.67%
2025-02-06 18:10:36,518 - INFO - #################### Training epoch 0 ####################
2025-02-06 18:10:36,518 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:36,767 - INFO - Epoch 0: train_loss=1.1389
2025-02-06 18:10:37,127 - INFO - Epoch 0: train_loss=1.2065
2025-02-06 18:10:37,422 - INFO - Epoch 0: val_loss=1.0972, val_acc=66.67%
2025-02-06 18:10:37,439 - INFO - Epoch 0: EPOCH_AVG_TRAIN_LOSS=1.1389
2025-02-06 18:10:37,468 - INFO - #################### Training epoch 1 ####################
2025-02-06 18:10:37,468 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:37,866 - INFO - Epoch 1: train_loss=1.0490
2025-02-06 18:10:38,156 - INFO - Epoch 1: train_loss=1.0942
2025-02-06 18:10:38,471 - INFO - Epoch 1: val_loss=1.0967, val_acc=33.33%
2025-02-06 18:10:38,475 - INFO - Epoch 1: EPOCH_AVG_TRAIN_LOSS=1.0490
2025-02-06 18:10:38,515 - INFO - #################### Training epoch 2 ####################
2025-02-06 18:10:38,515 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:38,915 - INFO - Epoch 2: train_loss=1.0344
2025-02-06 18:10:39,205 - INFO - Epoch 2: train_loss=1.1000
2025-02-06 18:10:39,523 - INFO - Epoch 2: val_loss=1.0966, val_acc=66.67%
2025-02-06 18:10:39,527 - INFO - Epoch 2: EPOCH_AVG_TRAIN_LOSS=1.0344
2025-02-06 18:10:39,565 - INFO - #################### Training epoch 3 ####################
2025-02-06 18:10:39,565 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:39,965 - INFO - Epoch 3: train_loss=1.0216
2025-02-06 18:10:40,256 - INFO - Epoch 3: train_loss=1.0134
2025-02-06 18:10:40,572 - INFO - Epoch 3: val_loss=1.0634, val_acc=66.67%
2025-02-06 18:10:40,575 - INFO - Epoch 3: EPOCH_AVG_TRAIN_LOSS=1.0134
2025-02-06 18:10:40,604 - INFO - #################### Training epoch 4 ####################
2025-02-06 18:10:40,604 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:41,005 - INFO - Epoch 4: train_loss=0.9309
2025-02-06 18:10:41,296 - INFO - Epoch 4: train_loss=1.0266
2025-02-06 18:10:41,613 - INFO - Epoch 4: val_loss=1.0586, val_acc=66.67%
2025-02-06 18:10:41,617 - INFO - Epoch 4: EPOCH_AVG_TRAIN_LOSS=0.9309
2025-02-06 18:10:41,645 - INFO - #################### Training epoch 5 ####################
2025-02-06 18:10:41,645 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:42,046 - INFO - Epoch 5: train_loss=0.9250
2025-02-06 18:10:42,337 - INFO - Epoch 5: train_loss=0.9275
2025-02-06 18:10:42,654 - INFO - Epoch 5: val_loss=1.1334, val_acc=66.67%
2025-02-06 18:10:42,658 - INFO - Epoch 5: EPOCH_AVG_TRAIN_LOSS=0.9250
2025-02-06 18:10:42,661 - INFO - #################### Training epoch 6 ####################
2025-02-06 18:10:42,661 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:43,065 - INFO - Epoch 6: train_loss=0.8917
2025-02-06 18:10:43,355 - INFO - Epoch 6: train_loss=0.9025
2025-02-06 18:10:43,669 - INFO - Epoch 6: val_loss=1.1152, val_acc=33.33%
2025-02-06 18:10:43,673 - INFO - Epoch 6: EPOCH_AVG_TRAIN_LOSS=0.8917
2025-02-06 18:10:43,675 - INFO - #################### Training epoch 7 ####################
2025-02-06 18:10:43,675 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:44,075 - INFO - Epoch 7: train_loss=0.8419
2025-02-06 18:10:44,367 - INFO - Epoch 7: train_loss=0.8651
2025-02-06 18:10:44,685 - INFO - Epoch 7: val_loss=1.2356, val_acc=66.67%
2025-02-06 18:10:44,689 - INFO - Epoch 7: EPOCH_AVG_TRAIN_LOSS=0.8419
2025-02-06 18:10:44,691 - INFO - #################### Training epoch 8 ####################
2025-02-06 18:10:44,691 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:45,093 - INFO - Epoch 8: train_loss=0.8809
2025-02-06 18:10:45,385 - INFO - Epoch 8: train_loss=0.5496
2025-02-06 18:10:45,701 - INFO - Epoch 8: val_loss=1.3235, val_acc=66.67%
2025-02-06 18:10:45,705 - INFO - Epoch 8: EPOCH_AVG_TRAIN_LOSS=0.5496
2025-02-06 18:10:45,707 - INFO - #################### Training epoch 9 ####################
2025-02-06 18:10:45,707 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:46,111 - INFO - Epoch 9: train_loss=0.8365
2025-02-06 18:10:46,401 - INFO - Epoch 9: train_loss=0.5456
2025-02-06 18:10:46,718 - INFO - Epoch 9: val_loss=1.5391, val_acc=33.33%
2025-02-06 18:10:46,722 - INFO - Epoch 9: EPOCH_AVG_TRAIN_LOSS=0.5456
2025-02-06 18:10:46,724 - INFO - #################### Training epoch 10 ####################
2025-02-06 18:10:46,724 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:47,123 - INFO - Epoch 10: train_loss=0.7415
2025-02-06 18:10:47,415 - INFO - Epoch 10: train_loss=0.5694
2025-02-06 18:10:47,733 - INFO - Epoch 10: val_loss=1.5437, val_acc=33.33%
2025-02-06 18:10:47,737 - INFO - Epoch 10: EPOCH_AVG_TRAIN_LOSS=0.5694
2025-02-06 18:10:47,739 - INFO - #################### Training epoch 11 ####################
2025-02-06 18:10:47,739 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:48,139 - INFO - Epoch 11: train_loss=0.6639
2025-02-06 18:10:48,432 - INFO - Epoch 11: train_loss=0.6673
2025-02-06 18:10:48,751 - INFO - Epoch 11: val_loss=1.5666, val_acc=66.67%
2025-02-06 18:10:48,754 - INFO - Epoch 11: EPOCH_AVG_TRAIN_LOSS=0.6639
2025-02-06 18:10:48,756 - INFO - #################### Training epoch 12 ####################
2025-02-06 18:10:48,756 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:49,160 - INFO - Epoch 12: train_loss=0.5110
2025-02-06 18:10:49,452 - INFO - Epoch 12: train_loss=1.0101
2025-02-06 18:10:49,768 - INFO - Epoch 12: val_loss=1.7505, val_acc=33.33%
2025-02-06 18:10:49,771 - INFO - Epoch 12: EPOCH_AVG_TRAIN_LOSS=0.5110
2025-02-06 18:10:49,774 - INFO - #################### Training epoch 13 ####################
2025-02-06 18:10:49,774 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:50,177 - INFO - Epoch 13: train_loss=0.6123
2025-02-06 18:10:50,469 - INFO - Epoch 13: train_loss=0.7096
2025-02-06 18:10:50,789 - INFO - Epoch 13: val_loss=1.9694, val_acc=33.33%
2025-02-06 18:10:50,792 - INFO - Epoch 13: EPOCH_AVG_TRAIN_LOSS=0.6123
2025-02-06 18:10:50,795 - INFO - #################### Training epoch 14 ####################
2025-02-06 18:10:50,795 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:51,199 - INFO - Epoch 14: train_loss=0.5590
2025-02-06 18:10:51,491 - INFO - Epoch 14: train_loss=1.0029
2025-02-06 18:10:51,810 - INFO - Epoch 14: val_loss=1.9976, val_acc=33.33%
2025-02-06 18:10:51,814 - INFO - Epoch 14: EPOCH_AVG_TRAIN_LOSS=0.5590
2025-02-06 18:10:51,816 - INFO - #################### Training epoch 15 ####################
2025-02-06 18:10:51,816 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:52,219 - INFO - Epoch 15: train_loss=0.6035
2025-02-06 18:10:52,510 - INFO - Epoch 15: train_loss=0.8614
2025-02-06 18:10:52,828 - INFO - Epoch 15: val_loss=2.0285, val_acc=33.33%
2025-02-06 18:10:52,832 - INFO - Epoch 15: EPOCH_AVG_TRAIN_LOSS=0.6035
2025-02-06 18:10:52,834 - INFO - #################### Training epoch 16 ####################
2025-02-06 18:10:52,834 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:53,239 - INFO - Epoch 16: train_loss=0.5007
2025-02-06 18:10:53,531 - INFO - Epoch 16: train_loss=0.9347
2025-02-06 18:10:53,852 - INFO - Epoch 16: val_loss=2.0310, val_acc=33.33%
2025-02-06 18:10:53,855 - INFO - Epoch 16: EPOCH_AVG_TRAIN_LOSS=0.5007
2025-02-06 18:10:53,858 - INFO - #################### Training epoch 17 ####################
2025-02-06 18:10:53,858 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:54,260 - INFO - Epoch 17: train_loss=0.7247
2025-02-06 18:10:54,552 - INFO - Epoch 17: train_loss=0.6586
2025-02-06 18:10:54,872 - INFO - Epoch 17: val_loss=2.0148, val_acc=33.33%
2025-02-06 18:10:54,876 - INFO - Epoch 17: EPOCH_AVG_TRAIN_LOSS=0.6586
2025-02-06 18:10:54,878 - INFO - #################### Training epoch 18 ####################
2025-02-06 18:10:54,878 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:55,284 - INFO - Epoch 18: train_loss=0.5444
2025-02-06 18:10:55,575 - INFO - Epoch 18: train_loss=0.9900
2025-02-06 18:10:55,893 - INFO - Epoch 18: val_loss=2.0438, val_acc=33.33%
2025-02-06 18:10:55,896 - INFO - Epoch 18: EPOCH_AVG_TRAIN_LOSS=0.5444
2025-02-06 18:10:55,899 - INFO - #################### Training epoch 19 ####################
2025-02-06 18:10:55,899 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:56,303 - INFO - Epoch 19: train_loss=0.7374
2025-02-06 18:10:56,594 - INFO - Epoch 19: train_loss=0.6415
2025-02-06 18:10:56,914 - INFO - Epoch 19: val_loss=2.0799, val_acc=33.33%
2025-02-06 18:10:56,918 - INFO - Epoch 19: EPOCH_AVG_TRAIN_LOSS=0.6415
2025-02-06 18:10:56,920 - INFO - #################### Training epoch 20 ####################
2025-02-06 18:10:56,920 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:10:57,322 - INFO - Epoch 20: train_loss=0.4701
2025-02-06 18:10:57,613 - INFO - Epoch 20: train_loss=1.0273
2025-02-06 18:10:57,932 - INFO - Epoch 20: val_loss=2.0745, val_acc=33.33%
2025-02-06 18:10:57,936 - INFO - Epoch 20: EPOCH_AVG_TRAIN_LOSS=0.4701
2025-02-06 18:10:57,938 - INFO - #################### Training epoch 21 ####################
2025-02-06 18:10:57,938 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:10:58,342 - INFO - Epoch 21: train_loss=0.7308
2025-02-06 18:10:58,633 - INFO - Epoch 21: train_loss=0.6263
2025-02-06 18:10:58,951 - INFO - Epoch 21: val_loss=2.1106, val_acc=33.33%
2025-02-06 18:10:58,955 - INFO - Epoch 21: EPOCH_AVG_TRAIN_LOSS=0.6263
2025-02-06 18:10:58,957 - INFO - #################### Training epoch 22 ####################
2025-02-06 18:10:58,957 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:10:59,361 - INFO - Epoch 22: train_loss=0.7166
2025-02-06 18:10:59,652 - INFO - Epoch 22: train_loss=0.6021
2025-02-06 18:10:59,974 - INFO - Epoch 22: val_loss=2.0989, val_acc=33.33%
2025-02-06 18:10:59,978 - INFO - Epoch 22: EPOCH_AVG_TRAIN_LOSS=0.6021
2025-02-06 18:10:59,980 - INFO - #################### Training epoch 23 ####################
2025-02-06 18:10:59,980 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:00,381 - INFO - Epoch 23: train_loss=0.6459
2025-02-06 18:11:00,672 - INFO - Epoch 23: train_loss=0.6455
2025-02-06 18:11:00,989 - INFO - Epoch 23: val_loss=2.0972, val_acc=33.33%
2025-02-06 18:11:00,993 - INFO - Epoch 23: EPOCH_AVG_TRAIN_LOSS=0.6455
2025-02-06 18:11:00,995 - INFO - #################### Training epoch 24 ####################
2025-02-06 18:11:00,995 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:01,393 - INFO - Epoch 24: train_loss=0.4678
2025-02-06 18:11:01,685 - INFO - Epoch 24: train_loss=1.1359
2025-02-06 18:11:02,004 - INFO - Epoch 24: val_loss=2.1175, val_acc=33.33%
2025-02-06 18:11:02,008 - INFO - Epoch 24: EPOCH_AVG_TRAIN_LOSS=0.4678
2025-02-06 18:11:02,010 - INFO - #################### Training epoch 25 ####################
2025-02-06 18:11:02,010 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:02,416 - INFO - Epoch 25: train_loss=0.7653
2025-02-06 18:11:02,707 - INFO - Epoch 25: train_loss=0.5867
2025-02-06 18:11:03,025 - INFO - Epoch 25: val_loss=2.0200, val_acc=33.33%
2025-02-06 18:11:03,029 - INFO - Epoch 25: EPOCH_AVG_TRAIN_LOSS=0.5867
2025-02-06 18:11:03,031 - INFO - #################### Training epoch 26 ####################
2025-02-06 18:11:03,031 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:03,432 - INFO - Epoch 26: train_loss=0.7369
2025-02-06 18:11:03,724 - INFO - Epoch 26: train_loss=0.6337
2025-02-06 18:11:04,043 - INFO - Epoch 26: val_loss=2.0346, val_acc=33.33%
2025-02-06 18:11:04,047 - INFO - Epoch 26: EPOCH_AVG_TRAIN_LOSS=0.6337
2025-02-06 18:11:04,049 - INFO - #################### Training epoch 27 ####################
2025-02-06 18:11:04,049 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:04,452 - INFO - Epoch 27: train_loss=0.7307
2025-02-06 18:11:04,744 - INFO - Epoch 27: train_loss=0.6941
2025-02-06 18:11:05,061 - INFO - Epoch 27: val_loss=1.9718, val_acc=33.33%
2025-02-06 18:11:05,065 - INFO - Epoch 27: EPOCH_AVG_TRAIN_LOSS=0.6941
2025-02-06 18:11:05,067 - INFO - #################### Training epoch 28 ####################
2025-02-06 18:11:05,067 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:05,469 - INFO - Epoch 28: train_loss=0.5867
2025-02-06 18:11:05,760 - INFO - Epoch 28: train_loss=0.9840
2025-02-06 18:11:06,079 - INFO - Epoch 28: val_loss=2.0017, val_acc=33.33%
2025-02-06 18:11:06,082 - INFO - Epoch 28: EPOCH_AVG_TRAIN_LOSS=0.5867
2025-02-06 18:11:06,085 - INFO - #################### Training epoch 29 ####################
2025-02-06 18:11:06,085 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:06,484 - INFO - Epoch 29: train_loss=0.8112
2025-02-06 18:11:06,776 - INFO - Epoch 29: train_loss=0.5693
2025-02-06 18:11:07,093 - INFO - Epoch 29: val_loss=1.9805, val_acc=33.33%
2025-02-06 18:11:07,097 - INFO - Epoch 29: EPOCH_AVG_TRAIN_LOSS=0.5693
2025-02-06 18:11:07,099 - INFO - #################### Training epoch 30 ####################
2025-02-06 18:11:07,099 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:07,502 - INFO - Epoch 30: train_loss=0.6721
2025-02-06 18:11:07,793 - INFO - Epoch 30: train_loss=0.8790
2025-02-06 18:11:08,111 - INFO - Epoch 30: val_loss=1.9543, val_acc=33.33%
2025-02-06 18:11:08,114 - INFO - Epoch 30: EPOCH_AVG_TRAIN_LOSS=0.6721
2025-02-06 18:11:08,117 - INFO - #################### Training epoch 31 ####################
2025-02-06 18:11:08,117 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:08,521 - INFO - Epoch 31: train_loss=0.9704
2025-02-06 18:11:08,812 - INFO - Epoch 31: train_loss=0.4203
2025-02-06 18:11:09,132 - INFO - Epoch 31: val_loss=1.9580, val_acc=33.33%
2025-02-06 18:11:09,135 - INFO - Epoch 31: EPOCH_AVG_TRAIN_LOSS=0.4203
2025-02-06 18:11:09,138 - INFO - #################### Training epoch 32 ####################
2025-02-06 18:11:09,138 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:09,540 - INFO - Epoch 32: train_loss=0.6526
2025-02-06 18:11:09,831 - INFO - Epoch 32: train_loss=0.9265
2025-02-06 18:11:10,147 - INFO - Epoch 32: val_loss=1.9458, val_acc=33.33%
2025-02-06 18:11:10,150 - INFO - Epoch 32: EPOCH_AVG_TRAIN_LOSS=0.6526
2025-02-06 18:11:10,153 - INFO - #################### Training epoch 33 ####################
2025-02-06 18:11:10,153 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:10,554 - INFO - Epoch 33: train_loss=0.7871
2025-02-06 18:11:10,845 - INFO - Epoch 33: train_loss=0.7207
2025-02-06 18:11:11,167 - INFO - Epoch 33: val_loss=1.9437, val_acc=33.33%
2025-02-06 18:11:11,171 - INFO - Epoch 33: EPOCH_AVG_TRAIN_LOSS=0.7207
2025-02-06 18:11:11,173 - INFO - #################### Training epoch 34 ####################
2025-02-06 18:11:11,173 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:11,576 - INFO - Epoch 34: train_loss=0.7718
2025-02-06 18:11:11,868 - INFO - Epoch 34: train_loss=0.8083
2025-02-06 18:11:12,187 - INFO - Epoch 34: val_loss=1.9432, val_acc=33.33%
2025-02-06 18:11:12,191 - INFO - Epoch 34: EPOCH_AVG_TRAIN_LOSS=0.7718
2025-02-06 18:11:12,193 - INFO - #################### Training epoch 35 ####################
2025-02-06 18:11:12,193 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:12,598 - INFO - Epoch 35: train_loss=0.7133
2025-02-06 18:11:12,889 - INFO - Epoch 35: train_loss=0.8544
2025-02-06 18:11:13,207 - INFO - Epoch 35: val_loss=1.9227, val_acc=33.33%
2025-02-06 18:11:13,210 - INFO - Epoch 35: EPOCH_AVG_TRAIN_LOSS=0.7133
2025-02-06 18:11:13,213 - INFO - #################### Training epoch 36 ####################
2025-02-06 18:11:13,213 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:13,613 - INFO - Epoch 36: train_loss=0.9463
2025-02-06 18:11:13,905 - INFO - Epoch 36: train_loss=0.4200
2025-02-06 18:11:14,225 - INFO - Epoch 36: val_loss=1.9279, val_acc=33.33%
2025-02-06 18:11:14,229 - INFO - Epoch 36: EPOCH_AVG_TRAIN_LOSS=0.4200
2025-02-06 18:11:14,231 - INFO - #################### Training epoch 37 ####################
2025-02-06 18:11:14,231 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:14,634 - INFO - Epoch 37: train_loss=0.7703
2025-02-06 18:11:14,925 - INFO - Epoch 37: train_loss=0.7722
2025-02-06 18:11:15,243 - INFO - Epoch 37: val_loss=1.9398, val_acc=33.33%
2025-02-06 18:11:15,247 - INFO - Epoch 37: EPOCH_AVG_TRAIN_LOSS=0.7703
2025-02-06 18:11:15,249 - INFO - #################### Training epoch 38 ####################
2025-02-06 18:11:15,249 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:15,652 - INFO - Epoch 38: train_loss=0.7511
2025-02-06 18:11:15,943 - INFO - Epoch 38: train_loss=0.7665
2025-02-06 18:11:16,262 - INFO - Epoch 38: val_loss=1.9777, val_acc=33.33%
2025-02-06 18:11:16,265 - INFO - Epoch 38: EPOCH_AVG_TRAIN_LOSS=0.7511
2025-02-06 18:11:16,268 - INFO - #################### Training epoch 39 ####################
2025-02-06 18:11:16,268 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:16,672 - INFO - Epoch 39: train_loss=0.6079
2025-02-06 18:11:16,964 - INFO - Epoch 39: train_loss=0.8651
2025-02-06 18:11:17,283 - INFO - Epoch 39: val_loss=1.9689, val_acc=33.33%
2025-02-06 18:11:17,286 - INFO - Epoch 39: EPOCH_AVG_TRAIN_LOSS=0.6079
2025-02-06 18:11:17,289 - INFO - #################### Training epoch 40 ####################
2025-02-06 18:11:17,289 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:17,690 - INFO - Epoch 40: train_loss=0.5902
2025-02-06 18:11:17,981 - INFO - Epoch 40: train_loss=0.9507
2025-02-06 18:11:18,301 - INFO - Epoch 40: val_loss=2.0155, val_acc=33.33%
2025-02-06 18:11:18,304 - INFO - Epoch 40: EPOCH_AVG_TRAIN_LOSS=0.5902
2025-02-06 18:11:18,306 - INFO - #################### Training epoch 41 ####################
2025-02-06 18:11:18,307 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:18,706 - INFO - Epoch 41: train_loss=0.8546
2025-02-06 18:11:18,998 - INFO - Epoch 41: train_loss=0.6280
2025-02-06 18:11:19,321 - INFO - Epoch 41: val_loss=2.0045, val_acc=33.33%
2025-02-06 18:11:19,324 - INFO - Epoch 41: EPOCH_AVG_TRAIN_LOSS=0.6280
2025-02-06 18:11:19,327 - INFO - #################### Training epoch 42 ####################
2025-02-06 18:11:19,327 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:19,728 - INFO - Epoch 42: train_loss=0.8015
2025-02-06 18:11:20,020 - INFO - Epoch 42: train_loss=0.4933
2025-02-06 18:11:20,335 - INFO - Epoch 42: val_loss=2.0030, val_acc=33.33%
2025-02-06 18:11:20,339 - INFO - Epoch 42: EPOCH_AVG_TRAIN_LOSS=0.4933
2025-02-06 18:11:20,341 - INFO - #################### Training epoch 43 ####################
2025-02-06 18:11:20,341 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:20,745 - INFO - Epoch 43: train_loss=0.7780
2025-02-06 18:11:21,036 - INFO - Epoch 43: train_loss=0.6806
2025-02-06 18:11:21,354 - INFO - Epoch 43: val_loss=2.0387, val_acc=33.33%
2025-02-06 18:11:21,358 - INFO - Epoch 43: EPOCH_AVG_TRAIN_LOSS=0.6806
2025-02-06 18:11:21,360 - INFO - #################### Training epoch 44 ####################
2025-02-06 18:11:21,360 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:21,763 - INFO - Epoch 44: train_loss=0.5342
2025-02-06 18:11:22,054 - INFO - Epoch 44: train_loss=1.1344
2025-02-06 18:11:22,372 - INFO - Epoch 44: val_loss=2.0163, val_acc=33.33%
2025-02-06 18:11:22,376 - INFO - Epoch 44: EPOCH_AVG_TRAIN_LOSS=0.5342
2025-02-06 18:11:22,378 - INFO - #################### Training epoch 45 ####################
2025-02-06 18:11:22,378 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:22,781 - INFO - Epoch 45: train_loss=0.6074
2025-02-06 18:11:23,073 - INFO - Epoch 45: train_loss=0.8915
2025-02-06 18:11:23,392 - INFO - Epoch 45: val_loss=1.9727, val_acc=33.33%
2025-02-06 18:11:23,395 - INFO - Epoch 45: EPOCH_AVG_TRAIN_LOSS=0.6074
2025-02-06 18:11:23,398 - INFO - #################### Training epoch 46 ####################
2025-02-06 18:11:23,398 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:23,802 - INFO - Epoch 46: train_loss=0.6432
2025-02-06 18:11:24,094 - INFO - Epoch 46: train_loss=0.8508
2025-02-06 18:11:24,417 - INFO - Epoch 46: val_loss=2.0581, val_acc=33.33%
2025-02-06 18:11:24,420 - INFO - Epoch 46: EPOCH_AVG_TRAIN_LOSS=0.6432
2025-02-06 18:11:24,423 - INFO - #################### Training epoch 47 ####################
2025-02-06 18:11:24,423 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:11:24,827 - INFO - Epoch 47: train_loss=0.7388
2025-02-06 18:11:25,118 - INFO - Epoch 47: train_loss=0.6333
2025-02-06 18:11:25,438 - INFO - Epoch 47: val_loss=2.0607, val_acc=33.33%
2025-02-06 18:11:25,441 - INFO - Epoch 47: EPOCH_AVG_TRAIN_LOSS=0.6333
2025-02-06 18:11:25,444 - INFO - #################### Training epoch 48 ####################
2025-02-06 18:11:25,444 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:25,847 - INFO - Epoch 48: train_loss=0.7464
2025-02-06 18:11:26,139 - INFO - Epoch 48: train_loss=0.5444
2025-02-06 18:11:26,460 - INFO - Epoch 48: val_loss=2.0541, val_acc=33.33%
2025-02-06 18:11:26,464 - INFO - Epoch 48: EPOCH_AVG_TRAIN_LOSS=0.5444
2025-02-06 18:11:26,466 - INFO - #################### Training epoch 49 ####################
2025-02-06 18:11:26,466 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:26,868 - INFO - Epoch 49: train_loss=0.7489
2025-02-06 18:11:27,160 - INFO - Epoch 49: train_loss=0.4876
2025-02-06 18:11:27,478 - INFO - Epoch 49: val_loss=2.0508, val_acc=33.33%
2025-02-06 18:11:27,481 - INFO - Epoch 49: EPOCH_AVG_TRAIN_LOSS=0.4876
2025-02-06 18:11:27,484 - INFO - #################### Training epoch 50 ####################
2025-02-06 18:11:27,484 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:27,889 - INFO - Epoch 50: train_loss=0.8430
2025-02-06 18:11:28,181 - INFO - Epoch 50: train_loss=0.4101
2025-02-06 18:11:28,499 - INFO - Epoch 50: val_loss=2.0762, val_acc=33.33%
2025-02-06 18:11:28,503 - INFO - Epoch 50: EPOCH_AVG_TRAIN_LOSS=0.4101
2025-02-06 18:11:28,505 - INFO - #################### Training epoch 51 ####################
2025-02-06 18:11:28,505 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:28,907 - INFO - Epoch 51: train_loss=0.7155
2025-02-06 18:11:29,199 - INFO - Epoch 51: train_loss=0.6771
2025-02-06 18:11:29,523 - INFO - Epoch 51: val_loss=2.0952, val_acc=33.33%
2025-02-06 18:11:29,526 - INFO - Epoch 51: EPOCH_AVG_TRAIN_LOSS=0.6771
2025-02-06 18:11:29,529 - INFO - #################### Training epoch 52 ####################
2025-02-06 18:11:29,529 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:29,931 - INFO - Epoch 52: train_loss=0.7093
2025-02-06 18:11:30,222 - INFO - Epoch 52: train_loss=0.6678
2025-02-06 18:11:30,543 - INFO - Epoch 52: val_loss=2.1210, val_acc=33.33%
2025-02-06 18:11:30,547 - INFO - Epoch 52: EPOCH_AVG_TRAIN_LOSS=0.6678
2025-02-06 18:11:30,549 - INFO - #################### Training epoch 53 ####################
2025-02-06 18:11:30,549 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:30,953 - INFO - Epoch 53: train_loss=0.5564
2025-02-06 18:11:31,245 - INFO - Epoch 53: train_loss=0.9964
2025-02-06 18:11:31,566 - INFO - Epoch 53: val_loss=2.0832, val_acc=33.33%
2025-02-06 18:11:31,570 - INFO - Epoch 53: EPOCH_AVG_TRAIN_LOSS=0.5564
2025-02-06 18:11:31,572 - INFO - #################### Training epoch 54 ####################
2025-02-06 18:11:31,572 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:31,977 - INFO - Epoch 54: train_loss=0.5089
2025-02-06 18:11:32,269 - INFO - Epoch 54: train_loss=0.8849
2025-02-06 18:11:32,585 - INFO - Epoch 54: val_loss=2.0741, val_acc=33.33%
2025-02-06 18:11:32,589 - INFO - Epoch 54: EPOCH_AVG_TRAIN_LOSS=0.5089
2025-02-06 18:11:32,591 - INFO - #################### Training epoch 55 ####################
2025-02-06 18:11:32,591 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:32,995 - INFO - Epoch 55: train_loss=0.7957
2025-02-06 18:11:33,286 - INFO - Epoch 55: train_loss=0.5643
2025-02-06 18:11:33,607 - INFO - Epoch 55: val_loss=2.0921, val_acc=33.33%
2025-02-06 18:11:33,611 - INFO - Epoch 55: EPOCH_AVG_TRAIN_LOSS=0.5643
2025-02-06 18:11:33,613 - INFO - #################### Training epoch 56 ####################
2025-02-06 18:11:33,613 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:34,018 - INFO - Epoch 56: train_loss=0.6570
2025-02-06 18:11:34,310 - INFO - Epoch 56: train_loss=0.7011
2025-02-06 18:11:34,632 - INFO - Epoch 56: val_loss=2.0758, val_acc=33.33%
2025-02-06 18:11:34,635 - INFO - Epoch 56: EPOCH_AVG_TRAIN_LOSS=0.6570
2025-02-06 18:11:34,638 - INFO - #################### Training epoch 57 ####################
2025-02-06 18:11:34,638 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:35,040 - INFO - Epoch 57: train_loss=0.7401
2025-02-06 18:11:35,331 - INFO - Epoch 57: train_loss=0.5931
2025-02-06 18:11:35,653 - INFO - Epoch 57: val_loss=2.0439, val_acc=33.33%
2025-02-06 18:11:35,657 - INFO - Epoch 57: EPOCH_AVG_TRAIN_LOSS=0.5931
2025-02-06 18:11:35,659 - INFO - #################### Training epoch 58 ####################
2025-02-06 18:11:35,659 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:36,065 - INFO - Epoch 58: train_loss=0.7919
2025-02-06 18:11:36,356 - INFO - Epoch 58: train_loss=0.4934
2025-02-06 18:11:36,675 - INFO - Epoch 58: val_loss=2.0731, val_acc=33.33%
2025-02-06 18:11:36,679 - INFO - Epoch 58: EPOCH_AVG_TRAIN_LOSS=0.4934
2025-02-06 18:11:36,681 - INFO - #################### Training epoch 59 ####################
2025-02-06 18:11:36,681 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:37,081 - INFO - Epoch 59: train_loss=0.6673
2025-02-06 18:11:37,372 - INFO - Epoch 59: train_loss=0.7876
2025-02-06 18:11:37,687 - INFO - Epoch 59: val_loss=2.0950, val_acc=33.33%
2025-02-06 18:11:37,690 - INFO - Epoch 59: EPOCH_AVG_TRAIN_LOSS=0.6673
2025-02-06 18:11:37,693 - INFO - #################### Training epoch 60 ####################
2025-02-06 18:11:37,693 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:38,098 - INFO - Epoch 60: train_loss=0.7892
2025-02-06 18:11:38,389 - INFO - Epoch 60: train_loss=0.4217
2025-02-06 18:11:38,708 - INFO - Epoch 60: val_loss=2.0569, val_acc=33.33%
2025-02-06 18:11:38,712 - INFO - Epoch 60: EPOCH_AVG_TRAIN_LOSS=0.4217
2025-02-06 18:11:38,714 - INFO - #################### Training epoch 61 ####################
2025-02-06 18:11:38,714 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:11:39,118 - INFO - Epoch 61: train_loss=0.5703
2025-02-06 18:11:39,409 - INFO - Epoch 61: train_loss=0.9227
2025-02-06 18:11:39,725 - INFO - Epoch 61: val_loss=2.0913, val_acc=33.33%
2025-02-06 18:11:39,729 - INFO - Epoch 61: EPOCH_AVG_TRAIN_LOSS=0.5703
2025-02-06 18:11:39,731 - INFO - #################### Training epoch 62 ####################
2025-02-06 18:11:39,731 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:40,136 - INFO - Epoch 62: train_loss=0.6965
2025-02-06 18:11:40,427 - INFO - Epoch 62: train_loss=0.7265
2025-02-06 18:11:40,747 - INFO - Epoch 62: val_loss=2.0478, val_acc=33.33%
2025-02-06 18:11:40,750 - INFO - Epoch 62: EPOCH_AVG_TRAIN_LOSS=0.6965
2025-02-06 18:11:40,753 - INFO - #################### Training epoch 63 ####################
2025-02-06 18:11:40,753 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:41,155 - INFO - Epoch 63: train_loss=0.6151
2025-02-06 18:11:41,447 - INFO - Epoch 63: train_loss=0.8924
2025-02-06 18:11:41,766 - INFO - Epoch 63: val_loss=2.0440, val_acc=33.33%
2025-02-06 18:11:41,770 - INFO - Epoch 63: EPOCH_AVG_TRAIN_LOSS=0.6151
2025-02-06 18:11:41,772 - INFO - #################### Training epoch 64 ####################
2025-02-06 18:11:41,772 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:42,175 - INFO - Epoch 64: train_loss=0.6250
2025-02-06 18:11:42,466 - INFO - Epoch 64: train_loss=0.7877
2025-02-06 18:11:42,782 - INFO - Epoch 64: val_loss=2.0952, val_acc=33.33%
2025-02-06 18:11:42,785 - INFO - Epoch 64: EPOCH_AVG_TRAIN_LOSS=0.6250
2025-02-06 18:11:42,788 - INFO - #################### Training epoch 65 ####################
2025-02-06 18:11:42,788 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:43,191 - INFO - Epoch 65: train_loss=0.7483
2025-02-06 18:11:43,482 - INFO - Epoch 65: train_loss=0.5206
2025-02-06 18:11:43,801 - INFO - Epoch 65: val_loss=2.0720, val_acc=33.33%
2025-02-06 18:11:43,805 - INFO - Epoch 65: EPOCH_AVG_TRAIN_LOSS=0.5206
2025-02-06 18:11:43,807 - INFO - #################### Training epoch 66 ####################
2025-02-06 18:11:43,807 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:44,212 - INFO - Epoch 66: train_loss=0.8042
2025-02-06 18:11:44,503 - INFO - Epoch 66: train_loss=0.4444
2025-02-06 18:11:44,820 - INFO - Epoch 66: val_loss=2.0872, val_acc=33.33%
2025-02-06 18:11:44,824 - INFO - Epoch 66: EPOCH_AVG_TRAIN_LOSS=0.4444
2025-02-06 18:11:44,826 - INFO - #################### Training epoch 67 ####################
2025-02-06 18:11:44,827 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:45,232 - INFO - Epoch 67: train_loss=0.6795
2025-02-06 18:11:45,524 - INFO - Epoch 67: train_loss=0.8114
2025-02-06 18:11:45,844 - INFO - Epoch 67: val_loss=2.0634, val_acc=33.33%
2025-02-06 18:11:45,848 - INFO - Epoch 67: EPOCH_AVG_TRAIN_LOSS=0.6795
2025-02-06 18:11:45,850 - INFO - #################### Training epoch 68 ####################
2025-02-06 18:11:45,850 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:46,249 - INFO - Epoch 68: train_loss=0.7419
2025-02-06 18:11:46,540 - INFO - Epoch 68: train_loss=0.6457
2025-02-06 18:11:46,857 - INFO - Epoch 68: val_loss=2.0657, val_acc=33.33%
2025-02-06 18:11:46,861 - INFO - Epoch 68: EPOCH_AVG_TRAIN_LOSS=0.6457
2025-02-06 18:11:46,863 - INFO - #################### Training epoch 69 ####################
2025-02-06 18:11:46,863 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:47,261 - INFO - Epoch 69: train_loss=0.6438
2025-02-06 18:11:47,552 - INFO - Epoch 69: train_loss=0.8418
2025-02-06 18:11:47,875 - INFO - Epoch 69: val_loss=2.1016, val_acc=33.33%
2025-02-06 18:11:47,878 - INFO - Epoch 69: EPOCH_AVG_TRAIN_LOSS=0.6438
2025-02-06 18:11:47,881 - INFO - #################### Training epoch 70 ####################
2025-02-06 18:11:47,881 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:48,287 - INFO - Epoch 70: train_loss=0.7802
2025-02-06 18:11:48,578 - INFO - Epoch 70: train_loss=0.4668
2025-02-06 18:11:48,898 - INFO - Epoch 70: val_loss=2.0988, val_acc=33.33%
2025-02-06 18:11:48,901 - INFO - Epoch 70: EPOCH_AVG_TRAIN_LOSS=0.4668
2025-02-06 18:11:48,903 - INFO - #################### Training epoch 71 ####################
2025-02-06 18:11:48,904 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:49,305 - INFO - Epoch 71: train_loss=0.7557
2025-02-06 18:11:49,597 - INFO - Epoch 71: train_loss=0.5978
2025-02-06 18:11:49,912 - INFO - Epoch 71: val_loss=2.1104, val_acc=33.33%
2025-02-06 18:11:49,916 - INFO - Epoch 71: EPOCH_AVG_TRAIN_LOSS=0.5978
2025-02-06 18:11:49,918 - INFO - #################### Training epoch 72 ####################
2025-02-06 18:11:49,918 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:11:50,324 - INFO - Epoch 72: train_loss=0.6370
2025-02-06 18:11:50,615 - INFO - Epoch 72: train_loss=0.8149
2025-02-06 18:11:50,936 - INFO - Epoch 72: val_loss=2.0598, val_acc=33.33%
2025-02-06 18:11:50,940 - INFO - Epoch 72: EPOCH_AVG_TRAIN_LOSS=0.6370
2025-02-06 18:11:50,942 - INFO - #################### Training epoch 73 ####################
2025-02-06 18:11:50,942 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:11:51,346 - INFO - Epoch 73: train_loss=0.7498
2025-02-06 18:11:51,638 - INFO - Epoch 73: train_loss=0.4699
2025-02-06 18:11:51,960 - INFO - Epoch 73: val_loss=2.0797, val_acc=33.33%
2025-02-06 18:11:51,964 - INFO - Epoch 73: EPOCH_AVG_TRAIN_LOSS=0.4699
2025-02-06 18:11:51,966 - INFO - #################### Training epoch 74 ####################
2025-02-06 18:11:51,966 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:11:52,368 - INFO - Epoch 74: train_loss=0.7813
2025-02-06 18:11:52,659 - INFO - Epoch 74: train_loss=0.5482
2025-02-06 18:11:52,979 - INFO - Epoch 74: val_loss=2.1107, val_acc=33.33%
2025-02-06 18:11:52,983 - INFO - Epoch 74: EPOCH_AVG_TRAIN_LOSS=0.5482
2025-02-06 18:11:52,985 - INFO - #################### Training epoch 75 ####################
2025-02-06 18:11:52,985 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:11:53,389 - INFO - Epoch 75: train_loss=0.8616
2025-02-06 18:11:53,681 - INFO - Epoch 75: train_loss=0.3324
2025-02-06 18:11:54,002 - INFO - Epoch 75: val_loss=2.1123, val_acc=33.33%
2025-02-06 18:11:54,006 - INFO - Epoch 75: EPOCH_AVG_TRAIN_LOSS=0.3324
2025-02-06 18:11:54,008 - INFO - #################### Training epoch 76 ####################
2025-02-06 18:11:54,008 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:11:54,412 - INFO - Epoch 76: train_loss=0.5885
2025-02-06 18:11:54,703 - INFO - Epoch 76: train_loss=0.9428
2025-02-06 18:11:55,018 - INFO - Epoch 76: val_loss=2.0949, val_acc=33.33%
2025-02-06 18:11:55,021 - INFO - Epoch 76: EPOCH_AVG_TRAIN_LOSS=0.5885
2025-02-06 18:11:55,023 - INFO - #################### Training epoch 77 ####################
2025-02-06 18:11:55,024 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:11:55,428 - INFO - Epoch 77: train_loss=0.6508
2025-02-06 18:11:55,719 - INFO - Epoch 77: train_loss=0.7827
2025-02-06 18:11:56,036 - INFO - Epoch 77: val_loss=2.1036, val_acc=33.33%
2025-02-06 18:11:56,040 - INFO - Epoch 77: EPOCH_AVG_TRAIN_LOSS=0.6508
2025-02-06 18:11:56,042 - INFO - #################### Training epoch 78 ####################
2025-02-06 18:11:56,042 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:11:56,448 - INFO - Epoch 78: train_loss=0.6266
2025-02-06 18:11:56,738 - INFO - Epoch 78: train_loss=0.8612
2025-02-06 18:11:57,056 - INFO - Epoch 78: val_loss=2.0769, val_acc=33.33%
2025-02-06 18:11:57,060 - INFO - Epoch 78: EPOCH_AVG_TRAIN_LOSS=0.6266
2025-02-06 18:11:57,062 - INFO - #################### Training epoch 79 ####################
2025-02-06 18:11:57,063 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:11:57,463 - INFO - Epoch 79: train_loss=0.6976
2025-02-06 18:11:57,755 - INFO - Epoch 79: train_loss=0.6059
2025-02-06 18:11:58,074 - INFO - Epoch 79: val_loss=2.1391, val_acc=33.33%
2025-02-06 18:11:58,078 - INFO - Epoch 79: EPOCH_AVG_TRAIN_LOSS=0.6059
2025-02-06 18:11:58,080 - INFO - #################### Training epoch 80 ####################
2025-02-06 18:11:58,080 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:11:58,483 - INFO - Epoch 80: train_loss=0.5722
2025-02-06 18:11:58,775 - INFO - Epoch 80: train_loss=0.9742
2025-02-06 18:11:59,096 - INFO - Epoch 80: val_loss=2.0497, val_acc=33.33%
2025-02-06 18:11:59,100 - INFO - Epoch 80: EPOCH_AVG_TRAIN_LOSS=0.5722
2025-02-06 18:11:59,102 - INFO - #################### Training epoch 81 ####################
2025-02-06 18:11:59,103 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:11:59,507 - INFO - Epoch 81: train_loss=0.5423
2025-02-06 18:11:59,798 - INFO - Epoch 81: train_loss=0.9509
2025-02-06 18:12:00,111 - INFO - Epoch 81: val_loss=2.0690, val_acc=33.33%
2025-02-06 18:12:00,115 - INFO - Epoch 81: EPOCH_AVG_TRAIN_LOSS=0.5423
2025-02-06 18:12:00,117 - INFO - #################### Training epoch 82 ####################
2025-02-06 18:12:00,117 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:12:00,521 - INFO - Epoch 82: train_loss=0.7895
2025-02-06 18:12:00,813 - INFO - Epoch 82: train_loss=0.5249
2025-02-06 18:12:01,133 - INFO - Epoch 82: val_loss=2.1030, val_acc=33.33%
2025-02-06 18:12:01,137 - INFO - Epoch 82: EPOCH_AVG_TRAIN_LOSS=0.5249
2025-02-06 18:12:01,139 - INFO - #################### Training epoch 83 ####################
2025-02-06 18:12:01,139 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:12:01,540 - INFO - Epoch 83: train_loss=0.6476
2025-02-06 18:12:01,831 - INFO - Epoch 83: train_loss=0.7598
2025-02-06 18:12:02,148 - INFO - Epoch 83: val_loss=2.1125, val_acc=33.33%
2025-02-06 18:12:02,152 - INFO - Epoch 83: EPOCH_AVG_TRAIN_LOSS=0.6476
2025-02-06 18:12:02,154 - INFO - #################### Training epoch 84 ####################
2025-02-06 18:12:02,154 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:12:02,560 - INFO - Epoch 84: train_loss=0.5359
2025-02-06 18:12:02,851 - INFO - Epoch 84: train_loss=0.8899
2025-02-06 18:12:03,172 - INFO - Epoch 84: val_loss=2.1420, val_acc=33.33%
2025-02-06 18:12:03,176 - INFO - Epoch 84: EPOCH_AVG_TRAIN_LOSS=0.5359
2025-02-06 18:12:03,178 - INFO - #################### Training epoch 85 ####################
2025-02-06 18:12:03,178 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:12:03,579 - INFO - Epoch 85: train_loss=0.7690
2025-02-06 18:12:03,870 - INFO - Epoch 85: train_loss=0.5495
2025-02-06 18:12:04,192 - INFO - Epoch 85: val_loss=2.0924, val_acc=33.33%
2025-02-06 18:12:04,195 - INFO - Epoch 85: EPOCH_AVG_TRAIN_LOSS=0.5495
2025-02-06 18:12:04,198 - INFO - #################### Training epoch 86 ####################
2025-02-06 18:12:04,198 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:12:04,597 - INFO - Epoch 86: train_loss=0.6901
2025-02-06 18:12:04,888 - INFO - Epoch 86: train_loss=0.7383
2025-02-06 18:12:05,207 - INFO - Epoch 86: val_loss=2.1196, val_acc=33.33%
2025-02-06 18:12:05,211 - INFO - Epoch 86: EPOCH_AVG_TRAIN_LOSS=0.6901
2025-02-06 18:12:05,214 - INFO - #################### Training epoch 87 ####################
2025-02-06 18:12:05,214 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:05,617 - INFO - Epoch 87: train_loss=0.7155
2025-02-06 18:12:05,909 - INFO - Epoch 87: train_loss=0.6331
2025-02-06 18:12:06,230 - INFO - Epoch 87: val_loss=2.1113, val_acc=33.33%
2025-02-06 18:12:06,234 - INFO - Epoch 87: EPOCH_AVG_TRAIN_LOSS=0.6331
2025-02-06 18:12:06,236 - INFO - #################### Training epoch 88 ####################
2025-02-06 18:12:06,236 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:06,639 - INFO - Epoch 88: train_loss=0.6667
2025-02-06 18:12:06,930 - INFO - Epoch 88: train_loss=0.7034
2025-02-06 18:12:07,247 - INFO - Epoch 88: val_loss=2.0943, val_acc=33.33%
2025-02-06 18:12:07,251 - INFO - Epoch 88: EPOCH_AVG_TRAIN_LOSS=0.6667
2025-02-06 18:12:07,253 - INFO - #################### Training epoch 89 ####################
2025-02-06 18:12:07,253 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:07,656 - INFO - Epoch 89: train_loss=0.5980
2025-02-06 18:12:07,948 - INFO - Epoch 89: train_loss=0.7430
2025-02-06 18:12:08,268 - INFO - Epoch 89: val_loss=2.1054, val_acc=33.33%
2025-02-06 18:12:08,272 - INFO - Epoch 89: EPOCH_AVG_TRAIN_LOSS=0.5980
2025-02-06 18:12:08,274 - INFO - #################### Training epoch 90 ####################
2025-02-06 18:12:08,274 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:08,678 - INFO - Epoch 90: train_loss=0.7084
2025-02-06 18:12:08,970 - INFO - Epoch 90: train_loss=0.6689
2025-02-06 18:12:09,290 - INFO - Epoch 90: val_loss=2.1194, val_acc=33.33%
2025-02-06 18:12:09,294 - INFO - Epoch 90: EPOCH_AVG_TRAIN_LOSS=0.6689
2025-02-06 18:12:09,296 - INFO - #################### Training epoch 91 ####################
2025-02-06 18:12:09,296 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:09,698 - INFO - Epoch 91: train_loss=0.5430
2025-02-06 18:12:09,990 - INFO - Epoch 91: train_loss=0.9684
2025-02-06 18:12:10,310 - INFO - Epoch 91: val_loss=2.0918, val_acc=33.33%
2025-02-06 18:12:10,313 - INFO - Epoch 91: EPOCH_AVG_TRAIN_LOSS=0.5430
2025-02-06 18:12:10,316 - INFO - #################### Training epoch 92 ####################
2025-02-06 18:12:10,316 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:10,718 - INFO - Epoch 92: train_loss=0.5268
2025-02-06 18:12:11,009 - INFO - Epoch 92: train_loss=1.0356
2025-02-06 18:12:11,329 - INFO - Epoch 92: val_loss=2.0927, val_acc=33.33%
2025-02-06 18:12:11,332 - INFO - Epoch 92: EPOCH_AVG_TRAIN_LOSS=0.5268
2025-02-06 18:12:11,335 - INFO - #################### Training epoch 93 ####################
2025-02-06 18:12:11,335 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:11,739 - INFO - Epoch 93: train_loss=0.5266
2025-02-06 18:12:12,030 - INFO - Epoch 93: train_loss=0.9166
2025-02-06 18:12:12,347 - INFO - Epoch 93: val_loss=2.0848, val_acc=33.33%
2025-02-06 18:12:12,351 - INFO - Epoch 93: EPOCH_AVG_TRAIN_LOSS=0.5266
2025-02-06 18:12:12,353 - INFO - #################### Training epoch 94 ####################
2025-02-06 18:12:12,353 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:12,755 - INFO - Epoch 94: train_loss=0.7447
2025-02-06 18:12:13,047 - INFO - Epoch 94: train_loss=0.5013
2025-02-06 18:12:13,362 - INFO - Epoch 94: val_loss=2.0921, val_acc=33.33%
2025-02-06 18:12:13,366 - INFO - Epoch 94: EPOCH_AVG_TRAIN_LOSS=0.5013
2025-02-06 18:12:13,368 - INFO - #################### Training epoch 95 ####################
2025-02-06 18:12:13,368 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:13,772 - INFO - Epoch 95: train_loss=0.8014
2025-02-06 18:12:14,064 - INFO - Epoch 95: train_loss=0.3213
2025-02-06 18:12:14,381 - INFO - Epoch 95: val_loss=2.0791, val_acc=33.33%
2025-02-06 18:12:14,385 - INFO - Epoch 95: EPOCH_AVG_TRAIN_LOSS=0.3213
2025-02-06 18:12:14,387 - INFO - #################### Training epoch 96 ####################
2025-02-06 18:12:14,387 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:14,791 - INFO - Epoch 96: train_loss=0.7828
2025-02-06 18:12:15,083 - INFO - Epoch 96: train_loss=0.4219
2025-02-06 18:12:15,402 - INFO - Epoch 96: val_loss=2.0976, val_acc=33.33%
2025-02-06 18:12:15,405 - INFO - Epoch 96: EPOCH_AVG_TRAIN_LOSS=0.4219
2025-02-06 18:12:15,408 - INFO - #################### Training epoch 97 ####################
2025-02-06 18:12:15,408 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:15,809 - INFO - Epoch 97: train_loss=0.5934
2025-02-06 18:12:16,101 - INFO - Epoch 97: train_loss=0.8877
2025-02-06 18:12:16,421 - INFO - Epoch 97: val_loss=2.0891, val_acc=33.33%
2025-02-06 18:12:16,424 - INFO - Epoch 97: EPOCH_AVG_TRAIN_LOSS=0.5934
2025-02-06 18:12:16,427 - INFO - #################### Training epoch 98 ####################
2025-02-06 18:12:16,427 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:16,828 - INFO - Epoch 98: train_loss=0.7275
2025-02-06 18:12:17,120 - INFO - Epoch 98: train_loss=0.6554
2025-02-06 18:12:17,439 - INFO - Epoch 98: val_loss=2.1210, val_acc=33.33%
2025-02-06 18:12:17,443 - INFO - Epoch 98: EPOCH_AVG_TRAIN_LOSS=0.6554
2025-02-06 18:12:17,445 - INFO - #################### Training epoch 99 ####################
2025-02-06 18:12:17,445 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:17,850 - INFO - Epoch 99: train_loss=0.7011
2025-02-06 18:12:18,142 - INFO - Epoch 99: train_loss=0.6092
2025-02-06 18:12:18,462 - INFO - Epoch 99: val_loss=2.1267, val_acc=33.33%
2025-02-06 18:12:18,465 - INFO - Epoch 99: EPOCH_AVG_TRAIN_LOSS=0.6092
2025-02-06 18:12:18,467 - INFO - #################### Training epoch 100 ####################
2025-02-06 18:12:18,468 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:18,867 - INFO - Epoch 100: train_loss=0.6371
2025-02-06 18:12:19,158 - INFO - Epoch 100: train_loss=0.6613
2025-02-06 18:12:19,474 - INFO - Epoch 100: val_loss=2.0893, val_acc=33.33%
2025-02-06 18:12:19,478 - INFO - Epoch 100: EPOCH_AVG_TRAIN_LOSS=0.6371
2025-02-06 18:12:19,480 - INFO - #################### Training epoch 101 ####################
2025-02-06 18:12:19,480 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:19,883 - INFO - Epoch 101: train_loss=0.6940
2025-02-06 18:12:20,175 - INFO - Epoch 101: train_loss=0.4842
2025-02-06 18:12:20,497 - INFO - Epoch 101: val_loss=2.0839, val_acc=33.33%
2025-02-06 18:12:20,501 - INFO - Epoch 101: EPOCH_AVG_TRAIN_LOSS=0.4842
2025-02-06 18:12:20,503 - INFO - #################### Training epoch 102 ####################
2025-02-06 18:12:20,503 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:20,907 - INFO - Epoch 102: train_loss=0.8334
2025-02-06 18:12:21,198 - INFO - Epoch 102: train_loss=0.3021
2025-02-06 18:12:21,522 - INFO - Epoch 102: val_loss=2.0755, val_acc=33.33%
2025-02-06 18:12:21,525 - INFO - Epoch 102: EPOCH_AVG_TRAIN_LOSS=0.3021
2025-02-06 18:12:21,528 - INFO - #################### Training epoch 103 ####################
2025-02-06 18:12:21,528 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:21,929 - INFO - Epoch 103: train_loss=0.5624
2025-02-06 18:12:22,222 - INFO - Epoch 103: train_loss=0.9516
2025-02-06 18:12:22,542 - INFO - Epoch 103: val_loss=2.0947, val_acc=33.33%
2025-02-06 18:12:22,546 - INFO - Epoch 103: EPOCH_AVG_TRAIN_LOSS=0.5624
2025-02-06 18:12:22,548 - INFO - #################### Training epoch 104 ####################
2025-02-06 18:12:22,548 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:22,948 - INFO - Epoch 104: train_loss=0.6554
2025-02-06 18:12:23,241 - INFO - Epoch 104: train_loss=0.7376
2025-02-06 18:12:23,559 - INFO - Epoch 104: val_loss=2.1288, val_acc=33.33%
2025-02-06 18:12:23,563 - INFO - Epoch 104: EPOCH_AVG_TRAIN_LOSS=0.6554
2025-02-06 18:12:23,565 - INFO - #################### Training epoch 105 ####################
2025-02-06 18:12:23,565 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:23,966 - INFO - Epoch 105: train_loss=0.6966
2025-02-06 18:12:24,257 - INFO - Epoch 105: train_loss=0.6904
2025-02-06 18:12:24,573 - INFO - Epoch 105: val_loss=2.1188, val_acc=33.33%
2025-02-06 18:12:24,576 - INFO - Epoch 105: EPOCH_AVG_TRAIN_LOSS=0.6904
2025-02-06 18:12:24,579 - INFO - #################### Training epoch 106 ####################
2025-02-06 18:12:24,579 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:24,981 - INFO - Epoch 106: train_loss=0.4954
2025-02-06 18:12:25,272 - INFO - Epoch 106: train_loss=1.0759
2025-02-06 18:12:25,591 - INFO - Epoch 106: val_loss=2.0843, val_acc=33.33%
2025-02-06 18:12:25,595 - INFO - Epoch 106: EPOCH_AVG_TRAIN_LOSS=0.4954
2025-02-06 18:12:25,597 - INFO - #################### Training epoch 107 ####################
2025-02-06 18:12:25,597 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:26,001 - INFO - Epoch 107: train_loss=0.7182
2025-02-06 18:12:26,293 - INFO - Epoch 107: train_loss=0.5708
2025-02-06 18:12:26,613 - INFO - Epoch 107: val_loss=2.0720, val_acc=33.33%
2025-02-06 18:12:26,616 - INFO - Epoch 107: EPOCH_AVG_TRAIN_LOSS=0.5708
2025-02-06 18:12:26,619 - INFO - #################### Training epoch 108 ####################
2025-02-06 18:12:26,619 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:27,022 - INFO - Epoch 108: train_loss=0.7330
2025-02-06 18:12:27,313 - INFO - Epoch 108: train_loss=0.5676
2025-02-06 18:12:27,633 - INFO - Epoch 108: val_loss=2.1021, val_acc=33.33%
2025-02-06 18:12:27,636 - INFO - Epoch 108: EPOCH_AVG_TRAIN_LOSS=0.5676
2025-02-06 18:12:27,639 - INFO - #################### Training epoch 109 ####################
2025-02-06 18:12:27,639 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:28,043 - INFO - Epoch 109: train_loss=0.7624
2025-02-06 18:12:28,335 - INFO - Epoch 109: train_loss=0.5880
2025-02-06 18:12:28,655 - INFO - Epoch 109: val_loss=2.0983, val_acc=33.33%
2025-02-06 18:12:28,659 - INFO - Epoch 109: EPOCH_AVG_TRAIN_LOSS=0.5880
2025-02-06 18:12:28,661 - INFO - #################### Training epoch 110 ####################
2025-02-06 18:12:28,661 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:29,066 - INFO - Epoch 110: train_loss=0.4820
2025-02-06 18:12:29,358 - INFO - Epoch 110: train_loss=1.0999
2025-02-06 18:12:29,673 - INFO - Epoch 110: val_loss=2.0817, val_acc=33.33%
2025-02-06 18:12:29,676 - INFO - Epoch 110: EPOCH_AVG_TRAIN_LOSS=0.4820
2025-02-06 18:12:29,678 - INFO - #################### Training epoch 111 ####################
2025-02-06 18:12:29,678 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:30,083 - INFO - Epoch 111: train_loss=0.5563
2025-02-06 18:12:30,374 - INFO - Epoch 111: train_loss=0.8743
2025-02-06 18:12:30,692 - INFO - Epoch 111: val_loss=2.0714, val_acc=33.33%
2025-02-06 18:12:30,696 - INFO - Epoch 111: EPOCH_AVG_TRAIN_LOSS=0.5563
2025-02-06 18:12:30,698 - INFO - #################### Training epoch 112 ####################
2025-02-06 18:12:30,698 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:31,099 - INFO - Epoch 112: train_loss=0.5442
2025-02-06 18:12:31,390 - INFO - Epoch 112: train_loss=1.0236
2025-02-06 18:12:31,706 - INFO - Epoch 112: val_loss=2.1008, val_acc=33.33%
2025-02-06 18:12:31,709 - INFO - Epoch 112: EPOCH_AVG_TRAIN_LOSS=0.5442
2025-02-06 18:12:31,712 - INFO - #################### Training epoch 113 ####################
2025-02-06 18:12:31,712 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:12:32,115 - INFO - Epoch 113: train_loss=0.7031
2025-02-06 18:12:32,406 - INFO - Epoch 113: train_loss=0.6845
2025-02-06 18:12:32,724 - INFO - Epoch 113: val_loss=2.1043, val_acc=33.33%
2025-02-06 18:12:32,728 - INFO - Epoch 113: EPOCH_AVG_TRAIN_LOSS=0.6845
2025-02-06 18:12:32,730 - INFO - #################### Training epoch 114 ####################
2025-02-06 18:12:32,730 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:33,131 - INFO - Epoch 114: train_loss=0.6364
2025-02-06 18:12:33,423 - INFO - Epoch 114: train_loss=0.8029
2025-02-06 18:12:33,739 - INFO - Epoch 114: val_loss=2.1361, val_acc=33.33%
2025-02-06 18:12:33,743 - INFO - Epoch 114: EPOCH_AVG_TRAIN_LOSS=0.6364
2025-02-06 18:12:33,745 - INFO - #################### Training epoch 115 ####################
2025-02-06 18:12:33,745 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:34,149 - INFO - Epoch 115: train_loss=0.6856
2025-02-06 18:12:34,440 - INFO - Epoch 115: train_loss=0.7353
2025-02-06 18:12:34,756 - INFO - Epoch 115: val_loss=2.0749, val_acc=33.33%
2025-02-06 18:12:34,760 - INFO - Epoch 115: EPOCH_AVG_TRAIN_LOSS=0.6856
2025-02-06 18:12:34,762 - INFO - #################### Training epoch 116 ####################
2025-02-06 18:12:34,762 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:35,160 - INFO - Epoch 116: train_loss=0.6732
2025-02-06 18:12:35,451 - INFO - Epoch 116: train_loss=0.6758
2025-02-06 18:12:35,773 - INFO - Epoch 116: val_loss=2.0946, val_acc=33.33%
2025-02-06 18:12:35,777 - INFO - Epoch 116: EPOCH_AVG_TRAIN_LOSS=0.6732
2025-02-06 18:12:35,779 - INFO - #################### Training epoch 117 ####################
2025-02-06 18:12:35,779 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:36,182 - INFO - Epoch 117: train_loss=0.5651
2025-02-06 18:12:36,473 - INFO - Epoch 117: train_loss=0.8929
2025-02-06 18:12:36,789 - INFO - Epoch 117: val_loss=2.0498, val_acc=33.33%
2025-02-06 18:12:36,793 - INFO - Epoch 117: EPOCH_AVG_TRAIN_LOSS=0.5651
2025-02-06 18:12:36,795 - INFO - #################### Training epoch 118 ####################
2025-02-06 18:12:36,795 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:37,198 - INFO - Epoch 118: train_loss=0.8170
2025-02-06 18:12:37,489 - INFO - Epoch 118: train_loss=0.3973
2025-02-06 18:12:37,805 - INFO - Epoch 118: val_loss=2.0882, val_acc=33.33%
2025-02-06 18:12:37,809 - INFO - Epoch 118: EPOCH_AVG_TRAIN_LOSS=0.3973
2025-02-06 18:12:37,811 - INFO - #################### Training epoch 119 ####################
2025-02-06 18:12:37,811 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:38,212 - INFO - Epoch 119: train_loss=0.7757
2025-02-06 18:12:38,503 - INFO - Epoch 119: train_loss=0.5173
2025-02-06 18:12:38,815 - INFO - Epoch 119: val_loss=2.0810, val_acc=33.33%
2025-02-06 18:12:38,819 - INFO - Epoch 119: EPOCH_AVG_TRAIN_LOSS=0.5173
2025-02-06 18:12:38,821 - INFO - #################### Training epoch 120 ####################
2025-02-06 18:12:38,821 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:39,221 - INFO - Epoch 120: train_loss=0.7426
2025-02-06 18:12:39,512 - INFO - Epoch 120: train_loss=0.5602
2025-02-06 18:12:39,826 - INFO - Epoch 120: val_loss=2.0678, val_acc=33.33%
2025-02-06 18:12:39,830 - INFO - Epoch 120: EPOCH_AVG_TRAIN_LOSS=0.5602
2025-02-06 18:12:39,832 - INFO - #################### Training epoch 121 ####################
2025-02-06 18:12:39,832 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:40,235 - INFO - Epoch 121: train_loss=0.6619
2025-02-06 18:12:40,526 - INFO - Epoch 121: train_loss=0.7257
2025-02-06 18:12:40,841 - INFO - Epoch 121: val_loss=2.0734, val_acc=33.33%
2025-02-06 18:12:40,845 - INFO - Epoch 121: EPOCH_AVG_TRAIN_LOSS=0.6619
2025-02-06 18:12:40,847 - INFO - #################### Training epoch 122 ####################
2025-02-06 18:12:40,847 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:41,251 - INFO - Epoch 122: train_loss=0.7336
2025-02-06 18:12:41,542 - INFO - Epoch 122: train_loss=0.6321
2025-02-06 18:12:41,856 - INFO - Epoch 122: val_loss=2.0691, val_acc=33.33%
2025-02-06 18:12:41,860 - INFO - Epoch 122: EPOCH_AVG_TRAIN_LOSS=0.6321
2025-02-06 18:12:41,862 - INFO - #################### Training epoch 123 ####################
2025-02-06 18:12:41,862 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:42,265 - INFO - Epoch 123: train_loss=0.7423
2025-02-06 18:12:42,556 - INFO - Epoch 123: train_loss=0.4376
2025-02-06 18:12:42,873 - INFO - Epoch 123: val_loss=2.0676, val_acc=33.33%
2025-02-06 18:12:42,877 - INFO - Epoch 123: EPOCH_AVG_TRAIN_LOSS=0.4376
2025-02-06 18:12:42,879 - INFO - #################### Training epoch 124 ####################
2025-02-06 18:12:42,879 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:12:43,278 - INFO - Epoch 124: train_loss=0.7038
2025-02-06 18:12:43,569 - INFO - Epoch 124: train_loss=0.5227
2025-02-06 18:12:43,885 - INFO - Epoch 124: val_loss=2.0772, val_acc=33.33%
2025-02-06 18:12:43,888 - INFO - Epoch 124: EPOCH_AVG_TRAIN_LOSS=0.5227
2025-02-06 18:12:43,891 - INFO - #################### Training epoch 125 ####################
2025-02-06 18:12:43,891 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:44,292 - INFO - Epoch 125: train_loss=0.7993
2025-02-06 18:12:44,583 - INFO - Epoch 125: train_loss=0.5476
2025-02-06 18:12:44,901 - INFO - Epoch 125: val_loss=2.0794, val_acc=33.33%
2025-02-06 18:12:44,904 - INFO - Epoch 125: EPOCH_AVG_TRAIN_LOSS=0.5476
2025-02-06 18:12:44,907 - INFO - #################### Training epoch 126 ####################
2025-02-06 18:12:44,907 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:45,311 - INFO - Epoch 126: train_loss=0.7259
2025-02-06 18:12:45,602 - INFO - Epoch 126: train_loss=0.6469
2025-02-06 18:12:45,919 - INFO - Epoch 126: val_loss=2.0741, val_acc=33.33%
2025-02-06 18:12:45,923 - INFO - Epoch 126: EPOCH_AVG_TRAIN_LOSS=0.6469
2025-02-06 18:12:45,925 - INFO - #################### Training epoch 127 ####################
2025-02-06 18:12:45,925 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:46,327 - INFO - Epoch 127: train_loss=0.7874
2025-02-06 18:12:46,619 - INFO - Epoch 127: train_loss=0.3790
2025-02-06 18:12:46,933 - INFO - Epoch 127: val_loss=2.0890, val_acc=33.33%
2025-02-06 18:12:46,937 - INFO - Epoch 127: EPOCH_AVG_TRAIN_LOSS=0.3790
2025-02-06 18:12:46,939 - INFO - #################### Training epoch 128 ####################
2025-02-06 18:12:46,939 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:47,341 - INFO - Epoch 128: train_loss=0.6994
2025-02-06 18:12:47,633 - INFO - Epoch 128: train_loss=0.6726
2025-02-06 18:12:47,954 - INFO - Epoch 128: val_loss=2.1008, val_acc=33.33%
2025-02-06 18:12:47,958 - INFO - Epoch 128: EPOCH_AVG_TRAIN_LOSS=0.6726
2025-02-06 18:12:47,960 - INFO - #################### Training epoch 129 ####################
2025-02-06 18:12:47,960 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:48,364 - INFO - Epoch 129: train_loss=0.4544
2025-02-06 18:12:48,655 - INFO - Epoch 129: train_loss=1.1006
2025-02-06 18:12:48,974 - INFO - Epoch 129: val_loss=2.0796, val_acc=33.33%
2025-02-06 18:12:48,978 - INFO - Epoch 129: EPOCH_AVG_TRAIN_LOSS=0.4544
2025-02-06 18:12:48,980 - INFO - #################### Training epoch 130 ####################
2025-02-06 18:12:48,980 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:49,383 - INFO - Epoch 130: train_loss=0.8067
2025-02-06 18:12:49,675 - INFO - Epoch 130: train_loss=0.5315
2025-02-06 18:12:49,993 - INFO - Epoch 130: val_loss=2.0888, val_acc=33.33%
2025-02-06 18:12:49,997 - INFO - Epoch 130: EPOCH_AVG_TRAIN_LOSS=0.5315
2025-02-06 18:12:49,999 - INFO - #################### Training epoch 131 ####################
2025-02-06 18:12:49,999 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:50,401 - INFO - Epoch 131: train_loss=0.4926
2025-02-06 18:12:50,692 - INFO - Epoch 131: train_loss=0.9659
2025-02-06 18:12:51,011 - INFO - Epoch 131: val_loss=2.0862, val_acc=33.33%
2025-02-06 18:12:51,015 - INFO - Epoch 131: EPOCH_AVG_TRAIN_LOSS=0.4926
2025-02-06 18:12:51,017 - INFO - #################### Training epoch 132 ####################
2025-02-06 18:12:51,017 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:51,418 - INFO - Epoch 132: train_loss=0.7753
2025-02-06 18:12:51,709 - INFO - Epoch 132: train_loss=0.5022
2025-02-06 18:12:52,027 - INFO - Epoch 132: val_loss=2.1093, val_acc=33.33%
2025-02-06 18:12:52,031 - INFO - Epoch 132: EPOCH_AVG_TRAIN_LOSS=0.5022
2025-02-06 18:12:52,033 - INFO - #################### Training epoch 133 ####################
2025-02-06 18:12:52,033 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:52,434 - INFO - Epoch 133: train_loss=0.7435
2025-02-06 18:12:52,726 - INFO - Epoch 133: train_loss=0.5932
2025-02-06 18:12:53,046 - INFO - Epoch 133: val_loss=2.0736, val_acc=33.33%
2025-02-06 18:12:53,050 - INFO - Epoch 133: EPOCH_AVG_TRAIN_LOSS=0.5932
2025-02-06 18:12:53,052 - INFO - #################### Training epoch 134 ####################
2025-02-06 18:12:53,052 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:53,455 - INFO - Epoch 134: train_loss=0.7721
2025-02-06 18:12:53,746 - INFO - Epoch 134: train_loss=0.4555
2025-02-06 18:12:54,065 - INFO - Epoch 134: val_loss=2.1175, val_acc=33.33%
2025-02-06 18:12:54,068 - INFO - Epoch 134: EPOCH_AVG_TRAIN_LOSS=0.4555
2025-02-06 18:12:54,071 - INFO - #################### Training epoch 135 ####################
2025-02-06 18:12:54,071 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:12:54,469 - INFO - Epoch 135: train_loss=0.5971
2025-02-06 18:12:54,760 - INFO - Epoch 135: train_loss=0.8435
2025-02-06 18:12:55,077 - INFO - Epoch 135: val_loss=2.0799, val_acc=33.33%
2025-02-06 18:12:55,081 - INFO - Epoch 135: EPOCH_AVG_TRAIN_LOSS=0.5971
2025-02-06 18:12:55,083 - INFO - #################### Training epoch 136 ####################
2025-02-06 18:12:55,083 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:12:55,485 - INFO - Epoch 136: train_loss=0.7183
2025-02-06 18:12:55,777 - INFO - Epoch 136: train_loss=0.6483
2025-02-06 18:12:56,090 - INFO - Epoch 136: val_loss=2.0973, val_acc=33.33%
2025-02-06 18:12:56,094 - INFO - Epoch 136: EPOCH_AVG_TRAIN_LOSS=0.6483
2025-02-06 18:12:56,096 - INFO - #################### Training epoch 137 ####################
2025-02-06 18:12:56,096 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:12:56,497 - INFO - Epoch 137: train_loss=0.8090
2025-02-06 18:12:56,788 - INFO - Epoch 137: train_loss=0.4822
2025-02-06 18:12:57,106 - INFO - Epoch 137: val_loss=2.0907, val_acc=33.33%
2025-02-06 18:12:57,110 - INFO - Epoch 137: EPOCH_AVG_TRAIN_LOSS=0.4822
2025-02-06 18:12:57,112 - INFO - #################### Training epoch 138 ####################
2025-02-06 18:12:57,112 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:12:57,515 - INFO - Epoch 138: train_loss=0.7463
2025-02-06 18:12:57,807 - INFO - Epoch 138: train_loss=0.5705
2025-02-06 18:12:58,124 - INFO - Epoch 138: val_loss=2.0915, val_acc=33.33%
2025-02-06 18:12:58,128 - INFO - Epoch 138: EPOCH_AVG_TRAIN_LOSS=0.5705
2025-02-06 18:12:58,130 - INFO - #################### Training epoch 139 ####################
2025-02-06 18:12:58,130 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:12:58,530 - INFO - Epoch 139: train_loss=0.6579
2025-02-06 18:12:58,822 - INFO - Epoch 139: train_loss=0.7923
2025-02-06 18:12:59,136 - INFO - Epoch 139: val_loss=2.0908, val_acc=33.33%
2025-02-06 18:12:59,140 - INFO - Epoch 139: EPOCH_AVG_TRAIN_LOSS=0.6579
2025-02-06 18:12:59,142 - INFO - #################### Training epoch 140 ####################
2025-02-06 18:12:59,142 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:12:59,542 - INFO - Epoch 140: train_loss=0.5456
2025-02-06 18:12:59,833 - INFO - Epoch 140: train_loss=0.9224
2025-02-06 18:13:00,150 - INFO - Epoch 140: val_loss=2.0947, val_acc=33.33%
2025-02-06 18:13:00,154 - INFO - Epoch 140: EPOCH_AVG_TRAIN_LOSS=0.5456
2025-02-06 18:13:00,156 - INFO - #################### Training epoch 141 ####################
2025-02-06 18:13:00,156 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:13:00,556 - INFO - Epoch 141: train_loss=0.8285
2025-02-06 18:13:00,848 - INFO - Epoch 141: train_loss=0.4877
2025-02-06 18:13:01,165 - INFO - Epoch 141: val_loss=2.1109, val_acc=33.33%
2025-02-06 18:13:01,169 - INFO - Epoch 141: EPOCH_AVG_TRAIN_LOSS=0.4877
2025-02-06 18:13:01,171 - INFO - #################### Training epoch 142 ####################
2025-02-06 18:13:01,171 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:13:01,571 - INFO - Epoch 142: train_loss=0.6108
2025-02-06 18:13:01,862 - INFO - Epoch 142: train_loss=0.9246
2025-02-06 18:13:02,178 - INFO - Epoch 142: val_loss=2.0880, val_acc=33.33%
2025-02-06 18:13:02,182 - INFO - Epoch 142: EPOCH_AVG_TRAIN_LOSS=0.6108
2025-02-06 18:13:02,184 - INFO - #################### Training epoch 143 ####################
2025-02-06 18:13:02,184 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:13:02,585 - INFO - Epoch 143: train_loss=0.6918
2025-02-06 18:13:02,877 - INFO - Epoch 143: train_loss=0.6740
2025-02-06 18:13:03,195 - INFO - Epoch 143: val_loss=2.0842, val_acc=33.33%
2025-02-06 18:13:03,198 - INFO - Epoch 143: EPOCH_AVG_TRAIN_LOSS=0.6740
2025-02-06 18:13:03,200 - INFO - #################### Training epoch 144 ####################
2025-02-06 18:13:03,201 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:13:03,602 - INFO - Epoch 144: train_loss=0.7092
2025-02-06 18:13:03,893 - INFO - Epoch 144: train_loss=0.6077
2025-02-06 18:13:04,210 - INFO - Epoch 144: val_loss=2.1169, val_acc=33.33%
2025-02-06 18:13:04,214 - INFO - Epoch 144: EPOCH_AVG_TRAIN_LOSS=0.6077
2025-02-06 18:13:04,216 - INFO - #################### Training epoch 145 ####################
2025-02-06 18:13:04,216 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:13:04,621 - INFO - Epoch 145: train_loss=0.7522
2025-02-06 18:13:04,912 - INFO - Epoch 145: train_loss=0.5882
2025-02-06 18:13:05,230 - INFO - Epoch 145: val_loss=2.1171, val_acc=33.33%
2025-02-06 18:13:05,234 - INFO - Epoch 145: EPOCH_AVG_TRAIN_LOSS=0.5882
2025-02-06 18:13:05,236 - INFO - #################### Training epoch 146 ####################
2025-02-06 18:13:05,236 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:13:05,639 - INFO - Epoch 146: train_loss=0.7173
2025-02-06 18:13:05,931 - INFO - Epoch 146: train_loss=0.5918
2025-02-06 18:13:06,251 - INFO - Epoch 146: val_loss=2.1110, val_acc=33.33%
2025-02-06 18:13:06,254 - INFO - Epoch 146: EPOCH_AVG_TRAIN_LOSS=0.5918
2025-02-06 18:13:06,257 - INFO - #################### Training epoch 147 ####################
2025-02-06 18:13:06,257 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:06,659 - INFO - Epoch 147: train_loss=0.7601
2025-02-06 18:13:06,951 - INFO - Epoch 147: train_loss=0.5461
2025-02-06 18:13:07,267 - INFO - Epoch 147: val_loss=2.0667, val_acc=33.33%
2025-02-06 18:13:07,271 - INFO - Epoch 147: EPOCH_AVG_TRAIN_LOSS=0.5461
2025-02-06 18:13:07,273 - INFO - #################### Training epoch 148 ####################
2025-02-06 18:13:07,273 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:07,674 - INFO - Epoch 148: train_loss=0.7548
2025-02-06 18:13:07,965 - INFO - Epoch 148: train_loss=0.4718
2025-02-06 18:13:08,283 - INFO - Epoch 148: val_loss=2.1298, val_acc=33.33%
2025-02-06 18:13:08,287 - INFO - Epoch 148: EPOCH_AVG_TRAIN_LOSS=0.4718
2025-02-06 18:13:08,289 - INFO - #################### Training epoch 149 ####################
2025-02-06 18:13:08,289 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:08,690 - INFO - Epoch 149: train_loss=0.8301
2025-02-06 18:13:08,981 - INFO - Epoch 149: train_loss=0.4265
2025-02-06 18:13:09,299 - INFO - Epoch 149: val_loss=2.0654, val_acc=33.33%
2025-02-06 18:13:09,302 - INFO - Epoch 149: EPOCH_AVG_TRAIN_LOSS=0.4265
2025-02-06 18:13:09,305 - INFO - #################### Training epoch 150 ####################
2025-02-06 18:13:09,305 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:09,705 - INFO - Epoch 150: train_loss=0.7121
2025-02-06 18:13:09,997 - INFO - Epoch 150: train_loss=0.7057
2025-02-06 18:13:10,313 - INFO - Epoch 150: val_loss=2.1171, val_acc=33.33%
2025-02-06 18:13:10,317 - INFO - Epoch 150: EPOCH_AVG_TRAIN_LOSS=0.7057
2025-02-06 18:13:10,319 - INFO - #################### Training epoch 151 ####################
2025-02-06 18:13:10,319 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:10,723 - INFO - Epoch 151: train_loss=0.6407
2025-02-06 18:13:11,014 - INFO - Epoch 151: train_loss=0.7414
2025-02-06 18:13:11,330 - INFO - Epoch 151: val_loss=2.1402, val_acc=33.33%
2025-02-06 18:13:11,334 - INFO - Epoch 151: EPOCH_AVG_TRAIN_LOSS=0.6407
2025-02-06 18:13:11,336 - INFO - #################### Training epoch 152 ####################
2025-02-06 18:13:11,336 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:11,736 - INFO - Epoch 152: train_loss=0.7807
2025-02-06 18:13:12,029 - INFO - Epoch 152: train_loss=0.4041
2025-02-06 18:13:12,345 - INFO - Epoch 152: val_loss=2.0910, val_acc=33.33%
2025-02-06 18:13:12,349 - INFO - Epoch 152: EPOCH_AVG_TRAIN_LOSS=0.4041
2025-02-06 18:13:12,352 - INFO - #################### Training epoch 153 ####################
2025-02-06 18:13:12,352 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:12,754 - INFO - Epoch 153: train_loss=0.6997
2025-02-06 18:13:13,046 - INFO - Epoch 153: train_loss=0.6636
2025-02-06 18:13:13,365 - INFO - Epoch 153: val_loss=2.1109, val_acc=33.33%
2025-02-06 18:13:13,369 - INFO - Epoch 153: EPOCH_AVG_TRAIN_LOSS=0.6636
2025-02-06 18:13:13,371 - INFO - #################### Training epoch 154 ####################
2025-02-06 18:13:13,371 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:13,776 - INFO - Epoch 154: train_loss=0.7520
2025-02-06 18:13:14,068 - INFO - Epoch 154: train_loss=0.6332
2025-02-06 18:13:14,384 - INFO - Epoch 154: val_loss=2.1121, val_acc=33.33%
2025-02-06 18:13:14,387 - INFO - Epoch 154: EPOCH_AVG_TRAIN_LOSS=0.6332
2025-02-06 18:13:14,390 - INFO - #################### Training epoch 155 ####################
2025-02-06 18:13:14,390 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:14,792 - INFO - Epoch 155: train_loss=0.7938
2025-02-06 18:13:15,084 - INFO - Epoch 155: train_loss=0.4521
2025-02-06 18:13:15,405 - INFO - Epoch 155: val_loss=2.0954, val_acc=33.33%
2025-02-06 18:13:15,409 - INFO - Epoch 155: EPOCH_AVG_TRAIN_LOSS=0.4521
2025-02-06 18:13:15,411 - INFO - #################### Training epoch 156 ####################
2025-02-06 18:13:15,411 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:15,812 - INFO - Epoch 156: train_loss=0.5181
2025-02-06 18:13:16,104 - INFO - Epoch 156: train_loss=1.0392
2025-02-06 18:13:16,423 - INFO - Epoch 156: val_loss=2.1023, val_acc=33.33%
2025-02-06 18:13:16,427 - INFO - Epoch 156: EPOCH_AVG_TRAIN_LOSS=0.5181
2025-02-06 18:13:16,429 - INFO - #################### Training epoch 157 ####################
2025-02-06 18:13:16,429 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:13:16,829 - INFO - Epoch 157: train_loss=0.6505
2025-02-06 18:13:17,120 - INFO - Epoch 157: train_loss=0.8053
2025-02-06 18:13:17,440 - INFO - Epoch 157: val_loss=2.0833, val_acc=33.33%
2025-02-06 18:13:17,444 - INFO - Epoch 157: EPOCH_AVG_TRAIN_LOSS=0.6505
2025-02-06 18:13:17,447 - INFO - #################### Training epoch 158 ####################
2025-02-06 18:13:17,447 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:17,850 - INFO - Epoch 158: train_loss=0.6580
2025-02-06 18:13:18,141 - INFO - Epoch 158: train_loss=0.6873
2025-02-06 18:13:18,460 - INFO - Epoch 158: val_loss=2.0835, val_acc=33.33%
2025-02-06 18:13:18,464 - INFO - Epoch 158: EPOCH_AVG_TRAIN_LOSS=0.6580
2025-02-06 18:13:18,466 - INFO - #################### Training epoch 159 ####################
2025-02-06 18:13:18,466 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:18,865 - INFO - Epoch 159: train_loss=0.7444
2025-02-06 18:13:19,157 - INFO - Epoch 159: train_loss=0.5895
2025-02-06 18:13:19,473 - INFO - Epoch 159: val_loss=2.0921, val_acc=33.33%
2025-02-06 18:13:19,477 - INFO - Epoch 159: EPOCH_AVG_TRAIN_LOSS=0.5895
2025-02-06 18:13:19,479 - INFO - #################### Training epoch 160 ####################
2025-02-06 18:13:19,479 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:19,883 - INFO - Epoch 160: train_loss=0.5789
2025-02-06 18:13:20,175 - INFO - Epoch 160: train_loss=0.9450
2025-02-06 18:13:20,492 - INFO - Epoch 160: val_loss=2.1112, val_acc=33.33%
2025-02-06 18:13:20,496 - INFO - Epoch 160: EPOCH_AVG_TRAIN_LOSS=0.5789
2025-02-06 18:13:20,498 - INFO - #################### Training epoch 161 ####################
2025-02-06 18:13:20,498 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:20,904 - INFO - Epoch 161: train_loss=0.7293
2025-02-06 18:13:21,195 - INFO - Epoch 161: train_loss=0.5779
2025-02-06 18:13:21,508 - INFO - Epoch 161: val_loss=2.1055, val_acc=33.33%
2025-02-06 18:13:21,512 - INFO - Epoch 161: EPOCH_AVG_TRAIN_LOSS=0.5779
2025-02-06 18:13:21,514 - INFO - #################### Training epoch 162 ####################
2025-02-06 18:13:21,514 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:21,915 - INFO - Epoch 162: train_loss=0.6310
2025-02-06 18:13:22,206 - INFO - Epoch 162: train_loss=0.8169
2025-02-06 18:13:22,523 - INFO - Epoch 162: val_loss=2.1013, val_acc=33.33%
2025-02-06 18:13:22,528 - INFO - Epoch 162: EPOCH_AVG_TRAIN_LOSS=0.6310
2025-02-06 18:13:22,530 - INFO - #################### Training epoch 163 ####################
2025-02-06 18:13:22,530 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:22,931 - INFO - Epoch 163: train_loss=0.6793
2025-02-06 18:13:23,223 - INFO - Epoch 163: train_loss=0.6755
2025-02-06 18:13:23,539 - INFO - Epoch 163: val_loss=2.0780, val_acc=33.33%
2025-02-06 18:13:23,543 - INFO - Epoch 163: EPOCH_AVG_TRAIN_LOSS=0.6755
2025-02-06 18:13:23,545 - INFO - #################### Training epoch 164 ####################
2025-02-06 18:13:23,545 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:23,946 - INFO - Epoch 164: train_loss=0.7586
2025-02-06 18:13:24,237 - INFO - Epoch 164: train_loss=0.5239
2025-02-06 18:13:24,550 - INFO - Epoch 164: val_loss=2.1088, val_acc=33.33%
2025-02-06 18:13:24,554 - INFO - Epoch 164: EPOCH_AVG_TRAIN_LOSS=0.5239
2025-02-06 18:13:24,556 - INFO - #################### Training epoch 165 ####################
2025-02-06 18:13:24,556 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:24,955 - INFO - Epoch 165: train_loss=0.7300
2025-02-06 18:13:25,246 - INFO - Epoch 165: train_loss=0.5996
2025-02-06 18:13:25,561 - INFO - Epoch 165: val_loss=2.0671, val_acc=33.33%
2025-02-06 18:13:25,565 - INFO - Epoch 165: EPOCH_AVG_TRAIN_LOSS=0.5996
2025-02-06 18:13:25,567 - INFO - #################### Training epoch 166 ####################
2025-02-06 18:13:25,567 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:25,970 - INFO - Epoch 166: train_loss=0.5326
2025-02-06 18:13:26,261 - INFO - Epoch 166: train_loss=1.0568
2025-02-06 18:13:26,575 - INFO - Epoch 166: val_loss=2.0834, val_acc=33.33%
2025-02-06 18:13:26,578 - INFO - Epoch 166: EPOCH_AVG_TRAIN_LOSS=0.5326
2025-02-06 18:13:26,581 - INFO - #################### Training epoch 167 ####################
2025-02-06 18:13:26,581 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:26,979 - INFO - Epoch 167: train_loss=0.6371
2025-02-06 18:13:27,271 - INFO - Epoch 167: train_loss=0.7284
2025-02-06 18:13:27,587 - INFO - Epoch 167: val_loss=2.0966, val_acc=33.33%
2025-02-06 18:13:27,590 - INFO - Epoch 167: EPOCH_AVG_TRAIN_LOSS=0.6371
2025-02-06 18:13:27,593 - INFO - #################### Training epoch 168 ####################
2025-02-06 18:13:27,593 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:13:27,992 - INFO - Epoch 168: train_loss=0.6321
2025-02-06 18:13:28,284 - INFO - Epoch 168: train_loss=0.7358
2025-02-06 18:13:28,597 - INFO - Epoch 168: val_loss=2.0677, val_acc=33.33%
2025-02-06 18:13:28,601 - INFO - Epoch 168: EPOCH_AVG_TRAIN_LOSS=0.6321
2025-02-06 18:13:28,604 - INFO - #################### Training epoch 169 ####################
2025-02-06 18:13:28,604 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:29,005 - INFO - Epoch 169: train_loss=0.5928
2025-02-06 18:13:29,297 - INFO - Epoch 169: train_loss=0.9302
2025-02-06 18:13:29,613 - INFO - Epoch 169: val_loss=2.0910, val_acc=33.33%
2025-02-06 18:13:29,617 - INFO - Epoch 169: EPOCH_AVG_TRAIN_LOSS=0.5928
2025-02-06 18:13:29,619 - INFO - #################### Training epoch 170 ####################
2025-02-06 18:13:29,619 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:30,018 - INFO - Epoch 170: train_loss=0.7586
2025-02-06 18:13:30,309 - INFO - Epoch 170: train_loss=0.6267
2025-02-06 18:13:30,624 - INFO - Epoch 170: val_loss=2.0943, val_acc=33.33%
2025-02-06 18:13:30,628 - INFO - Epoch 170: EPOCH_AVG_TRAIN_LOSS=0.6267
2025-02-06 18:13:30,630 - INFO - #################### Training epoch 171 ####################
2025-02-06 18:13:30,630 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:31,034 - INFO - Epoch 171: train_loss=0.7968
2025-02-06 18:13:31,325 - INFO - Epoch 171: train_loss=0.5049
2025-02-06 18:13:31,640 - INFO - Epoch 171: val_loss=2.0765, val_acc=33.33%
2025-02-06 18:13:31,644 - INFO - Epoch 171: EPOCH_AVG_TRAIN_LOSS=0.5049
2025-02-06 18:13:31,646 - INFO - #################### Training epoch 172 ####################
2025-02-06 18:13:31,646 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:32,050 - INFO - Epoch 172: train_loss=0.6779
2025-02-06 18:13:32,342 - INFO - Epoch 172: train_loss=0.6759
2025-02-06 18:13:32,659 - INFO - Epoch 172: val_loss=2.0582, val_acc=33.33%
2025-02-06 18:13:32,663 - INFO - Epoch 172: EPOCH_AVG_TRAIN_LOSS=0.6759
2025-02-06 18:13:32,665 - INFO - #################### Training epoch 173 ####################
2025-02-06 18:13:32,665 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:33,067 - INFO - Epoch 173: train_loss=0.6674
2025-02-06 18:13:33,358 - INFO - Epoch 173: train_loss=0.7383
2025-02-06 18:13:33,672 - INFO - Epoch 173: val_loss=2.0934, val_acc=33.33%
2025-02-06 18:13:33,676 - INFO - Epoch 173: EPOCH_AVG_TRAIN_LOSS=0.6674
2025-02-06 18:13:33,678 - INFO - #################### Training epoch 174 ####################
2025-02-06 18:13:33,678 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:34,082 - INFO - Epoch 174: train_loss=0.7981
2025-02-06 18:13:34,373 - INFO - Epoch 174: train_loss=0.4566
2025-02-06 18:13:34,685 - INFO - Epoch 174: val_loss=2.1005, val_acc=33.33%
2025-02-06 18:13:34,689 - INFO - Epoch 174: EPOCH_AVG_TRAIN_LOSS=0.4566
2025-02-06 18:13:34,691 - INFO - #################### Training epoch 175 ####################
2025-02-06 18:13:34,691 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:35,094 - INFO - Epoch 175: train_loss=0.7577
2025-02-06 18:13:35,385 - INFO - Epoch 175: train_loss=0.5573
2025-02-06 18:13:35,696 - INFO - Epoch 175: val_loss=2.1098, val_acc=33.33%
2025-02-06 18:13:35,699 - INFO - Epoch 175: EPOCH_AVG_TRAIN_LOSS=0.5573
2025-02-06 18:13:35,701 - INFO - #################### Training epoch 176 ####################
2025-02-06 18:13:35,702 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:36,104 - INFO - Epoch 176: train_loss=0.6592
2025-02-06 18:13:36,395 - INFO - Epoch 176: train_loss=0.8368
2025-02-06 18:13:36,709 - INFO - Epoch 176: val_loss=2.1162, val_acc=33.33%
2025-02-06 18:13:36,712 - INFO - Epoch 176: EPOCH_AVG_TRAIN_LOSS=0.6592
2025-02-06 18:13:36,715 - INFO - #################### Training epoch 177 ####################
2025-02-06 18:13:36,715 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:37,118 - INFO - Epoch 177: train_loss=0.6421
2025-02-06 18:13:37,409 - INFO - Epoch 177: train_loss=0.8593
2025-02-06 18:13:37,724 - INFO - Epoch 177: val_loss=2.0905, val_acc=33.33%
2025-02-06 18:13:37,728 - INFO - Epoch 177: EPOCH_AVG_TRAIN_LOSS=0.6421
2025-02-06 18:13:37,730 - INFO - #################### Training epoch 178 ####################
2025-02-06 18:13:37,730 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:38,134 - INFO - Epoch 178: train_loss=0.5416
2025-02-06 18:13:38,425 - INFO - Epoch 178: train_loss=0.9759
2025-02-06 18:13:38,739 - INFO - Epoch 178: val_loss=2.1003, val_acc=33.33%
2025-02-06 18:13:38,743 - INFO - Epoch 178: EPOCH_AVG_TRAIN_LOSS=0.5416
2025-02-06 18:13:38,745 - INFO - #################### Training epoch 179 ####################
2025-02-06 18:13:38,745 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:13:39,148 - INFO - Epoch 179: train_loss=0.6311
2025-02-06 18:13:39,440 - INFO - Epoch 179: train_loss=0.9677
2025-02-06 18:13:39,760 - INFO - Epoch 179: val_loss=2.1018, val_acc=33.33%
2025-02-06 18:13:39,764 - INFO - Epoch 179: EPOCH_AVG_TRAIN_LOSS=0.6311
2025-02-06 18:13:39,766 - INFO - #################### Training epoch 180 ####################
2025-02-06 18:13:39,766 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:40,172 - INFO - Epoch 180: train_loss=0.6459
2025-02-06 18:13:40,463 - INFO - Epoch 180: train_loss=0.7876
2025-02-06 18:13:40,781 - INFO - Epoch 180: val_loss=2.1149, val_acc=33.33%
2025-02-06 18:13:40,785 - INFO - Epoch 180: EPOCH_AVG_TRAIN_LOSS=0.6459
2025-02-06 18:13:40,787 - INFO - #################### Training epoch 181 ####################
2025-02-06 18:13:40,787 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:41,189 - INFO - Epoch 181: train_loss=0.5426
2025-02-06 18:13:41,480 - INFO - Epoch 181: train_loss=1.0320
2025-02-06 18:13:41,798 - INFO - Epoch 181: val_loss=2.1167, val_acc=33.33%
2025-02-06 18:13:41,802 - INFO - Epoch 181: EPOCH_AVG_TRAIN_LOSS=0.5426
2025-02-06 18:13:41,804 - INFO - #################### Training epoch 182 ####################
2025-02-06 18:13:41,804 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:42,208 - INFO - Epoch 182: train_loss=0.6045
2025-02-06 18:13:42,499 - INFO - Epoch 182: train_loss=0.8901
2025-02-06 18:13:42,816 - INFO - Epoch 182: val_loss=2.1213, val_acc=33.33%
2025-02-06 18:13:42,820 - INFO - Epoch 182: EPOCH_AVG_TRAIN_LOSS=0.6045
2025-02-06 18:13:42,822 - INFO - #################### Training epoch 183 ####################
2025-02-06 18:13:42,822 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:43,225 - INFO - Epoch 183: train_loss=0.6327
2025-02-06 18:13:43,516 - INFO - Epoch 183: train_loss=0.8071
2025-02-06 18:13:43,833 - INFO - Epoch 183: val_loss=2.1160, val_acc=33.33%
2025-02-06 18:13:43,837 - INFO - Epoch 183: EPOCH_AVG_TRAIN_LOSS=0.6327
2025-02-06 18:13:43,839 - INFO - #################### Training epoch 184 ####################
2025-02-06 18:13:43,839 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:44,239 - INFO - Epoch 184: train_loss=0.7205
2025-02-06 18:13:44,530 - INFO - Epoch 184: train_loss=0.5898
2025-02-06 18:13:44,849 - INFO - Epoch 184: val_loss=2.0875, val_acc=33.33%
2025-02-06 18:13:44,853 - INFO - Epoch 184: EPOCH_AVG_TRAIN_LOSS=0.5898
2025-02-06 18:13:44,855 - INFO - #################### Training epoch 185 ####################
2025-02-06 18:13:44,855 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:45,257 - INFO - Epoch 185: train_loss=0.5096
2025-02-06 18:13:45,548 - INFO - Epoch 185: train_loss=1.0177
2025-02-06 18:13:45,870 - INFO - Epoch 185: val_loss=2.0848, val_acc=33.33%
2025-02-06 18:13:45,874 - INFO - Epoch 185: EPOCH_AVG_TRAIN_LOSS=0.5096
2025-02-06 18:13:45,876 - INFO - #################### Training epoch 186 ####################
2025-02-06 18:13:45,876 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:46,281 - INFO - Epoch 186: train_loss=0.6823
2025-02-06 18:13:46,572 - INFO - Epoch 186: train_loss=0.6320
2025-02-06 18:13:46,890 - INFO - Epoch 186: val_loss=2.1007, val_acc=33.33%
2025-02-06 18:13:46,894 - INFO - Epoch 186: EPOCH_AVG_TRAIN_LOSS=0.6320
2025-02-06 18:13:46,896 - INFO - #################### Training epoch 187 ####################
2025-02-06 18:13:46,896 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:47,298 - INFO - Epoch 187: train_loss=0.7093
2025-02-06 18:13:47,589 - INFO - Epoch 187: train_loss=0.5888
2025-02-06 18:13:47,911 - INFO - Epoch 187: val_loss=2.0886, val_acc=33.33%
2025-02-06 18:13:47,915 - INFO - Epoch 187: EPOCH_AVG_TRAIN_LOSS=0.5888
2025-02-06 18:13:47,917 - INFO - #################### Training epoch 188 ####################
2025-02-06 18:13:47,917 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:48,323 - INFO - Epoch 188: train_loss=0.5023
2025-02-06 18:13:48,615 - INFO - Epoch 188: train_loss=1.0890
2025-02-06 18:13:48,933 - INFO - Epoch 188: val_loss=2.1292, val_acc=33.33%
2025-02-06 18:13:48,937 - INFO - Epoch 188: EPOCH_AVG_TRAIN_LOSS=0.5023
2025-02-06 18:13:48,939 - INFO - #################### Training epoch 189 ####################
2025-02-06 18:13:48,939 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:49,340 - INFO - Epoch 189: train_loss=0.6835
2025-02-06 18:13:49,631 - INFO - Epoch 189: train_loss=0.7102
2025-02-06 18:13:49,948 - INFO - Epoch 189: val_loss=2.1037, val_acc=33.33%
2025-02-06 18:13:49,952 - INFO - Epoch 189: EPOCH_AVG_TRAIN_LOSS=0.6835
2025-02-06 18:13:49,955 - INFO - #################### Training epoch 190 ####################
2025-02-06 18:13:49,955 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:13:50,358 - INFO - Epoch 190: train_loss=0.5304
2025-02-06 18:13:50,650 - INFO - Epoch 190: train_loss=0.9516
2025-02-06 18:13:50,969 - INFO - Epoch 190: val_loss=2.1100, val_acc=33.33%
2025-02-06 18:13:50,973 - INFO - Epoch 190: EPOCH_AVG_TRAIN_LOSS=0.5304
2025-02-06 18:13:50,975 - INFO - #################### Training epoch 191 ####################
2025-02-06 18:13:50,975 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:13:51,380 - INFO - Epoch 191: train_loss=0.7673
2025-02-06 18:13:51,671 - INFO - Epoch 191: train_loss=0.5344
2025-02-06 18:13:51,991 - INFO - Epoch 191: val_loss=2.0786, val_acc=33.33%
2025-02-06 18:13:51,994 - INFO - Epoch 191: EPOCH_AVG_TRAIN_LOSS=0.5344
2025-02-06 18:13:51,997 - INFO - #################### Training epoch 192 ####################
2025-02-06 18:13:51,997 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:13:52,398 - INFO - Epoch 192: train_loss=0.6642
2025-02-06 18:13:52,689 - INFO - Epoch 192: train_loss=0.7538
2025-02-06 18:13:53,005 - INFO - Epoch 192: val_loss=2.0793, val_acc=33.33%
2025-02-06 18:13:53,008 - INFO - Epoch 192: EPOCH_AVG_TRAIN_LOSS=0.6642
2025-02-06 18:13:53,011 - INFO - #################### Training epoch 193 ####################
2025-02-06 18:13:53,011 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:13:53,414 - INFO - Epoch 193: train_loss=0.7791
2025-02-06 18:13:53,705 - INFO - Epoch 193: train_loss=0.5030
2025-02-06 18:13:54,023 - INFO - Epoch 193: val_loss=2.1146, val_acc=33.33%
2025-02-06 18:13:54,027 - INFO - Epoch 193: EPOCH_AVG_TRAIN_LOSS=0.5030
2025-02-06 18:13:54,029 - INFO - #################### Training epoch 194 ####################
2025-02-06 18:13:54,029 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:13:54,434 - INFO - Epoch 194: train_loss=0.6958
2025-02-06 18:13:54,725 - INFO - Epoch 194: train_loss=0.5683
2025-02-06 18:13:55,045 - INFO - Epoch 194: val_loss=2.0873, val_acc=33.33%
2025-02-06 18:13:55,049 - INFO - Epoch 194: EPOCH_AVG_TRAIN_LOSS=0.5683
2025-02-06 18:13:55,051 - INFO - #################### Training epoch 195 ####################
2025-02-06 18:13:55,051 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:13:55,452 - INFO - Epoch 195: train_loss=0.8263
2025-02-06 18:13:55,743 - INFO - Epoch 195: train_loss=0.4731
2025-02-06 18:13:56,057 - INFO - Epoch 195: val_loss=2.0914, val_acc=33.33%
2025-02-06 18:13:56,061 - INFO - Epoch 195: EPOCH_AVG_TRAIN_LOSS=0.4731
2025-02-06 18:13:56,063 - INFO - #################### Training epoch 196 ####################
2025-02-06 18:13:56,063 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:13:56,464 - INFO - Epoch 196: train_loss=0.8156
2025-02-06 18:13:56,755 - INFO - Epoch 196: train_loss=0.4194
2025-02-06 18:13:57,073 - INFO - Epoch 196: val_loss=2.1158, val_acc=33.33%
2025-02-06 18:13:57,077 - INFO - Epoch 196: EPOCH_AVG_TRAIN_LOSS=0.4194
2025-02-06 18:13:57,079 - INFO - #################### Training epoch 197 ####################
2025-02-06 18:13:57,079 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:13:57,481 - INFO - Epoch 197: train_loss=0.7364
2025-02-06 18:13:57,772 - INFO - Epoch 197: train_loss=0.5069
2025-02-06 18:13:58,092 - INFO - Epoch 197: val_loss=2.1012, val_acc=33.33%
2025-02-06 18:13:58,096 - INFO - Epoch 197: EPOCH_AVG_TRAIN_LOSS=0.5069
2025-02-06 18:13:58,098 - INFO - #################### Training epoch 198 ####################
2025-02-06 18:13:58,098 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:13:58,498 - INFO - Epoch 198: train_loss=0.5272
2025-02-06 18:13:58,790 - INFO - Epoch 198: train_loss=0.9282
2025-02-06 18:13:59,105 - INFO - Epoch 198: val_loss=2.0777, val_acc=33.33%
2025-02-06 18:13:59,109 - INFO - Epoch 198: EPOCH_AVG_TRAIN_LOSS=0.5272
2025-02-06 18:13:59,111 - INFO - #################### Training epoch 199 ####################
2025-02-06 18:13:59,111 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:13:59,514 - INFO - Epoch 199: train_loss=0.7633
2025-02-06 18:13:59,805 - INFO - Epoch 199: train_loss=0.5523
2025-02-06 18:14:00,121 - INFO - Epoch 199: val_loss=2.1124, val_acc=33.33%
2025-02-06 18:14:00,125 - INFO - Epoch 199: EPOCH_AVG_TRAIN_LOSS=0.5523
2025-02-06 18:14:00,294 - INFO - Model saved.
