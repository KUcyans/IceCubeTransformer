2025-02-06 17:53:14,990 - INFO - Starting training with the following parameters:
2025-02-06 17:53:14,991 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product|
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.001          |
| epochs          | 200            |
| batch_size      | 16             |

2025-02-06 17:53:15,595 - INFO - Epoch 0: val_loss=213145088.0000, val_acc=33.33%
2025-02-06 17:53:15,733 - INFO - #################### Training epoch 0 ####################
2025-02-06 17:53:15,733 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:15,980 - INFO - Epoch 0: train_loss=155750816.0000
2025-02-06 17:53:16,336 - INFO - Epoch 0: train_loss=201490096.0000
2025-02-06 17:53:16,631 - INFO - Epoch 0: val_loss=145796816.0000, val_acc=66.67%
2025-02-06 17:53:18,418 - INFO - Epoch 0: EPOCH_AVG_TRAIN_LOSS=155750816.0000
2025-02-06 17:53:18,447 - INFO - #################### Training epoch 1 ####################
2025-02-06 17:53:18,447 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:18,849 - INFO - Epoch 1: train_loss=169160128.0000
2025-02-06 17:53:19,144 - INFO - Epoch 1: train_loss=208548640.0000
2025-02-06 17:53:19,461 - INFO - Epoch 1: val_loss=89361416.0000, val_acc=0.00%
2025-02-06 17:53:19,465 - INFO - Epoch 1: EPOCH_AVG_TRAIN_LOSS=169160128.0000
2025-02-06 17:53:19,493 - INFO - #################### Training epoch 2 ####################
2025-02-06 17:53:19,493 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:19,889 - INFO - Epoch 2: train_loss=92924416.0000
2025-02-06 17:53:20,179 - INFO - Epoch 2: train_loss=88381368.0000
2025-02-06 17:53:20,495 - INFO - Epoch 2: val_loss=171964112.0000, val_acc=33.33%
2025-02-06 17:53:20,499 - INFO - Epoch 2: EPOCH_AVG_TRAIN_LOSS=88381368.0000
2025-02-06 17:53:20,524 - INFO - #################### Training epoch 3 ####################
2025-02-06 17:53:20,524 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:20,925 - INFO - Epoch 3: train_loss=154828496.0000
2025-02-06 17:53:21,215 - INFO - Epoch 3: train_loss=164434160.0000
2025-02-06 17:53:21,533 - INFO - Epoch 3: val_loss=200339072.0000, val_acc=33.33%
2025-02-06 17:53:21,536 - INFO - Epoch 3: EPOCH_AVG_TRAIN_LOSS=154828496.0000
2025-02-06 17:53:21,539 - INFO - #################### Training epoch 4 ####################
2025-02-06 17:53:21,539 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:21,940 - INFO - Epoch 4: train_loss=176471984.0000
2025-02-06 17:53:22,230 - INFO - Epoch 4: train_loss=153903392.0000
2025-02-06 17:53:22,543 - INFO - Epoch 4: val_loss=48320380.0000, val_acc=33.33%
2025-02-06 17:53:22,547 - INFO - Epoch 4: EPOCH_AVG_TRAIN_LOSS=153903392.0000
2025-02-06 17:53:22,576 - INFO - #################### Training epoch 5 ####################
2025-02-06 17:53:22,576 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:22,978 - INFO - Epoch 5: train_loss=65689432.0000
2025-02-06 17:53:23,267 - INFO - Epoch 5: train_loss=69898096.0000
2025-02-06 17:53:23,587 - INFO - Epoch 5: val_loss=95818536.0000, val_acc=0.00%
2025-02-06 17:53:23,590 - INFO - Epoch 5: EPOCH_AVG_TRAIN_LOSS=65689432.0000
2025-02-06 17:53:23,635 - INFO - #################### Training epoch 6 ####################
2025-02-06 17:53:23,635 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:24,036 - INFO - Epoch 6: train_loss=87415232.0000
2025-02-06 17:53:24,327 - INFO - Epoch 6: train_loss=96996120.0000
2025-02-06 17:53:24,645 - INFO - Epoch 6: val_loss=104167336.0000, val_acc=66.67%
2025-02-06 17:53:24,648 - INFO - Epoch 6: EPOCH_AVG_TRAIN_LOSS=87415232.0000
2025-02-06 17:53:24,651 - INFO - #################### Training epoch 7 ####################
2025-02-06 17:53:24,651 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:25,053 - INFO - Epoch 7: train_loss=143795904.0000
2025-02-06 17:53:25,342 - INFO - Epoch 7: train_loss=96216448.0000
2025-02-06 17:53:25,663 - INFO - Epoch 7: val_loss=84305256.0000, val_acc=66.67%
2025-02-06 17:53:25,666 - INFO - Epoch 7: EPOCH_AVG_TRAIN_LOSS=96216448.0000
2025-02-06 17:53:25,697 - INFO - #################### Training epoch 8 ####################
2025-02-06 17:53:25,697 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:26,100 - INFO - Epoch 8: train_loss=126364712.0000
2025-02-06 17:53:26,391 - INFO - Epoch 8: train_loss=59530772.0000
2025-02-06 17:53:26,710 - INFO - Epoch 8: val_loss=34319304.0000, val_acc=0.00%
2025-02-06 17:53:26,714 - INFO - Epoch 8: EPOCH_AVG_TRAIN_LOSS=59530772.0000
2025-02-06 17:53:26,757 - INFO - #################### Training epoch 9 ####################
2025-02-06 17:53:26,757 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:27,155 - INFO - Epoch 9: train_loss=50214544.0000
2025-02-06 17:53:27,446 - INFO - Epoch 9: train_loss=62766216.0000
2025-02-06 17:53:27,764 - INFO - Epoch 9: val_loss=102421992.0000, val_acc=33.33%
2025-02-06 17:53:27,767 - INFO - Epoch 9: EPOCH_AVG_TRAIN_LOSS=50214544.0000
2025-02-06 17:53:27,770 - INFO - #################### Training epoch 10 ####################
2025-02-06 17:53:27,770 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:28,173 - INFO - Epoch 10: train_loss=125362040.0000
2025-02-06 17:53:28,464 - INFO - Epoch 10: train_loss=160402304.0000
2025-02-06 17:53:28,784 - INFO - Epoch 10: val_loss=152230320.0000, val_acc=33.33%
2025-02-06 17:53:28,788 - INFO - Epoch 10: EPOCH_AVG_TRAIN_LOSS=125362040.0000
2025-02-06 17:53:28,790 - INFO - #################### Training epoch 11 ####################
2025-02-06 17:53:28,790 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:29,192 - INFO - Epoch 11: train_loss=155446992.0000
2025-02-06 17:53:29,483 - INFO - Epoch 11: train_loss=120138440.0000
2025-02-06 17:53:29,803 - INFO - Epoch 11: val_loss=93494056.0000, val_acc=33.33%
2025-02-06 17:53:29,807 - INFO - Epoch 11: EPOCH_AVG_TRAIN_LOSS=120138440.0000
2025-02-06 17:53:29,809 - INFO - #################### Training epoch 12 ####################
2025-02-06 17:53:29,809 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:30,213 - INFO - Epoch 12: train_loss=70952336.0000
2025-02-06 17:53:30,504 - INFO - Epoch 12: train_loss=44020824.0000
2025-02-06 17:53:30,822 - INFO - Epoch 12: val_loss=24614854.0000, val_acc=0.00%
2025-02-06 17:53:30,826 - INFO - Epoch 12: EPOCH_AVG_TRAIN_LOSS=44020824.0000
2025-02-06 17:53:30,857 - INFO - #################### Training epoch 13 ####################
2025-02-06 17:53:30,857 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:31,260 - INFO - Epoch 13: train_loss=34654560.0000
2025-02-06 17:53:31,551 - INFO - Epoch 13: train_loss=57372832.0000
2025-02-06 17:53:31,870 - INFO - Epoch 13: val_loss=58898688.0000, val_acc=66.67%
2025-02-06 17:53:31,874 - INFO - Epoch 13: EPOCH_AVG_TRAIN_LOSS=34654560.0000
2025-02-06 17:53:31,876 - INFO - #################### Training epoch 14 ####################
2025-02-06 17:53:31,876 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:32,279 - INFO - Epoch 14: train_loss=54722648.0000
2025-02-06 17:53:32,569 - INFO - Epoch 14: train_loss=104001032.0000
2025-02-06 17:53:32,892 - INFO - Epoch 14: val_loss=49394516.0000, val_acc=0.00%
2025-02-06 17:53:32,896 - INFO - Epoch 14: EPOCH_AVG_TRAIN_LOSS=54722648.0000
2025-02-06 17:53:32,898 - INFO - #################### Training epoch 15 ####################
2025-02-06 17:53:32,898 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:33,303 - INFO - Epoch 15: train_loss=92480672.0000
2025-02-06 17:53:33,593 - INFO - Epoch 15: train_loss=54442808.0000
2025-02-06 17:53:33,914 - INFO - Epoch 15: val_loss=32803470.0000, val_acc=0.00%
2025-02-06 17:53:33,918 - INFO - Epoch 15: EPOCH_AVG_TRAIN_LOSS=54442808.0000
2025-02-06 17:53:33,946 - INFO - #################### Training epoch 16 ####################
2025-02-06 17:53:33,946 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:34,349 - INFO - Epoch 16: train_loss=32724820.0000
2025-02-06 17:53:34,640 - INFO - Epoch 16: train_loss=32622280.0000
2025-02-06 17:53:34,959 - INFO - Epoch 16: val_loss=41917988.0000, val_acc=33.33%
2025-02-06 17:53:34,963 - INFO - Epoch 16: EPOCH_AVG_TRAIN_LOSS=32622280.0000
2025-02-06 17:53:34,965 - INFO - #################### Training epoch 17 ####################
2025-02-06 17:53:34,965 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:35,370 - INFO - Epoch 17: train_loss=34224652.0000
2025-02-06 17:53:35,661 - INFO - Epoch 17: train_loss=24247568.0000
2025-02-06 17:53:35,982 - INFO - Epoch 17: val_loss=7950141.5000, val_acc=33.33%
2025-02-06 17:53:35,986 - INFO - Epoch 17: EPOCH_AVG_TRAIN_LOSS=24247568.0000
2025-02-06 17:53:36,015 - INFO - #################### Training epoch 18 ####################
2025-02-06 17:53:36,015 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:36,419 - INFO - Epoch 18: train_loss=44950528.0000
2025-02-06 17:53:36,709 - INFO - Epoch 18: train_loss=56761000.0000
2025-02-06 17:53:37,031 - INFO - Epoch 18: val_loss=26734838.0000, val_acc=66.67%
2025-02-06 17:53:37,035 - INFO - Epoch 18: EPOCH_AVG_TRAIN_LOSS=44950528.0000
2025-02-06 17:53:37,082 - INFO - #################### Training epoch 19 ####################
2025-02-06 17:53:37,082 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:37,488 - INFO - Epoch 19: train_loss=31340074.0000
2025-02-06 17:53:37,778 - INFO - Epoch 19: train_loss=53384748.0000
2025-02-06 17:53:38,103 - INFO - Epoch 19: val_loss=63665120.0000, val_acc=0.00%
2025-02-06 17:53:38,106 - INFO - Epoch 19: EPOCH_AVG_TRAIN_LOSS=31340074.0000
2025-02-06 17:53:38,109 - INFO - #################### Training epoch 20 ####################
2025-02-06 17:53:38,109 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:38,510 - INFO - Epoch 20: train_loss=54604968.0000
2025-02-06 17:53:38,802 - INFO - Epoch 20: train_loss=27241584.0000
2025-02-06 17:53:39,125 - INFO - Epoch 20: val_loss=12713283.0000, val_acc=33.33%
2025-02-06 17:53:39,129 - INFO - Epoch 20: EPOCH_AVG_TRAIN_LOSS=27241584.0000
2025-02-06 17:53:39,159 - INFO - #################### Training epoch 21 ####################
2025-02-06 17:53:39,159 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 17:53:39,563 - INFO - Epoch 21: train_loss=16000747.0000
2025-02-06 17:53:39,853 - INFO - Epoch 21: train_loss=44907276.0000
2025-02-06 17:53:40,175 - INFO - Epoch 21: val_loss=10859328.0000, val_acc=33.33%
2025-02-06 17:53:40,179 - INFO - Epoch 21: EPOCH_AVG_TRAIN_LOSS=16000747.0000
2025-02-06 17:53:40,210 - INFO - #################### Training epoch 22 ####################
2025-02-06 17:53:40,210 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 17:53:40,615 - INFO - Epoch 22: train_loss=36961380.0000
2025-02-06 17:53:40,906 - INFO - Epoch 22: train_loss=12343521.0000
2025-02-06 17:53:41,228 - INFO - Epoch 22: val_loss=2761921.2500, val_acc=66.67%
2025-02-06 17:53:41,232 - INFO - Epoch 22: EPOCH_AVG_TRAIN_LOSS=12343521.0000
2025-02-06 17:53:41,261 - INFO - #################### Training epoch 23 ####################
2025-02-06 17:53:41,261 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 17:53:41,665 - INFO - Epoch 23: train_loss=24298788.0000
2025-02-06 17:53:41,956 - INFO - Epoch 23: train_loss=31621918.0000
2025-02-06 17:53:42,278 - INFO - Epoch 23: val_loss=24712792.0000, val_acc=0.00%
2025-02-06 17:53:42,281 - INFO - Epoch 23: EPOCH_AVG_TRAIN_LOSS=24298788.0000
2025-02-06 17:53:42,284 - INFO - #################### Training epoch 24 ####################
2025-02-06 17:53:42,284 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 17:53:42,687 - INFO - Epoch 24: train_loss=27545636.0000
2025-02-06 17:53:42,978 - INFO - Epoch 24: train_loss=22924930.0000
2025-02-06 17:53:43,302 - INFO - Epoch 24: val_loss=16452237.0000, val_acc=0.00%
2025-02-06 17:53:43,305 - INFO - Epoch 24: EPOCH_AVG_TRAIN_LOSS=22924930.0000
2025-02-06 17:53:43,308 - INFO - #################### Training epoch 25 ####################
2025-02-06 17:53:43,308 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 17:53:43,715 - INFO - Epoch 25: train_loss=17982488.0000
2025-02-06 17:53:44,006 - INFO - Epoch 25: train_loss=4803050.0000
2025-02-06 17:53:44,323 - INFO - Epoch 25: val_loss=1661514.6250, val_acc=66.67%
2025-02-06 17:53:44,330 - INFO - Epoch 25: EPOCH_AVG_TRAIN_LOSS=4803050.0000
2025-02-06 17:53:44,358 - INFO - #################### Training epoch 26 ####################
2025-02-06 17:53:44,358 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 17:53:44,764 - INFO - Epoch 26: train_loss=16177449.0000
2025-02-06 17:53:45,055 - INFO - Epoch 26: train_loss=21108230.0000
2025-02-06 17:53:45,371 - INFO - Epoch 26: val_loss=365482.6562, val_acc=66.67%
2025-02-06 17:53:45,375 - INFO - Epoch 26: EPOCH_AVG_TRAIN_LOSS=16177449.0000
2025-02-06 17:53:45,404 - INFO - #################### Training epoch 27 ####################
2025-02-06 17:53:45,404 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 17:53:45,807 - INFO - Epoch 27: train_loss=22180052.0000
2025-02-06 17:53:46,098 - INFO - Epoch 27: train_loss=15881560.0000
2025-02-06 17:53:46,415 - INFO - Epoch 27: val_loss=5521398.5000, val_acc=0.00%
2025-02-06 17:53:46,418 - INFO - Epoch 27: EPOCH_AVG_TRAIN_LOSS=15881560.0000
2025-02-06 17:53:46,421 - INFO - #################### Training epoch 28 ####################
2025-02-06 17:53:46,421 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 17:53:46,824 - INFO - Epoch 28: train_loss=23219800.0000
2025-02-06 17:53:47,115 - INFO - Epoch 28: train_loss=19003734.0000
2025-02-06 17:53:47,435 - INFO - Epoch 28: val_loss=12246239.0000, val_acc=0.00%
2025-02-06 17:53:47,439 - INFO - Epoch 28: EPOCH_AVG_TRAIN_LOSS=19003734.0000
2025-02-06 17:53:47,441 - INFO - #################### Training epoch 29 ####################
2025-02-06 17:53:47,441 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 17:53:47,844 - INFO - Epoch 29: train_loss=12916651.0000
2025-02-06 17:53:48,135 - INFO - Epoch 29: train_loss=16752377.0000
2025-02-06 17:53:48,450 - INFO - Epoch 29: val_loss=3880988.0000, val_acc=66.67%
2025-02-06 17:53:48,454 - INFO - Epoch 29: EPOCH_AVG_TRAIN_LOSS=12916651.0000
2025-02-06 17:53:48,456 - INFO - #################### Training epoch 30 ####################
2025-02-06 17:53:48,456 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 17:53:48,857 - INFO - Epoch 30: train_loss=15705366.0000
2025-02-06 17:53:49,149 - INFO - Epoch 30: train_loss=10289783.0000
2025-02-06 17:53:49,466 - INFO - Epoch 30: val_loss=3376945.2500, val_acc=33.33%
2025-02-06 17:53:49,470 - INFO - Epoch 30: EPOCH_AVG_TRAIN_LOSS=10289783.0000
2025-02-06 17:53:49,472 - INFO - #################### Training epoch 31 ####################
2025-02-06 17:53:49,472 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 17:53:49,875 - INFO - Epoch 31: train_loss=11045407.0000
2025-02-06 17:53:50,167 - INFO - Epoch 31: train_loss=17800644.0000
2025-02-06 17:53:50,487 - INFO - Epoch 31: val_loss=6658490.5000, val_acc=0.00%
2025-02-06 17:53:50,490 - INFO - Epoch 31: EPOCH_AVG_TRAIN_LOSS=11045407.0000
2025-02-06 17:53:50,493 - INFO - #################### Training epoch 32 ####################
2025-02-06 17:53:50,493 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 17:53:50,896 - INFO - Epoch 32: train_loss=11300369.0000
2025-02-06 17:53:51,187 - INFO - Epoch 32: train_loss=10653416.0000
2025-02-06 17:53:51,508 - INFO - Epoch 32: val_loss=10726695.0000, val_acc=0.00%
2025-02-06 17:53:51,512 - INFO - Epoch 32: EPOCH_AVG_TRAIN_LOSS=10653416.0000
2025-02-06 17:53:51,514 - INFO - #################### Training epoch 33 ####################
2025-02-06 17:53:51,514 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 17:53:51,917 - INFO - Epoch 33: train_loss=4931967.5000
2025-02-06 17:53:52,209 - INFO - Epoch 33: train_loss=10958475.0000
2025-02-06 17:53:52,526 - INFO - Epoch 33: val_loss=9992983.0000, val_acc=66.67%
2025-02-06 17:53:52,530 - INFO - Epoch 33: EPOCH_AVG_TRAIN_LOSS=4931967.5000
2025-02-06 17:53:52,533 - INFO - #################### Training epoch 34 ####################
2025-02-06 17:53:52,533 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 17:53:52,934 - INFO - Epoch 34: train_loss=12227525.0000
2025-02-06 17:53:53,225 - INFO - Epoch 34: train_loss=19809400.0000
2025-02-06 17:53:53,547 - INFO - Epoch 34: val_loss=10176446.0000, val_acc=66.67%
2025-02-06 17:53:53,550 - INFO - Epoch 34: EPOCH_AVG_TRAIN_LOSS=12227525.0000
2025-02-06 17:53:53,553 - INFO - #################### Training epoch 35 ####################
2025-02-06 17:53:53,553 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 17:53:53,957 - INFO - Epoch 35: train_loss=12817922.0000
2025-02-06 17:53:54,248 - INFO - Epoch 35: train_loss=18191584.0000
2025-02-06 17:53:54,565 - INFO - Epoch 35: val_loss=7193226.5000, val_acc=66.67%
2025-02-06 17:53:54,569 - INFO - Epoch 35: EPOCH_AVG_TRAIN_LOSS=12817922.0000
2025-02-06 17:53:54,571 - INFO - #################### Training epoch 36 ####################
2025-02-06 17:53:54,571 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 17:53:54,975 - INFO - Epoch 36: train_loss=8135610.0000
2025-02-06 17:53:55,267 - INFO - Epoch 36: train_loss=10152524.0000
2025-02-06 17:53:55,587 - INFO - Epoch 36: val_loss=6812229.5000, val_acc=0.00%
2025-02-06 17:53:55,591 - INFO - Epoch 36: EPOCH_AVG_TRAIN_LOSS=8135610.0000
2025-02-06 17:53:55,593 - INFO - #################### Training epoch 37 ####################
2025-02-06 17:53:55,593 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 17:53:55,997 - INFO - Epoch 37: train_loss=11030680.0000
2025-02-06 17:53:56,288 - INFO - Epoch 37: train_loss=10111796.0000
2025-02-06 17:53:56,608 - INFO - Epoch 37: val_loss=4032938.7500, val_acc=33.33%
2025-02-06 17:53:56,612 - INFO - Epoch 37: EPOCH_AVG_TRAIN_LOSS=10111796.0000
2025-02-06 17:53:56,614 - INFO - #################### Training epoch 38 ####################
2025-02-06 17:53:56,614 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:53:57,018 - INFO - Epoch 38: train_loss=7130157.5000
2025-02-06 17:53:57,309 - INFO - Epoch 38: train_loss=11134748.0000
2025-02-06 17:53:57,630 - INFO - Epoch 38: val_loss=4580316.5000, val_acc=33.33%
2025-02-06 17:53:57,633 - INFO - Epoch 38: EPOCH_AVG_TRAIN_LOSS=7130157.5000
2025-02-06 17:53:57,636 - INFO - #################### Training epoch 39 ####################
2025-02-06 17:53:57,636 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:53:58,040 - INFO - Epoch 39: train_loss=14370396.0000
2025-02-06 17:53:58,330 - INFO - Epoch 39: train_loss=7153387.0000
2025-02-06 17:53:58,655 - INFO - Epoch 39: val_loss=2015066.0000, val_acc=33.33%
2025-02-06 17:53:58,659 - INFO - Epoch 39: EPOCH_AVG_TRAIN_LOSS=7153387.0000
2025-02-06 17:53:58,689 - INFO - #################### Training epoch 40 ####################
2025-02-06 17:53:58,689 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:53:59,093 - INFO - Epoch 40: train_loss=8893771.0000
2025-02-06 17:53:59,384 - INFO - Epoch 40: train_loss=4811621.5000
2025-02-06 17:53:59,704 - INFO - Epoch 40: val_loss=1625195.3750, val_acc=0.00%
2025-02-06 17:53:59,708 - INFO - Epoch 40: EPOCH_AVG_TRAIN_LOSS=4811621.5000
2025-02-06 17:53:59,739 - INFO - #################### Training epoch 41 ####################
2025-02-06 17:53:59,739 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:54:00,147 - INFO - Epoch 41: train_loss=7023262.5000
2025-02-06 17:54:00,439 - INFO - Epoch 41: train_loss=4490112.0000
2025-02-06 17:54:00,760 - INFO - Epoch 41: val_loss=1603009.0000, val_acc=66.67%
2025-02-06 17:54:00,763 - INFO - Epoch 41: EPOCH_AVG_TRAIN_LOSS=4490112.0000
2025-02-06 17:54:00,793 - INFO - #################### Training epoch 42 ####################
2025-02-06 17:54:00,793 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:54:01,198 - INFO - Epoch 42: train_loss=13061523.0000
2025-02-06 17:54:01,489 - INFO - Epoch 42: train_loss=11579029.0000
2025-02-06 17:54:01,807 - INFO - Epoch 42: val_loss=1731048.6250, val_acc=0.00%
2025-02-06 17:54:01,811 - INFO - Epoch 42: EPOCH_AVG_TRAIN_LOSS=11579029.0000
2025-02-06 17:54:01,813 - INFO - #################### Training epoch 43 ####################
2025-02-06 17:54:01,813 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:54:02,219 - INFO - Epoch 43: train_loss=6630452.0000
2025-02-06 17:54:02,510 - INFO - Epoch 43: train_loss=7400106.5000
2025-02-06 17:54:02,831 - INFO - Epoch 43: val_loss=2492699.0000, val_acc=66.67%
2025-02-06 17:54:02,835 - INFO - Epoch 43: EPOCH_AVG_TRAIN_LOSS=6630452.0000
2025-02-06 17:54:02,837 - INFO - #################### Training epoch 44 ####################
2025-02-06 17:54:02,837 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:54:03,241 - INFO - Epoch 44: train_loss=15210721.0000
2025-02-06 17:54:03,532 - INFO - Epoch 44: train_loss=3428079.2500
2025-02-06 17:54:03,863 - INFO - Epoch 44: val_loss=2156408.2500, val_acc=66.67%
2025-02-06 17:54:03,867 - INFO - Epoch 44: EPOCH_AVG_TRAIN_LOSS=3428079.2500
2025-02-06 17:54:03,870 - INFO - #################### Training epoch 45 ####################
2025-02-06 17:54:03,870 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:54:04,276 - INFO - Epoch 45: train_loss=8822640.0000
2025-02-06 17:54:04,567 - INFO - Epoch 45: train_loss=4322125.0000
2025-02-06 17:54:04,887 - INFO - Epoch 45: val_loss=1394976.0000, val_acc=0.00%
2025-02-06 17:54:04,891 - INFO - Epoch 45: EPOCH_AVG_TRAIN_LOSS=4322125.0000
2025-02-06 17:54:04,922 - INFO - #################### Training epoch 46 ####################
2025-02-06 17:54:04,922 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:54:05,327 - INFO - Epoch 46: train_loss=7497469.0000
2025-02-06 17:54:05,618 - INFO - Epoch 46: train_loss=2176437.7500
2025-02-06 17:54:05,939 - INFO - Epoch 46: val_loss=829129.3125, val_acc=0.00%
2025-02-06 17:54:05,942 - INFO - Epoch 46: EPOCH_AVG_TRAIN_LOSS=2176437.7500
2025-02-06 17:54:05,973 - INFO - #################### Training epoch 47 ####################
2025-02-06 17:54:05,973 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:54:06,378 - INFO - Epoch 47: train_loss=6278822.0000
2025-02-06 17:54:06,669 - INFO - Epoch 47: train_loss=9781883.0000
2025-02-06 17:54:06,987 - INFO - Epoch 47: val_loss=2034090.3750, val_acc=0.00%
2025-02-06 17:54:06,991 - INFO - Epoch 47: EPOCH_AVG_TRAIN_LOSS=6278822.0000
2025-02-06 17:54:06,993 - INFO - #################### Training epoch 48 ####################
2025-02-06 17:54:06,993 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:54:07,400 - INFO - Epoch 48: train_loss=4322134.0000
2025-02-06 17:54:07,691 - INFO - Epoch 48: train_loss=8175082.0000
2025-02-06 17:54:08,014 - INFO - Epoch 48: val_loss=2629002.0000, val_acc=33.33%
2025-02-06 17:54:08,018 - INFO - Epoch 48: EPOCH_AVG_TRAIN_LOSS=4322134.0000
2025-02-06 17:54:08,020 - INFO - #################### Training epoch 49 ####################
2025-02-06 17:54:08,020 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:54:08,425 - INFO - Epoch 49: train_loss=4284030.0000
2025-02-06 17:54:08,718 - INFO - Epoch 49: train_loss=3437681.0000
2025-02-06 17:54:09,042 - INFO - Epoch 49: val_loss=1326353.0000, val_acc=33.33%
2025-02-06 17:54:09,045 - INFO - Epoch 49: EPOCH_AVG_TRAIN_LOSS=3437681.0000
2025-02-06 17:54:09,076 - INFO - #################### Training epoch 50 ####################
2025-02-06 17:54:09,076 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 17:54:09,479 - INFO - Epoch 50: train_loss=5229155.0000
2025-02-06 17:54:09,770 - INFO - Epoch 50: train_loss=3554887.2500
2025-02-06 17:54:10,093 - INFO - Epoch 50: val_loss=2156774.2500, val_acc=0.00%
2025-02-06 17:54:10,096 - INFO - Epoch 50: EPOCH_AVG_TRAIN_LOSS=3554887.2500
2025-02-06 17:54:10,099 - INFO - #################### Training epoch 51 ####################
2025-02-06 17:54:10,099 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 17:54:10,504 - INFO - Epoch 51: train_loss=7439444.5000
2025-02-06 17:54:10,795 - INFO - Epoch 51: train_loss=6765348.0000
2025-02-06 17:54:11,117 - INFO - Epoch 51: val_loss=2334086.2500, val_acc=0.00%
2025-02-06 17:54:11,121 - INFO - Epoch 51: EPOCH_AVG_TRAIN_LOSS=6765348.0000
2025-02-06 17:54:11,123 - INFO - #################### Training epoch 52 ####################
2025-02-06 17:54:11,123 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 17:54:11,526 - INFO - Epoch 52: train_loss=2719263.5000
2025-02-06 17:54:11,817 - INFO - Epoch 52: train_loss=3091101.5000
2025-02-06 17:54:12,139 - INFO - Epoch 52: val_loss=1981543.0000, val_acc=0.00%
2025-02-06 17:54:12,143 - INFO - Epoch 52: EPOCH_AVG_TRAIN_LOSS=2719263.5000
2025-02-06 17:54:12,145 - INFO - #################### Training epoch 53 ####################
2025-02-06 17:54:12,145 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 17:54:12,550 - INFO - Epoch 53: train_loss=5771240.0000
2025-02-06 17:54:12,841 - INFO - Epoch 53: train_loss=1928230.7500
2025-02-06 17:54:13,159 - INFO - Epoch 53: val_loss=1002386.6875, val_acc=66.67%
2025-02-06 17:54:13,163 - INFO - Epoch 53: EPOCH_AVG_TRAIN_LOSS=1928230.7500
2025-02-06 17:54:13,191 - INFO - #################### Training epoch 54 ####################
2025-02-06 17:54:13,191 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 17:54:13,596 - INFO - Epoch 54: train_loss=5330149.5000
2025-02-06 17:54:13,887 - INFO - Epoch 54: train_loss=6535319.0000
2025-02-06 17:54:14,205 - INFO - Epoch 54: val_loss=1306257.3750, val_acc=66.67%
2025-02-06 17:54:14,209 - INFO - Epoch 54: EPOCH_AVG_TRAIN_LOSS=5330149.5000
2025-02-06 17:54:14,211 - INFO - #################### Training epoch 55 ####################
2025-02-06 17:54:14,211 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 17:54:14,614 - INFO - Epoch 55: train_loss=8560448.0000
2025-02-06 17:54:14,906 - INFO - Epoch 55: train_loss=6178479.5000
2025-02-06 17:54:15,226 - INFO - Epoch 55: val_loss=1074412.0000, val_acc=66.67%
2025-02-06 17:54:15,230 - INFO - Epoch 55: EPOCH_AVG_TRAIN_LOSS=6178479.5000
2025-02-06 17:54:15,232 - INFO - #################### Training epoch 56 ####################
2025-02-06 17:54:15,232 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 17:54:15,634 - INFO - Epoch 56: train_loss=5255551.0000
2025-02-06 17:54:15,924 - INFO - Epoch 56: train_loss=6683704.0000
2025-02-06 17:54:16,245 - INFO - Epoch 56: val_loss=530090.3125, val_acc=66.67%
2025-02-06 17:54:16,249 - INFO - Epoch 56: EPOCH_AVG_TRAIN_LOSS=5255551.0000
2025-02-06 17:54:16,279 - INFO - #################### Training epoch 57 ####################
2025-02-06 17:54:16,279 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 17:54:16,686 - INFO - Epoch 57: train_loss=7155292.5000
2025-02-06 17:54:16,976 - INFO - Epoch 57: train_loss=4757433.0000
2025-02-06 17:54:17,299 - INFO - Epoch 57: val_loss=324336.3438, val_acc=0.00%
2025-02-06 17:54:17,303 - INFO - Epoch 57: EPOCH_AVG_TRAIN_LOSS=4757433.0000
2025-02-06 17:54:17,333 - INFO - #################### Training epoch 58 ####################
2025-02-06 17:54:17,333 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 17:54:17,737 - INFO - Epoch 58: train_loss=10472704.0000
2025-02-06 17:54:18,028 - INFO - Epoch 58: train_loss=8597000.0000
2025-02-06 17:54:18,350 - INFO - Epoch 58: val_loss=328352.6562, val_acc=0.00%
2025-02-06 17:54:18,353 - INFO - Epoch 58: EPOCH_AVG_TRAIN_LOSS=8597000.0000
2025-02-06 17:54:18,384 - INFO - #################### Training epoch 59 ####################
2025-02-06 17:54:18,384 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 17:54:18,790 - INFO - Epoch 59: train_loss=1942227.0000
2025-02-06 17:54:19,081 - INFO - Epoch 59: train_loss=5434401.0000
2025-02-06 17:54:19,401 - INFO - Epoch 59: val_loss=455546.6562, val_acc=33.33%
2025-02-06 17:54:19,405 - INFO - Epoch 59: EPOCH_AVG_TRAIN_LOSS=1942227.0000
2025-02-06 17:54:19,407 - INFO - #################### Training epoch 60 ####################
2025-02-06 17:54:19,407 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 17:54:19,810 - INFO - Epoch 60: train_loss=6257830.0000
2025-02-06 17:54:20,101 - INFO - Epoch 60: train_loss=4170014.5000
2025-02-06 17:54:20,422 - INFO - Epoch 60: val_loss=636918.3125, val_acc=33.33%
2025-02-06 17:54:20,426 - INFO - Epoch 60: EPOCH_AVG_TRAIN_LOSS=4170014.5000
2025-02-06 17:54:20,428 - INFO - #################### Training epoch 61 ####################
2025-02-06 17:54:20,428 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 17:54:20,832 - INFO - Epoch 61: train_loss=8337813.0000
2025-02-06 17:54:21,124 - INFO - Epoch 61: train_loss=9453298.0000
2025-02-06 17:54:21,443 - INFO - Epoch 61: val_loss=250882.0000, val_acc=33.33%
2025-02-06 17:54:21,446 - INFO - Epoch 61: EPOCH_AVG_TRAIN_LOSS=8337813.0000
2025-02-06 17:54:21,476 - INFO - #################### Training epoch 62 ####################
2025-02-06 17:54:21,476 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 17:54:21,880 - INFO - Epoch 62: train_loss=3582683.7500
2025-02-06 17:54:22,172 - INFO - Epoch 62: train_loss=8203213.5000
2025-02-06 17:54:22,489 - INFO - Epoch 62: val_loss=200346.0000, val_acc=0.00%
2025-02-06 17:54:22,493 - INFO - Epoch 62: EPOCH_AVG_TRAIN_LOSS=3582683.7500
2025-02-06 17:54:22,524 - INFO - #################### Training epoch 63 ####################
2025-02-06 17:54:22,524 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 17:54:22,925 - INFO - Epoch 63: train_loss=4831019.0000
2025-02-06 17:54:23,216 - INFO - Epoch 63: train_loss=1049759.1250
2025-02-06 17:54:23,541 - INFO - Epoch 63: val_loss=181155.6719, val_acc=0.00%
2025-02-06 17:54:23,545 - INFO - Epoch 63: EPOCH_AVG_TRAIN_LOSS=1049759.1250
2025-02-06 17:54:23,591 - INFO - #################### Training epoch 64 ####################
2025-02-06 17:54:23,592 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 17:54:23,993 - INFO - Epoch 64: train_loss=3221035.2500
2025-02-06 17:54:24,285 - INFO - Epoch 64: train_loss=3224303.5000
2025-02-06 17:54:24,607 - INFO - Epoch 64: val_loss=242942.3281, val_acc=0.00%
2025-02-06 17:54:24,611 - INFO - Epoch 64: EPOCH_AVG_TRAIN_LOSS=3221035.2500
2025-02-06 17:54:24,642 - INFO - #################### Training epoch 65 ####################
2025-02-06 17:54:24,642 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 17:54:25,045 - INFO - Epoch 65: train_loss=3110695.7500
2025-02-06 17:54:25,335 - INFO - Epoch 65: train_loss=2751600.0000
2025-02-06 17:54:25,655 - INFO - Epoch 65: val_loss=366525.0000, val_acc=66.67%
2025-02-06 17:54:25,659 - INFO - Epoch 65: EPOCH_AVG_TRAIN_LOSS=2751600.0000
2025-02-06 17:54:25,661 - INFO - #################### Training epoch 66 ####################
2025-02-06 17:54:25,661 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 17:54:26,064 - INFO - Epoch 66: train_loss=2739693.5000
2025-02-06 17:54:26,355 - INFO - Epoch 66: train_loss=3034058.0000
2025-02-06 17:54:26,677 - INFO - Epoch 66: val_loss=398880.3438, val_acc=0.00%
2025-02-06 17:54:26,681 - INFO - Epoch 66: EPOCH_AVG_TRAIN_LOSS=2739693.5000
2025-02-06 17:54:26,683 - INFO - #################### Training epoch 67 ####################
2025-02-06 17:54:26,683 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 17:54:27,089 - INFO - Epoch 67: train_loss=5214917.0000
2025-02-06 17:54:27,382 - INFO - Epoch 67: train_loss=3582993.2500
2025-02-06 17:54:27,702 - INFO - Epoch 67: val_loss=405331.3438, val_acc=66.67%
2025-02-06 17:54:27,706 - INFO - Epoch 67: EPOCH_AVG_TRAIN_LOSS=3582993.2500
2025-02-06 17:54:27,708 - INFO - #################### Training epoch 68 ####################
2025-02-06 17:54:27,708 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 17:54:28,112 - INFO - Epoch 68: train_loss=8913187.0000
2025-02-06 17:54:28,404 - INFO - Epoch 68: train_loss=3209365.0000
2025-02-06 17:54:28,721 - INFO - Epoch 68: val_loss=471574.6562, val_acc=66.67%
2025-02-06 17:54:28,724 - INFO - Epoch 68: EPOCH_AVG_TRAIN_LOSS=3209365.0000
2025-02-06 17:54:28,727 - INFO - #################### Training epoch 69 ####################
2025-02-06 17:54:28,727 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 17:54:29,132 - INFO - Epoch 69: train_loss=4176621.7500
2025-02-06 17:54:29,425 - INFO - Epoch 69: train_loss=3726612.0000
2025-02-06 17:54:29,747 - INFO - Epoch 69: val_loss=504908.3438, val_acc=66.67%
2025-02-06 17:54:29,751 - INFO - Epoch 69: EPOCH_AVG_TRAIN_LOSS=3726612.0000
2025-02-06 17:54:29,753 - INFO - #################### Training epoch 70 ####################
2025-02-06 17:54:29,753 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 17:54:30,154 - INFO - Epoch 70: train_loss=4685213.0000
2025-02-06 17:54:30,446 - INFO - Epoch 70: train_loss=2475096.5000
2025-02-06 17:54:30,768 - INFO - Epoch 70: val_loss=538101.3125, val_acc=66.67%
2025-02-06 17:54:30,772 - INFO - Epoch 70: EPOCH_AVG_TRAIN_LOSS=2475096.5000
2025-02-06 17:54:30,774 - INFO - #################### Training epoch 71 ####################
2025-02-06 17:54:30,774 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 17:54:31,177 - INFO - Epoch 71: train_loss=2616867.0000
2025-02-06 17:54:31,470 - INFO - Epoch 71: train_loss=1110076.6250
2025-02-06 17:54:31,787 - INFO - Epoch 71: val_loss=507815.3438, val_acc=66.67%
2025-02-06 17:54:31,791 - INFO - Epoch 71: EPOCH_AVG_TRAIN_LOSS=1110076.6250
2025-02-06 17:54:31,793 - INFO - #################### Training epoch 72 ####################
2025-02-06 17:54:31,793 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 17:54:32,194 - INFO - Epoch 72: train_loss=4199461.5000
2025-02-06 17:54:32,486 - INFO - Epoch 72: train_loss=1783137.1250
2025-02-06 17:54:32,808 - INFO - Epoch 72: val_loss=476073.6562, val_acc=66.67%
2025-02-06 17:54:32,811 - INFO - Epoch 72: EPOCH_AVG_TRAIN_LOSS=1783137.1250
2025-02-06 17:54:32,814 - INFO - #################### Training epoch 73 ####################
2025-02-06 17:54:32,814 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 17:54:33,221 - INFO - Epoch 73: train_loss=4153058.0000
2025-02-06 17:54:33,514 - INFO - Epoch 73: train_loss=4557528.5000
2025-02-06 17:54:33,834 - INFO - Epoch 73: val_loss=547412.6875, val_acc=0.00%
2025-02-06 17:54:33,838 - INFO - Epoch 73: EPOCH_AVG_TRAIN_LOSS=4153058.0000
2025-02-06 17:54:33,840 - INFO - #################### Training epoch 74 ####################
2025-02-06 17:54:33,840 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 17:54:34,243 - INFO - Epoch 74: train_loss=3932645.0000
2025-02-06 17:54:34,535 - INFO - Epoch 74: train_loss=7582358.5000
2025-02-06 17:54:34,853 - INFO - Epoch 74: val_loss=557303.6875, val_acc=0.00%
2025-02-06 17:54:34,857 - INFO - Epoch 74: EPOCH_AVG_TRAIN_LOSS=3932645.0000
2025-02-06 17:54:34,859 - INFO - #################### Training epoch 75 ####################
2025-02-06 17:54:34,859 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 17:54:35,267 - INFO - Epoch 75: train_loss=6512838.5000
2025-02-06 17:54:35,559 - INFO - Epoch 75: train_loss=3457011.5000
2025-02-06 17:54:35,884 - INFO - Epoch 75: val_loss=576288.0000, val_acc=0.00%
2025-02-06 17:54:35,887 - INFO - Epoch 75: EPOCH_AVG_TRAIN_LOSS=3457011.5000
2025-02-06 17:54:35,890 - INFO - #################### Training epoch 76 ####################
2025-02-06 17:54:35,890 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 17:54:36,294 - INFO - Epoch 76: train_loss=5833948.0000
2025-02-06 17:54:36,586 - INFO - Epoch 76: train_loss=4543382.5000
2025-02-06 17:54:36,910 - INFO - Epoch 76: val_loss=576158.0000, val_acc=0.00%
2025-02-06 17:54:36,914 - INFO - Epoch 76: EPOCH_AVG_TRAIN_LOSS=4543382.5000
2025-02-06 17:54:36,916 - INFO - #################### Training epoch 77 ####################
2025-02-06 17:54:36,916 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 17:54:37,320 - INFO - Epoch 77: train_loss=6401604.5000
2025-02-06 17:54:37,613 - INFO - Epoch 77: train_loss=7869700.0000
2025-02-06 17:54:37,935 - INFO - Epoch 77: val_loss=584689.6875, val_acc=0.00%
2025-02-06 17:54:37,938 - INFO - Epoch 77: EPOCH_AVG_TRAIN_LOSS=6401604.5000
2025-02-06 17:54:37,940 - INFO - #################### Training epoch 78 ####################
2025-02-06 17:54:37,941 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 17:54:38,346 - INFO - Epoch 78: train_loss=4769629.0000
2025-02-06 17:54:38,638 - INFO - Epoch 78: train_loss=12773994.0000
2025-02-06 17:54:38,956 - INFO - Epoch 78: val_loss=598908.3125, val_acc=0.00%
2025-02-06 17:54:38,960 - INFO - Epoch 78: EPOCH_AVG_TRAIN_LOSS=4769629.0000
2025-02-06 17:54:38,962 - INFO - #################### Training epoch 79 ####################
2025-02-06 17:54:38,962 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 17:54:39,369 - INFO - Epoch 79: train_loss=5616796.5000
2025-02-06 17:54:39,661 - INFO - Epoch 79: train_loss=5571537.5000
2025-02-06 17:54:39,984 - INFO - Epoch 79: val_loss=607493.6875, val_acc=0.00%
2025-02-06 17:54:39,988 - INFO - Epoch 79: EPOCH_AVG_TRAIN_LOSS=5571537.5000
2025-02-06 17:54:39,990 - INFO - #################### Training epoch 80 ####################
2025-02-06 17:54:39,990 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 17:54:40,394 - INFO - Epoch 80: train_loss=2815632.2500
2025-02-06 17:54:40,688 - INFO - Epoch 80: train_loss=4823780.0000
2025-02-06 17:54:41,007 - INFO - Epoch 80: val_loss=613734.6875, val_acc=0.00%
2025-02-06 17:54:41,011 - INFO - Epoch 80: EPOCH_AVG_TRAIN_LOSS=2815632.2500
2025-02-06 17:54:41,013 - INFO - #################### Training epoch 81 ####################
2025-02-06 17:54:41,013 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 17:54:41,413 - INFO - Epoch 81: train_loss=7060702.5000
2025-02-06 17:54:41,705 - INFO - Epoch 81: train_loss=2708717.2500
2025-02-06 17:54:42,023 - INFO - Epoch 81: val_loss=634176.0000, val_acc=0.00%
2025-02-06 17:54:42,026 - INFO - Epoch 81: EPOCH_AVG_TRAIN_LOSS=2708717.2500
2025-02-06 17:54:42,028 - INFO - #################### Training epoch 82 ####################
2025-02-06 17:54:42,028 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 17:54:42,433 - INFO - Epoch 82: train_loss=4420024.0000
2025-02-06 17:54:42,726 - INFO - Epoch 82: train_loss=13320451.0000
2025-02-06 17:54:43,047 - INFO - Epoch 82: val_loss=655045.0000, val_acc=0.00%
2025-02-06 17:54:43,051 - INFO - Epoch 82: EPOCH_AVG_TRAIN_LOSS=4420024.0000
2025-02-06 17:54:43,053 - INFO - #################### Training epoch 83 ####################
2025-02-06 17:54:43,053 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 17:54:43,457 - INFO - Epoch 83: train_loss=4358926.5000
2025-02-06 17:54:43,749 - INFO - Epoch 83: train_loss=5903440.5000
2025-02-06 17:54:44,070 - INFO - Epoch 83: val_loss=680728.3125, val_acc=0.00%
2025-02-06 17:54:44,074 - INFO - Epoch 83: EPOCH_AVG_TRAIN_LOSS=4358926.5000
2025-02-06 17:54:44,076 - INFO - #################### Training epoch 84 ####################
2025-02-06 17:54:44,077 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 17:54:44,479 - INFO - Epoch 84: train_loss=4710028.0000
2025-02-06 17:54:44,771 - INFO - Epoch 84: train_loss=5800802.0000
2025-02-06 17:54:45,089 - INFO - Epoch 84: val_loss=689495.6875, val_acc=0.00%
2025-02-06 17:54:45,093 - INFO - Epoch 84: EPOCH_AVG_TRAIN_LOSS=4710028.0000
2025-02-06 17:54:45,095 - INFO - #################### Training epoch 85 ####################
2025-02-06 17:54:45,095 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 17:54:45,499 - INFO - Epoch 85: train_loss=3127985.5000
2025-02-06 17:54:45,791 - INFO - Epoch 85: train_loss=2126253.0000
2025-02-06 17:54:46,108 - INFO - Epoch 85: val_loss=693695.0000, val_acc=0.00%
2025-02-06 17:54:46,112 - INFO - Epoch 85: EPOCH_AVG_TRAIN_LOSS=2126253.0000
2025-02-06 17:54:46,114 - INFO - #################### Training epoch 86 ####################
2025-02-06 17:54:46,114 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 17:54:46,516 - INFO - Epoch 86: train_loss=2949246.0000
2025-02-06 17:54:46,808 - INFO - Epoch 86: train_loss=5477089.0000
2025-02-06 17:54:47,130 - INFO - Epoch 86: val_loss=698897.3125, val_acc=0.00%
2025-02-06 17:54:47,133 - INFO - Epoch 86: EPOCH_AVG_TRAIN_LOSS=2949246.0000
2025-02-06 17:54:47,136 - INFO - #################### Training epoch 87 ####################
2025-02-06 17:54:47,136 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 17:54:47,538 - INFO - Epoch 87: train_loss=3692672.0000
2025-02-06 17:54:47,830 - INFO - Epoch 87: train_loss=5982344.0000
2025-02-06 17:54:48,149 - INFO - Epoch 87: val_loss=701998.6875, val_acc=0.00%
2025-02-06 17:54:48,153 - INFO - Epoch 87: EPOCH_AVG_TRAIN_LOSS=3692672.0000
2025-02-06 17:54:48,155 - INFO - #################### Training epoch 88 ####################
2025-02-06 17:54:48,155 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 17:54:48,558 - INFO - Epoch 88: train_loss=8067773.0000
2025-02-06 17:54:48,849 - INFO - Epoch 88: train_loss=7672148.5000
2025-02-06 17:54:49,170 - INFO - Epoch 88: val_loss=702811.3125, val_acc=0.00%
2025-02-06 17:54:49,173 - INFO - Epoch 88: EPOCH_AVG_TRAIN_LOSS=7672148.5000
2025-02-06 17:54:49,176 - INFO - #################### Training epoch 89 ####################
2025-02-06 17:54:49,176 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 17:54:49,579 - INFO - Epoch 89: train_loss=3143862.2500
2025-02-06 17:54:49,871 - INFO - Epoch 89: train_loss=5172682.0000
2025-02-06 17:54:50,192 - INFO - Epoch 89: val_loss=699308.0000, val_acc=0.00%
2025-02-06 17:54:50,196 - INFO - Epoch 89: EPOCH_AVG_TRAIN_LOSS=3143862.2500
2025-02-06 17:54:50,198 - INFO - #################### Training epoch 90 ####################
2025-02-06 17:54:50,198 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 17:54:50,603 - INFO - Epoch 90: train_loss=3352384.2500
2025-02-06 17:54:50,895 - INFO - Epoch 90: train_loss=3917167.7500
2025-02-06 17:54:51,212 - INFO - Epoch 90: val_loss=694110.6875, val_acc=0.00%
2025-02-06 17:54:51,216 - INFO - Epoch 90: EPOCH_AVG_TRAIN_LOSS=3352384.2500
2025-02-06 17:54:51,218 - INFO - #################### Training epoch 91 ####################
2025-02-06 17:54:51,218 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 17:54:51,623 - INFO - Epoch 91: train_loss=5749106.5000
2025-02-06 17:54:51,915 - INFO - Epoch 91: train_loss=3312129.5000
2025-02-06 17:54:52,236 - INFO - Epoch 91: val_loss=689166.3125, val_acc=0.00%
2025-02-06 17:54:52,240 - INFO - Epoch 91: EPOCH_AVG_TRAIN_LOSS=3312129.5000
2025-02-06 17:54:52,242 - INFO - #################### Training epoch 92 ####################
2025-02-06 17:54:52,242 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 17:54:52,642 - INFO - Epoch 92: train_loss=6125957.0000
2025-02-06 17:54:52,935 - INFO - Epoch 92: train_loss=3791422.7500
2025-02-06 17:54:53,256 - INFO - Epoch 92: val_loss=686219.0000, val_acc=0.00%
2025-02-06 17:54:53,260 - INFO - Epoch 92: EPOCH_AVG_TRAIN_LOSS=3791422.7500
2025-02-06 17:54:53,262 - INFO - #################### Training epoch 93 ####################
2025-02-06 17:54:53,262 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 17:54:53,666 - INFO - Epoch 93: train_loss=4691419.5000
2025-02-06 17:54:53,957 - INFO - Epoch 93: train_loss=2748477.7500
2025-02-06 17:54:54,278 - INFO - Epoch 93: val_loss=684181.0000, val_acc=0.00%
2025-02-06 17:54:54,282 - INFO - Epoch 93: EPOCH_AVG_TRAIN_LOSS=2748477.7500
2025-02-06 17:54:54,284 - INFO - #################### Training epoch 94 ####################
2025-02-06 17:54:54,284 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 17:54:54,688 - INFO - Epoch 94: train_loss=1613193.6250
2025-02-06 17:54:54,981 - INFO - Epoch 94: train_loss=8971432.0000
2025-02-06 17:54:55,300 - INFO - Epoch 94: val_loss=681765.0000, val_acc=0.00%
2025-02-06 17:54:55,304 - INFO - Epoch 94: EPOCH_AVG_TRAIN_LOSS=1613193.6250
2025-02-06 17:54:55,306 - INFO - #################### Training epoch 95 ####################
2025-02-06 17:54:55,306 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 17:54:55,711 - INFO - Epoch 95: train_loss=10638242.0000
2025-02-06 17:54:56,003 - INFO - Epoch 95: train_loss=5017714.0000
2025-02-06 17:54:56,325 - INFO - Epoch 95: val_loss=679053.3125, val_acc=0.00%
2025-02-06 17:54:56,329 - INFO - Epoch 95: EPOCH_AVG_TRAIN_LOSS=5017714.0000
2025-02-06 17:54:56,331 - INFO - #################### Training epoch 96 ####################
2025-02-06 17:54:56,331 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 17:54:56,735 - INFO - Epoch 96: train_loss=4502025.0000
2025-02-06 17:54:57,027 - INFO - Epoch 96: train_loss=5908479.0000
2025-02-06 17:54:57,348 - INFO - Epoch 96: val_loss=677958.6875, val_acc=0.00%
2025-02-06 17:54:57,352 - INFO - Epoch 96: EPOCH_AVG_TRAIN_LOSS=4502025.0000
2025-02-06 17:54:57,354 - INFO - #################### Training epoch 97 ####################
2025-02-06 17:54:57,354 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 17:54:57,761 - INFO - Epoch 97: train_loss=5455746.0000
2025-02-06 17:54:58,053 - INFO - Epoch 97: train_loss=6753290.5000
2025-02-06 17:54:58,374 - INFO - Epoch 97: val_loss=677126.3125, val_acc=0.00%
2025-02-06 17:54:58,378 - INFO - Epoch 97: EPOCH_AVG_TRAIN_LOSS=5455746.0000
2025-02-06 17:54:58,380 - INFO - #################### Training epoch 98 ####################
2025-02-06 17:54:58,380 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 17:54:58,786 - INFO - Epoch 98: train_loss=5662405.0000
2025-02-06 17:54:59,079 - INFO - Epoch 98: train_loss=2255513.5000
2025-02-06 17:54:59,399 - INFO - Epoch 98: val_loss=676000.3125, val_acc=0.00%
2025-02-06 17:54:59,403 - INFO - Epoch 98: EPOCH_AVG_TRAIN_LOSS=2255513.5000
2025-02-06 17:54:59,405 - INFO - #################### Training epoch 99 ####################
2025-02-06 17:54:59,405 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 17:54:59,809 - INFO - Epoch 99: train_loss=5960928.5000
2025-02-06 17:55:00,103 - INFO - Epoch 99: train_loss=4067173.0000
2025-02-06 17:55:00,426 - INFO - Epoch 99: val_loss=674339.0000, val_acc=0.00%
2025-02-06 17:55:00,430 - INFO - Epoch 99: EPOCH_AVG_TRAIN_LOSS=4067173.0000
2025-02-06 17:55:00,432 - INFO - #################### Training epoch 100 ####################
2025-02-06 17:55:00,432 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:00,831 - INFO - Epoch 100: train_loss=3396495.7500
2025-02-06 17:55:01,124 - INFO - Epoch 100: train_loss=1438429.2500
2025-02-06 17:55:01,443 - INFO - Epoch 100: val_loss=673183.3125, val_acc=0.00%
2025-02-06 17:55:01,447 - INFO - Epoch 100: EPOCH_AVG_TRAIN_LOSS=1438429.2500
2025-02-06 17:55:01,449 - INFO - #################### Training epoch 101 ####################
2025-02-06 17:55:01,449 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:01,854 - INFO - Epoch 101: train_loss=4845392.0000
2025-02-06 17:55:02,145 - INFO - Epoch 101: train_loss=4657498.5000
2025-02-06 17:55:02,467 - INFO - Epoch 101: val_loss=672274.0000, val_acc=0.00%
2025-02-06 17:55:02,471 - INFO - Epoch 101: EPOCH_AVG_TRAIN_LOSS=4657498.5000
2025-02-06 17:55:02,473 - INFO - #################### Training epoch 102 ####################
2025-02-06 17:55:02,473 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:02,878 - INFO - Epoch 102: train_loss=2593761.2500
2025-02-06 17:55:03,171 - INFO - Epoch 102: train_loss=6167445.5000
2025-02-06 17:55:03,486 - INFO - Epoch 102: val_loss=670941.6875, val_acc=0.00%
2025-02-06 17:55:03,490 - INFO - Epoch 102: EPOCH_AVG_TRAIN_LOSS=2593761.2500
2025-02-06 17:55:03,492 - INFO - #################### Training epoch 103 ####################
2025-02-06 17:55:03,492 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:03,896 - INFO - Epoch 103: train_loss=5190262.0000
2025-02-06 17:55:04,188 - INFO - Epoch 103: train_loss=5857136.5000
2025-02-06 17:55:04,510 - INFO - Epoch 103: val_loss=669332.0000, val_acc=0.00%
2025-02-06 17:55:04,514 - INFO - Epoch 103: EPOCH_AVG_TRAIN_LOSS=5190262.0000
2025-02-06 17:55:04,516 - INFO - #################### Training epoch 104 ####################
2025-02-06 17:55:04,516 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:04,921 - INFO - Epoch 104: train_loss=4040409.7500
2025-02-06 17:55:05,216 - INFO - Epoch 104: train_loss=1551729.0000
2025-02-06 17:55:05,535 - INFO - Epoch 104: val_loss=667885.6875, val_acc=0.00%
2025-02-06 17:55:05,539 - INFO - Epoch 104: EPOCH_AVG_TRAIN_LOSS=1551729.0000
2025-02-06 17:55:05,541 - INFO - #################### Training epoch 105 ####################
2025-02-06 17:55:05,541 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:05,947 - INFO - Epoch 105: train_loss=5049368.0000
2025-02-06 17:55:06,241 - INFO - Epoch 105: train_loss=4713402.0000
2025-02-06 17:55:06,556 - INFO - Epoch 105: val_loss=666499.0000, val_acc=0.00%
2025-02-06 17:55:06,560 - INFO - Epoch 105: EPOCH_AVG_TRAIN_LOSS=4713402.0000
2025-02-06 17:55:06,562 - INFO - #################### Training epoch 106 ####################
2025-02-06 17:55:06,562 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:06,964 - INFO - Epoch 106: train_loss=4760240.0000
2025-02-06 17:55:07,256 - INFO - Epoch 106: train_loss=2213023.0000
2025-02-06 17:55:07,574 - INFO - Epoch 106: val_loss=665242.0000, val_acc=0.00%
2025-02-06 17:55:07,578 - INFO - Epoch 106: EPOCH_AVG_TRAIN_LOSS=2213023.0000
2025-02-06 17:55:07,580 - INFO - #################### Training epoch 107 ####################
2025-02-06 17:55:07,581 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:07,987 - INFO - Epoch 107: train_loss=3268780.2500
2025-02-06 17:55:08,280 - INFO - Epoch 107: train_loss=1765304.8750
2025-02-06 17:55:08,598 - INFO - Epoch 107: val_loss=663765.6875, val_acc=0.00%
2025-02-06 17:55:08,602 - INFO - Epoch 107: EPOCH_AVG_TRAIN_LOSS=1765304.8750
2025-02-06 17:55:08,604 - INFO - #################### Training epoch 108 ####################
2025-02-06 17:55:08,604 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:09,008 - INFO - Epoch 108: train_loss=2845284.5000
2025-02-06 17:55:09,300 - INFO - Epoch 108: train_loss=9929346.0000
2025-02-06 17:55:09,635 - INFO - Epoch 108: val_loss=662437.3125, val_acc=0.00%
2025-02-06 17:55:09,639 - INFO - Epoch 108: EPOCH_AVG_TRAIN_LOSS=2845284.5000
2025-02-06 17:55:09,642 - INFO - #################### Training epoch 109 ####################
2025-02-06 17:55:09,642 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:10,047 - INFO - Epoch 109: train_loss=2187980.0000
2025-02-06 17:55:10,342 - INFO - Epoch 109: train_loss=3238791.0000
2025-02-06 17:55:10,661 - INFO - Epoch 109: val_loss=660945.6875, val_acc=0.00%
2025-02-06 17:55:10,665 - INFO - Epoch 109: EPOCH_AVG_TRAIN_LOSS=2187980.0000
2025-02-06 17:55:10,667 - INFO - #################### Training epoch 110 ####################
2025-02-06 17:55:10,667 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:11,070 - INFO - Epoch 110: train_loss=4167640.5000
2025-02-06 17:55:11,362 - INFO - Epoch 110: train_loss=11908060.0000
2025-02-06 17:55:11,679 - INFO - Epoch 110: val_loss=659532.3125, val_acc=0.00%
2025-02-06 17:55:11,683 - INFO - Epoch 110: EPOCH_AVG_TRAIN_LOSS=4167640.5000
2025-02-06 17:55:11,685 - INFO - #################### Training epoch 111 ####################
2025-02-06 17:55:11,685 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:12,087 - INFO - Epoch 111: train_loss=4064066.7500
2025-02-06 17:55:12,380 - INFO - Epoch 111: train_loss=9152878.0000
2025-02-06 17:55:12,695 - INFO - Epoch 111: val_loss=658299.6875, val_acc=0.00%
2025-02-06 17:55:12,699 - INFO - Epoch 111: EPOCH_AVG_TRAIN_LOSS=4064066.7500
2025-02-06 17:55:12,701 - INFO - #################### Training epoch 112 ####################
2025-02-06 17:55:12,701 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:13,127 - INFO - Epoch 112: train_loss=6040965.5000
2025-02-06 17:55:13,420 - INFO - Epoch 112: train_loss=3683898.5000
2025-02-06 17:55:13,740 - INFO - Epoch 112: val_loss=656878.3125, val_acc=0.00%
2025-02-06 17:55:13,744 - INFO - Epoch 112: EPOCH_AVG_TRAIN_LOSS=3683898.5000
2025-02-06 17:55:13,746 - INFO - #################### Training epoch 113 ####################
2025-02-06 17:55:13,746 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:14,149 - INFO - Epoch 113: train_loss=3317563.5000
2025-02-06 17:55:14,442 - INFO - Epoch 113: train_loss=3001536.0000
2025-02-06 17:55:14,762 - INFO - Epoch 113: val_loss=655273.3125, val_acc=0.00%
2025-02-06 17:55:14,765 - INFO - Epoch 113: EPOCH_AVG_TRAIN_LOSS=3001536.0000
2025-02-06 17:55:14,768 - INFO - #################### Training epoch 114 ####################
2025-02-06 17:55:14,768 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:15,178 - INFO - Epoch 114: train_loss=4153692.2500
2025-02-06 17:55:15,470 - INFO - Epoch 114: train_loss=3922928.5000
2025-02-06 17:55:15,789 - INFO - Epoch 114: val_loss=654133.0000, val_acc=0.00%
2025-02-06 17:55:15,793 - INFO - Epoch 114: EPOCH_AVG_TRAIN_LOSS=3922928.5000
2025-02-06 17:55:15,796 - INFO - #################### Training epoch 115 ####################
2025-02-06 17:55:15,796 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:16,198 - INFO - Epoch 115: train_loss=2971489.5000
2025-02-06 17:55:16,492 - INFO - Epoch 115: train_loss=3623089.5000
2025-02-06 17:55:16,810 - INFO - Epoch 115: val_loss=653134.3125, val_acc=0.00%
2025-02-06 17:55:16,814 - INFO - Epoch 115: EPOCH_AVG_TRAIN_LOSS=2971489.5000
2025-02-06 17:55:16,816 - INFO - #################### Training epoch 116 ####################
2025-02-06 17:55:16,816 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:17,221 - INFO - Epoch 116: train_loss=9011166.0000
2025-02-06 17:55:17,513 - INFO - Epoch 116: train_loss=5064354.0000
2025-02-06 17:55:17,833 - INFO - Epoch 116: val_loss=652202.3125, val_acc=0.00%
2025-02-06 17:55:17,837 - INFO - Epoch 116: EPOCH_AVG_TRAIN_LOSS=5064354.0000
2025-02-06 17:55:17,839 - INFO - #################### Training epoch 117 ####################
2025-02-06 17:55:17,839 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:18,242 - INFO - Epoch 117: train_loss=3083225.0000
2025-02-06 17:55:18,535 - INFO - Epoch 117: train_loss=5949026.5000
2025-02-06 17:55:18,860 - INFO - Epoch 117: val_loss=651017.3125, val_acc=0.00%
2025-02-06 17:55:18,864 - INFO - Epoch 117: EPOCH_AVG_TRAIN_LOSS=3083225.0000
2025-02-06 17:55:18,866 - INFO - #################### Training epoch 118 ####################
2025-02-06 17:55:18,866 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:19,267 - INFO - Epoch 118: train_loss=5988821.5000
2025-02-06 17:55:19,559 - INFO - Epoch 118: train_loss=4182659.0000
2025-02-06 17:55:19,881 - INFO - Epoch 118: val_loss=650058.0000, val_acc=0.00%
2025-02-06 17:55:19,885 - INFO - Epoch 118: EPOCH_AVG_TRAIN_LOSS=4182659.0000
2025-02-06 17:55:19,887 - INFO - #################### Training epoch 119 ####################
2025-02-06 17:55:19,887 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:20,290 - INFO - Epoch 119: train_loss=6750156.0000
2025-02-06 17:55:20,583 - INFO - Epoch 119: train_loss=4687132.0000
2025-02-06 17:55:20,902 - INFO - Epoch 119: val_loss=648909.0000, val_acc=0.00%
2025-02-06 17:55:20,906 - INFO - Epoch 119: EPOCH_AVG_TRAIN_LOSS=4687132.0000
2025-02-06 17:55:20,908 - INFO - #################### Training epoch 120 ####################
2025-02-06 17:55:20,908 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:21,311 - INFO - Epoch 120: train_loss=3270401.0000
2025-02-06 17:55:21,603 - INFO - Epoch 120: train_loss=3813784.7500
2025-02-06 17:55:21,922 - INFO - Epoch 120: val_loss=648009.0000, val_acc=0.00%
2025-02-06 17:55:21,926 - INFO - Epoch 120: EPOCH_AVG_TRAIN_LOSS=3270401.0000
2025-02-06 17:55:21,928 - INFO - #################### Training epoch 121 ####################
2025-02-06 17:55:21,928 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:22,331 - INFO - Epoch 121: train_loss=3917156.0000
2025-02-06 17:55:22,624 - INFO - Epoch 121: train_loss=935714.5000
2025-02-06 17:55:22,944 - INFO - Epoch 121: val_loss=647115.0000, val_acc=0.00%
2025-02-06 17:55:22,948 - INFO - Epoch 121: EPOCH_AVG_TRAIN_LOSS=935714.5000
2025-02-06 17:55:22,950 - INFO - #################### Training epoch 122 ####################
2025-02-06 17:55:22,950 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:23,354 - INFO - Epoch 122: train_loss=2571795.0000
2025-02-06 17:55:23,646 - INFO - Epoch 122: train_loss=6893070.5000
2025-02-06 17:55:23,968 - INFO - Epoch 122: val_loss=646308.3125, val_acc=0.00%
2025-02-06 17:55:23,971 - INFO - Epoch 122: EPOCH_AVG_TRAIN_LOSS=2571795.0000
2025-02-06 17:55:23,974 - INFO - #################### Training epoch 123 ####################
2025-02-06 17:55:23,974 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:24,378 - INFO - Epoch 123: train_loss=1664159.3750
2025-02-06 17:55:24,671 - INFO - Epoch 123: train_loss=3793208.0000
2025-02-06 17:55:24,997 - INFO - Epoch 123: val_loss=645441.6875, val_acc=0.00%
2025-02-06 17:55:25,000 - INFO - Epoch 123: EPOCH_AVG_TRAIN_LOSS=1664159.3750
2025-02-06 17:55:25,003 - INFO - #################### Training epoch 124 ####################
2025-02-06 17:55:25,003 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:25,407 - INFO - Epoch 124: train_loss=2287729.0000
2025-02-06 17:55:25,699 - INFO - Epoch 124: train_loss=9128035.0000
2025-02-06 17:55:26,022 - INFO - Epoch 124: val_loss=644731.0000, val_acc=0.00%
2025-02-06 17:55:26,025 - INFO - Epoch 124: EPOCH_AVG_TRAIN_LOSS=2287729.0000
2025-02-06 17:55:26,028 - INFO - #################### Training epoch 125 ####################
2025-02-06 17:55:26,028 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:26,432 - INFO - Epoch 125: train_loss=3145551.5000
2025-02-06 17:55:26,724 - INFO - Epoch 125: train_loss=4604909.0000
2025-02-06 17:55:27,047 - INFO - Epoch 125: val_loss=644120.6875, val_acc=0.00%
2025-02-06 17:55:27,050 - INFO - Epoch 125: EPOCH_AVG_TRAIN_LOSS=3145551.5000
2025-02-06 17:55:27,053 - INFO - #################### Training epoch 126 ####################
2025-02-06 17:55:27,053 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:27,456 - INFO - Epoch 126: train_loss=2253975.0000
2025-02-06 17:55:27,748 - INFO - Epoch 126: train_loss=4581231.0000
2025-02-06 17:55:28,070 - INFO - Epoch 126: val_loss=643141.3125, val_acc=0.00%
2025-02-06 17:55:28,074 - INFO - Epoch 126: EPOCH_AVG_TRAIN_LOSS=2253975.0000
2025-02-06 17:55:28,076 - INFO - #################### Training epoch 127 ####################
2025-02-06 17:55:28,076 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:28,480 - INFO - Epoch 127: train_loss=2920515.2500
2025-02-06 17:55:28,773 - INFO - Epoch 127: train_loss=6049570.0000
2025-02-06 17:55:29,095 - INFO - Epoch 127: val_loss=641836.6875, val_acc=0.00%
2025-02-06 17:55:29,099 - INFO - Epoch 127: EPOCH_AVG_TRAIN_LOSS=2920515.2500
2025-02-06 17:55:29,101 - INFO - #################### Training epoch 128 ####################
2025-02-06 17:55:29,101 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:29,507 - INFO - Epoch 128: train_loss=6117576.0000
2025-02-06 17:55:29,799 - INFO - Epoch 128: train_loss=4204112.0000
2025-02-06 17:55:30,121 - INFO - Epoch 128: val_loss=640623.6875, val_acc=0.00%
2025-02-06 17:55:30,125 - INFO - Epoch 128: EPOCH_AVG_TRAIN_LOSS=4204112.0000
2025-02-06 17:55:30,127 - INFO - #################### Training epoch 129 ####################
2025-02-06 17:55:30,127 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:30,532 - INFO - Epoch 129: train_loss=4334845.0000
2025-02-06 17:55:30,824 - INFO - Epoch 129: train_loss=4137336.0000
2025-02-06 17:55:31,144 - INFO - Epoch 129: val_loss=639772.6875, val_acc=0.00%
2025-02-06 17:55:31,147 - INFO - Epoch 129: EPOCH_AVG_TRAIN_LOSS=4137336.0000
2025-02-06 17:55:31,150 - INFO - #################### Training epoch 130 ####################
2025-02-06 17:55:31,150 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:31,554 - INFO - Epoch 130: train_loss=1666399.8750
2025-02-06 17:55:31,847 - INFO - Epoch 130: train_loss=6331854.0000
2025-02-06 17:55:32,167 - INFO - Epoch 130: val_loss=638922.3125, val_acc=0.00%
2025-02-06 17:55:32,171 - INFO - Epoch 130: EPOCH_AVG_TRAIN_LOSS=1666399.8750
2025-02-06 17:55:32,173 - INFO - #################### Training epoch 131 ####################
2025-02-06 17:55:32,173 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:32,578 - INFO - Epoch 131: train_loss=3110551.2500
2025-02-06 17:55:32,871 - INFO - Epoch 131: train_loss=4641485.5000
2025-02-06 17:55:33,190 - INFO - Epoch 131: val_loss=638048.6875, val_acc=0.00%
2025-02-06 17:55:33,194 - INFO - Epoch 131: EPOCH_AVG_TRAIN_LOSS=3110551.2500
2025-02-06 17:55:33,196 - INFO - #################### Training epoch 132 ####################
2025-02-06 17:55:33,196 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:33,602 - INFO - Epoch 132: train_loss=5994068.0000
2025-02-06 17:55:33,894 - INFO - Epoch 132: train_loss=7981602.0000
2025-02-06 17:55:34,217 - INFO - Epoch 132: val_loss=637440.0000, val_acc=0.00%
2025-02-06 17:55:34,221 - INFO - Epoch 132: EPOCH_AVG_TRAIN_LOSS=5994068.0000
2025-02-06 17:55:34,223 - INFO - #################### Training epoch 133 ####################
2025-02-06 17:55:34,223 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:34,629 - INFO - Epoch 133: train_loss=6391831.0000
2025-02-06 17:55:34,922 - INFO - Epoch 133: train_loss=7211603.0000
2025-02-06 17:55:35,239 - INFO - Epoch 133: val_loss=636641.0000, val_acc=0.00%
2025-02-06 17:55:35,243 - INFO - Epoch 133: EPOCH_AVG_TRAIN_LOSS=6391831.0000
2025-02-06 17:55:35,245 - INFO - #################### Training epoch 134 ####################
2025-02-06 17:55:35,245 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:35,650 - INFO - Epoch 134: train_loss=3360764.7500
2025-02-06 17:55:35,942 - INFO - Epoch 134: train_loss=3512983.5000
2025-02-06 17:55:36,261 - INFO - Epoch 134: val_loss=635767.0000, val_acc=0.00%
2025-02-06 17:55:36,265 - INFO - Epoch 134: EPOCH_AVG_TRAIN_LOSS=3360764.7500
2025-02-06 17:55:36,267 - INFO - #################### Training epoch 135 ####################
2025-02-06 17:55:36,267 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:36,672 - INFO - Epoch 135: train_loss=2065771.7500
2025-02-06 17:55:36,964 - INFO - Epoch 135: train_loss=4807781.0000
2025-02-06 17:55:37,286 - INFO - Epoch 135: val_loss=634758.6875, val_acc=0.00%
2025-02-06 17:55:37,290 - INFO - Epoch 135: EPOCH_AVG_TRAIN_LOSS=2065771.7500
2025-02-06 17:55:37,292 - INFO - #################### Training epoch 136 ####################
2025-02-06 17:55:37,292 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:37,697 - INFO - Epoch 136: train_loss=5298951.0000
2025-02-06 17:55:37,990 - INFO - Epoch 136: train_loss=3808029.5000
2025-02-06 17:55:38,311 - INFO - Epoch 136: val_loss=634062.6875, val_acc=0.00%
2025-02-06 17:55:38,315 - INFO - Epoch 136: EPOCH_AVG_TRAIN_LOSS=3808029.5000
2025-02-06 17:55:38,317 - INFO - #################### Training epoch 137 ####################
2025-02-06 17:55:38,317 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:38,723 - INFO - Epoch 137: train_loss=4350442.0000
2025-02-06 17:55:39,015 - INFO - Epoch 137: train_loss=4033264.0000
2025-02-06 17:55:39,335 - INFO - Epoch 137: val_loss=633621.6875, val_acc=0.00%
2025-02-06 17:55:39,339 - INFO - Epoch 137: EPOCH_AVG_TRAIN_LOSS=4033264.0000
2025-02-06 17:55:39,341 - INFO - #################### Training epoch 138 ####################
2025-02-06 17:55:39,341 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:39,746 - INFO - Epoch 138: train_loss=6748288.0000
2025-02-06 17:55:40,038 - INFO - Epoch 138: train_loss=4483343.0000
2025-02-06 17:55:40,361 - INFO - Epoch 138: val_loss=633381.0000, val_acc=0.00%
2025-02-06 17:55:40,365 - INFO - Epoch 138: EPOCH_AVG_TRAIN_LOSS=4483343.0000
2025-02-06 17:55:40,367 - INFO - #################### Training epoch 139 ####################
2025-02-06 17:55:40,367 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:40,772 - INFO - Epoch 139: train_loss=3462378.2500
2025-02-06 17:55:41,065 - INFO - Epoch 139: train_loss=7405969.0000
2025-02-06 17:55:41,381 - INFO - Epoch 139: val_loss=632842.0000, val_acc=0.00%
2025-02-06 17:55:41,385 - INFO - Epoch 139: EPOCH_AVG_TRAIN_LOSS=3462378.2500
2025-02-06 17:55:41,388 - INFO - #################### Training epoch 140 ####################
2025-02-06 17:55:41,388 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:41,790 - INFO - Epoch 140: train_loss=7772520.0000
2025-02-06 17:55:42,082 - INFO - Epoch 140: train_loss=2933020.5000
2025-02-06 17:55:42,399 - INFO - Epoch 140: val_loss=632300.3125, val_acc=0.00%
2025-02-06 17:55:42,403 - INFO - Epoch 140: EPOCH_AVG_TRAIN_LOSS=2933020.5000
2025-02-06 17:55:42,405 - INFO - #################### Training epoch 141 ####################
2025-02-06 17:55:42,405 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:42,806 - INFO - Epoch 141: train_loss=7810083.0000
2025-02-06 17:55:43,098 - INFO - Epoch 141: train_loss=5559208.5000
2025-02-06 17:55:43,415 - INFO - Epoch 141: val_loss=631791.3125, val_acc=0.00%
2025-02-06 17:55:43,419 - INFO - Epoch 141: EPOCH_AVG_TRAIN_LOSS=5559208.5000
2025-02-06 17:55:43,421 - INFO - #################### Training epoch 142 ####################
2025-02-06 17:55:43,421 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:43,824 - INFO - Epoch 142: train_loss=7472965.0000
2025-02-06 17:55:44,117 - INFO - Epoch 142: train_loss=4341355.0000
2025-02-06 17:55:44,435 - INFO - Epoch 142: val_loss=631652.0000, val_acc=0.00%
2025-02-06 17:55:44,438 - INFO - Epoch 142: EPOCH_AVG_TRAIN_LOSS=4341355.0000
2025-02-06 17:55:44,441 - INFO - #################### Training epoch 143 ####################
2025-02-06 17:55:44,441 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:44,845 - INFO - Epoch 143: train_loss=6189408.5000
2025-02-06 17:55:45,137 - INFO - Epoch 143: train_loss=5768641.0000
2025-02-06 17:55:45,459 - INFO - Epoch 143: val_loss=631488.3125, val_acc=0.00%
2025-02-06 17:55:45,463 - INFO - Epoch 143: EPOCH_AVG_TRAIN_LOSS=5768641.0000
2025-02-06 17:55:45,465 - INFO - #################### Training epoch 144 ####################
2025-02-06 17:55:45,465 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:45,869 - INFO - Epoch 144: train_loss=2182494.5000
2025-02-06 17:55:46,161 - INFO - Epoch 144: train_loss=5046545.0000
2025-02-06 17:55:46,486 - INFO - Epoch 144: val_loss=630936.6875, val_acc=0.00%
2025-02-06 17:55:46,489 - INFO - Epoch 144: EPOCH_AVG_TRAIN_LOSS=2182494.5000
2025-02-06 17:55:46,492 - INFO - #################### Training epoch 145 ####################
2025-02-06 17:55:46,492 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:46,897 - INFO - Epoch 145: train_loss=3150723.7500
2025-02-06 17:55:47,189 - INFO - Epoch 145: train_loss=4623278.5000
2025-02-06 17:55:47,509 - INFO - Epoch 145: val_loss=630504.6875, val_acc=0.00%
2025-02-06 17:55:47,513 - INFO - Epoch 145: EPOCH_AVG_TRAIN_LOSS=3150723.7500
2025-02-06 17:55:47,515 - INFO - #################### Training epoch 146 ####################
2025-02-06 17:55:47,516 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:47,919 - INFO - Epoch 146: train_loss=2577353.2500
2025-02-06 17:55:48,211 - INFO - Epoch 146: train_loss=5427848.0000
2025-02-06 17:55:48,531 - INFO - Epoch 146: val_loss=629931.6875, val_acc=0.00%
2025-02-06 17:55:48,535 - INFO - Epoch 146: EPOCH_AVG_TRAIN_LOSS=2577353.2500
2025-02-06 17:55:48,537 - INFO - #################### Training epoch 147 ####################
2025-02-06 17:55:48,537 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:48,942 - INFO - Epoch 147: train_loss=3712189.5000
2025-02-06 17:55:49,234 - INFO - Epoch 147: train_loss=4418230.0000
2025-02-06 17:55:49,552 - INFO - Epoch 147: val_loss=629217.3125, val_acc=0.00%
2025-02-06 17:55:49,556 - INFO - Epoch 147: EPOCH_AVG_TRAIN_LOSS=3712189.5000
2025-02-06 17:55:49,558 - INFO - #################### Training epoch 148 ####################
2025-02-06 17:55:49,558 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:49,962 - INFO - Epoch 148: train_loss=6521953.0000
2025-02-06 17:55:50,254 - INFO - Epoch 148: train_loss=2505387.7500
2025-02-06 17:55:50,573 - INFO - Epoch 148: val_loss=628465.0000, val_acc=0.00%
2025-02-06 17:55:50,577 - INFO - Epoch 148: EPOCH_AVG_TRAIN_LOSS=2505387.7500
2025-02-06 17:55:50,579 - INFO - #################### Training epoch 149 ####################
2025-02-06 17:55:50,579 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:50,984 - INFO - Epoch 149: train_loss=3810586.0000
2025-02-06 17:55:51,276 - INFO - Epoch 149: train_loss=3037052.0000
2025-02-06 17:55:51,593 - INFO - Epoch 149: val_loss=627677.6875, val_acc=0.00%
2025-02-06 17:55:51,597 - INFO - Epoch 149: EPOCH_AVG_TRAIN_LOSS=3037052.0000
2025-02-06 17:55:51,599 - INFO - #################### Training epoch 150 ####################
2025-02-06 17:55:51,599 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:52,002 - INFO - Epoch 150: train_loss=6482456.5000
2025-02-06 17:55:52,294 - INFO - Epoch 150: train_loss=3450454.7500
2025-02-06 17:55:52,615 - INFO - Epoch 150: val_loss=626646.3125, val_acc=0.00%
2025-02-06 17:55:52,619 - INFO - Epoch 150: EPOCH_AVG_TRAIN_LOSS=3450454.7500
2025-02-06 17:55:52,621 - INFO - #################### Training epoch 151 ####################
2025-02-06 17:55:52,621 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:53,026 - INFO - Epoch 151: train_loss=2989954.7500
2025-02-06 17:55:53,318 - INFO - Epoch 151: train_loss=8997228.0000
2025-02-06 17:55:53,639 - INFO - Epoch 151: val_loss=625780.6875, val_acc=0.00%
2025-02-06 17:55:53,643 - INFO - Epoch 151: EPOCH_AVG_TRAIN_LOSS=2989954.7500
2025-02-06 17:55:53,645 - INFO - #################### Training epoch 152 ####################
2025-02-06 17:55:53,645 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:54,048 - INFO - Epoch 152: train_loss=8035267.5000
2025-02-06 17:55:54,340 - INFO - Epoch 152: train_loss=6330443.0000
2025-02-06 17:55:54,662 - INFO - Epoch 152: val_loss=624966.3125, val_acc=0.00%
2025-02-06 17:55:54,666 - INFO - Epoch 152: EPOCH_AVG_TRAIN_LOSS=6330443.0000
2025-02-06 17:55:54,668 - INFO - #################### Training epoch 153 ####################
2025-02-06 17:55:54,668 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:55,072 - INFO - Epoch 153: train_loss=6361556.0000
2025-02-06 17:55:55,364 - INFO - Epoch 153: train_loss=1890117.8750
2025-02-06 17:55:55,686 - INFO - Epoch 153: val_loss=624367.6875, val_acc=0.00%
2025-02-06 17:55:55,690 - INFO - Epoch 153: EPOCH_AVG_TRAIN_LOSS=1890117.8750
2025-02-06 17:55:55,692 - INFO - #################### Training epoch 154 ####################
2025-02-06 17:55:55,692 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:56,097 - INFO - Epoch 154: train_loss=2047628.5000
2025-02-06 17:55:56,389 - INFO - Epoch 154: train_loss=3624195.0000
2025-02-06 17:55:56,710 - INFO - Epoch 154: val_loss=623222.3125, val_acc=0.00%
2025-02-06 17:55:56,713 - INFO - Epoch 154: EPOCH_AVG_TRAIN_LOSS=2047628.5000
2025-02-06 17:55:56,716 - INFO - #################### Training epoch 155 ####################
2025-02-06 17:55:56,716 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:57,123 - INFO - Epoch 155: train_loss=5565969.0000
2025-02-06 17:55:57,415 - INFO - Epoch 155: train_loss=9457558.0000
2025-02-06 17:55:57,735 - INFO - Epoch 155: val_loss=622100.3125, val_acc=0.00%
2025-02-06 17:55:57,739 - INFO - Epoch 155: EPOCH_AVG_TRAIN_LOSS=5565969.0000
2025-02-06 17:55:57,741 - INFO - #################### Training epoch 156 ####################
2025-02-06 17:55:57,741 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:58,145 - INFO - Epoch 156: train_loss=5987519.5000
2025-02-06 17:55:58,438 - INFO - Epoch 156: train_loss=2248285.5000
2025-02-06 17:55:58,757 - INFO - Epoch 156: val_loss=621040.0000, val_acc=0.00%
2025-02-06 17:55:58,761 - INFO - Epoch 156: EPOCH_AVG_TRAIN_LOSS=2248285.5000
2025-02-06 17:55:58,763 - INFO - #################### Training epoch 157 ####################
2025-02-06 17:55:58,763 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:55:59,168 - INFO - Epoch 157: train_loss=4834081.5000
2025-02-06 17:55:59,461 - INFO - Epoch 157: train_loss=7043805.0000
2025-02-06 17:55:59,779 - INFO - Epoch 157: val_loss=619995.0000, val_acc=0.00%
2025-02-06 17:55:59,783 - INFO - Epoch 157: EPOCH_AVG_TRAIN_LOSS=4834081.5000
2025-02-06 17:55:59,785 - INFO - #################### Training epoch 158 ####################
2025-02-06 17:55:59,785 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:00,190 - INFO - Epoch 158: train_loss=3734868.7500
2025-02-06 17:56:00,483 - INFO - Epoch 158: train_loss=1909490.5000
2025-02-06 17:56:00,803 - INFO - Epoch 158: val_loss=618929.6875, val_acc=0.00%
2025-02-06 17:56:00,806 - INFO - Epoch 158: EPOCH_AVG_TRAIN_LOSS=1909490.5000
2025-02-06 17:56:00,809 - INFO - #################### Training epoch 159 ####################
2025-02-06 17:56:00,809 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:01,211 - INFO - Epoch 159: train_loss=3226494.7500
2025-02-06 17:56:01,505 - INFO - Epoch 159: train_loss=1283527.6250
2025-02-06 17:56:01,822 - INFO - Epoch 159: val_loss=617585.3125, val_acc=0.00%
2025-02-06 17:56:01,826 - INFO - Epoch 159: EPOCH_AVG_TRAIN_LOSS=1283527.6250
2025-02-06 17:56:01,828 - INFO - #################### Training epoch 160 ####################
2025-02-06 17:56:01,829 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:02,234 - INFO - Epoch 160: train_loss=4862067.5000
2025-02-06 17:56:02,526 - INFO - Epoch 160: train_loss=7664967.5000
2025-02-06 17:56:02,849 - INFO - Epoch 160: val_loss=616239.0000, val_acc=0.00%
2025-02-06 17:56:02,852 - INFO - Epoch 160: EPOCH_AVG_TRAIN_LOSS=4862067.5000
2025-02-06 17:56:02,855 - INFO - #################### Training epoch 161 ####################
2025-02-06 17:56:02,855 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:03,259 - INFO - Epoch 161: train_loss=5671487.0000
2025-02-06 17:56:03,551 - INFO - Epoch 161: train_loss=2296272.5000
2025-02-06 17:56:03,869 - INFO - Epoch 161: val_loss=615024.3125, val_acc=0.00%
2025-02-06 17:56:03,873 - INFO - Epoch 161: EPOCH_AVG_TRAIN_LOSS=2296272.5000
2025-02-06 17:56:03,875 - INFO - #################### Training epoch 162 ####################
2025-02-06 17:56:03,875 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:04,281 - INFO - Epoch 162: train_loss=5711808.0000
2025-02-06 17:56:04,573 - INFO - Epoch 162: train_loss=2797242.7500
2025-02-06 17:56:04,894 - INFO - Epoch 162: val_loss=614168.3125, val_acc=0.00%
2025-02-06 17:56:04,898 - INFO - Epoch 162: EPOCH_AVG_TRAIN_LOSS=2797242.7500
2025-02-06 17:56:04,900 - INFO - #################### Training epoch 163 ####################
2025-02-06 17:56:04,900 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:05,305 - INFO - Epoch 163: train_loss=7863566.0000
2025-02-06 17:56:05,598 - INFO - Epoch 163: train_loss=3896766.5000
2025-02-06 17:56:05,919 - INFO - Epoch 163: val_loss=612945.0000, val_acc=0.00%
2025-02-06 17:56:05,922 - INFO - Epoch 163: EPOCH_AVG_TRAIN_LOSS=3896766.5000
2025-02-06 17:56:05,925 - INFO - #################### Training epoch 164 ####################
2025-02-06 17:56:05,925 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:06,328 - INFO - Epoch 164: train_loss=6375422.0000
2025-02-06 17:56:06,621 - INFO - Epoch 164: train_loss=1986434.5000
2025-02-06 17:56:06,939 - INFO - Epoch 164: val_loss=611535.3125, val_acc=0.00%
2025-02-06 17:56:06,943 - INFO - Epoch 164: EPOCH_AVG_TRAIN_LOSS=1986434.5000
2025-02-06 17:56:06,945 - INFO - #################### Training epoch 165 ####################
2025-02-06 17:56:06,945 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:07,350 - INFO - Epoch 165: train_loss=5233969.0000
2025-02-06 17:56:07,643 - INFO - Epoch 165: train_loss=3069170.0000
2025-02-06 17:56:07,967 - INFO - Epoch 165: val_loss=610142.6875, val_acc=0.00%
2025-02-06 17:56:07,971 - INFO - Epoch 165: EPOCH_AVG_TRAIN_LOSS=3069170.0000
2025-02-06 17:56:07,973 - INFO - #################### Training epoch 166 ####################
2025-02-06 17:56:07,973 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:08,379 - INFO - Epoch 166: train_loss=5114254.5000
2025-02-06 17:56:08,672 - INFO - Epoch 166: train_loss=6330228.0000
2025-02-06 17:56:08,990 - INFO - Epoch 166: val_loss=608716.0000, val_acc=0.00%
2025-02-06 17:56:08,994 - INFO - Epoch 166: EPOCH_AVG_TRAIN_LOSS=5114254.5000
2025-02-06 17:56:08,996 - INFO - #################### Training epoch 167 ####################
2025-02-06 17:56:08,996 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:09,401 - INFO - Epoch 167: train_loss=2348213.0000
2025-02-06 17:56:09,694 - INFO - Epoch 167: train_loss=4699027.5000
2025-02-06 17:56:10,016 - INFO - Epoch 167: val_loss=607413.6875, val_acc=0.00%
2025-02-06 17:56:10,020 - INFO - Epoch 167: EPOCH_AVG_TRAIN_LOSS=2348213.0000
2025-02-06 17:56:10,022 - INFO - #################### Training epoch 168 ####################
2025-02-06 17:56:10,022 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:10,426 - INFO - Epoch 168: train_loss=4748405.0000
2025-02-06 17:56:10,720 - INFO - Epoch 168: train_loss=2033554.1250
2025-02-06 17:56:11,042 - INFO - Epoch 168: val_loss=606574.0000, val_acc=0.00%
2025-02-06 17:56:11,046 - INFO - Epoch 168: EPOCH_AVG_TRAIN_LOSS=2033554.1250
2025-02-06 17:56:11,048 - INFO - #################### Training epoch 169 ####################
2025-02-06 17:56:11,048 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:11,453 - INFO - Epoch 169: train_loss=3798923.0000
2025-02-06 17:56:11,745 - INFO - Epoch 169: train_loss=5288492.5000
2025-02-06 17:56:12,070 - INFO - Epoch 169: val_loss=605791.6875, val_acc=0.00%
2025-02-06 17:56:12,073 - INFO - Epoch 169: EPOCH_AVG_TRAIN_LOSS=3798923.0000
2025-02-06 17:56:12,076 - INFO - #################### Training epoch 170 ####################
2025-02-06 17:56:12,076 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:12,482 - INFO - Epoch 170: train_loss=7392510.5000
2025-02-06 17:56:12,774 - INFO - Epoch 170: train_loss=5182551.0000
2025-02-06 17:56:13,098 - INFO - Epoch 170: val_loss=604713.6875, val_acc=0.00%
2025-02-06 17:56:13,102 - INFO - Epoch 170: EPOCH_AVG_TRAIN_LOSS=5182551.0000
2025-02-06 17:56:13,104 - INFO - #################### Training epoch 171 ####################
2025-02-06 17:56:13,105 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:13,510 - INFO - Epoch 171: train_loss=3361355.5000
2025-02-06 17:56:13,802 - INFO - Epoch 171: train_loss=7328326.0000
2025-02-06 17:56:14,123 - INFO - Epoch 171: val_loss=603589.6875, val_acc=0.00%
2025-02-06 17:56:14,127 - INFO - Epoch 171: EPOCH_AVG_TRAIN_LOSS=3361355.5000
2025-02-06 17:56:14,129 - INFO - #################### Training epoch 172 ####################
2025-02-06 17:56:14,129 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:14,534 - INFO - Epoch 172: train_loss=3697197.7500
2025-02-06 17:56:14,827 - INFO - Epoch 172: train_loss=6815849.0000
2025-02-06 17:56:15,149 - INFO - Epoch 172: val_loss=602567.3125, val_acc=0.00%
2025-02-06 17:56:15,153 - INFO - Epoch 172: EPOCH_AVG_TRAIN_LOSS=3697197.7500
2025-02-06 17:56:15,155 - INFO - #################### Training epoch 173 ####################
2025-02-06 17:56:15,155 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:15,559 - INFO - Epoch 173: train_loss=3563090.5000
2025-02-06 17:56:15,852 - INFO - Epoch 173: train_loss=4193856.5000
2025-02-06 17:56:16,177 - INFO - Epoch 173: val_loss=601772.3125, val_acc=0.00%
2025-02-06 17:56:16,181 - INFO - Epoch 173: EPOCH_AVG_TRAIN_LOSS=3563090.5000
2025-02-06 17:56:16,184 - INFO - #################### Training epoch 174 ####################
2025-02-06 17:56:16,184 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:16,589 - INFO - Epoch 174: train_loss=8121464.0000
2025-02-06 17:56:16,882 - INFO - Epoch 174: train_loss=4011728.7500
2025-02-06 17:56:17,208 - INFO - Epoch 174: val_loss=601123.3125, val_acc=0.00%
2025-02-06 17:56:17,212 - INFO - Epoch 174: EPOCH_AVG_TRAIN_LOSS=4011728.7500
2025-02-06 17:56:17,214 - INFO - #################### Training epoch 175 ####################
2025-02-06 17:56:17,214 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:17,618 - INFO - Epoch 175: train_loss=4023386.0000
2025-02-06 17:56:17,910 - INFO - Epoch 175: train_loss=4011238.0000
2025-02-06 17:56:18,231 - INFO - Epoch 175: val_loss=600290.0000, val_acc=0.00%
2025-02-06 17:56:18,235 - INFO - Epoch 175: EPOCH_AVG_TRAIN_LOSS=4011238.0000
2025-02-06 17:56:18,237 - INFO - #################### Training epoch 176 ####################
2025-02-06 17:56:18,237 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:18,644 - INFO - Epoch 176: train_loss=2103187.0000
2025-02-06 17:56:18,937 - INFO - Epoch 176: train_loss=5405906.0000
2025-02-06 17:56:19,254 - INFO - Epoch 176: val_loss=599573.0000, val_acc=0.00%
2025-02-06 17:56:19,258 - INFO - Epoch 176: EPOCH_AVG_TRAIN_LOSS=2103187.0000
2025-02-06 17:56:19,260 - INFO - #################### Training epoch 177 ####################
2025-02-06 17:56:19,260 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:19,662 - INFO - Epoch 177: train_loss=5565288.0000
2025-02-06 17:56:19,955 - INFO - Epoch 177: train_loss=11156088.0000
2025-02-06 17:56:20,275 - INFO - Epoch 177: val_loss=599012.3125, val_acc=0.00%
2025-02-06 17:56:20,279 - INFO - Epoch 177: EPOCH_AVG_TRAIN_LOSS=5565288.0000
2025-02-06 17:56:20,281 - INFO - #################### Training epoch 178 ####################
2025-02-06 17:56:20,281 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:20,687 - INFO - Epoch 178: train_loss=4456497.5000
2025-02-06 17:56:20,980 - INFO - Epoch 178: train_loss=5231340.0000
2025-02-06 17:56:21,299 - INFO - Epoch 178: val_loss=598493.6875, val_acc=0.00%
2025-02-06 17:56:21,303 - INFO - Epoch 178: EPOCH_AVG_TRAIN_LOSS=4456497.5000
2025-02-06 17:56:21,305 - INFO - #################### Training epoch 179 ####################
2025-02-06 17:56:21,305 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:21,708 - INFO - Epoch 179: train_loss=7009415.5000
2025-02-06 17:56:22,000 - INFO - Epoch 179: train_loss=4455318.0000
2025-02-06 17:56:22,321 - INFO - Epoch 179: val_loss=597562.3125, val_acc=0.00%
2025-02-06 17:56:22,325 - INFO - Epoch 179: EPOCH_AVG_TRAIN_LOSS=4455318.0000
2025-02-06 17:56:22,327 - INFO - #################### Training epoch 180 ####################
2025-02-06 17:56:22,327 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:22,732 - INFO - Epoch 180: train_loss=3980833.7500
2025-02-06 17:56:23,025 - INFO - Epoch 180: train_loss=7732643.5000
2025-02-06 17:56:23,348 - INFO - Epoch 180: val_loss=596432.6875, val_acc=0.00%
2025-02-06 17:56:23,352 - INFO - Epoch 180: EPOCH_AVG_TRAIN_LOSS=3980833.7500
2025-02-06 17:56:23,354 - INFO - #################### Training epoch 181 ####################
2025-02-06 17:56:23,354 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:23,756 - INFO - Epoch 181: train_loss=6073654.0000
2025-02-06 17:56:24,048 - INFO - Epoch 181: train_loss=11173376.0000
2025-02-06 17:56:24,368 - INFO - Epoch 181: val_loss=595364.0000, val_acc=0.00%
2025-02-06 17:56:24,372 - INFO - Epoch 181: EPOCH_AVG_TRAIN_LOSS=6073654.0000
2025-02-06 17:56:24,374 - INFO - #################### Training epoch 182 ####################
2025-02-06 17:56:24,374 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:24,777 - INFO - Epoch 182: train_loss=3147072.5000
2025-02-06 17:56:25,069 - INFO - Epoch 182: train_loss=5477902.0000
2025-02-06 17:56:25,390 - INFO - Epoch 182: val_loss=594482.0000, val_acc=0.00%
2025-02-06 17:56:25,394 - INFO - Epoch 182: EPOCH_AVG_TRAIN_LOSS=3147072.5000
2025-02-06 17:56:25,396 - INFO - #################### Training epoch 183 ####################
2025-02-06 17:56:25,396 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:25,800 - INFO - Epoch 183: train_loss=9658154.0000
2025-02-06 17:56:26,092 - INFO - Epoch 183: train_loss=4187548.2500
2025-02-06 17:56:26,413 - INFO - Epoch 183: val_loss=593579.6875, val_acc=0.00%
2025-02-06 17:56:26,417 - INFO - Epoch 183: EPOCH_AVG_TRAIN_LOSS=4187548.2500
2025-02-06 17:56:26,419 - INFO - #################### Training epoch 184 ####################
2025-02-06 17:56:26,419 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:26,824 - INFO - Epoch 184: train_loss=6215435.5000
2025-02-06 17:56:27,116 - INFO - Epoch 184: train_loss=6030470.5000
2025-02-06 17:56:27,439 - INFO - Epoch 184: val_loss=592554.6875, val_acc=0.00%
2025-02-06 17:56:27,442 - INFO - Epoch 184: EPOCH_AVG_TRAIN_LOSS=6030470.5000
2025-02-06 17:56:27,445 - INFO - #################### Training epoch 185 ####################
2025-02-06 17:56:27,445 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:27,849 - INFO - Epoch 185: train_loss=2570378.5000
2025-02-06 17:56:28,141 - INFO - Epoch 185: train_loss=2366734.0000
2025-02-06 17:56:28,463 - INFO - Epoch 185: val_loss=591631.0000, val_acc=0.00%
2025-02-06 17:56:28,467 - INFO - Epoch 185: EPOCH_AVG_TRAIN_LOSS=2366734.0000
2025-02-06 17:56:28,469 - INFO - #################### Training epoch 186 ####################
2025-02-06 17:56:28,470 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:28,874 - INFO - Epoch 186: train_loss=3336961.7500
2025-02-06 17:56:29,166 - INFO - Epoch 186: train_loss=1870651.5000
2025-02-06 17:56:29,489 - INFO - Epoch 186: val_loss=590701.6875, val_acc=0.00%
2025-02-06 17:56:29,493 - INFO - Epoch 186: EPOCH_AVG_TRAIN_LOSS=1870651.5000
2025-02-06 17:56:29,495 - INFO - #################### Training epoch 187 ####################
2025-02-06 17:56:29,495 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:29,901 - INFO - Epoch 187: train_loss=7616792.0000
2025-02-06 17:56:30,193 - INFO - Epoch 187: train_loss=4783676.5000
2025-02-06 17:56:30,516 - INFO - Epoch 187: val_loss=589973.0000, val_acc=0.00%
2025-02-06 17:56:30,519 - INFO - Epoch 187: EPOCH_AVG_TRAIN_LOSS=4783676.5000
2025-02-06 17:56:30,521 - INFO - #################### Training epoch 188 ####################
2025-02-06 17:56:30,521 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:30,926 - INFO - Epoch 188: train_loss=3049497.5000
2025-02-06 17:56:31,218 - INFO - Epoch 188: train_loss=1372010.5000
2025-02-06 17:56:31,536 - INFO - Epoch 188: val_loss=589083.6875, val_acc=0.00%
2025-02-06 17:56:31,540 - INFO - Epoch 188: EPOCH_AVG_TRAIN_LOSS=1372010.5000
2025-02-06 17:56:31,542 - INFO - #################### Training epoch 189 ####################
2025-02-06 17:56:31,542 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:31,947 - INFO - Epoch 189: train_loss=5987628.0000
2025-02-06 17:56:32,239 - INFO - Epoch 189: train_loss=5825136.0000
2025-02-06 17:56:32,562 - INFO - Epoch 189: val_loss=587891.0000, val_acc=0.00%
2025-02-06 17:56:32,566 - INFO - Epoch 189: EPOCH_AVG_TRAIN_LOSS=5825136.0000
2025-02-06 17:56:32,568 - INFO - #################### Training epoch 190 ####################
2025-02-06 17:56:32,569 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:32,974 - INFO - Epoch 190: train_loss=6402998.0000
2025-02-06 17:56:33,266 - INFO - Epoch 190: train_loss=9355180.0000
2025-02-06 17:56:33,586 - INFO - Epoch 190: val_loss=586708.0000, val_acc=0.00%
2025-02-06 17:56:33,590 - INFO - Epoch 190: EPOCH_AVG_TRAIN_LOSS=6402998.0000
2025-02-06 17:56:33,592 - INFO - #################### Training epoch 191 ####################
2025-02-06 17:56:33,592 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:33,996 - INFO - Epoch 191: train_loss=3257939.0000
2025-02-06 17:56:34,288 - INFO - Epoch 191: train_loss=3901137.5000
2025-02-06 17:56:34,611 - INFO - Epoch 191: val_loss=585271.6875, val_acc=0.00%
2025-02-06 17:56:34,615 - INFO - Epoch 191: EPOCH_AVG_TRAIN_LOSS=3257939.0000
2025-02-06 17:56:34,617 - INFO - #################### Training epoch 192 ####################
2025-02-06 17:56:34,617 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:35,021 - INFO - Epoch 192: train_loss=7083111.5000
2025-02-06 17:56:35,314 - INFO - Epoch 192: train_loss=5553851.0000
2025-02-06 17:56:35,640 - INFO - Epoch 192: val_loss=583917.6875, val_acc=0.00%
2025-02-06 17:56:35,645 - INFO - Epoch 192: EPOCH_AVG_TRAIN_LOSS=5553851.0000
2025-02-06 17:56:35,647 - INFO - #################### Training epoch 193 ####################
2025-02-06 17:56:35,647 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:36,054 - INFO - Epoch 193: train_loss=4240222.0000
2025-02-06 17:56:36,346 - INFO - Epoch 193: train_loss=8563303.0000
2025-02-06 17:56:36,669 - INFO - Epoch 193: val_loss=582674.3125, val_acc=0.00%
2025-02-06 17:56:36,672 - INFO - Epoch 193: EPOCH_AVG_TRAIN_LOSS=4240222.0000
2025-02-06 17:56:36,675 - INFO - #################### Training epoch 194 ####################
2025-02-06 17:56:36,675 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:37,080 - INFO - Epoch 194: train_loss=6360233.0000
2025-02-06 17:56:37,372 - INFO - Epoch 194: train_loss=9018984.0000
2025-02-06 17:56:37,695 - INFO - Epoch 194: val_loss=581553.0000, val_acc=0.00%
2025-02-06 17:56:37,699 - INFO - Epoch 194: EPOCH_AVG_TRAIN_LOSS=6360233.0000
2025-02-06 17:56:37,701 - INFO - #################### Training epoch 195 ####################
2025-02-06 17:56:37,702 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:38,108 - INFO - Epoch 195: train_loss=4745183.5000
2025-02-06 17:56:38,400 - INFO - Epoch 195: train_loss=7999355.0000
2025-02-06 17:56:38,722 - INFO - Epoch 195: val_loss=580610.0000, val_acc=0.00%
2025-02-06 17:56:38,726 - INFO - Epoch 195: EPOCH_AVG_TRAIN_LOSS=4745183.5000
2025-02-06 17:56:38,728 - INFO - #################### Training epoch 196 ####################
2025-02-06 17:56:38,728 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:39,134 - INFO - Epoch 196: train_loss=6118315.0000
2025-02-06 17:56:39,427 - INFO - Epoch 196: train_loss=9088176.0000
2025-02-06 17:56:39,751 - INFO - Epoch 196: val_loss=579762.0000, val_acc=0.00%
2025-02-06 17:56:39,755 - INFO - Epoch 196: EPOCH_AVG_TRAIN_LOSS=6118315.0000
2025-02-06 17:56:39,757 - INFO - #################### Training epoch 197 ####################
2025-02-06 17:56:39,757 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:40,164 - INFO - Epoch 197: train_loss=11007764.0000
2025-02-06 17:56:40,457 - INFO - Epoch 197: train_loss=5917025.5000
2025-02-06 17:56:40,781 - INFO - Epoch 197: val_loss=579158.3125, val_acc=0.00%
2025-02-06 17:56:40,784 - INFO - Epoch 197: EPOCH_AVG_TRAIN_LOSS=5917025.5000
2025-02-06 17:56:40,787 - INFO - #################### Training epoch 198 ####################
2025-02-06 17:56:40,787 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:41,192 - INFO - Epoch 198: train_loss=3843794.5000
2025-02-06 17:56:41,484 - INFO - Epoch 198: train_loss=7444801.0000
2025-02-06 17:56:41,807 - INFO - Epoch 198: val_loss=578737.0000, val_acc=0.00%
2025-02-06 17:56:41,811 - INFO - Epoch 198: EPOCH_AVG_TRAIN_LOSS=3843794.5000
2025-02-06 17:56:41,813 - INFO - #################### Training epoch 199 ####################
2025-02-06 17:56:41,813 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 17:56:42,219 - INFO - Epoch 199: train_loss=3275292.7500
2025-02-06 17:56:42,512 - INFO - Epoch 199: train_loss=7530622.5000
2025-02-06 17:56:42,834 - INFO - Epoch 199: val_loss=578075.6875, val_acc=0.00%
2025-02-06 17:56:42,838 - INFO - Epoch 199: EPOCH_AVG_TRAIN_LOSS=3275292.7500
2025-02-06 17:56:43,008 - INFO - Model saved.
