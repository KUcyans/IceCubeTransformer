2025-02-06 18:05:58,283 - INFO - Starting training with the following parameters:
2025-02-06 18:05:58,283 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product|
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.001          |
| epochs          | 200            |
| batch_size      | 16             |

2025-02-06 18:05:58,890 - INFO - Epoch 0: val_loss=1.1743, val_acc=0.00%
2025-02-06 18:05:59,037 - INFO - #################### Training epoch 0 ####################
2025-02-06 18:05:59,038 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:05:59,286 - INFO - Epoch 0: train_loss=1.1355
2025-02-06 18:05:59,643 - INFO - Epoch 0: train_loss=1.0928
2025-02-06 18:05:59,952 - INFO - Epoch 0: val_loss=1.0521, val_acc=66.67%
2025-02-06 18:05:59,969 - INFO - Epoch 0: EPOCH_AVG_TRAIN_LOSS=1.0928
2025-02-06 18:05:59,999 - INFO - #################### Training epoch 1 ####################
2025-02-06 18:05:59,999 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:00,411 - INFO - Epoch 1: train_loss=1.0319
2025-02-06 18:06:00,701 - INFO - Epoch 1: train_loss=1.0890
2025-02-06 18:06:01,033 - INFO - Epoch 1: val_loss=1.1372, val_acc=0.00%
2025-02-06 18:06:01,037 - INFO - Epoch 1: EPOCH_AVG_TRAIN_LOSS=1.0319
2025-02-06 18:06:01,085 - INFO - #################### Training epoch 2 ####################
2025-02-06 18:06:01,086 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:01,499 - INFO - Epoch 2: train_loss=0.9838
2025-02-06 18:06:01,790 - INFO - Epoch 2: train_loss=1.0789
2025-02-06 18:06:02,119 - INFO - Epoch 2: val_loss=1.1895, val_acc=0.00%
2025-02-06 18:06:02,123 - INFO - Epoch 2: EPOCH_AVG_TRAIN_LOSS=0.9838
2025-02-06 18:06:02,166 - INFO - #################### Training epoch 3 ####################
2025-02-06 18:06:02,166 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:02,583 - INFO - Epoch 3: train_loss=0.9204
2025-02-06 18:06:02,873 - INFO - Epoch 3: train_loss=1.0902
2025-02-06 18:06:03,203 - INFO - Epoch 3: val_loss=1.1300, val_acc=33.33%
2025-02-06 18:06:03,207 - INFO - Epoch 3: EPOCH_AVG_TRAIN_LOSS=0.9204
2025-02-06 18:06:03,236 - INFO - #################### Training epoch 4 ####################
2025-02-06 18:06:03,236 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:03,651 - INFO - Epoch 4: train_loss=0.8912
2025-02-06 18:06:03,941 - INFO - Epoch 4: train_loss=0.9884
2025-02-06 18:06:04,275 - INFO - Epoch 4: val_loss=1.2135, val_acc=33.33%
2025-02-06 18:06:04,279 - INFO - Epoch 4: EPOCH_AVG_TRAIN_LOSS=0.8912
2025-02-06 18:06:04,281 - INFO - #################### Training epoch 5 ####################
2025-02-06 18:06:04,281 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:04,698 - INFO - Epoch 5: train_loss=0.8691
2025-02-06 18:06:04,989 - INFO - Epoch 5: train_loss=1.0996
2025-02-06 18:06:05,320 - INFO - Epoch 5: val_loss=1.4160, val_acc=33.33%
2025-02-06 18:06:05,324 - INFO - Epoch 5: EPOCH_AVG_TRAIN_LOSS=0.8691
2025-02-06 18:06:05,326 - INFO - #################### Training epoch 6 ####################
2025-02-06 18:06:05,326 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:05,740 - INFO - Epoch 6: train_loss=1.0677
2025-02-06 18:06:06,031 - INFO - Epoch 6: train_loss=1.0351
2025-02-06 18:06:06,360 - INFO - Epoch 6: val_loss=1.4070, val_acc=33.33%
2025-02-06 18:06:06,363 - INFO - Epoch 6: EPOCH_AVG_TRAIN_LOSS=1.0351
2025-02-06 18:06:06,366 - INFO - #################### Training epoch 7 ####################
2025-02-06 18:06:06,366 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:06,785 - INFO - Epoch 7: train_loss=1.0066
2025-02-06 18:06:07,075 - INFO - Epoch 7: train_loss=1.0918
2025-02-06 18:06:07,408 - INFO - Epoch 7: val_loss=1.2845, val_acc=33.33%
2025-02-06 18:06:07,412 - INFO - Epoch 7: EPOCH_AVG_TRAIN_LOSS=1.0066
2025-02-06 18:06:07,414 - INFO - #################### Training epoch 8 ####################
2025-02-06 18:06:07,414 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:07,828 - INFO - Epoch 8: train_loss=0.9210
2025-02-06 18:06:08,119 - INFO - Epoch 8: train_loss=0.7847
2025-02-06 18:06:08,451 - INFO - Epoch 8: val_loss=1.2555, val_acc=0.00%
2025-02-06 18:06:08,454 - INFO - Epoch 8: EPOCH_AVG_TRAIN_LOSS=0.7847
2025-02-06 18:06:08,457 - INFO - #################### Training epoch 9 ####################
2025-02-06 18:06:08,457 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:08,874 - INFO - Epoch 9: train_loss=0.8938
2025-02-06 18:06:09,164 - INFO - Epoch 9: train_loss=1.0068
2025-02-06 18:06:09,499 - INFO - Epoch 9: val_loss=1.2918, val_acc=33.33%
2025-02-06 18:06:09,503 - INFO - Epoch 9: EPOCH_AVG_TRAIN_LOSS=0.8938
2025-02-06 18:06:09,505 - INFO - #################### Training epoch 10 ####################
2025-02-06 18:06:09,505 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:09,922 - INFO - Epoch 10: train_loss=0.9243
2025-02-06 18:06:10,212 - INFO - Epoch 10: train_loss=1.1742
2025-02-06 18:06:10,543 - INFO - Epoch 10: val_loss=1.3496, val_acc=0.00%
2025-02-06 18:06:10,547 - INFO - Epoch 10: EPOCH_AVG_TRAIN_LOSS=0.9243
2025-02-06 18:06:10,549 - INFO - #################### Training epoch 11 ####################
2025-02-06 18:06:10,549 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:10,967 - INFO - Epoch 11: train_loss=0.9954
2025-02-06 18:06:11,258 - INFO - Epoch 11: train_loss=0.9160
2025-02-06 18:06:11,591 - INFO - Epoch 11: val_loss=1.2583, val_acc=0.00%
2025-02-06 18:06:11,594 - INFO - Epoch 11: EPOCH_AVG_TRAIN_LOSS=0.9160
2025-02-06 18:06:11,597 - INFO - #################### Training epoch 12 ####################
2025-02-06 18:06:11,597 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:12,012 - INFO - Epoch 12: train_loss=0.9810
2025-02-06 18:06:12,304 - INFO - Epoch 12: train_loss=0.7448
2025-02-06 18:06:12,635 - INFO - Epoch 12: val_loss=1.1512, val_acc=0.00%
2025-02-06 18:06:12,638 - INFO - Epoch 12: EPOCH_AVG_TRAIN_LOSS=0.7448
2025-02-06 18:06:12,641 - INFO - #################### Training epoch 13 ####################
2025-02-06 18:06:12,641 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:13,058 - INFO - Epoch 13: train_loss=0.8917
2025-02-06 18:06:13,349 - INFO - Epoch 13: train_loss=0.7839
2025-02-06 18:06:13,680 - INFO - Epoch 13: val_loss=1.0993, val_acc=33.33%
2025-02-06 18:06:13,684 - INFO - Epoch 13: EPOCH_AVG_TRAIN_LOSS=0.7839
2025-02-06 18:06:13,735 - INFO - #################### Training epoch 14 ####################
2025-02-06 18:06:13,735 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:14,151 - INFO - Epoch 14: train_loss=0.8896
2025-02-06 18:06:14,442 - INFO - Epoch 14: train_loss=1.0470
2025-02-06 18:06:14,774 - INFO - Epoch 14: val_loss=1.0991, val_acc=33.33%
2025-02-06 18:06:14,778 - INFO - Epoch 14: EPOCH_AVG_TRAIN_LOSS=0.8896
2025-02-06 18:06:14,806 - INFO - #################### Training epoch 15 ####################
2025-02-06 18:06:14,806 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:15,223 - INFO - Epoch 15: train_loss=0.9361
2025-02-06 18:06:15,514 - INFO - Epoch 15: train_loss=1.2135
2025-02-06 18:06:15,846 - INFO - Epoch 15: val_loss=1.0933, val_acc=33.33%
2025-02-06 18:06:15,849 - INFO - Epoch 15: EPOCH_AVG_TRAIN_LOSS=0.9361
2025-02-06 18:06:15,878 - INFO - #################### Training epoch 16 ####################
2025-02-06 18:06:15,878 - INFO - Current Learning Rate: 1.000000e-03
2025-02-06 18:06:16,294 - INFO - Epoch 16: train_loss=1.2005
2025-02-06 18:06:16,585 - INFO - Epoch 16: train_loss=0.9258
2025-02-06 18:06:16,917 - INFO - Epoch 16: val_loss=1.0953, val_acc=33.33%
2025-02-06 18:06:16,920 - INFO - Epoch 16: EPOCH_AVG_TRAIN_LOSS=0.9258
2025-02-06 18:06:16,948 - INFO - #################### Training epoch 17 ####################
2025-02-06 18:06:16,949 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:06:17,366 - INFO - Epoch 17: train_loss=1.1096
2025-02-06 18:06:17,657 - INFO - Epoch 17: train_loss=1.2128
2025-02-06 18:06:17,990 - INFO - Epoch 17: val_loss=1.1049, val_acc=33.33%
2025-02-06 18:06:17,994 - INFO - Epoch 17: EPOCH_AVG_TRAIN_LOSS=1.1096
2025-02-06 18:06:17,996 - INFO - #################### Training epoch 18 ####################
2025-02-06 18:06:17,997 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:06:18,415 - INFO - Epoch 18: train_loss=1.1531
2025-02-06 18:06:18,707 - INFO - Epoch 18: train_loss=1.3034
2025-02-06 18:06:19,039 - INFO - Epoch 18: val_loss=1.1022, val_acc=33.33%
2025-02-06 18:06:19,042 - INFO - Epoch 18: EPOCH_AVG_TRAIN_LOSS=1.1531
2025-02-06 18:06:19,045 - INFO - #################### Training epoch 19 ####################
2025-02-06 18:06:19,045 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:06:19,463 - INFO - Epoch 19: train_loss=1.2788
2025-02-06 18:06:19,754 - INFO - Epoch 19: train_loss=1.0600
2025-02-06 18:06:20,090 - INFO - Epoch 19: val_loss=1.1046, val_acc=33.33%
2025-02-06 18:06:20,094 - INFO - Epoch 19: EPOCH_AVG_TRAIN_LOSS=1.0600
2025-02-06 18:06:20,096 - INFO - #################### Training epoch 20 ####################
2025-02-06 18:06:20,096 - INFO - Current Learning Rate: 5.000000e-04
2025-02-06 18:06:20,513 - INFO - Epoch 20: train_loss=1.3206
2025-02-06 18:06:20,806 - INFO - Epoch 20: train_loss=0.9913
2025-02-06 18:06:21,133 - INFO - Epoch 20: val_loss=1.1076, val_acc=33.33%
2025-02-06 18:06:21,137 - INFO - Epoch 20: EPOCH_AVG_TRAIN_LOSS=0.9913
2025-02-06 18:06:21,139 - INFO - #################### Training epoch 21 ####################
2025-02-06 18:06:21,139 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:06:21,557 - INFO - Epoch 21: train_loss=1.1267
2025-02-06 18:06:21,849 - INFO - Epoch 21: train_loss=1.4096
2025-02-06 18:06:22,184 - INFO - Epoch 21: val_loss=1.1139, val_acc=33.33%
2025-02-06 18:06:22,188 - INFO - Epoch 21: EPOCH_AVG_TRAIN_LOSS=1.1267
2025-02-06 18:06:22,190 - INFO - #################### Training epoch 22 ####################
2025-02-06 18:06:22,190 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:06:22,610 - INFO - Epoch 22: train_loss=1.0519
2025-02-06 18:06:22,901 - INFO - Epoch 22: train_loss=1.4484
2025-02-06 18:06:23,232 - INFO - Epoch 22: val_loss=1.1135, val_acc=33.33%
2025-02-06 18:06:23,236 - INFO - Epoch 22: EPOCH_AVG_TRAIN_LOSS=1.0519
2025-02-06 18:06:23,238 - INFO - #################### Training epoch 23 ####################
2025-02-06 18:06:23,238 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:06:23,657 - INFO - Epoch 23: train_loss=1.0534
2025-02-06 18:06:23,949 - INFO - Epoch 23: train_loss=1.6425
2025-02-06 18:06:24,280 - INFO - Epoch 23: val_loss=1.1100, val_acc=33.33%
2025-02-06 18:06:24,284 - INFO - Epoch 23: EPOCH_AVG_TRAIN_LOSS=1.0534
2025-02-06 18:06:24,286 - INFO - #################### Training epoch 24 ####################
2025-02-06 18:06:24,286 - INFO - Current Learning Rate: 2.500000e-04
2025-02-06 18:06:24,694 - INFO - Epoch 24: train_loss=1.1096
2025-02-06 18:06:24,986 - INFO - Epoch 24: train_loss=1.4938
2025-02-06 18:06:25,320 - INFO - Epoch 24: val_loss=1.1111, val_acc=33.33%
2025-02-06 18:06:25,323 - INFO - Epoch 24: EPOCH_AVG_TRAIN_LOSS=1.1096
2025-02-06 18:06:25,326 - INFO - #################### Training epoch 25 ####################
2025-02-06 18:06:25,326 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:06:25,741 - INFO - Epoch 25: train_loss=1.2623
2025-02-06 18:06:26,032 - INFO - Epoch 25: train_loss=1.3213
2025-02-06 18:06:26,365 - INFO - Epoch 25: val_loss=1.1114, val_acc=33.33%
2025-02-06 18:06:26,369 - INFO - Epoch 25: EPOCH_AVG_TRAIN_LOSS=1.2623
2025-02-06 18:06:26,371 - INFO - #################### Training epoch 26 ####################
2025-02-06 18:06:26,371 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:06:26,787 - INFO - Epoch 26: train_loss=1.3195
2025-02-06 18:06:27,077 - INFO - Epoch 26: train_loss=1.1774
2025-02-06 18:06:27,412 - INFO - Epoch 26: val_loss=1.1141, val_acc=33.33%
2025-02-06 18:06:27,415 - INFO - Epoch 26: EPOCH_AVG_TRAIN_LOSS=1.1774
2025-02-06 18:06:27,418 - INFO - #################### Training epoch 27 ####################
2025-02-06 18:06:27,418 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:06:27,831 - INFO - Epoch 27: train_loss=1.2193
2025-02-06 18:06:28,123 - INFO - Epoch 27: train_loss=1.3459
2025-02-06 18:06:28,453 - INFO - Epoch 27: val_loss=1.1135, val_acc=33.33%
2025-02-06 18:06:28,456 - INFO - Epoch 27: EPOCH_AVG_TRAIN_LOSS=1.2193
2025-02-06 18:06:28,459 - INFO - #################### Training epoch 28 ####################
2025-02-06 18:06:28,459 - INFO - Current Learning Rate: 1.250000e-04
2025-02-06 18:06:28,872 - INFO - Epoch 28: train_loss=1.2267
2025-02-06 18:06:29,164 - INFO - Epoch 28: train_loss=1.4609
2025-02-06 18:06:29,496 - INFO - Epoch 28: val_loss=1.1156, val_acc=33.33%
2025-02-06 18:06:29,500 - INFO - Epoch 28: EPOCH_AVG_TRAIN_LOSS=1.2267
2025-02-06 18:06:29,502 - INFO - #################### Training epoch 29 ####################
2025-02-06 18:06:29,502 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:06:29,917 - INFO - Epoch 29: train_loss=1.2744
2025-02-06 18:06:30,208 - INFO - Epoch 29: train_loss=1.2620
2025-02-06 18:06:30,541 - INFO - Epoch 29: val_loss=1.1080, val_acc=33.33%
2025-02-06 18:06:30,545 - INFO - Epoch 29: EPOCH_AVG_TRAIN_LOSS=1.2620
2025-02-06 18:06:30,547 - INFO - #################### Training epoch 30 ####################
2025-02-06 18:06:30,547 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:06:30,958 - INFO - Epoch 30: train_loss=1.3400
2025-02-06 18:06:31,249 - INFO - Epoch 30: train_loss=1.1559
2025-02-06 18:06:31,582 - INFO - Epoch 30: val_loss=1.1127, val_acc=33.33%
2025-02-06 18:06:31,586 - INFO - Epoch 30: EPOCH_AVG_TRAIN_LOSS=1.1559
2025-02-06 18:06:31,588 - INFO - #################### Training epoch 31 ####################
2025-02-06 18:06:31,588 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:06:32,008 - INFO - Epoch 31: train_loss=1.1226
2025-02-06 18:06:32,299 - INFO - Epoch 31: train_loss=1.4620
2025-02-06 18:06:32,631 - INFO - Epoch 31: val_loss=1.1121, val_acc=33.33%
2025-02-06 18:06:32,635 - INFO - Epoch 31: EPOCH_AVG_TRAIN_LOSS=1.1226
2025-02-06 18:06:32,637 - INFO - #################### Training epoch 32 ####################
2025-02-06 18:06:32,637 - INFO - Current Learning Rate: 6.250000e-05
2025-02-06 18:06:33,052 - INFO - Epoch 32: train_loss=1.2868
2025-02-06 18:06:33,344 - INFO - Epoch 32: train_loss=1.2845
2025-02-06 18:06:33,674 - INFO - Epoch 32: val_loss=1.1167, val_acc=33.33%
2025-02-06 18:06:33,678 - INFO - Epoch 32: EPOCH_AVG_TRAIN_LOSS=1.2845
2025-02-06 18:06:33,680 - INFO - #################### Training epoch 33 ####################
2025-02-06 18:06:33,680 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:06:34,097 - INFO - Epoch 33: train_loss=1.2713
2025-02-06 18:06:34,388 - INFO - Epoch 33: train_loss=1.1296
2025-02-06 18:06:34,719 - INFO - Epoch 33: val_loss=1.1116, val_acc=33.33%
2025-02-06 18:06:34,723 - INFO - Epoch 33: EPOCH_AVG_TRAIN_LOSS=1.1296
2025-02-06 18:06:34,725 - INFO - #################### Training epoch 34 ####################
2025-02-06 18:06:34,725 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:06:35,141 - INFO - Epoch 34: train_loss=1.0387
2025-02-06 18:06:35,432 - INFO - Epoch 34: train_loss=1.6699
2025-02-06 18:06:35,760 - INFO - Epoch 34: val_loss=1.1134, val_acc=33.33%
2025-02-06 18:06:35,763 - INFO - Epoch 34: EPOCH_AVG_TRAIN_LOSS=1.0387
2025-02-06 18:06:35,766 - INFO - #################### Training epoch 35 ####################
2025-02-06 18:06:35,766 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:06:36,183 - INFO - Epoch 35: train_loss=1.3774
2025-02-06 18:06:36,474 - INFO - Epoch 35: train_loss=0.9860
2025-02-06 18:06:36,807 - INFO - Epoch 35: val_loss=1.1164, val_acc=33.33%
2025-02-06 18:06:36,810 - INFO - Epoch 35: EPOCH_AVG_TRAIN_LOSS=0.9860
2025-02-06 18:06:36,813 - INFO - #################### Training epoch 36 ####################
2025-02-06 18:06:36,813 - INFO - Current Learning Rate: 3.125000e-05
2025-02-06 18:06:37,229 - INFO - Epoch 36: train_loss=1.5142
2025-02-06 18:06:37,521 - INFO - Epoch 36: train_loss=0.8766
2025-02-06 18:06:37,852 - INFO - Epoch 36: val_loss=1.1180, val_acc=33.33%
2025-02-06 18:06:37,856 - INFO - Epoch 36: EPOCH_AVG_TRAIN_LOSS=0.8766
2025-02-06 18:06:37,858 - INFO - #################### Training epoch 37 ####################
2025-02-06 18:06:37,858 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:06:38,273 - INFO - Epoch 37: train_loss=1.1498
2025-02-06 18:06:38,564 - INFO - Epoch 37: train_loss=1.5517
2025-02-06 18:06:38,893 - INFO - Epoch 37: val_loss=1.1108, val_acc=33.33%
2025-02-06 18:06:38,896 - INFO - Epoch 37: EPOCH_AVG_TRAIN_LOSS=1.1498
2025-02-06 18:06:38,899 - INFO - #################### Training epoch 38 ####################
2025-02-06 18:06:38,899 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:06:39,315 - INFO - Epoch 38: train_loss=1.2750
2025-02-06 18:06:39,606 - INFO - Epoch 38: train_loss=1.2411
2025-02-06 18:06:39,937 - INFO - Epoch 38: val_loss=1.1166, val_acc=33.33%
2025-02-06 18:06:39,940 - INFO - Epoch 38: EPOCH_AVG_TRAIN_LOSS=1.2411
2025-02-06 18:06:39,943 - INFO - #################### Training epoch 39 ####################
2025-02-06 18:06:39,943 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:06:40,359 - INFO - Epoch 39: train_loss=1.1702
2025-02-06 18:06:40,651 - INFO - Epoch 39: train_loss=1.4389
2025-02-06 18:06:40,979 - INFO - Epoch 39: val_loss=1.1147, val_acc=33.33%
2025-02-06 18:06:40,983 - INFO - Epoch 39: EPOCH_AVG_TRAIN_LOSS=1.1702
2025-02-06 18:06:40,985 - INFO - #################### Training epoch 40 ####################
2025-02-06 18:06:40,985 - INFO - Current Learning Rate: 1.562500e-05
2025-02-06 18:06:41,400 - INFO - Epoch 40: train_loss=1.0228
2025-02-06 18:06:41,691 - INFO - Epoch 40: train_loss=1.7645
2025-02-06 18:06:42,022 - INFO - Epoch 40: val_loss=1.1070, val_acc=33.33%
2025-02-06 18:06:42,026 - INFO - Epoch 40: EPOCH_AVG_TRAIN_LOSS=1.0228
2025-02-06 18:06:42,028 - INFO - #################### Training epoch 41 ####################
2025-02-06 18:06:42,028 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:06:42,445 - INFO - Epoch 41: train_loss=1.4320
2025-02-06 18:06:42,736 - INFO - Epoch 41: train_loss=0.9628
2025-02-06 18:06:43,064 - INFO - Epoch 41: val_loss=1.1136, val_acc=33.33%
2025-02-06 18:06:43,068 - INFO - Epoch 41: EPOCH_AVG_TRAIN_LOSS=0.9628
2025-02-06 18:06:43,070 - INFO - #################### Training epoch 42 ####################
2025-02-06 18:06:43,070 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:06:43,488 - INFO - Epoch 42: train_loss=1.2969
2025-02-06 18:06:43,779 - INFO - Epoch 42: train_loss=1.1888
2025-02-06 18:06:44,108 - INFO - Epoch 42: val_loss=1.1125, val_acc=33.33%
2025-02-06 18:06:44,111 - INFO - Epoch 42: EPOCH_AVG_TRAIN_LOSS=1.1888
2025-02-06 18:06:44,113 - INFO - #################### Training epoch 43 ####################
2025-02-06 18:06:44,114 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:06:44,532 - INFO - Epoch 43: train_loss=1.0878
2025-02-06 18:06:44,823 - INFO - Epoch 43: train_loss=1.5825
2025-02-06 18:06:45,152 - INFO - Epoch 43: val_loss=1.1147, val_acc=33.33%
2025-02-06 18:06:45,156 - INFO - Epoch 43: EPOCH_AVG_TRAIN_LOSS=1.0878
2025-02-06 18:06:45,158 - INFO - #################### Training epoch 44 ####################
2025-02-06 18:06:45,158 - INFO - Current Learning Rate: 7.812500e-06
2025-02-06 18:06:45,580 - INFO - Epoch 44: train_loss=1.2736
2025-02-06 18:06:45,872 - INFO - Epoch 44: train_loss=1.2571
2025-02-06 18:06:46,204 - INFO - Epoch 44: val_loss=1.1127, val_acc=33.33%
2025-02-06 18:06:46,208 - INFO - Epoch 44: EPOCH_AVG_TRAIN_LOSS=1.2571
2025-02-06 18:06:46,210 - INFO - #################### Training epoch 45 ####################
2025-02-06 18:06:46,211 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:06:46,629 - INFO - Epoch 45: train_loss=1.2447
2025-02-06 18:06:46,920 - INFO - Epoch 45: train_loss=1.2769
2025-02-06 18:06:47,251 - INFO - Epoch 45: val_loss=1.1160, val_acc=33.33%
2025-02-06 18:06:47,255 - INFO - Epoch 45: EPOCH_AVG_TRAIN_LOSS=1.2447
2025-02-06 18:06:47,257 - INFO - #################### Training epoch 46 ####################
2025-02-06 18:06:47,257 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:06:47,674 - INFO - Epoch 46: train_loss=1.4055
2025-02-06 18:06:47,965 - INFO - Epoch 46: train_loss=1.0846
2025-02-06 18:06:48,293 - INFO - Epoch 46: val_loss=1.1176, val_acc=33.33%
2025-02-06 18:06:48,297 - INFO - Epoch 46: EPOCH_AVG_TRAIN_LOSS=1.0846
2025-02-06 18:06:48,299 - INFO - #################### Training epoch 47 ####################
2025-02-06 18:06:48,299 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:06:48,714 - INFO - Epoch 47: train_loss=1.2832
2025-02-06 18:06:49,006 - INFO - Epoch 47: train_loss=1.0975
2025-02-06 18:06:49,340 - INFO - Epoch 47: val_loss=1.1221, val_acc=33.33%
2025-02-06 18:06:49,344 - INFO - Epoch 47: EPOCH_AVG_TRAIN_LOSS=1.0975
2025-02-06 18:06:49,346 - INFO - #################### Training epoch 48 ####################
2025-02-06 18:06:49,346 - INFO - Current Learning Rate: 3.906250e-06
2025-02-06 18:06:49,761 - INFO - Epoch 48: train_loss=1.2327
2025-02-06 18:06:50,053 - INFO - Epoch 48: train_loss=1.2121
2025-02-06 18:06:50,384 - INFO - Epoch 48: val_loss=1.1146, val_acc=33.33%
2025-02-06 18:06:50,387 - INFO - Epoch 48: EPOCH_AVG_TRAIN_LOSS=1.2121
2025-02-06 18:06:50,390 - INFO - #################### Training epoch 49 ####################
2025-02-06 18:06:50,390 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:06:50,807 - INFO - Epoch 49: train_loss=1.2031
2025-02-06 18:06:51,099 - INFO - Epoch 49: train_loss=1.3649
2025-02-06 18:06:51,428 - INFO - Epoch 49: val_loss=1.1157, val_acc=33.33%
2025-02-06 18:06:51,432 - INFO - Epoch 49: EPOCH_AVG_TRAIN_LOSS=1.2031
2025-02-06 18:06:51,434 - INFO - #################### Training epoch 50 ####################
2025-02-06 18:06:51,434 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:06:51,850 - INFO - Epoch 50: train_loss=1.4453
2025-02-06 18:06:52,142 - INFO - Epoch 50: train_loss=0.8597
2025-02-06 18:06:52,474 - INFO - Epoch 50: val_loss=1.1145, val_acc=33.33%
2025-02-06 18:06:52,478 - INFO - Epoch 50: EPOCH_AVG_TRAIN_LOSS=0.8597
2025-02-06 18:06:52,480 - INFO - #################### Training epoch 51 ####################
2025-02-06 18:06:52,480 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:06:52,895 - INFO - Epoch 51: train_loss=1.3748
2025-02-06 18:06:53,187 - INFO - Epoch 51: train_loss=1.0269
2025-02-06 18:06:53,519 - INFO - Epoch 51: val_loss=1.1136, val_acc=33.33%
2025-02-06 18:06:53,522 - INFO - Epoch 51: EPOCH_AVG_TRAIN_LOSS=1.0269
2025-02-06 18:06:53,525 - INFO - #################### Training epoch 52 ####################
2025-02-06 18:06:53,525 - INFO - Current Learning Rate: 1.953125e-06
2025-02-06 18:06:53,940 - INFO - Epoch 52: train_loss=1.1466
2025-02-06 18:06:54,231 - INFO - Epoch 52: train_loss=1.4578
2025-02-06 18:06:54,564 - INFO - Epoch 52: val_loss=1.1076, val_acc=33.33%
2025-02-06 18:06:54,568 - INFO - Epoch 52: EPOCH_AVG_TRAIN_LOSS=1.1466
2025-02-06 18:06:54,570 - INFO - #################### Training epoch 53 ####################
2025-02-06 18:06:54,570 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:06:54,987 - INFO - Epoch 53: train_loss=1.0979
2025-02-06 18:06:55,279 - INFO - Epoch 53: train_loss=1.5537
2025-02-06 18:06:55,610 - INFO - Epoch 53: val_loss=1.1126, val_acc=33.33%
2025-02-06 18:06:55,614 - INFO - Epoch 53: EPOCH_AVG_TRAIN_LOSS=1.0979
2025-02-06 18:06:55,616 - INFO - #################### Training epoch 54 ####################
2025-02-06 18:06:55,616 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:06:56,034 - INFO - Epoch 54: train_loss=1.4390
2025-02-06 18:06:56,325 - INFO - Epoch 54: train_loss=0.8518
2025-02-06 18:06:56,660 - INFO - Epoch 54: val_loss=1.1136, val_acc=33.33%
2025-02-06 18:06:56,664 - INFO - Epoch 54: EPOCH_AVG_TRAIN_LOSS=0.8518
2025-02-06 18:06:56,666 - INFO - #################### Training epoch 55 ####################
2025-02-06 18:06:56,666 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:06:57,083 - INFO - Epoch 55: train_loss=1.2982
2025-02-06 18:06:57,375 - INFO - Epoch 55: train_loss=1.2035
2025-02-06 18:06:57,711 - INFO - Epoch 55: val_loss=1.1163, val_acc=33.33%
2025-02-06 18:06:57,714 - INFO - Epoch 55: EPOCH_AVG_TRAIN_LOSS=1.2035
2025-02-06 18:06:57,717 - INFO - #################### Training epoch 56 ####################
2025-02-06 18:06:57,717 - INFO - Current Learning Rate: 9.765625e-07
2025-02-06 18:06:58,133 - INFO - Epoch 56: train_loss=1.2644
2025-02-06 18:06:58,425 - INFO - Epoch 56: train_loss=1.3621
2025-02-06 18:06:58,757 - INFO - Epoch 56: val_loss=1.1179, val_acc=33.33%
2025-02-06 18:06:58,761 - INFO - Epoch 56: EPOCH_AVG_TRAIN_LOSS=1.2644
2025-02-06 18:06:58,763 - INFO - #################### Training epoch 57 ####################
2025-02-06 18:06:58,763 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:06:59,182 - INFO - Epoch 57: train_loss=1.3970
2025-02-06 18:06:59,474 - INFO - Epoch 57: train_loss=1.1045
2025-02-06 18:06:59,807 - INFO - Epoch 57: val_loss=1.1139, val_acc=33.33%
2025-02-06 18:06:59,811 - INFO - Epoch 57: EPOCH_AVG_TRAIN_LOSS=1.1045
2025-02-06 18:06:59,813 - INFO - #################### Training epoch 58 ####################
2025-02-06 18:06:59,813 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:07:00,228 - INFO - Epoch 58: train_loss=1.1942
2025-02-06 18:07:00,520 - INFO - Epoch 58: train_loss=1.3348
2025-02-06 18:07:00,851 - INFO - Epoch 58: val_loss=1.1124, val_acc=33.33%
2025-02-06 18:07:00,854 - INFO - Epoch 58: EPOCH_AVG_TRAIN_LOSS=1.1942
2025-02-06 18:07:00,857 - INFO - #################### Training epoch 59 ####################
2025-02-06 18:07:00,857 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:07:01,275 - INFO - Epoch 59: train_loss=1.1847
2025-02-06 18:07:01,566 - INFO - Epoch 59: train_loss=1.3509
2025-02-06 18:07:01,902 - INFO - Epoch 59: val_loss=1.1159, val_acc=33.33%
2025-02-06 18:07:01,906 - INFO - Epoch 59: EPOCH_AVG_TRAIN_LOSS=1.1847
2025-02-06 18:07:01,908 - INFO - #################### Training epoch 60 ####################
2025-02-06 18:07:01,908 - INFO - Current Learning Rate: 4.882813e-07
2025-02-06 18:07:02,324 - INFO - Epoch 60: train_loss=1.4450
2025-02-06 18:07:02,616 - INFO - Epoch 60: train_loss=0.8927
2025-02-06 18:07:02,948 - INFO - Epoch 60: val_loss=1.1142, val_acc=33.33%
2025-02-06 18:07:02,952 - INFO - Epoch 60: EPOCH_AVG_TRAIN_LOSS=0.8927
2025-02-06 18:07:02,954 - INFO - #################### Training epoch 61 ####################
2025-02-06 18:07:02,954 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:07:03,373 - INFO - Epoch 61: train_loss=1.1845
2025-02-06 18:07:03,664 - INFO - Epoch 61: train_loss=1.3658
2025-02-06 18:07:03,998 - INFO - Epoch 61: val_loss=1.1181, val_acc=33.33%
2025-02-06 18:07:04,002 - INFO - Epoch 61: EPOCH_AVG_TRAIN_LOSS=1.1845
2025-02-06 18:07:04,004 - INFO - #################### Training epoch 62 ####################
2025-02-06 18:07:04,004 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:07:04,424 - INFO - Epoch 62: train_loss=1.4627
2025-02-06 18:07:04,715 - INFO - Epoch 62: train_loss=0.8754
2025-02-06 18:07:05,048 - INFO - Epoch 62: val_loss=1.1139, val_acc=33.33%
2025-02-06 18:07:05,052 - INFO - Epoch 62: EPOCH_AVG_TRAIN_LOSS=0.8754
2025-02-06 18:07:05,054 - INFO - #################### Training epoch 63 ####################
2025-02-06 18:07:05,054 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:07:05,471 - INFO - Epoch 63: train_loss=1.3843
2025-02-06 18:07:05,762 - INFO - Epoch 63: train_loss=1.0255
2025-02-06 18:07:06,095 - INFO - Epoch 63: val_loss=1.1168, val_acc=33.33%
2025-02-06 18:07:06,099 - INFO - Epoch 63: EPOCH_AVG_TRAIN_LOSS=1.0255
2025-02-06 18:07:06,101 - INFO - #################### Training epoch 64 ####################
2025-02-06 18:07:06,101 - INFO - Current Learning Rate: 2.441406e-07
2025-02-06 18:07:06,519 - INFO - Epoch 64: train_loss=1.1550
2025-02-06 18:07:06,811 - INFO - Epoch 64: train_loss=1.3314
2025-02-06 18:07:07,143 - INFO - Epoch 64: val_loss=1.1100, val_acc=33.33%
2025-02-06 18:07:07,147 - INFO - Epoch 64: EPOCH_AVG_TRAIN_LOSS=1.1550
2025-02-06 18:07:07,149 - INFO - #################### Training epoch 65 ####################
2025-02-06 18:07:07,149 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:07:07,567 - INFO - Epoch 65: train_loss=1.1958
2025-02-06 18:07:07,858 - INFO - Epoch 65: train_loss=1.3010
2025-02-06 18:07:08,184 - INFO - Epoch 65: val_loss=1.1145, val_acc=33.33%
2025-02-06 18:07:08,188 - INFO - Epoch 65: EPOCH_AVG_TRAIN_LOSS=1.1958
2025-02-06 18:07:08,190 - INFO - #################### Training epoch 66 ####################
2025-02-06 18:07:08,190 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:07:08,605 - INFO - Epoch 66: train_loss=1.1676
2025-02-06 18:07:08,896 - INFO - Epoch 66: train_loss=1.4787
2025-02-06 18:07:09,228 - INFO - Epoch 66: val_loss=1.1136, val_acc=33.33%
2025-02-06 18:07:09,231 - INFO - Epoch 66: EPOCH_AVG_TRAIN_LOSS=1.1676
2025-02-06 18:07:09,234 - INFO - #################### Training epoch 67 ####################
2025-02-06 18:07:09,234 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:07:09,650 - INFO - Epoch 67: train_loss=1.1760
2025-02-06 18:07:09,942 - INFO - Epoch 67: train_loss=1.3986
2025-02-06 18:07:10,272 - INFO - Epoch 67: val_loss=1.1119, val_acc=33.33%
2025-02-06 18:07:10,276 - INFO - Epoch 67: EPOCH_AVG_TRAIN_LOSS=1.1760
2025-02-06 18:07:10,278 - INFO - #################### Training epoch 68 ####################
2025-02-06 18:07:10,279 - INFO - Current Learning Rate: 1.220703e-07
2025-02-06 18:07:10,698 - INFO - Epoch 68: train_loss=1.2796
2025-02-06 18:07:10,990 - INFO - Epoch 68: train_loss=1.2798
2025-02-06 18:07:11,320 - INFO - Epoch 68: val_loss=1.1133, val_acc=33.33%
2025-02-06 18:07:11,324 - INFO - Epoch 68: EPOCH_AVG_TRAIN_LOSS=1.2796
2025-02-06 18:07:11,326 - INFO - #################### Training epoch 69 ####################
2025-02-06 18:07:11,326 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 18:07:11,745 - INFO - Epoch 69: train_loss=1.3370
2025-02-06 18:07:12,036 - INFO - Epoch 69: train_loss=1.1366
2025-02-06 18:07:12,370 - INFO - Epoch 69: val_loss=1.1202, val_acc=33.33%
2025-02-06 18:07:12,374 - INFO - Epoch 69: EPOCH_AVG_TRAIN_LOSS=1.1366
2025-02-06 18:07:12,376 - INFO - #################### Training epoch 70 ####################
2025-02-06 18:07:12,376 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 18:07:12,789 - INFO - Epoch 70: train_loss=1.2491
2025-02-06 18:07:13,081 - INFO - Epoch 70: train_loss=1.2120
2025-02-06 18:07:13,413 - INFO - Epoch 70: val_loss=1.1144, val_acc=33.33%
2025-02-06 18:07:13,417 - INFO - Epoch 70: EPOCH_AVG_TRAIN_LOSS=1.2120
2025-02-06 18:07:13,419 - INFO - #################### Training epoch 71 ####################
2025-02-06 18:07:13,419 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 18:07:13,836 - INFO - Epoch 71: train_loss=1.2672
2025-02-06 18:07:14,128 - INFO - Epoch 71: train_loss=1.1982
2025-02-06 18:07:14,457 - INFO - Epoch 71: val_loss=1.1196, val_acc=33.33%
2025-02-06 18:07:14,461 - INFO - Epoch 71: EPOCH_AVG_TRAIN_LOSS=1.1982
2025-02-06 18:07:14,463 - INFO - #################### Training epoch 72 ####################
2025-02-06 18:07:14,463 - INFO - Current Learning Rate: 6.103516e-08
2025-02-06 18:07:14,880 - INFO - Epoch 72: train_loss=1.2721
2025-02-06 18:07:15,171 - INFO - Epoch 72: train_loss=1.2250
2025-02-06 18:07:15,503 - INFO - Epoch 72: val_loss=1.1074, val_acc=33.33%
2025-02-06 18:07:15,507 - INFO - Epoch 72: EPOCH_AVG_TRAIN_LOSS=1.2250
2025-02-06 18:07:15,509 - INFO - #################### Training epoch 73 ####################
2025-02-06 18:07:15,509 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 18:07:15,926 - INFO - Epoch 73: train_loss=1.1882
2025-02-06 18:07:16,217 - INFO - Epoch 73: train_loss=1.4339
2025-02-06 18:07:16,546 - INFO - Epoch 73: val_loss=1.1126, val_acc=33.33%
2025-02-06 18:07:16,550 - INFO - Epoch 73: EPOCH_AVG_TRAIN_LOSS=1.1882
2025-02-06 18:07:16,552 - INFO - #################### Training epoch 74 ####################
2025-02-06 18:07:16,552 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 18:07:16,969 - INFO - Epoch 74: train_loss=1.2921
2025-02-06 18:07:17,260 - INFO - Epoch 74: train_loss=1.2257
2025-02-06 18:07:17,594 - INFO - Epoch 74: val_loss=1.1140, val_acc=33.33%
2025-02-06 18:07:17,597 - INFO - Epoch 74: EPOCH_AVG_TRAIN_LOSS=1.2257
2025-02-06 18:07:17,599 - INFO - #################### Training epoch 75 ####################
2025-02-06 18:07:17,600 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 18:07:18,015 - INFO - Epoch 75: train_loss=1.1201
2025-02-06 18:07:18,307 - INFO - Epoch 75: train_loss=1.6225
2025-02-06 18:07:18,636 - INFO - Epoch 75: val_loss=1.1140, val_acc=33.33%
2025-02-06 18:07:18,640 - INFO - Epoch 75: EPOCH_AVG_TRAIN_LOSS=1.1201
2025-02-06 18:07:18,642 - INFO - #################### Training epoch 76 ####################
2025-02-06 18:07:18,642 - INFO - Current Learning Rate: 3.051758e-08
2025-02-06 18:07:19,059 - INFO - Epoch 76: train_loss=1.2660
2025-02-06 18:07:19,351 - INFO - Epoch 76: train_loss=1.2403
2025-02-06 18:07:19,684 - INFO - Epoch 76: val_loss=1.1165, val_acc=33.33%
2025-02-06 18:07:19,688 - INFO - Epoch 76: EPOCH_AVG_TRAIN_LOSS=1.2403
2025-02-06 18:07:19,690 - INFO - #################### Training epoch 77 ####################
2025-02-06 18:07:19,690 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:20,106 - INFO - Epoch 77: train_loss=1.3071
2025-02-06 18:07:20,398 - INFO - Epoch 77: train_loss=1.1620
2025-02-06 18:07:20,727 - INFO - Epoch 77: val_loss=1.1165, val_acc=33.33%
2025-02-06 18:07:20,731 - INFO - Epoch 77: EPOCH_AVG_TRAIN_LOSS=1.1620
2025-02-06 18:07:20,734 - INFO - #################### Training epoch 78 ####################
2025-02-06 18:07:20,734 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:21,151 - INFO - Epoch 78: train_loss=1.2686
2025-02-06 18:07:21,443 - INFO - Epoch 78: train_loss=1.1100
2025-02-06 18:07:21,772 - INFO - Epoch 78: val_loss=1.1098, val_acc=33.33%
2025-02-06 18:07:21,776 - INFO - Epoch 78: EPOCH_AVG_TRAIN_LOSS=1.1100
2025-02-06 18:07:21,778 - INFO - #################### Training epoch 79 ####################
2025-02-06 18:07:21,778 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:22,194 - INFO - Epoch 79: train_loss=1.2666
2025-02-06 18:07:22,486 - INFO - Epoch 79: train_loss=1.1923
2025-02-06 18:07:22,813 - INFO - Epoch 79: val_loss=1.1201, val_acc=33.33%
2025-02-06 18:07:22,817 - INFO - Epoch 79: EPOCH_AVG_TRAIN_LOSS=1.1923
2025-02-06 18:07:22,819 - INFO - #################### Training epoch 80 ####################
2025-02-06 18:07:22,819 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:23,234 - INFO - Epoch 80: train_loss=1.0819
2025-02-06 18:07:23,526 - INFO - Epoch 80: train_loss=1.5773
2025-02-06 18:07:23,857 - INFO - Epoch 80: val_loss=1.1191, val_acc=33.33%
2025-02-06 18:07:23,861 - INFO - Epoch 80: EPOCH_AVG_TRAIN_LOSS=1.0819
2025-02-06 18:07:23,863 - INFO - #################### Training epoch 81 ####################
2025-02-06 18:07:23,863 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:24,281 - INFO - Epoch 81: train_loss=1.1220
2025-02-06 18:07:24,573 - INFO - Epoch 81: train_loss=1.5247
2025-02-06 18:07:24,905 - INFO - Epoch 81: val_loss=1.1157, val_acc=33.33%
2025-02-06 18:07:24,909 - INFO - Epoch 81: EPOCH_AVG_TRAIN_LOSS=1.1220
2025-02-06 18:07:24,911 - INFO - #################### Training epoch 82 ####################
2025-02-06 18:07:24,911 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:25,329 - INFO - Epoch 82: train_loss=1.1712
2025-02-06 18:07:25,620 - INFO - Epoch 82: train_loss=1.3904
2025-02-06 18:07:25,953 - INFO - Epoch 82: val_loss=1.1123, val_acc=33.33%
2025-02-06 18:07:25,957 - INFO - Epoch 82: EPOCH_AVG_TRAIN_LOSS=1.1712
2025-02-06 18:07:25,960 - INFO - #################### Training epoch 83 ####################
2025-02-06 18:07:25,960 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:26,376 - INFO - Epoch 83: train_loss=1.4372
2025-02-06 18:07:26,668 - INFO - Epoch 83: train_loss=0.9447
2025-02-06 18:07:27,000 - INFO - Epoch 83: val_loss=1.1127, val_acc=33.33%
2025-02-06 18:07:27,004 - INFO - Epoch 83: EPOCH_AVG_TRAIN_LOSS=0.9447
2025-02-06 18:07:27,006 - INFO - #################### Training epoch 84 ####################
2025-02-06 18:07:27,006 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:27,421 - INFO - Epoch 84: train_loss=1.3442
2025-02-06 18:07:27,712 - INFO - Epoch 84: train_loss=1.0401
2025-02-06 18:07:28,042 - INFO - Epoch 84: val_loss=1.1082, val_acc=33.33%
2025-02-06 18:07:28,046 - INFO - Epoch 84: EPOCH_AVG_TRAIN_LOSS=1.0401
2025-02-06 18:07:28,048 - INFO - #################### Training epoch 85 ####################
2025-02-06 18:07:28,048 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:28,467 - INFO - Epoch 85: train_loss=1.2103
2025-02-06 18:07:28,759 - INFO - Epoch 85: train_loss=1.4337
2025-02-06 18:07:29,089 - INFO - Epoch 85: val_loss=1.1184, val_acc=33.33%
2025-02-06 18:07:29,093 - INFO - Epoch 85: EPOCH_AVG_TRAIN_LOSS=1.2103
2025-02-06 18:07:29,095 - INFO - #################### Training epoch 86 ####################
2025-02-06 18:07:29,095 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:29,512 - INFO - Epoch 86: train_loss=1.3058
2025-02-06 18:07:29,804 - INFO - Epoch 86: train_loss=1.0170
2025-02-06 18:07:30,134 - INFO - Epoch 86: val_loss=1.1149, val_acc=33.33%
2025-02-06 18:07:30,137 - INFO - Epoch 86: EPOCH_AVG_TRAIN_LOSS=1.0170
2025-02-06 18:07:30,140 - INFO - #################### Training epoch 87 ####################
2025-02-06 18:07:30,140 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:30,555 - INFO - Epoch 87: train_loss=0.9795
2025-02-06 18:07:30,846 - INFO - Epoch 87: train_loss=1.7608
2025-02-06 18:07:31,177 - INFO - Epoch 87: val_loss=1.1128, val_acc=33.33%
2025-02-06 18:07:31,180 - INFO - Epoch 87: EPOCH_AVG_TRAIN_LOSS=0.9795
2025-02-06 18:07:31,183 - INFO - #################### Training epoch 88 ####################
2025-02-06 18:07:31,183 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:31,600 - INFO - Epoch 88: train_loss=1.2802
2025-02-06 18:07:31,892 - INFO - Epoch 88: train_loss=1.1872
2025-02-06 18:07:32,228 - INFO - Epoch 88: val_loss=1.1181, val_acc=33.33%
2025-02-06 18:07:32,232 - INFO - Epoch 88: EPOCH_AVG_TRAIN_LOSS=1.1872
2025-02-06 18:07:32,234 - INFO - #################### Training epoch 89 ####################
2025-02-06 18:07:32,234 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:32,648 - INFO - Epoch 89: train_loss=1.3813
2025-02-06 18:07:32,939 - INFO - Epoch 89: train_loss=0.9669
2025-02-06 18:07:33,271 - INFO - Epoch 89: val_loss=1.1139, val_acc=33.33%
2025-02-06 18:07:33,275 - INFO - Epoch 89: EPOCH_AVG_TRAIN_LOSS=0.9669
2025-02-06 18:07:33,277 - INFO - #################### Training epoch 90 ####################
2025-02-06 18:07:33,277 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:33,697 - INFO - Epoch 90: train_loss=1.1284
2025-02-06 18:07:33,989 - INFO - Epoch 90: train_loss=1.4652
2025-02-06 18:07:34,323 - INFO - Epoch 90: val_loss=1.1141, val_acc=33.33%
2025-02-06 18:07:34,326 - INFO - Epoch 90: EPOCH_AVG_TRAIN_LOSS=1.1284
2025-02-06 18:07:34,329 - INFO - #################### Training epoch 91 ####################
2025-02-06 18:07:34,329 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:34,747 - INFO - Epoch 91: train_loss=1.2525
2025-02-06 18:07:35,039 - INFO - Epoch 91: train_loss=1.2821
2025-02-06 18:07:35,369 - INFO - Epoch 91: val_loss=1.1122, val_acc=33.33%
2025-02-06 18:07:35,373 - INFO - Epoch 91: EPOCH_AVG_TRAIN_LOSS=1.2525
2025-02-06 18:07:35,375 - INFO - #################### Training epoch 92 ####################
2025-02-06 18:07:35,375 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:35,791 - INFO - Epoch 92: train_loss=1.2260
2025-02-06 18:07:36,083 - INFO - Epoch 92: train_loss=1.3118
2025-02-06 18:07:36,416 - INFO - Epoch 92: val_loss=1.1173, val_acc=33.33%
2025-02-06 18:07:36,420 - INFO - Epoch 92: EPOCH_AVG_TRAIN_LOSS=1.2260
2025-02-06 18:07:36,423 - INFO - #################### Training epoch 93 ####################
2025-02-06 18:07:36,423 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:36,841 - INFO - Epoch 93: train_loss=1.3523
2025-02-06 18:07:37,134 - INFO - Epoch 93: train_loss=1.0329
2025-02-06 18:07:37,465 - INFO - Epoch 93: val_loss=1.1177, val_acc=33.33%
2025-02-06 18:07:37,469 - INFO - Epoch 93: EPOCH_AVG_TRAIN_LOSS=1.0329
2025-02-06 18:07:37,471 - INFO - #################### Training epoch 94 ####################
2025-02-06 18:07:37,471 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:37,888 - INFO - Epoch 94: train_loss=1.0898
2025-02-06 18:07:38,180 - INFO - Epoch 94: train_loss=1.5564
2025-02-06 18:07:38,508 - INFO - Epoch 94: val_loss=1.1135, val_acc=33.33%
2025-02-06 18:07:38,512 - INFO - Epoch 94: EPOCH_AVG_TRAIN_LOSS=1.0898
2025-02-06 18:07:38,514 - INFO - #################### Training epoch 95 ####################
2025-02-06 18:07:38,514 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:38,932 - INFO - Epoch 95: train_loss=1.4227
2025-02-06 18:07:39,225 - INFO - Epoch 95: train_loss=0.8718
2025-02-06 18:07:39,558 - INFO - Epoch 95: val_loss=1.1146, val_acc=33.33%
2025-02-06 18:07:39,562 - INFO - Epoch 95: EPOCH_AVG_TRAIN_LOSS=0.8718
2025-02-06 18:07:39,564 - INFO - #################### Training epoch 96 ####################
2025-02-06 18:07:39,564 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:39,980 - INFO - Epoch 96: train_loss=1.1754
2025-02-06 18:07:40,271 - INFO - Epoch 96: train_loss=1.4215
2025-02-06 18:07:40,605 - INFO - Epoch 96: val_loss=1.1094, val_acc=33.33%
2025-02-06 18:07:40,609 - INFO - Epoch 96: EPOCH_AVG_TRAIN_LOSS=1.1754
2025-02-06 18:07:40,611 - INFO - #################### Training epoch 97 ####################
2025-02-06 18:07:40,611 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:41,028 - INFO - Epoch 97: train_loss=1.1295
2025-02-06 18:07:41,321 - INFO - Epoch 97: train_loss=1.3569
2025-02-06 18:07:41,661 - INFO - Epoch 97: val_loss=1.1093, val_acc=33.33%
2025-02-06 18:07:41,664 - INFO - Epoch 97: EPOCH_AVG_TRAIN_LOSS=1.1295
2025-02-06 18:07:41,667 - INFO - #################### Training epoch 98 ####################
2025-02-06 18:07:41,667 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:42,083 - INFO - Epoch 98: train_loss=1.3852
2025-02-06 18:07:42,375 - INFO - Epoch 98: train_loss=0.9906
2025-02-06 18:07:42,704 - INFO - Epoch 98: val_loss=1.1175, val_acc=33.33%
2025-02-06 18:07:42,708 - INFO - Epoch 98: EPOCH_AVG_TRAIN_LOSS=0.9906
2025-02-06 18:07:42,710 - INFO - #################### Training epoch 99 ####################
2025-02-06 18:07:42,710 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:43,129 - INFO - Epoch 99: train_loss=1.3152
2025-02-06 18:07:43,422 - INFO - Epoch 99: train_loss=1.1968
2025-02-06 18:07:43,751 - INFO - Epoch 99: val_loss=1.1171, val_acc=33.33%
2025-02-06 18:07:43,756 - INFO - Epoch 99: EPOCH_AVG_TRAIN_LOSS=1.1968
2025-02-06 18:07:43,758 - INFO - #################### Training epoch 100 ####################
2025-02-06 18:07:43,758 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:44,176 - INFO - Epoch 100: train_loss=1.2616
2025-02-06 18:07:44,468 - INFO - Epoch 100: train_loss=1.2337
2025-02-06 18:07:44,798 - INFO - Epoch 100: val_loss=1.1160, val_acc=33.33%
2025-02-06 18:07:44,802 - INFO - Epoch 100: EPOCH_AVG_TRAIN_LOSS=1.2337
2025-02-06 18:07:44,804 - INFO - #################### Training epoch 101 ####################
2025-02-06 18:07:44,804 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:45,222 - INFO - Epoch 101: train_loss=1.0381
2025-02-06 18:07:45,514 - INFO - Epoch 101: train_loss=1.5725
2025-02-06 18:07:45,849 - INFO - Epoch 101: val_loss=1.1131, val_acc=33.33%
2025-02-06 18:07:45,853 - INFO - Epoch 101: EPOCH_AVG_TRAIN_LOSS=1.0381
2025-02-06 18:07:45,855 - INFO - #################### Training epoch 102 ####################
2025-02-06 18:07:45,855 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:46,274 - INFO - Epoch 102: train_loss=1.3853
2025-02-06 18:07:46,566 - INFO - Epoch 102: train_loss=1.0629
2025-02-06 18:07:46,903 - INFO - Epoch 102: val_loss=1.1149, val_acc=33.33%
2025-02-06 18:07:46,906 - INFO - Epoch 102: EPOCH_AVG_TRAIN_LOSS=1.0629
2025-02-06 18:07:46,909 - INFO - #################### Training epoch 103 ####################
2025-02-06 18:07:46,909 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:47,326 - INFO - Epoch 103: train_loss=1.1984
2025-02-06 18:07:47,619 - INFO - Epoch 103: train_loss=1.3368
2025-02-06 18:07:47,956 - INFO - Epoch 103: val_loss=1.1191, val_acc=33.33%
2025-02-06 18:07:47,960 - INFO - Epoch 103: EPOCH_AVG_TRAIN_LOSS=1.1984
2025-02-06 18:07:47,963 - INFO - #################### Training epoch 104 ####################
2025-02-06 18:07:47,963 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:48,378 - INFO - Epoch 104: train_loss=1.2121
2025-02-06 18:07:48,671 - INFO - Epoch 104: train_loss=1.4303
2025-02-06 18:07:49,004 - INFO - Epoch 104: val_loss=1.1100, val_acc=33.33%
2025-02-06 18:07:49,008 - INFO - Epoch 104: EPOCH_AVG_TRAIN_LOSS=1.2121
2025-02-06 18:07:49,010 - INFO - #################### Training epoch 105 ####################
2025-02-06 18:07:49,010 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:49,428 - INFO - Epoch 105: train_loss=1.0144
2025-02-06 18:07:49,723 - INFO - Epoch 105: train_loss=1.7420
2025-02-06 18:07:50,057 - INFO - Epoch 105: val_loss=1.1172, val_acc=33.33%
2025-02-06 18:07:50,061 - INFO - Epoch 105: EPOCH_AVG_TRAIN_LOSS=1.0144
2025-02-06 18:07:50,063 - INFO - #################### Training epoch 106 ####################
2025-02-06 18:07:50,064 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:50,482 - INFO - Epoch 106: train_loss=1.1823
2025-02-06 18:07:50,776 - INFO - Epoch 106: train_loss=1.2854
2025-02-06 18:07:51,110 - INFO - Epoch 106: val_loss=1.1178, val_acc=33.33%
2025-02-06 18:07:51,114 - INFO - Epoch 106: EPOCH_AVG_TRAIN_LOSS=1.1823
2025-02-06 18:07:51,116 - INFO - #################### Training epoch 107 ####################
2025-02-06 18:07:51,116 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:51,534 - INFO - Epoch 107: train_loss=1.3785
2025-02-06 18:07:51,825 - INFO - Epoch 107: train_loss=1.1430
2025-02-06 18:07:52,156 - INFO - Epoch 107: val_loss=1.1144, val_acc=33.33%
2025-02-06 18:07:52,160 - INFO - Epoch 107: EPOCH_AVG_TRAIN_LOSS=1.1430
2025-02-06 18:07:52,162 - INFO - #################### Training epoch 108 ####################
2025-02-06 18:07:52,163 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:52,581 - INFO - Epoch 108: train_loss=1.1293
2025-02-06 18:07:52,872 - INFO - Epoch 108: train_loss=1.5645
2025-02-06 18:07:53,208 - INFO - Epoch 108: val_loss=1.1139, val_acc=33.33%
2025-02-06 18:07:53,212 - INFO - Epoch 108: EPOCH_AVG_TRAIN_LOSS=1.1293
2025-02-06 18:07:53,214 - INFO - #################### Training epoch 109 ####################
2025-02-06 18:07:53,214 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:53,632 - INFO - Epoch 109: train_loss=1.2586
2025-02-06 18:07:53,923 - INFO - Epoch 109: train_loss=1.1650
2025-02-06 18:07:54,256 - INFO - Epoch 109: val_loss=1.1189, val_acc=33.33%
2025-02-06 18:07:54,259 - INFO - Epoch 109: EPOCH_AVG_TRAIN_LOSS=1.1650
2025-02-06 18:07:54,262 - INFO - #################### Training epoch 110 ####################
2025-02-06 18:07:54,262 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:54,678 - INFO - Epoch 110: train_loss=1.3887
2025-02-06 18:07:54,969 - INFO - Epoch 110: train_loss=1.0113
2025-02-06 18:07:55,299 - INFO - Epoch 110: val_loss=1.1082, val_acc=33.33%
2025-02-06 18:07:55,303 - INFO - Epoch 110: EPOCH_AVG_TRAIN_LOSS=1.0113
2025-02-06 18:07:55,305 - INFO - #################### Training epoch 111 ####################
2025-02-06 18:07:55,305 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:55,722 - INFO - Epoch 111: train_loss=1.3570
2025-02-06 18:07:56,013 - INFO - Epoch 111: train_loss=0.9385
2025-02-06 18:07:56,345 - INFO - Epoch 111: val_loss=1.1125, val_acc=33.33%
2025-02-06 18:07:56,349 - INFO - Epoch 111: EPOCH_AVG_TRAIN_LOSS=0.9385
2025-02-06 18:07:56,351 - INFO - #################### Training epoch 112 ####################
2025-02-06 18:07:56,351 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:56,769 - INFO - Epoch 112: train_loss=1.0329
2025-02-06 18:07:57,060 - INFO - Epoch 112: train_loss=1.6848
2025-02-06 18:07:57,390 - INFO - Epoch 112: val_loss=1.1145, val_acc=33.33%
2025-02-06 18:07:57,394 - INFO - Epoch 112: EPOCH_AVG_TRAIN_LOSS=1.0329
2025-02-06 18:07:57,396 - INFO - #################### Training epoch 113 ####################
2025-02-06 18:07:57,396 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:57,812 - INFO - Epoch 113: train_loss=1.3211
2025-02-06 18:07:58,103 - INFO - Epoch 113: train_loss=1.1251
2025-02-06 18:07:58,439 - INFO - Epoch 113: val_loss=1.1157, val_acc=33.33%
2025-02-06 18:07:58,442 - INFO - Epoch 113: EPOCH_AVG_TRAIN_LOSS=1.1251
2025-02-06 18:07:58,444 - INFO - #################### Training epoch 114 ####################
2025-02-06 18:07:58,444 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:58,858 - INFO - Epoch 114: train_loss=1.1602
2025-02-06 18:07:59,150 - INFO - Epoch 114: train_loss=1.3174
2025-02-06 18:07:59,481 - INFO - Epoch 114: val_loss=1.1176, val_acc=33.33%
2025-02-06 18:07:59,485 - INFO - Epoch 114: EPOCH_AVG_TRAIN_LOSS=1.1602
2025-02-06 18:07:59,487 - INFO - #################### Training epoch 115 ####################
2025-02-06 18:07:59,487 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:07:59,905 - INFO - Epoch 115: train_loss=1.2895
2025-02-06 18:08:00,197 - INFO - Epoch 115: train_loss=1.1564
2025-02-06 18:08:00,531 - INFO - Epoch 115: val_loss=1.1186, val_acc=33.33%
2025-02-06 18:08:00,535 - INFO - Epoch 115: EPOCH_AVG_TRAIN_LOSS=1.1564
2025-02-06 18:08:00,537 - INFO - #################### Training epoch 116 ####################
2025-02-06 18:08:00,537 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:00,953 - INFO - Epoch 116: train_loss=1.2782
2025-02-06 18:08:01,245 - INFO - Epoch 116: train_loss=1.2381
2025-02-06 18:08:01,579 - INFO - Epoch 116: val_loss=1.1149, val_acc=33.33%
2025-02-06 18:08:01,583 - INFO - Epoch 116: EPOCH_AVG_TRAIN_LOSS=1.2381
2025-02-06 18:08:01,585 - INFO - #################### Training epoch 117 ####################
2025-02-06 18:08:01,585 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:02,003 - INFO - Epoch 117: train_loss=1.3271
2025-02-06 18:08:02,295 - INFO - Epoch 117: train_loss=1.1032
2025-02-06 18:08:02,627 - INFO - Epoch 117: val_loss=1.1157, val_acc=33.33%
2025-02-06 18:08:02,631 - INFO - Epoch 117: EPOCH_AVG_TRAIN_LOSS=1.1032
2025-02-06 18:08:02,633 - INFO - #################### Training epoch 118 ####################
2025-02-06 18:08:02,633 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:03,049 - INFO - Epoch 118: train_loss=1.1396
2025-02-06 18:08:03,341 - INFO - Epoch 118: train_loss=1.3095
2025-02-06 18:08:03,672 - INFO - Epoch 118: val_loss=1.1158, val_acc=33.33%
2025-02-06 18:08:03,676 - INFO - Epoch 118: EPOCH_AVG_TRAIN_LOSS=1.1396
2025-02-06 18:08:03,678 - INFO - #################### Training epoch 119 ####################
2025-02-06 18:08:03,678 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:04,096 - INFO - Epoch 119: train_loss=1.2952
2025-02-06 18:08:04,388 - INFO - Epoch 119: train_loss=1.0822
2025-02-06 18:08:04,718 - INFO - Epoch 119: val_loss=1.1140, val_acc=33.33%
2025-02-06 18:08:04,721 - INFO - Epoch 119: EPOCH_AVG_TRAIN_LOSS=1.0822
2025-02-06 18:08:04,724 - INFO - #################### Training epoch 120 ####################
2025-02-06 18:08:04,724 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:05,143 - INFO - Epoch 120: train_loss=1.2048
2025-02-06 18:08:05,434 - INFO - Epoch 120: train_loss=1.3894
2025-02-06 18:08:05,771 - INFO - Epoch 120: val_loss=1.1132, val_acc=33.33%
2025-02-06 18:08:05,775 - INFO - Epoch 120: EPOCH_AVG_TRAIN_LOSS=1.2048
2025-02-06 18:08:05,777 - INFO - #################### Training epoch 121 ####################
2025-02-06 18:08:05,777 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:06,195 - INFO - Epoch 121: train_loss=1.1250
2025-02-06 18:08:06,487 - INFO - Epoch 121: train_loss=1.5433
2025-02-06 18:08:06,819 - INFO - Epoch 121: val_loss=1.1172, val_acc=33.33%
2025-02-06 18:08:06,822 - INFO - Epoch 121: EPOCH_AVG_TRAIN_LOSS=1.1250
2025-02-06 18:08:06,824 - INFO - #################### Training epoch 122 ####################
2025-02-06 18:08:06,825 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:07,242 - INFO - Epoch 122: train_loss=1.1875
2025-02-06 18:08:07,534 - INFO - Epoch 122: train_loss=1.3992
2025-02-06 18:08:07,858 - INFO - Epoch 122: val_loss=1.1097, val_acc=33.33%
2025-02-06 18:08:07,862 - INFO - Epoch 122: EPOCH_AVG_TRAIN_LOSS=1.1875
2025-02-06 18:08:07,864 - INFO - #################### Training epoch 123 ####################
2025-02-06 18:08:07,864 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:08,281 - INFO - Epoch 123: train_loss=1.2125
2025-02-06 18:08:08,573 - INFO - Epoch 123: train_loss=1.2401
2025-02-06 18:08:08,906 - INFO - Epoch 123: val_loss=1.1150, val_acc=33.33%
2025-02-06 18:08:08,909 - INFO - Epoch 123: EPOCH_AVG_TRAIN_LOSS=1.2125
2025-02-06 18:08:08,911 - INFO - #################### Training epoch 124 ####################
2025-02-06 18:08:08,911 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:09,327 - INFO - Epoch 124: train_loss=1.2025
2025-02-06 18:08:09,619 - INFO - Epoch 124: train_loss=1.4938
2025-02-06 18:08:09,949 - INFO - Epoch 124: val_loss=1.1158, val_acc=33.33%
2025-02-06 18:08:09,953 - INFO - Epoch 124: EPOCH_AVG_TRAIN_LOSS=1.2025
2025-02-06 18:08:09,955 - INFO - #################### Training epoch 125 ####################
2025-02-06 18:08:09,955 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:10,374 - INFO - Epoch 125: train_loss=1.3048
2025-02-06 18:08:10,664 - INFO - Epoch 125: train_loss=1.1115
2025-02-06 18:08:10,997 - INFO - Epoch 125: val_loss=1.1141, val_acc=33.33%
2025-02-06 18:08:11,001 - INFO - Epoch 125: EPOCH_AVG_TRAIN_LOSS=1.1115
2025-02-06 18:08:11,003 - INFO - #################### Training epoch 126 ####################
2025-02-06 18:08:11,003 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:11,420 - INFO - Epoch 126: train_loss=1.2013
2025-02-06 18:08:11,712 - INFO - Epoch 126: train_loss=1.3689
2025-02-06 18:08:12,041 - INFO - Epoch 126: val_loss=1.1122, val_acc=33.33%
2025-02-06 18:08:12,045 - INFO - Epoch 126: EPOCH_AVG_TRAIN_LOSS=1.2013
2025-02-06 18:08:12,047 - INFO - #################### Training epoch 127 ####################
2025-02-06 18:08:12,047 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:12,465 - INFO - Epoch 127: train_loss=1.2995
2025-02-06 18:08:12,756 - INFO - Epoch 127: train_loss=1.1880
2025-02-06 18:08:13,089 - INFO - Epoch 127: val_loss=1.1161, val_acc=33.33%
2025-02-06 18:08:13,092 - INFO - Epoch 127: EPOCH_AVG_TRAIN_LOSS=1.1880
2025-02-06 18:08:13,095 - INFO - #################### Training epoch 128 ####################
2025-02-06 18:08:13,095 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:13,515 - INFO - Epoch 128: train_loss=1.2075
2025-02-06 18:08:13,809 - INFO - Epoch 128: train_loss=1.3100
2025-02-06 18:08:14,140 - INFO - Epoch 128: val_loss=1.1169, val_acc=33.33%
2025-02-06 18:08:14,143 - INFO - Epoch 128: EPOCH_AVG_TRAIN_LOSS=1.2075
2025-02-06 18:08:14,146 - INFO - #################### Training epoch 129 ####################
2025-02-06 18:08:14,146 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:14,562 - INFO - Epoch 129: train_loss=1.1609
2025-02-06 18:08:14,854 - INFO - Epoch 129: train_loss=1.3678
2025-02-06 18:08:15,183 - INFO - Epoch 129: val_loss=1.1150, val_acc=33.33%
2025-02-06 18:08:15,186 - INFO - Epoch 129: EPOCH_AVG_TRAIN_LOSS=1.1609
2025-02-06 18:08:15,189 - INFO - #################### Training epoch 130 ####################
2025-02-06 18:08:15,189 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:15,605 - INFO - Epoch 130: train_loss=1.2181
2025-02-06 18:08:15,897 - INFO - Epoch 130: train_loss=1.2136
2025-02-06 18:08:16,231 - INFO - Epoch 130: val_loss=1.1159, val_acc=33.33%
2025-02-06 18:08:16,235 - INFO - Epoch 130: EPOCH_AVG_TRAIN_LOSS=1.2136
2025-02-06 18:08:16,237 - INFO - #################### Training epoch 131 ####################
2025-02-06 18:08:16,237 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:16,654 - INFO - Epoch 131: train_loss=1.0317
2025-02-06 18:08:16,946 - INFO - Epoch 131: train_loss=1.7367
2025-02-06 18:08:17,275 - INFO - Epoch 131: val_loss=1.1136, val_acc=33.33%
2025-02-06 18:08:17,279 - INFO - Epoch 131: EPOCH_AVG_TRAIN_LOSS=1.0317
2025-02-06 18:08:17,281 - INFO - #################### Training epoch 132 ####################
2025-02-06 18:08:17,281 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:17,699 - INFO - Epoch 132: train_loss=1.1728
2025-02-06 18:08:17,991 - INFO - Epoch 132: train_loss=1.4604
2025-02-06 18:08:18,324 - INFO - Epoch 132: val_loss=1.1115, val_acc=33.33%
2025-02-06 18:08:18,328 - INFO - Epoch 132: EPOCH_AVG_TRAIN_LOSS=1.1728
2025-02-06 18:08:18,330 - INFO - #################### Training epoch 133 ####################
2025-02-06 18:08:18,330 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:18,754 - INFO - Epoch 133: train_loss=1.1630
2025-02-06 18:08:19,045 - INFO - Epoch 133: train_loss=1.4788
2025-02-06 18:08:19,376 - INFO - Epoch 133: val_loss=1.1075, val_acc=33.33%
2025-02-06 18:08:19,379 - INFO - Epoch 133: EPOCH_AVG_TRAIN_LOSS=1.1630
2025-02-06 18:08:19,381 - INFO - #################### Training epoch 134 ####################
2025-02-06 18:08:19,382 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:19,794 - INFO - Epoch 134: train_loss=1.2185
2025-02-06 18:08:20,086 - INFO - Epoch 134: train_loss=1.2822
2025-02-06 18:08:20,419 - INFO - Epoch 134: val_loss=1.1200, val_acc=33.33%
2025-02-06 18:08:20,422 - INFO - Epoch 134: EPOCH_AVG_TRAIN_LOSS=1.2185
2025-02-06 18:08:20,425 - INFO - #################### Training epoch 135 ####################
2025-02-06 18:08:20,425 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:20,837 - INFO - Epoch 135: train_loss=1.2558
2025-02-06 18:08:21,129 - INFO - Epoch 135: train_loss=1.1674
2025-02-06 18:08:21,458 - INFO - Epoch 135: val_loss=1.1120, val_acc=33.33%
2025-02-06 18:08:21,461 - INFO - Epoch 135: EPOCH_AVG_TRAIN_LOSS=1.1674
2025-02-06 18:08:21,464 - INFO - #################### Training epoch 136 ####################
2025-02-06 18:08:21,464 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:21,883 - INFO - Epoch 136: train_loss=1.1348
2025-02-06 18:08:22,174 - INFO - Epoch 136: train_loss=1.3152
2025-02-06 18:08:22,503 - INFO - Epoch 136: val_loss=1.1124, val_acc=33.33%
2025-02-06 18:08:22,507 - INFO - Epoch 136: EPOCH_AVG_TRAIN_LOSS=1.1348
2025-02-06 18:08:22,510 - INFO - #################### Training epoch 137 ####################
2025-02-06 18:08:22,510 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:22,925 - INFO - Epoch 137: train_loss=1.2067
2025-02-06 18:08:23,216 - INFO - Epoch 137: train_loss=1.2892
2025-02-06 18:08:23,542 - INFO - Epoch 137: val_loss=1.1115, val_acc=33.33%
2025-02-06 18:08:23,546 - INFO - Epoch 137: EPOCH_AVG_TRAIN_LOSS=1.2067
2025-02-06 18:08:23,548 - INFO - #################### Training epoch 138 ####################
2025-02-06 18:08:23,548 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:23,966 - INFO - Epoch 138: train_loss=1.2349
2025-02-06 18:08:24,258 - INFO - Epoch 138: train_loss=1.2956
2025-02-06 18:08:24,586 - INFO - Epoch 138: val_loss=1.1184, val_acc=33.33%
2025-02-06 18:08:24,589 - INFO - Epoch 138: EPOCH_AVG_TRAIN_LOSS=1.2349
2025-02-06 18:08:24,592 - INFO - #################### Training epoch 139 ####################
2025-02-06 18:08:24,592 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:25,008 - INFO - Epoch 139: train_loss=1.2113
2025-02-06 18:08:25,300 - INFO - Epoch 139: train_loss=1.3864
2025-02-06 18:08:25,629 - INFO - Epoch 139: val_loss=1.1097, val_acc=33.33%
2025-02-06 18:08:25,632 - INFO - Epoch 139: EPOCH_AVG_TRAIN_LOSS=1.2113
2025-02-06 18:08:25,635 - INFO - #################### Training epoch 140 ####################
2025-02-06 18:08:25,635 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:26,050 - INFO - Epoch 140: train_loss=1.3280
2025-02-06 18:08:26,342 - INFO - Epoch 140: train_loss=1.0514
2025-02-06 18:08:26,673 - INFO - Epoch 140: val_loss=1.1219, val_acc=33.33%
2025-02-06 18:08:26,677 - INFO - Epoch 140: EPOCH_AVG_TRAIN_LOSS=1.0514
2025-02-06 18:08:26,680 - INFO - #################### Training epoch 141 ####################
2025-02-06 18:08:26,680 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:27,090 - INFO - Epoch 141: train_loss=1.1685
2025-02-06 18:08:27,382 - INFO - Epoch 141: train_loss=1.3458
2025-02-06 18:08:27,713 - INFO - Epoch 141: val_loss=1.1100, val_acc=33.33%
2025-02-06 18:08:27,716 - INFO - Epoch 141: EPOCH_AVG_TRAIN_LOSS=1.1685
2025-02-06 18:08:27,719 - INFO - #################### Training epoch 142 ####################
2025-02-06 18:08:27,719 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:28,132 - INFO - Epoch 142: train_loss=1.2637
2025-02-06 18:08:28,425 - INFO - Epoch 142: train_loss=1.2957
2025-02-06 18:08:28,756 - INFO - Epoch 142: val_loss=1.1083, val_acc=33.33%
2025-02-06 18:08:28,760 - INFO - Epoch 142: EPOCH_AVG_TRAIN_LOSS=1.2637
2025-02-06 18:08:28,762 - INFO - #################### Training epoch 143 ####################
2025-02-06 18:08:28,762 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:29,176 - INFO - Epoch 143: train_loss=1.0745
2025-02-06 18:08:29,468 - INFO - Epoch 143: train_loss=1.5277
2025-02-06 18:08:29,796 - INFO - Epoch 143: val_loss=1.1107, val_acc=33.33%
2025-02-06 18:08:29,799 - INFO - Epoch 143: EPOCH_AVG_TRAIN_LOSS=1.0745
2025-02-06 18:08:29,802 - INFO - #################### Training epoch 144 ####################
2025-02-06 18:08:29,802 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:30,214 - INFO - Epoch 144: train_loss=1.1487
2025-02-06 18:08:30,506 - INFO - Epoch 144: train_loss=1.4143
2025-02-06 18:08:30,836 - INFO - Epoch 144: val_loss=1.1176, val_acc=33.33%
2025-02-06 18:08:30,840 - INFO - Epoch 144: EPOCH_AVG_TRAIN_LOSS=1.1487
2025-02-06 18:08:30,842 - INFO - #################### Training epoch 145 ####################
2025-02-06 18:08:30,842 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:31,259 - INFO - Epoch 145: train_loss=1.3530
2025-02-06 18:08:31,551 - INFO - Epoch 145: train_loss=1.0448
2025-02-06 18:08:31,880 - INFO - Epoch 145: val_loss=1.1149, val_acc=33.33%
2025-02-06 18:08:31,884 - INFO - Epoch 145: EPOCH_AVG_TRAIN_LOSS=1.0448
2025-02-06 18:08:31,886 - INFO - #################### Training epoch 146 ####################
2025-02-06 18:08:31,886 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:32,301 - INFO - Epoch 146: train_loss=1.2232
2025-02-06 18:08:32,593 - INFO - Epoch 146: train_loss=1.3284
2025-02-06 18:08:32,920 - INFO - Epoch 146: val_loss=1.1139, val_acc=33.33%
2025-02-06 18:08:32,924 - INFO - Epoch 146: EPOCH_AVG_TRAIN_LOSS=1.2232
2025-02-06 18:08:32,926 - INFO - #################### Training epoch 147 ####################
2025-02-06 18:08:32,926 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:33,343 - INFO - Epoch 147: train_loss=1.0510
2025-02-06 18:08:33,635 - INFO - Epoch 147: train_loss=1.7090
2025-02-06 18:08:33,962 - INFO - Epoch 147: val_loss=1.1185, val_acc=33.33%
2025-02-06 18:08:33,965 - INFO - Epoch 147: EPOCH_AVG_TRAIN_LOSS=1.0510
2025-02-06 18:08:33,967 - INFO - #################### Training epoch 148 ####################
2025-02-06 18:08:33,967 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:34,377 - INFO - Epoch 148: train_loss=1.2169
2025-02-06 18:08:34,669 - INFO - Epoch 148: train_loss=1.3760
2025-02-06 18:08:35,002 - INFO - Epoch 148: val_loss=1.1147, val_acc=33.33%
2025-02-06 18:08:35,006 - INFO - Epoch 148: EPOCH_AVG_TRAIN_LOSS=1.2169
2025-02-06 18:08:35,008 - INFO - #################### Training epoch 149 ####################
2025-02-06 18:08:35,008 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:35,422 - INFO - Epoch 149: train_loss=1.2549
2025-02-06 18:08:35,714 - INFO - Epoch 149: train_loss=1.2559
2025-02-06 18:08:36,039 - INFO - Epoch 149: val_loss=1.1198, val_acc=33.33%
2025-02-06 18:08:36,042 - INFO - Epoch 149: EPOCH_AVG_TRAIN_LOSS=1.2549
2025-02-06 18:08:36,045 - INFO - #################### Training epoch 150 ####################
2025-02-06 18:08:36,045 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:36,458 - INFO - Epoch 150: train_loss=1.0732
2025-02-06 18:08:36,750 - INFO - Epoch 150: train_loss=1.6221
2025-02-06 18:08:37,077 - INFO - Epoch 150: val_loss=1.1051, val_acc=33.33%
2025-02-06 18:08:37,081 - INFO - Epoch 150: EPOCH_AVG_TRAIN_LOSS=1.0732
2025-02-06 18:08:37,083 - INFO - #################### Training epoch 151 ####################
2025-02-06 18:08:37,083 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:37,498 - INFO - Epoch 151: train_loss=0.9181
2025-02-06 18:08:37,789 - INFO - Epoch 151: train_loss=1.9848
2025-02-06 18:08:38,117 - INFO - Epoch 151: val_loss=1.1131, val_acc=33.33%
2025-02-06 18:08:38,121 - INFO - Epoch 151: EPOCH_AVG_TRAIN_LOSS=0.9181
2025-02-06 18:08:38,123 - INFO - #################### Training epoch 152 ####################
2025-02-06 18:08:38,123 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:38,536 - INFO - Epoch 152: train_loss=1.2888
2025-02-06 18:08:38,827 - INFO - Epoch 152: train_loss=1.0886
2025-02-06 18:08:39,155 - INFO - Epoch 152: val_loss=1.1174, val_acc=33.33%
2025-02-06 18:08:39,159 - INFO - Epoch 152: EPOCH_AVG_TRAIN_LOSS=1.0886
2025-02-06 18:08:39,161 - INFO - #################### Training epoch 153 ####################
2025-02-06 18:08:39,161 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:39,579 - INFO - Epoch 153: train_loss=1.1627
2025-02-06 18:08:39,870 - INFO - Epoch 153: train_loss=1.2876
2025-02-06 18:08:40,198 - INFO - Epoch 153: val_loss=1.1153, val_acc=33.33%
2025-02-06 18:08:40,202 - INFO - Epoch 153: EPOCH_AVG_TRAIN_LOSS=1.1627
2025-02-06 18:08:40,204 - INFO - #################### Training epoch 154 ####################
2025-02-06 18:08:40,204 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:40,617 - INFO - Epoch 154: train_loss=1.3283
2025-02-06 18:08:40,909 - INFO - Epoch 154: train_loss=1.2286
2025-02-06 18:08:41,235 - INFO - Epoch 154: val_loss=1.1145, val_acc=33.33%
2025-02-06 18:08:41,239 - INFO - Epoch 154: EPOCH_AVG_TRAIN_LOSS=1.2286
2025-02-06 18:08:41,241 - INFO - #################### Training epoch 155 ####################
2025-02-06 18:08:41,241 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:41,657 - INFO - Epoch 155: train_loss=1.3662
2025-02-06 18:08:41,949 - INFO - Epoch 155: train_loss=1.1138
2025-02-06 18:08:42,278 - INFO - Epoch 155: val_loss=1.1122, val_acc=33.33%
2025-02-06 18:08:42,281 - INFO - Epoch 155: EPOCH_AVG_TRAIN_LOSS=1.1138
2025-02-06 18:08:42,284 - INFO - #################### Training epoch 156 ####################
2025-02-06 18:08:42,284 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:42,698 - INFO - Epoch 156: train_loss=1.3860
2025-02-06 18:08:42,990 - INFO - Epoch 156: train_loss=0.9263
2025-02-06 18:08:43,316 - INFO - Epoch 156: val_loss=1.1141, val_acc=33.33%
2025-02-06 18:08:43,320 - INFO - Epoch 156: EPOCH_AVG_TRAIN_LOSS=0.9263
2025-02-06 18:08:43,322 - INFO - #################### Training epoch 157 ####################
2025-02-06 18:08:43,322 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:43,730 - INFO - Epoch 157: train_loss=1.1708
2025-02-06 18:08:44,022 - INFO - Epoch 157: train_loss=1.3517
2025-02-06 18:08:44,347 - INFO - Epoch 157: val_loss=1.1138, val_acc=33.33%
2025-02-06 18:08:44,351 - INFO - Epoch 157: EPOCH_AVG_TRAIN_LOSS=1.1708
2025-02-06 18:08:44,353 - INFO - #################### Training epoch 158 ####################
2025-02-06 18:08:44,353 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:44,767 - INFO - Epoch 158: train_loss=1.2394
2025-02-06 18:08:45,059 - INFO - Epoch 158: train_loss=1.1272
2025-02-06 18:08:45,388 - INFO - Epoch 158: val_loss=1.1176, val_acc=33.33%
2025-02-06 18:08:45,392 - INFO - Epoch 158: EPOCH_AVG_TRAIN_LOSS=1.1272
2025-02-06 18:08:45,394 - INFO - #################### Training epoch 159 ####################
2025-02-06 18:08:45,394 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:45,812 - INFO - Epoch 159: train_loss=1.1554
2025-02-06 18:08:46,104 - INFO - Epoch 159: train_loss=1.3510
2025-02-06 18:08:46,434 - INFO - Epoch 159: val_loss=1.1142, val_acc=33.33%
2025-02-06 18:08:46,437 - INFO - Epoch 159: EPOCH_AVG_TRAIN_LOSS=1.1554
2025-02-06 18:08:46,440 - INFO - #################### Training epoch 160 ####################
2025-02-06 18:08:46,440 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:46,851 - INFO - Epoch 160: train_loss=1.1995
2025-02-06 18:08:47,143 - INFO - Epoch 160: train_loss=1.3269
2025-02-06 18:08:47,472 - INFO - Epoch 160: val_loss=1.1150, val_acc=33.33%
2025-02-06 18:08:47,476 - INFO - Epoch 160: EPOCH_AVG_TRAIN_LOSS=1.1995
2025-02-06 18:08:47,478 - INFO - #################### Training epoch 161 ####################
2025-02-06 18:08:47,478 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:47,893 - INFO - Epoch 161: train_loss=1.2387
2025-02-06 18:08:48,185 - INFO - Epoch 161: train_loss=1.2078
2025-02-06 18:08:48,514 - INFO - Epoch 161: val_loss=1.1137, val_acc=33.33%
2025-02-06 18:08:48,517 - INFO - Epoch 161: EPOCH_AVG_TRAIN_LOSS=1.2078
2025-02-06 18:08:48,520 - INFO - #################### Training epoch 162 ####################
2025-02-06 18:08:48,520 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:48,932 - INFO - Epoch 162: train_loss=1.1994
2025-02-06 18:08:49,224 - INFO - Epoch 162: train_loss=1.4351
2025-02-06 18:08:49,550 - INFO - Epoch 162: val_loss=1.1180, val_acc=33.33%
2025-02-06 18:08:49,554 - INFO - Epoch 162: EPOCH_AVG_TRAIN_LOSS=1.1994
2025-02-06 18:08:49,556 - INFO - #################### Training epoch 163 ####################
2025-02-06 18:08:49,556 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:49,969 - INFO - Epoch 163: train_loss=1.1706
2025-02-06 18:08:50,261 - INFO - Epoch 163: train_loss=1.4170
2025-02-06 18:08:50,587 - INFO - Epoch 163: val_loss=1.1185, val_acc=33.33%
2025-02-06 18:08:50,590 - INFO - Epoch 163: EPOCH_AVG_TRAIN_LOSS=1.1706
2025-02-06 18:08:50,592 - INFO - #################### Training epoch 164 ####################
2025-02-06 18:08:50,592 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:51,002 - INFO - Epoch 164: train_loss=1.1767
2025-02-06 18:08:51,293 - INFO - Epoch 164: train_loss=1.3472
2025-02-06 18:08:51,618 - INFO - Epoch 164: val_loss=1.1123, val_acc=33.33%
2025-02-06 18:08:51,622 - INFO - Epoch 164: EPOCH_AVG_TRAIN_LOSS=1.1767
2025-02-06 18:08:51,624 - INFO - #################### Training epoch 165 ####################
2025-02-06 18:08:51,624 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:52,039 - INFO - Epoch 165: train_loss=1.2293
2025-02-06 18:08:52,331 - INFO - Epoch 165: train_loss=1.2700
2025-02-06 18:08:52,660 - INFO - Epoch 165: val_loss=1.1124, val_acc=33.33%
2025-02-06 18:08:52,664 - INFO - Epoch 165: EPOCH_AVG_TRAIN_LOSS=1.2293
2025-02-06 18:08:52,666 - INFO - #################### Training epoch 166 ####################
2025-02-06 18:08:52,666 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:53,080 - INFO - Epoch 166: train_loss=1.0869
2025-02-06 18:08:53,371 - INFO - Epoch 166: train_loss=1.5774
2025-02-06 18:08:53,697 - INFO - Epoch 166: val_loss=1.1156, val_acc=33.33%
2025-02-06 18:08:53,700 - INFO - Epoch 166: EPOCH_AVG_TRAIN_LOSS=1.0869
2025-02-06 18:08:53,703 - INFO - #################### Training epoch 167 ####################
2025-02-06 18:08:53,703 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:54,115 - INFO - Epoch 167: train_loss=1.1327
2025-02-06 18:08:54,406 - INFO - Epoch 167: train_loss=1.4900
2025-02-06 18:08:54,738 - INFO - Epoch 167: val_loss=1.1092, val_acc=33.33%
2025-02-06 18:08:54,741 - INFO - Epoch 167: EPOCH_AVG_TRAIN_LOSS=1.1327
2025-02-06 18:08:54,744 - INFO - #################### Training epoch 168 ####################
2025-02-06 18:08:54,744 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:55,160 - INFO - Epoch 168: train_loss=1.2126
2025-02-06 18:08:55,452 - INFO - Epoch 168: train_loss=1.3665
2025-02-06 18:08:55,780 - INFO - Epoch 168: val_loss=1.1136, val_acc=33.33%
2025-02-06 18:08:55,784 - INFO - Epoch 168: EPOCH_AVG_TRAIN_LOSS=1.2126
2025-02-06 18:08:55,786 - INFO - #################### Training epoch 169 ####################
2025-02-06 18:08:55,786 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:56,200 - INFO - Epoch 169: train_loss=1.3510
2025-02-06 18:08:56,492 - INFO - Epoch 169: train_loss=1.0769
2025-02-06 18:08:56,819 - INFO - Epoch 169: val_loss=1.1164, val_acc=33.33%
2025-02-06 18:08:56,822 - INFO - Epoch 169: EPOCH_AVG_TRAIN_LOSS=1.0769
2025-02-06 18:08:56,825 - INFO - #################### Training epoch 170 ####################
2025-02-06 18:08:56,825 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:57,238 - INFO - Epoch 170: train_loss=1.1712
2025-02-06 18:08:57,529 - INFO - Epoch 170: train_loss=1.3554
2025-02-06 18:08:57,855 - INFO - Epoch 170: val_loss=1.1165, val_acc=33.33%
2025-02-06 18:08:57,859 - INFO - Epoch 170: EPOCH_AVG_TRAIN_LOSS=1.1712
2025-02-06 18:08:57,861 - INFO - #################### Training epoch 171 ####################
2025-02-06 18:08:57,861 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:58,276 - INFO - Epoch 171: train_loss=1.1135
2025-02-06 18:08:58,567 - INFO - Epoch 171: train_loss=1.4613
2025-02-06 18:08:58,893 - INFO - Epoch 171: val_loss=1.1142, val_acc=33.33%
2025-02-06 18:08:58,897 - INFO - Epoch 171: EPOCH_AVG_TRAIN_LOSS=1.1135
2025-02-06 18:08:58,899 - INFO - #################### Training epoch 172 ####################
2025-02-06 18:08:58,899 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:08:59,311 - INFO - Epoch 172: train_loss=1.3181
2025-02-06 18:08:59,603 - INFO - Epoch 172: train_loss=1.1591
2025-02-06 18:08:59,932 - INFO - Epoch 172: val_loss=1.1163, val_acc=33.33%
2025-02-06 18:08:59,935 - INFO - Epoch 172: EPOCH_AVG_TRAIN_LOSS=1.1591
2025-02-06 18:08:59,938 - INFO - #################### Training epoch 173 ####################
2025-02-06 18:08:59,938 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:00,355 - INFO - Epoch 173: train_loss=1.1331
2025-02-06 18:09:00,646 - INFO - Epoch 173: train_loss=1.4230
2025-02-06 18:09:00,978 - INFO - Epoch 173: val_loss=1.1087, val_acc=33.33%
2025-02-06 18:09:00,981 - INFO - Epoch 173: EPOCH_AVG_TRAIN_LOSS=1.1331
2025-02-06 18:09:00,984 - INFO - #################### Training epoch 174 ####################
2025-02-06 18:09:00,984 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:01,397 - INFO - Epoch 174: train_loss=1.2079
2025-02-06 18:09:01,689 - INFO - Epoch 174: train_loss=1.2391
2025-02-06 18:09:02,015 - INFO - Epoch 174: val_loss=1.1146, val_acc=33.33%
2025-02-06 18:09:02,019 - INFO - Epoch 174: EPOCH_AVG_TRAIN_LOSS=1.2079
2025-02-06 18:09:02,021 - INFO - #################### Training epoch 175 ####################
2025-02-06 18:09:02,021 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:02,432 - INFO - Epoch 175: train_loss=1.3731
2025-02-06 18:09:02,724 - INFO - Epoch 175: train_loss=0.9788
2025-02-06 18:09:03,054 - INFO - Epoch 175: val_loss=1.1182, val_acc=33.33%
2025-02-06 18:09:03,058 - INFO - Epoch 175: EPOCH_AVG_TRAIN_LOSS=0.9788
2025-02-06 18:09:03,060 - INFO - #################### Training epoch 176 ####################
2025-02-06 18:09:03,060 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:03,475 - INFO - Epoch 176: train_loss=1.1658
2025-02-06 18:09:03,766 - INFO - Epoch 176: train_loss=1.4751
2025-02-06 18:09:04,093 - INFO - Epoch 176: val_loss=1.1115, val_acc=33.33%
2025-02-06 18:09:04,096 - INFO - Epoch 176: EPOCH_AVG_TRAIN_LOSS=1.1658
2025-02-06 18:09:04,099 - INFO - #################### Training epoch 177 ####################
2025-02-06 18:09:04,099 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:04,514 - INFO - Epoch 177: train_loss=1.1841
2025-02-06 18:09:04,805 - INFO - Epoch 177: train_loss=1.3988
2025-02-06 18:09:05,134 - INFO - Epoch 177: val_loss=1.1161, val_acc=33.33%
2025-02-06 18:09:05,137 - INFO - Epoch 177: EPOCH_AVG_TRAIN_LOSS=1.1841
2025-02-06 18:09:05,140 - INFO - #################### Training epoch 178 ####################
2025-02-06 18:09:05,140 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:05,552 - INFO - Epoch 178: train_loss=1.3427
2025-02-06 18:09:05,844 - INFO - Epoch 178: train_loss=0.9412
2025-02-06 18:09:06,172 - INFO - Epoch 178: val_loss=1.1150, val_acc=33.33%
2025-02-06 18:09:06,176 - INFO - Epoch 178: EPOCH_AVG_TRAIN_LOSS=0.9412
2025-02-06 18:09:06,178 - INFO - #################### Training epoch 179 ####################
2025-02-06 18:09:06,178 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:06,593 - INFO - Epoch 179: train_loss=1.3211
2025-02-06 18:09:06,884 - INFO - Epoch 179: train_loss=1.1466
2025-02-06 18:09:07,211 - INFO - Epoch 179: val_loss=1.1146, val_acc=33.33%
2025-02-06 18:09:07,215 - INFO - Epoch 179: EPOCH_AVG_TRAIN_LOSS=1.1466
2025-02-06 18:09:07,217 - INFO - #################### Training epoch 180 ####################
2025-02-06 18:09:07,217 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:07,629 - INFO - Epoch 180: train_loss=1.2539
2025-02-06 18:09:07,920 - INFO - Epoch 180: train_loss=1.0607
2025-02-06 18:09:08,244 - INFO - Epoch 180: val_loss=1.1112, val_acc=33.33%
2025-02-06 18:09:08,248 - INFO - Epoch 180: EPOCH_AVG_TRAIN_LOSS=1.0607
2025-02-06 18:09:08,250 - INFO - #################### Training epoch 181 ####################
2025-02-06 18:09:08,250 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:08,658 - INFO - Epoch 181: train_loss=1.3758
2025-02-06 18:09:08,949 - INFO - Epoch 181: train_loss=0.9399
2025-02-06 18:09:09,275 - INFO - Epoch 181: val_loss=1.1174, val_acc=33.33%
2025-02-06 18:09:09,279 - INFO - Epoch 181: EPOCH_AVG_TRAIN_LOSS=0.9399
2025-02-06 18:09:09,281 - INFO - #################### Training epoch 182 ####################
2025-02-06 18:09:09,281 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:09,692 - INFO - Epoch 182: train_loss=1.2242
2025-02-06 18:09:09,983 - INFO - Epoch 182: train_loss=1.3285
2025-02-06 18:09:10,313 - INFO - Epoch 182: val_loss=1.1140, val_acc=33.33%
2025-02-06 18:09:10,317 - INFO - Epoch 182: EPOCH_AVG_TRAIN_LOSS=1.2242
2025-02-06 18:09:10,319 - INFO - #################### Training epoch 183 ####################
2025-02-06 18:09:10,319 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:10,728 - INFO - Epoch 183: train_loss=1.2593
2025-02-06 18:09:11,020 - INFO - Epoch 183: train_loss=1.2286
2025-02-06 18:09:11,351 - INFO - Epoch 183: val_loss=1.1121, val_acc=33.33%
2025-02-06 18:09:11,355 - INFO - Epoch 183: EPOCH_AVG_TRAIN_LOSS=1.2286
2025-02-06 18:09:11,357 - INFO - #################### Training epoch 184 ####################
2025-02-06 18:09:11,357 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:11,776 - INFO - Epoch 184: train_loss=1.3798
2025-02-06 18:09:12,067 - INFO - Epoch 184: train_loss=1.1186
2025-02-06 18:09:12,396 - INFO - Epoch 184: val_loss=1.1072, val_acc=33.33%
2025-02-06 18:09:12,400 - INFO - Epoch 184: EPOCH_AVG_TRAIN_LOSS=1.1186
2025-02-06 18:09:12,402 - INFO - #################### Training epoch 185 ####################
2025-02-06 18:09:12,402 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:12,814 - INFO - Epoch 185: train_loss=1.2658
2025-02-06 18:09:13,105 - INFO - Epoch 185: train_loss=1.0608
2025-02-06 18:09:13,435 - INFO - Epoch 185: val_loss=1.1143, val_acc=33.33%
2025-02-06 18:09:13,438 - INFO - Epoch 185: EPOCH_AVG_TRAIN_LOSS=1.0608
2025-02-06 18:09:13,441 - INFO - #################### Training epoch 186 ####################
2025-02-06 18:09:13,441 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:13,853 - INFO - Epoch 186: train_loss=1.5589
2025-02-06 18:09:14,144 - INFO - Epoch 186: train_loss=0.7222
2025-02-06 18:09:14,475 - INFO - Epoch 186: val_loss=1.1161, val_acc=33.33%
2025-02-06 18:09:14,479 - INFO - Epoch 186: EPOCH_AVG_TRAIN_LOSS=0.7222
2025-02-06 18:09:14,481 - INFO - #################### Training epoch 187 ####################
2025-02-06 18:09:14,481 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:14,895 - INFO - Epoch 187: train_loss=1.2583
2025-02-06 18:09:15,187 - INFO - Epoch 187: train_loss=1.1729
2025-02-06 18:09:15,521 - INFO - Epoch 187: val_loss=1.1091, val_acc=33.33%
2025-02-06 18:09:15,525 - INFO - Epoch 187: EPOCH_AVG_TRAIN_LOSS=1.1729
2025-02-06 18:09:15,527 - INFO - #################### Training epoch 188 ####################
2025-02-06 18:09:15,527 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:15,945 - INFO - Epoch 188: train_loss=1.1064
2025-02-06 18:09:16,236 - INFO - Epoch 188: train_loss=1.6381
2025-02-06 18:09:16,563 - INFO - Epoch 188: val_loss=1.1148, val_acc=33.33%
2025-02-06 18:09:16,568 - INFO - Epoch 188: EPOCH_AVG_TRAIN_LOSS=1.1064
2025-02-06 18:09:16,570 - INFO - #################### Training epoch 189 ####################
2025-02-06 18:09:16,570 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:16,987 - INFO - Epoch 189: train_loss=1.1356
2025-02-06 18:09:17,278 - INFO - Epoch 189: train_loss=1.5975
2025-02-06 18:09:17,613 - INFO - Epoch 189: val_loss=1.1120, val_acc=33.33%
2025-02-06 18:09:17,617 - INFO - Epoch 189: EPOCH_AVG_TRAIN_LOSS=1.1356
2025-02-06 18:09:17,619 - INFO - #################### Training epoch 190 ####################
2025-02-06 18:09:17,619 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:18,037 - INFO - Epoch 190: train_loss=1.2725
2025-02-06 18:09:18,329 - INFO - Epoch 190: train_loss=1.2562
2025-02-06 18:09:18,661 - INFO - Epoch 190: val_loss=1.1108, val_acc=33.33%
2025-02-06 18:09:18,665 - INFO - Epoch 190: EPOCH_AVG_TRAIN_LOSS=1.2562
2025-02-06 18:09:18,667 - INFO - #################### Training epoch 191 ####################
2025-02-06 18:09:18,667 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:19,084 - INFO - Epoch 191: train_loss=1.1078
2025-02-06 18:09:19,377 - INFO - Epoch 191: train_loss=1.4785
2025-02-06 18:09:19,711 - INFO - Epoch 191: val_loss=1.1059, val_acc=33.33%
2025-02-06 18:09:19,715 - INFO - Epoch 191: EPOCH_AVG_TRAIN_LOSS=1.1078
2025-02-06 18:09:19,717 - INFO - #################### Training epoch 192 ####################
2025-02-06 18:09:19,717 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:20,132 - INFO - Epoch 192: train_loss=1.1925
2025-02-06 18:09:20,423 - INFO - Epoch 192: train_loss=1.3562
2025-02-06 18:09:20,752 - INFO - Epoch 192: val_loss=1.1160, val_acc=33.33%
2025-02-06 18:09:20,756 - INFO - Epoch 192: EPOCH_AVG_TRAIN_LOSS=1.1925
2025-02-06 18:09:20,758 - INFO - #################### Training epoch 193 ####################
2025-02-06 18:09:20,758 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:21,171 - INFO - Epoch 193: train_loss=0.9925
2025-02-06 18:09:21,463 - INFO - Epoch 193: train_loss=1.8030
2025-02-06 18:09:21,790 - INFO - Epoch 193: val_loss=1.1153, val_acc=33.33%
2025-02-06 18:09:21,795 - INFO - Epoch 193: EPOCH_AVG_TRAIN_LOSS=0.9925
2025-02-06 18:09:21,797 - INFO - #################### Training epoch 194 ####################
2025-02-06 18:09:21,797 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:22,210 - INFO - Epoch 194: train_loss=1.2896
2025-02-06 18:09:22,502 - INFO - Epoch 194: train_loss=1.1852
2025-02-06 18:09:22,826 - INFO - Epoch 194: val_loss=1.1164, val_acc=33.33%
2025-02-06 18:09:22,829 - INFO - Epoch 194: EPOCH_AVG_TRAIN_LOSS=1.1852
2025-02-06 18:09:22,832 - INFO - #################### Training epoch 195 ####################
2025-02-06 18:09:22,832 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:23,241 - INFO - Epoch 195: train_loss=1.2487
2025-02-06 18:09:23,533 - INFO - Epoch 195: train_loss=1.2407
2025-02-06 18:09:23,860 - INFO - Epoch 195: val_loss=1.1116, val_acc=33.33%
2025-02-06 18:09:23,864 - INFO - Epoch 195: EPOCH_AVG_TRAIN_LOSS=1.2407
2025-02-06 18:09:23,866 - INFO - #################### Training epoch 196 ####################
2025-02-06 18:09:23,866 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:24,280 - INFO - Epoch 196: train_loss=1.4630
2025-02-06 18:09:24,572 - INFO - Epoch 196: train_loss=0.8505
2025-02-06 18:09:24,898 - INFO - Epoch 196: val_loss=1.1137, val_acc=33.33%
2025-02-06 18:09:24,902 - INFO - Epoch 196: EPOCH_AVG_TRAIN_LOSS=0.8505
2025-02-06 18:09:24,904 - INFO - #################### Training epoch 197 ####################
2025-02-06 18:09:24,904 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:25,313 - INFO - Epoch 197: train_loss=1.2160
2025-02-06 18:09:25,605 - INFO - Epoch 197: train_loss=1.2674
2025-02-06 18:09:25,931 - INFO - Epoch 197: val_loss=1.1097, val_acc=33.33%
2025-02-06 18:09:25,934 - INFO - Epoch 197: EPOCH_AVG_TRAIN_LOSS=1.2160
2025-02-06 18:09:25,937 - INFO - #################### Training epoch 198 ####################
2025-02-06 18:09:25,937 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:26,344 - INFO - Epoch 198: train_loss=1.3295
2025-02-06 18:09:26,635 - INFO - Epoch 198: train_loss=1.2287
2025-02-06 18:09:26,959 - INFO - Epoch 198: val_loss=1.1164, val_acc=33.33%
2025-02-06 18:09:26,962 - INFO - Epoch 198: EPOCH_AVG_TRAIN_LOSS=1.2287
2025-02-06 18:09:26,965 - INFO - #################### Training epoch 199 ####################
2025-02-06 18:09:26,965 - INFO - Current Learning Rate: 1.525879e-08
2025-02-06 18:09:27,374 - INFO - Epoch 199: train_loss=1.2160
2025-02-06 18:09:27,667 - INFO - Epoch 199: train_loss=1.3675
2025-02-06 18:09:27,995 - INFO - Epoch 199: val_loss=1.1141, val_acc=33.33%
2025-02-06 18:09:27,999 - INFO - Epoch 199: EPOCH_AVG_TRAIN_LOSS=1.2160
2025-02-06 18:09:28,174 - INFO - Model saved.
