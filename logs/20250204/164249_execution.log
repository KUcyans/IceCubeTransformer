nohup: ignoring input
wandb: Currently logged in as: cyans (cyans-k-benhavns-universitet) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.5
wandb: Run data is saved locally in /lustre/hpc/icecube/cyan/factory/IceCubeTransformer/wandb/run-20250204_164258-ys9snpro
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-silence-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cyans-k-benhavns-universitet/%5B20250204_164249%5D%20Flavour%20Classification
wandb: üöÄ View run at https://wandb.ai/cyans-k-benhavns-universitet/%5B20250204_164249%5D%20Flavour%20Classification/runs/ys9snpro
/groups/icecube/cyan/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.9 TrainingDebuggingYard.py --date 20250204 --time 1 ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/groups/icecube/cyan/.local/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
/groups/icecube/cyan/.local/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /lustre/hpc/icecube/cyan/factory/IceCubeTransformer/checkpoints/20250204 exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
/groups/icecube/cyan/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(

  | Name                        | Type       | Params | Mode 
-------------------------------------------------------------------
0 | input_projection            | Linear     | 4.2 K  | train
1 | encoder_blocks              | ModuleList | 297 K  | train
2 | classification_output_layer | Linear     | 387    | train
-------------------------------------------------------------------
301 K     Trainable params
0         Non-trainable params
301 K     Total params
1.207     Total estimated model params size (MB)
Number of GPUs available: 2
GPU 0: NVIDIA GeForce RTX 3090
GPU 1: NVIDIA GeForce RTX 3090
Number of GPUs available: 2
GPU 0: NVIDIA GeForce RTX 3090
GPU 1: NVIDIA GeForce RTX 3090
------------- Multi-Flavour Shard (Energy Band: ER_1_PEV_100_PEV, Part: 1, Shard: 1) -------------
------------- Multi-Flavour Shard (Energy Band: ER_1_PEV_100_PEV, Part: 1, Shard: 1) -------------
Config validation passed.
Dataset split into train (24), val (3), and test (3)
Class weights: tensor([0.1250, 0.1250, 0.1250])
Sanity Checking: |          | 0/? [00:00<?, ?it/s]/groups/icecube/cyan/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.
Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.89it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]  mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.1146
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.29it/s]Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.28it/s, v_num=npro]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.19it/s][A
                                                                      [AEpoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s, v_num=npro]Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.44it/s, v_num=npro]Metric val_acc improved. New best score: 0.667
Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro]        Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=2.8544
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.75it/s, v_num=npro]Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.74it/s, v_num=npro, epoch_avg_train_loss=1.110]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.43it/s][A
                                                                      [AEpoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.98it/s, v_num=npro, epoch_avg_train_loss=1.110]Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.98it/s, v_num=npro, epoch_avg_train_loss=1.110]Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.110]        Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.110] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=2.2777
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=1.110]Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=2.850]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.69it/s][A
                                                                      [AEpoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=2.850]Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=2.850]Metric val_acc improved by 0.333 >= min_delta = 0.0. New best score: 0.333
Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=2.850]        Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=2.850] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.7136
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=2.850]Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=2.280]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.72it/s][A
                                                                      [AEpoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=2.280]Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=2.280]Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=2.280]        Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=2.280] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.2217
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=2.280]Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=1.710]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.48it/s][A
                                                                      [AEpoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.710]Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.710]Metric val_acc improved by 0.333 >= min_delta = 0.0. New best score: 0.000
Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.710]        Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.710] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.1920
Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.71it/s, v_num=npro, epoch_avg_train_loss=1.710]Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=1.220]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.88it/s][A
                                                                      [AEpoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.220]Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.220]Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.220]        Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.220] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.2468
Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=1.220]Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=1.190]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.82it/s][A
                                                                      [AEpoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.190]Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.190]Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.190]        Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.190] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.1654
Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=1.190]Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=1.250]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.83it/s][A
                                                                      [AEpoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.250]Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.250]Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.250]        Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.250] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0921
Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=1.250]Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=1.170]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.11it/s][A
                                                                      [AEpoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=1.170]Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=1.170]Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.170]        Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.170] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0835
Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=1.170]Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=1.090]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.88it/s][A
                                                                      [AEpoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.090]Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.090]Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.090]        Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.090] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0884
Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=1.090]Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=1.080]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.93it/s][A
                                                                      [AEpoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.080]Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.080]Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.080]        Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.080] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0886
Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=1.080]Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=1.090]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.40it/s][A
                                                                      [AEpoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.090]Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=1.090]Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.090]        Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.090] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0841
Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=1.090]Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=1.090]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.54it/s][A
                                                                      [AEpoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=1.090]Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.090]Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.090]        Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.090] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0758
Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=1.090]Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=1.080]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 62.03it/s][A
                                                                      [AEpoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=1.080]Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=1.080]Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.080]        Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.080] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0698
Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=1.080]Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=1.080]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.39it/s][A
                                                                      [AEpoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=1.080]Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=1.080]Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.080]        Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.080] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0651
Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=1.080]Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=1.070]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.63it/s][A
                                                                      [AEpoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.070]Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.070]Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.070]        Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.070] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0619
Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=1.070]Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=1.070]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.00it/s][A
                                                                      [AEpoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=1.070]Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.070]Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.070]        Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.070] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0596
Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=1.070]Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=1.060]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 71.57it/s][A
                                                                      [AEpoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.060]Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.060]Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.060]        Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.060] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0494
Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=1.060]Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=1.060]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.53it/s][A
                                                                      [AEpoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=1.060]Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.060]Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.060]        Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.060] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0429
Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=1.060]Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=1.050]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.57it/s][A
                                                                      [AEpoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=1.050]Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=1.050]Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.050]        Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.050] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0456
Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=1.050]Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=1.040]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.63it/s][A
                                                                      [AEpoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.040]Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.040]Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.040]        Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.040] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0331
Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.71it/s, v_num=npro, epoch_avg_train_loss=1.040]Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=1.050]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.16it/s][A
                                                                      [AEpoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s, v_num=npro, epoch_avg_train_loss=1.050]Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s, v_num=npro, epoch_avg_train_loss=1.050]Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.050]        Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.050] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0287
Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.74it/s, v_num=npro, epoch_avg_train_loss=1.050]Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.74it/s, v_num=npro, epoch_avg_train_loss=1.030]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.72it/s][A
                                                                      [AEpoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=1.030]Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=1.030]Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.030]        Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.030] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0301
Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=1.030]Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=1.030]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.87it/s][A
                                                                      [AEpoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.030]Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.030]Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.030]        Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.030] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0185
Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=1.030]Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=1.030]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.17it/s][A
                                                                      [AEpoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.030]Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.030]Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.030]        Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.030] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0163
Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=1.030]Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=1.020]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.83it/s][A
                                                                      [AEpoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.020]Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.020]Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.020]        Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.020] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0140
Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=1.020]Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=1.020]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.10it/s][A
                                                                      [AEpoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.020]Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.020]Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.020]        Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.020] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0084
Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=1.020]Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=1.010]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.27it/s][A
                                                                      [AEpoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.010]Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.010]Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.010]        Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.010] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0050
Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=1.010]Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=1.010]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.30it/s][A
                                                                      [AEpoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.010]Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.010]Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.010]        Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.010] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0041
Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=1.010]Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=1.010]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 66.63it/s][A
                                                                      [AEpoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.010]Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=1.010]Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.010]        Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.010] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=1.0015
Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=1.010]Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=1.000]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.44it/s][A
                                                                      [AEpoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.000]Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=1.000]Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.000]        Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.000] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9996
Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=1.000]Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=1.000]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.41it/s][A
                                                                      [AEpoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=1.000]Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=1.000]Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.000]        Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.000] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9947
Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.73it/s, v_num=npro, epoch_avg_train_loss=1.000]Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.72it/s, v_num=npro, epoch_avg_train_loss=1.000]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.15it/s][A
                                                                      [AEpoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=1.000]Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=1.000]Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.000]        Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=1.000] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9930
Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=1.000]Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.995]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.82it/s][A
                                                                      [AEpoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=0.995]Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=0.995]Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.995]        Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.995] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9897
Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.71it/s, v_num=npro, epoch_avg_train_loss=0.995]Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=0.993]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.25it/s][A
                                                                      [AEpoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.993]Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.993]Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.993]        Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.993] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9894
Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.993]Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.990]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.58it/s][A
                                                                      [AEpoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.990]Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.990]Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.990]        Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.990] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9878
Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.990]Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.989]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 67.90it/s][A
                                                                      [AEpoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.989]Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.989]Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.989]        Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.989] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9873
Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.989]Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.988]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.30it/s][A
                                                                      [AEpoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.988]Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.988]Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.988]        Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.988] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9842
Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.75it/s, v_num=npro, epoch_avg_train_loss=0.988]Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.74it/s, v_num=npro, epoch_avg_train_loss=0.987]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.99it/s][A
                                                                      [AEpoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=0.987]Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=0.987]Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.987]        Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.987] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9857
Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.987]Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.984]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.77it/s][A
                                                                      [AEpoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.984]Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.984]Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.984]        Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.984] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9830
Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.984]Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.986]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.46it/s][A
                                                                      [AEpoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.986]Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.986]Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.986]        Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.986] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9804
Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.986]Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.983]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.23it/s][A
                                                                      [AEpoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.98it/s, v_num=npro, epoch_avg_train_loss=0.983]Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=0.983]Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.983]        Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.983] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9837
Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.983]Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.980]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.13it/s][A
                                                                      [AEpoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.980]Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.980]Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.980]        Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.980] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9806
Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.980]Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.984]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.09it/s][A
                                                                      [AEpoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.984]Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.984]Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.984]        Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.984] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9804
Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.984]Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.981]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.21it/s][A
                                                                      [AEpoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.981]Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.981]Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.981]        Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.981] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9794
Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.981]Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.980]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.25it/s][A
                                                                      [AEpoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.980]Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.980]Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.980]        Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.980] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9774
Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.980]Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.979]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 67.09it/s][A
                                                                      [AEpoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.979]Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.979]Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.979]        Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.979] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9776
Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.979]Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.977]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.08it/s][A
                                                                      [AEpoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.977]Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.977]Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.977]        Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.977] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9771
Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.977]Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.978]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.76it/s][A
                                                                      [AEpoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.978]        Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.978] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9785
Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.977]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.75it/s][A
                                                                      [AEpoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.977]Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.977]Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.977]        Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.977] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9782
Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.977]Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.978]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.59it/s][A
                                                                      [AEpoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.978]        Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.978] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9779
Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.978]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.23it/s][A
                                                                      [AEpoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.978]        Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.978] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9755
Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.978]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.88it/s][A
                                                                      [AEpoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.978]        Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.978] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9757
Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.978]Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.37it/s][A
                                                                      [AEpoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9755
Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 67.47it/s][A
                                                                      [AEpoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9752
Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.67it/s][A
                                                                      [AEpoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9761
Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.66it/s][A
                                                                      [AEpoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9750
Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.44it/s][A
                                                                      [AEpoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9747
Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.62it/s][A
                                                                      [AEpoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9756
Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.60it/s][A
                                                                      [AEpoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9757
Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.38it/s][A
                                                                      [AEpoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9737
Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.51it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.50it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.31it/s][A
                                                                      [AEpoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9748
Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.51it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.51it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.34it/s][A
                                                                      [AEpoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9749
Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.56it/s][A
                                                                      [AEpoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9746
Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.92it/s][A
                                                                      [AEpoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 64: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9756
Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.92it/s][A
                                                                      [AEpoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9765
Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.21it/s][A
                                                                      [AEpoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 66: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9734
Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.10it/s][A
                                                                      [AEpoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9743
Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.33it/s][A
                                                                      [AEpoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9742
Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.18it/s][A
                                                                      [AEpoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9752
Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.95it/s][A
                                                                      [AEpoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9738
Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.44it/s][A
                                                                      [AEpoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9747
Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.61it/s][A
                                                                      [AEpoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 72: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9731
Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.33it/s][A
                                                                      [AEpoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9736
Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.17it/s][A
                                                                      [AEpoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 74: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9739
Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.34it/s][A
                                                                      [AEpoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 75: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9744
Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.21it/s][A
                                                                      [AEpoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9740
Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.94it/s][A
                                                                      [AEpoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9731
Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.62it/s][A
                                                                      [AEpoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9759
Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.85it/s][A
                                                                      [AEpoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 79: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9739
Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.44it/s][A
                                                                      [AEpoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 80: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9746
Epoch 81: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 81: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.85it/s][A
                                                                      [AEpoch 81: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 81: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9744
Epoch 82: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 82: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 66.22it/s][A
                                                                      [AEpoch 82: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 82: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9748
Epoch 83: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 83: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.85it/s][A
                                                                      [AEpoch 83: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 83: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 84: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 84: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.75it/s][A
                                                                      [AEpoch 84: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 84: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9740
Epoch 85: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 85: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.45it/s][A
                                                                      [AEpoch 85: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 85: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9742
Epoch 86: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 86: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.21it/s][A
                                                                      [AEpoch 86: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 86: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9749
Epoch 87: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 87: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.42it/s][A
                                                                      [AEpoch 87: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 87: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9745
Epoch 88: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 88: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.94it/s][A
                                                                      [AEpoch 88: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 88: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9733
Epoch 89: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 89: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.19it/s][A
                                                                      [AEpoch 89: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 89: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9738
Epoch 90: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 90: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.93it/s][A
                                                                      [AEpoch 90: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 90: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9731
Epoch 91: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 91: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 66.67it/s][A
                                                                      [AEpoch 91: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 91: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9747
Epoch 92: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 92: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.33it/s][A
                                                                      [AEpoch 92: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 92: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9746
Epoch 93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.97it/s][A
                                                                      [AEpoch 93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 94: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 94: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 65.94it/s][A
                                                                      [AEpoch 94: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 94: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.44it/s][A
                                                                      [AEpoch 95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9745
Epoch 96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.40it/s][A
                                                                      [AEpoch 96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9731
Epoch 97: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 97: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.78it/s][A
                                                                      [AEpoch 97: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 97: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9743
Epoch 98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.69it/s][A
                                                                      [AEpoch 98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9748
Epoch 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.89it/s][A
                                                                      [AEpoch 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9749
Epoch 100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.10it/s][A
                                                                      [AEpoch 100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9736
Epoch 101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.61it/s][A
                                                                      [AEpoch 101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 102: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 102: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.19it/s][A
                                                                      [AEpoch 102: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 102: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9751
Epoch 103: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 103: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.80it/s][A
                                                                      [AEpoch 103: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 103: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9750
Epoch 104: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 104: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.77it/s][A
                                                                      [AEpoch 104: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 104: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9752
Epoch 105: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 105: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.84it/s][A
                                                                      [AEpoch 105: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 105: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9734
Epoch 106: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 106: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.73it/s][A
                                                                      [AEpoch 106: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 106: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9744
Epoch 107: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 107: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.67it/s][A
                                                                      [AEpoch 107: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 107: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9737
Epoch 108: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 108: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.76it/s][A
                                                                      [AEpoch 108: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 108: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9739
Epoch 109: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 109: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.19it/s][A
                                                                      [AEpoch 109: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 109: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9740
Epoch 110: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 110: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.85it/s][A
                                                                      [AEpoch 110: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 110: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9734
Epoch 111: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 111: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.75it/s][A
                                                                      [AEpoch 111: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 111: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9735
Epoch 112: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 112: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.39it/s][A
                                                                      [AEpoch 112: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 112: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9731
Epoch 113: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 113: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.03it/s][A
                                                                      [AEpoch 113: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 113: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9731
Epoch 114: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 114: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.50it/s][A
                                                                      [AEpoch 114: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 114: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9734
Epoch 115: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 115: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.91it/s][A
                                                                      [AEpoch 115: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 115: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9738
Epoch 116: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.71it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 116: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.84it/s][A
                                                                      [AEpoch 116: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 116: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9742
Epoch 117: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 117: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.03it/s][A
                                                                      [AEpoch 117: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 117: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9757
Epoch 118: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 118: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.43it/s][A
                                                                      [AEpoch 118: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 118: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9738
Epoch 119: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 119: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.00it/s][A
                                                                      [AEpoch 119: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 119: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9745
Epoch 120: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 120: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.59it/s][A
                                                                      [AEpoch 120: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 120: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9739
Epoch 121: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 121: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.26it/s][A
                                                                      [AEpoch 121: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 121: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9732
Epoch 122: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 122: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 67.95it/s][A
                                                                      [AEpoch 122: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 122: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 123: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 123: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.12it/s][A
                                                                      [AEpoch 123: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 123: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9733
Epoch 124: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 124: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.49it/s][A
                                                                      [AEpoch 124: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 124: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9750
Epoch 125: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 125: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.46it/s][A
                                                                      [AEpoch 125: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 125: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 126: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.72it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 126: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.71it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.72it/s][A
                                                                      [AEpoch 126: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 126: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9752
Epoch 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.95it/s][A
                                                                      [AEpoch 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9729
Epoch 128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.02it/s][A
                                                                      [AEpoch 128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9743
Epoch 129: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 129: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.87it/s][A
                                                                      [AEpoch 129: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 129: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9740
Epoch 130: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 130: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.60it/s][A
                                                                      [AEpoch 130: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 130: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9737
Epoch 131: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 131: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.52it/s][A
                                                                      [AEpoch 131: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 131: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9751
Epoch 132: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 132: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.92it/s][A
                                                                      [AEpoch 132: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 132: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9751
Epoch 133: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 133: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 67.10it/s][A
                                                                      [AEpoch 133: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 133: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9749
Epoch 134: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 134: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 71.04it/s][A
                                                                      [AEpoch 134: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 134: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9750
Epoch 135: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 135: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.60it/s][A
                                                                      [AEpoch 135: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 135: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9743
Epoch 136: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 136: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.60it/s][A
                                                                      [AEpoch 136: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 136: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 137: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 137: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.84it/s][A
                                                                      [AEpoch 137: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 137: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9740
Epoch 138: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 138: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.81it/s][A
                                                                      [AEpoch 138: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 138: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9757
Epoch 139: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 139: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 66.28it/s][A
                                                                      [AEpoch 139: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 139: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9734
Epoch 140: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 140: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.11it/s][A
                                                                      [AEpoch 140: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 140: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9745
Epoch 141: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 141: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.42it/s][A
                                                                      [AEpoch 141: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 141: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9734
Epoch 142: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 142: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 71.05it/s][A
                                                                      [AEpoch 142: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 142: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9749
Epoch 143: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 143: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 71.56it/s][A
                                                                      [AEpoch 143: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 143: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9750
Epoch 144: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.72it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 144: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.71it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.50it/s][A
                                                                      [AEpoch 144: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 144: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9752
Epoch 145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.91it/s][A
                                                                      [AEpoch 145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9744
Epoch 146: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 146: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.14it/s][A
                                                                      [AEpoch 146: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 146: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9736
Epoch 147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.92it/s][A
                                                                      [AEpoch 147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9738
Epoch 148: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 148: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.50it/s][A
                                                                      [AEpoch 148: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 148: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9758
Epoch 149: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 149: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.62it/s][A
                                                                      [AEpoch 149: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 149: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9731
Epoch 150: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 150: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.47it/s][A
                                                                      [AEpoch 150: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 150: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 151: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 151: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.17it/s][A
                                                                      [AEpoch 151: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 151: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9737
Epoch 152: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 152: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 71.63it/s][A
                                                                      [AEpoch 152: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 152: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9738
Epoch 153: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 153: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 67.73it/s][A
                                                                      [AEpoch 153: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 153: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9762
Epoch 154: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 154: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.14it/s][A
                                                                      [AEpoch 154: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 154: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9753
Epoch 155: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 155: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.36it/s][A
                                                                      [AEpoch 155: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 155: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9753
Epoch 156: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 156: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.98it/s][A
                                                                      [AEpoch 156: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 156: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9764
Epoch 157: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 157: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.69it/s][A
                                                                      [AEpoch 157: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 157: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9748
Epoch 158: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 158: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, v_num=npro, epoch_avg_train_loss=0.976]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.78it/s][A
                                                                      [AEpoch 158: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 158: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976]        Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.976] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9734
Epoch 159: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.976]Epoch 159: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.43it/s][A
                                                                      [AEpoch 159: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 159: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9738
Epoch 160: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 160: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.85it/s][A
                                                                      [AEpoch 160: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 160: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9748
Epoch 161: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 161: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.97it/s][A
                                                                      [AEpoch 161: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 161: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9737
Epoch 162: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 162: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.39it/s][A
                                                                      [AEpoch 162: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 162: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9748
Epoch 163: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 163: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.63it/s][A
                                                                      [AEpoch 163: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 163: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9744
Epoch 164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.73it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.73it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 67.70it/s][A
                                                                      [AEpoch 164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9740
Epoch 165: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 165: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.21it/s][A
                                                                      [AEpoch 165: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 165: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9744
Epoch 166: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 166: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.32it/s][A
                                                                      [AEpoch 166: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 166: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9745
Epoch 167: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 167: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.95it/s][A
                                                                      [AEpoch 167: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 167: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9743
Epoch 168: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 168: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.36it/s][A
                                                                      [AEpoch 168: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 168: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9737
Epoch 169: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 169: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.69it/s][A
                                                                      [AEpoch 169: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 169: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9746
Epoch 170: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 170: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.94it/s][A
                                                                      [AEpoch 170: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 170: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9745
Epoch 171: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 171: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 76.03it/s][A
                                                                      [AEpoch 171: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.51it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 171: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.51it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9742
Epoch 172: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 172: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.61it/s][A
                                                                      [AEpoch 172: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 172: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9730
Epoch 173: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 173: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.72it/s][A
                                                                      [AEpoch 173: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 173: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 174: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 174: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.34it/s][A
                                                                      [AEpoch 174: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 174: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9754
Epoch 175: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 175: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.16it/s][A
                                                                      [AEpoch 175: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 175: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 176: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 176: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.33it/s][A
                                                                      [AEpoch 176: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 176: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9740
Epoch 177: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 177: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.42it/s][A
                                                                      [AEpoch 177: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 177: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9753
Epoch 178: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.50it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 178: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.49it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.54it/s][A
                                                                      [AEpoch 178: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 178: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9734
Epoch 179: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 179: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.68it/s][A
                                                                      [AEpoch 179: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 179: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9743
Epoch 180: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 180: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.52it/s][A
                                                                      [AEpoch 180: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 180: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9729
Epoch 181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 71.19it/s][A
                                                                      [AEpoch 181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9752
Epoch 182: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 182: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 71.09it/s][A
                                                                      [AEpoch 182: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 182: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9751
Epoch 183: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.64it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 183: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.91it/s][A
                                                                      [AEpoch 183: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 183: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9738
Epoch 184: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 184: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.48it/s][A
                                                                      [AEpoch 184: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 184: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9746
Epoch 185: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 185: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.62it/s][A
                                                                      [AEpoch 185: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 185: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9732
Epoch 186: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 186: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.51it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.66it/s][A
                                                                      [AEpoch 186: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 186: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9734
Epoch 187: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 187: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.58it/s][A
                                                                      [AEpoch 187: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 187: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9741
Epoch 188: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 188: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.66it/s][A
                                                                      [AEpoch 188: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 188: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9749
Epoch 189: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 189: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.85it/s][A
                                                                      [AEpoch 189: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 189: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9743
Epoch 190: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 190: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.14it/s][A
                                                                      [AEpoch 190: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 190: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9739
Epoch 191: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 191: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.37it/s][A
                                                                      [AEpoch 191: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 191: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9747
Epoch 192: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 192: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.51it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.29it/s][A
                                                                      [AEpoch 192: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 192: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9740
Epoch 193: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.63it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 193: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, v_num=npro, epoch_avg_train_loss=0.975]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 67.96it/s][A
                                                                      [AEpoch 193: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 193: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975]        Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.975] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9734
Epoch 194: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.975]Epoch 194: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.56it/s][A
                                                                      [AEpoch 194: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 194: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9742
Epoch 195: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 195: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s, v_num=npro, epoch_avg_train_loss=0.973]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.41it/s][A
                                                                      [AEpoch 195: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 195: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973]        Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.973] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9740
Epoch 196: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.973]Epoch 196: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.43it/s][A
                                                                      [AEpoch 196: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 196: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9744
Epoch 197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 61.56it/s][A
                                                                      [AEpoch 197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9736
Epoch 198: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.48it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 198: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.48it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 62.30it/s][A
                                                                      [AEpoch 198: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 198: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974]        Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=npro, epoch_avg_train_loss=0.974] mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 24, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([24, 2421])
Batch 0: train_loss=0.9755
Epoch 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s, v_num=npro, epoch_avg_train_loss=0.974]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])
 mask shape should be [batch_size, n_heads, seq_length, seq_length]
 batch_size: 3, n_heads: 8, seq_length: 2421, embed_dim: 128
 the shape of the mask is torch.Size([3, 2421])

Validation DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 68.29it/s][A
                                                                      [AEpoch 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]Epoch 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s, v_num=npro, epoch_avg_train_loss=0.974]`Trainer.fit` stopped: `max_epochs=200` reached.
Epoch 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s, v_num=npro, epoch_avg_train_loss=0.974]FIT Profiler Report
Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.configure_callbacks
         7 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 module.py:936(configure_callbacks)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningDataModule]PMTfiedDataModule.setup
         2063 function calls (2047 primitive calls) in 0.012 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.012    0.012 PMTfiedDataModule.py:25(setup)
        1    0.000    0.000    0.009    0.009 PMTfiedDataModule.py:37(<listcomp>)
       25    0.000    0.000    0.009    0.000 dataset.py:409(__getitem__)
       24    0.000    0.000    0.009    0.000 DatasetMultiFlavourShard_Micro.py:50(__getitem__)
       24    0.001    0.000    0.009    0.000 DatasetMonoFlavourShard_Micro.py:55(__getitem__)
       24    0.002    0.000    0.004    0.000 DatasetMonoFlavourShard_Micro.py:153(_extract_features)
      121    0.002    0.000    0.002    0.000 {built-in method torch.tensor}
      4/1    0.000    0.000    0.002    0.002 _tensor.py:982(__format__)
        1    0.000    0.000    0.002    0.002 {function Tensor.__format__ at 0x7f1340ba3c10}
        1    0.000    0.000    0.002    0.002 _tensor.py:457(__repr__)
        1    0.000    0.000    0.002    0.002 _tensor_str.py:695(_str)
       24    0.002    0.000    0.002    0.000 DatasetMonoFlavourShard_Micro.py:166(<listcomp>)
        3    0.000    0.000    0.001    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.001    0.001 contextlib.py:114(__enter__)
        2    0.000    0.000    0.001    0.001 _python_dispatch.py:201(_disable_current_modes)
        1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap>:1002(_find_and_load)
        1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap>:967(_find_and_load_unlocked)
        1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap>:659(_load_unlocked)
       24    0.001    0.000    0.001    0.000 shape_base.py:372(stack)
        1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap_external>:844(exec_module)
        1    0.000    0.000    0.001    0.001 _tensor_str.py:391(_str_intern)
       48    0.001    0.000    0.001    0.000 {built-in method numpy.zeros}
        1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap_external>:916(get_code)
        1    0.000    0.000    0.001    0.001 _tensor_str.py:303(_tensor_str)
        1    0.000    0.000    0.001    0.001 _tensor_str.py:123(__init__)
        1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap_external>:1036(get_data)
        1    0.000    0.000    0.000    0.000 {built-in method io.open_code}
       24    0.000    0.000    0.000    0.000 {built-in method torch.argmax}
        1    0.000    0.000    0.000    0.000 dataset.py:426(random_split)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:220(_call_with_frames_removed)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}
        1    0.000    0.000    0.000    0.000 schema_check_mode.py:3(<module>)
        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}
        2    0.000    0.000    0.000    0.000 {built-in method builtins.print}
        4    0.000    0.000    0.000    0.000 redirect.py:644(write)
        4    0.000    0.000    0.000    0.000 wandb_run.py:2304(<lambda>)
        4    0.000    0.000    0.000    0.000 wandb_run.py:390(wrapper_fn)
        4    0.000    0.000    0.000    0.000 wandb_run.py:1429(_console_raw_callback)
        2    0.000    0.000    0.000    0.000 __init__.py:345(namedtuple)
        1    0.000    0.000    0.000    0.000 {built-in method torch.randperm}
        4    0.000    0.000    0.000    0.000 interface.py:749(publish_output_raw)
        1    0.000    0.000    0.000    0.000 {built-in method torch.isfinite}
        1    0.000    0.000    0.000    0.000 {built-in method torch.bincount}
       24    0.000    0.000    0.000    0.000 shape_base.py:455(<listcomp>)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:901(_find_spec)
       24    0.000    0.000    0.000    0.000 shape_base.py:443(<listcomp>)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1415(find_spec)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1383(_get_spec)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1514(find_spec)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:645(_compile_bytecode)
        1    0.000    0.000    0.000    0.000 {built-in method marshal.loads}
        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:135(_path_stat)
        1    0.000    0.000    0.000    0.000 _tensor.py:35(wrapped)
        1    0.000    0.000    0.000    0.000 {built-in method torch.masked_select}
        3    0.000    0.000    0.000    0.000 {built-in method posix.stat}
        4    0.000    0.000    0.000    0.000 interface_shared.py:76(_publish_output_raw)
        1    0.000    0.000    0.000    0.000 _tensor.py:964(__rdiv__)
       27    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 {built-in method builtins.eval}
        4    0.000    0.000    0.000    0.000 interface_sock.py:45(_publish)
        2    0.000    0.000    0.000    0.000 _tensor.py:1033(__iter__)
       24    0.000    0.000    0.000    0.000 shape_base.py:447(<setcomp>)
        4    0.000    0.000    0.000    0.000 sock_client.py:219(send_record_publish)
       24    0.000    0.000    0.000    0.000 DatasetMultiFlavourShard_Micro.py:72(_global_to_local_index)
        2    0.000    0.000    0.000    0.000 {method 'unbind' of 'torch._C.TensorBase' objects}
        4    0.000    0.000    0.000    0.000 sock_client.py:153(send_server_request)
        4    0.000    0.000    0.000    0.000 sock_client.py:145(_send_message)
       24    0.000    0.000    0.000    0.000 DatasetMonoFlavourShard_Micro.py:160(<listcomp>)
      768    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}
        1    0.000    0.000    0.000    0.000 {built-in method torch.ceil}
        3    0.000    0.000    0.000    0.000 _tensor_str.py:117(tensor_totype)
        1    0.000    0.000    0.000    0.000 {method 'read' of '_io.BufferedReader' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:154(_path_isfile)
        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:145(_path_is_mode_type)
       24    0.000    0.000    0.000    0.000 shape_base.py:362(_stack_dispatcher)
        4    0.000    0.000    0.000    0.000 well_known_types.py:172(GetCurrentTime)
        3    0.000    0.000    0.000    0.000 {method 'to' of 'torch._C.TensorBase' objects}
    62/50    0.000    0.000    0.000    0.000 {built-in method builtins.len}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:558(module_from_spec)
        1    0.000    0.000    0.000    0.000 _tensor_str.py:266(_tensor_str_with_formatter)
        4    0.000    0.000    0.000    0.000 sock_client.py:121(_sendall_with_error_handle)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:486(_init_module_attrs)
        4    0.000    0.000    0.000    0.000 well_known_types.py:242(FromDatetime)
        1    0.000    0.000    0.000    0.000 _tensor_str.py:221(_vector_str)
        2    0.000    0.000    0.000    0.000 DatasetMultiFlavourShard_Micro.py:47(__len__)
    59/58    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
       24    0.000    0.000    0.000    0.000 shape_base.py:207(_arrays_for_stack_dispatcher)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1077(path_stats)
        1    0.000    0.000    0.000    0.000 {method 'reciprocal' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 {method 'min' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 {method 'max' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:361(cache_from_source)
        2    0.000    0.000    0.000    0.000 {method 'tolist' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:385(cached)
        5    0.000    0.000    0.000    0.000 {built-in method builtins.sum}
        4    0.000    0.000    0.000    0.000 {method 'send' of '_socket.socket' objects}
       24    0.000    0.000    0.000    0.000 __init__.py:819(is_tensor)
        6    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:491(_get_cached)
        8    0.000    0.000    0.000    0.000 DatasetMultiFlavourShard_Micro.py:48(<genexpr>)
        1    0.000    0.000    0.000    0.000 {method 'float' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 {method 'ne' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 grad_mode.py:80(__enter__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:156(__enter__)
       24    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}
        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:121(_path_join)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}
        4    0.000    0.000    0.000    0.000 grad_mode.py:184(__init__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:166(_get_module_lock)
        4    0.000    0.000    0.000    0.000 enum_type_wrapper.py:92(__getattr__)
        4    0.000    0.000    0.000    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
       29    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
        1    0.000    0.000    0.000    0.000 _tensor_str.py:254(<listcomp>)
        2    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        4    0.000    0.000    0.000    0.000 calendar.py:655(timegm)
        6    0.000    0.000    0.000    0.000 DatasetMonoFlavourShard_Micro.py:52(__len__)
        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:127(_path_split)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1509(_get_spec)
        1    0.000    0.000    0.000    0.000 _ops.py:544(_len_torch_dispatch_stack_pre_dispatch)
        1    0.000    0.000    0.000    0.000 {built-in method torch._C._functorch.is_functorch_wrapped_tensor}
        3    0.000    0.000    0.000    0.000 _tensor_str.py:232(_val_formatter)
        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:123(<listcomp>)
        1    0.000    0.000    0.000    0.000 dataset.py:486(<listcomp>)
        1    0.000    0.000    0.000    0.000 {built-in method torch._is_functional_tensor}
       15    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
        2    0.000    0.000    0.000    0.000 grad_mode.py:75(__init__)
        2    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}
        1    0.000    0.000    0.000    0.000 {method 'abs' of 'torch._C.TensorBase' objects}
        6    0.000    0.000    0.000    0.000 {built-in method builtins.max}
       16    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        2    0.000    0.000    0.000    0.000 grad_mode.py:84(__exit__)
        3    0.000    0.000    0.000    0.000 _tensor_str.py:193(format)
        4    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 parameter.py:8(__instancecheck__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:560(_classify_pyc)
        4    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
        1    0.000    0.000    0.000    0.000 forward_ad.py:144(unpack_dual)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:696(spec_from_file_location)
        8    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        2    0.000    0.000    0.000    0.000 _contextlib.py:154(__new__)
        1    0.000    0.000    0.000    0.000 contextlib.py:261(helper)
        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}
        4    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}
        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:79(_unpack_uint32)
        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_default_device}
        1    0.000    0.000    0.000    0.000 _ops.py:441(count)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:160(__exit__)
        1    0.000    0.000    0.000    0.000 _tensor_str.py:354(_add_suffixes)
        1    0.000    0.000    0.000    0.000 contextlib.py:86(__init__)
        3    0.000    0.000    0.000    0.000 {method '__format__' of 'float' objects}
       24    0.000    0.000    0.000    0.000 multiarray.py:153(concatenate)
        1    0.000    0.000    0.000    0.000 import_hooks.py:233(find_spec)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:87(acquire)
        4    0.000    0.000    0.000    0.000 {built-in method utcnow}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:593(_validate_timestamp_pyc)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:112(release)
        3    0.000    0.000    0.000    0.000 dataset.py:405(__init__)
        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:129(<genexpr>)
        4    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:58(__init__)
        4    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
        1    0.000    0.000    0.000    0.000 {method '_is_zerotensor' of 'torch._C.TensorBase' objects}
        4    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
        1    0.000    0.000    0.000    0.000 typing.py:271(inner)
        1    0.000    0.000    0.000    0.000 {method 'is_neg' of 'torch._C.TensorBase' objects}
        7    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:231(_verbose_message)
        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1033(_handle_fromlist)
        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:874(__enter__)
        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:878(__exit__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:811(find_spec)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:185(cb)
        6    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}
        7    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}
        7    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 __init__.py:82(find_spec)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1346(_path_importer_cache)
        6    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}
        4    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C.TensorBase' objects}
        7    0.000    0.000    0.000    0.000 __init__.py:419(<genexpr>)
        7    0.000    0.000    0.000    0.000 {built-in method sys.intern}
       14    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:35(_new_module)
        6    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:523(_check_name_wrapper)
        1    0.000    0.000    0.000    0.000 {built-in method torch._C._len_torch_dispatch_stack}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}
        1    0.000    0.000    0.000    0.000 <string>:1(<lambda>)
        3    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
        1    0.000    0.000    0.000    0.000 schema_check_mode.py:61(SchemaCheckMode)
        4    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
        6    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:351(__init__)
        5    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}
        3    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}
        7    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}
        1    0.000    0.000    0.000    0.000 {built-in method math.isclose}
        7    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:398(parent)
        1    0.000    0.000    0.000    0.000 _tensor_str.py:259(<listcomp>)
        7    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}
        4    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
        5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        2    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)
        1    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}
        2    0.000    0.000    0.000    0.000 {built-in method torch.get_default_dtype}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1006(__init__)
        1    0.000    0.000    0.000    0.000 _tensor_str.py:256(<listcomp>)
        3    0.000    0.000    0.000    0.000 {built-in method from_bytes}
        1    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}
        5    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
        1    0.000    0.000    0.000    0.000 _ops.py:575(mode_stack_state_for_pre_dispatch)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:152(__init__)
        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}
        2    0.000    0.000    0.000    0.000 {method 'has_names' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 {built-in method math.floor}
        2    0.000    0.000    0.000    0.000 {built-in method sys._getframe}
        1    0.000    0.000    0.000    0.000 _ops.py:442(<listcomp>)
        2    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}
        4    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
        4    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
        1    0.000    0.000    0.000    0.000 _tensor_str.py:190(width)
        2    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
        3    0.000    0.000    0.000    0.000 {built-in method posix.fspath}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:736(find_spec)
        1    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 <string>:1(<module>)
        1    0.000    0.000    0.000    0.000 typing.py:1375(cast)
        1    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x7f133e5c8040}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:406(has_location)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:841(create_module)
        1    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}
        1    0.000    0.000    0.000    0.000 _python_dispatch.py:212(<listcomp>)
        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}
        1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1031(get_filename)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:68(_relax_case)
        1    0.000    0.000    0.000    0.000 _python_dispatch.py:229(<listcomp>)



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.setup
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 early_stopping.py:135(setup)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.setup
         13 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 progress_bar.py:171(setup)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 trainer.py:1241(is_global_zero)
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 single_device.py:81(is_global_zero)
        2    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.setup
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 callback.py:58(setup)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup
         1675 function calls in 0.002 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.002    0.002 model_checkpoint.py:267(setup)
        1    0.000    0.000    0.002    0.002 model_checkpoint.py:650(__warn_if_dir_not_empty)
        1    0.000    0.000    0.002    0.002 local.py:58(ls)
        1    0.001    0.001    0.001    0.001 local.py:63(<listcomp>)
       21    0.000    0.000    0.001    0.000 local.py:71(info)
        1    0.000    0.000    0.001    0.001 cloud_io.py:105(_is_dir)
        1    0.000    0.000    0.001    0.001 cloud_io.py:83(_is_object_storage)
        3    0.000    0.000    0.000    0.000 imports.py:45(module_available)
        3    0.000    0.000    0.000    0.000 imports.py:29(package_available)
        3    0.000    0.000    0.000    0.000 util.py:73(find_spec)
        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:901(_find_spec)
       20    0.000    0.000    0.000    0.000 {method 'stat' of 'posix.DirEntry' objects}
        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1415(find_spec)
        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1383(_get_spec)
       21    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1514(find_spec)
        1    0.000    0.000    0.000    0.000 {built-in method posix.scandir}
       23    0.000    0.000    0.000    0.000 {built-in method posix.stat}
        1    0.000    0.000    0.000    0.000 rank_zero.py:36(wrapped_fn)
       21    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:135(_path_stat)
        1    0.000    0.000    0.000    0.000 rank_zero.py:76(rank_zero_warn)
        1    0.000    0.000    0.000    0.000 rank_zero.py:72(_warn)
        1    0.000    0.000    0.000    0.000 {built-in method _warnings.warn}
      105    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:121(_path_join)
        1    0.000    0.000    0.000    0.000 warnings.py:96(_showwarnmsg)
        1    0.000    0.000    0.000    0.000 warnings.py:20(_showwarnmsg_impl)
       24    0.000    0.000    0.000    0.000 local.py:230(_strip_protocol)
        1    0.000    0.000    0.000    0.000 cloud_io.py:60(get_filesystem)
        1    0.000    0.000    0.000    0.000 core.py:362(url_to_fs)
        1    0.000    0.000    0.000    0.000 redirect.py:644(write)
      105    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:123(<listcomp>)
        1    0.000    0.000    0.000    0.000 wandb_run.py:2310(<lambda>)
        1    0.000    0.000    0.000    0.000 wandb_run.py:390(wrapper_fn)
        1    0.000    0.000    0.000    0.000 wandb_run.py:1429(_console_raw_callback)
        1    0.000    0.000    0.000    0.000 interface.py:749(publish_output_raw)
        1    0.000    0.000    0.000    0.000 warnings.py:117(_formatwarnmsg)
        1    0.000    0.000    0.000    0.000 warnings.py:40(_custom_format_warning)
        1    0.000    0.000    0.000    0.000 registry.py:289(filesystem)
        1    0.000    0.000    0.000    0.000 pathlib.py:1079(__new__)
        1    0.000    0.000    0.000    0.000 core.py:331(_un_chain)
        1    0.000    0.000    0.000    0.000 spec.py:65(__call__)
        1    0.000    0.000    0.000    0.000 interface_shared.py:76(_publish_output_raw)
        1    0.000    0.000    0.000    0.000 pathlib.py:702(_from_parts)
      134    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        1    0.000    0.000    0.000    0.000 interface_sock.py:45(_publish)
        1    0.000    0.000    0.000    0.000 local.py:133(isdir)
        1    0.000    0.000    0.000    0.000 pathlib.py:682(_parse_args)
        1    0.000    0.000    0.000    0.000 sock_client.py:219(send_record_publish)
       24    0.000    0.000    0.000    0.000 local.py:280(make_path_posix)
      234    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        1    0.000    0.000    0.000    0.000 sock_client.py:153(send_server_request)
        1    0.000    0.000    0.000    0.000 sock_client.py:145(_send_message)
        1    0.000    0.000    0.000    0.000 pathlib.py:64(parse_parts)
      124    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
      105    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:231(_verbose_message)
        1    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
        1    0.000    0.000    0.000    0.000 genericpath.py:39(isdir)
        1    0.000    0.000    0.000    0.000 utils.py:306(tokenize)
      106    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
       26    0.000    0.000    0.000    0.000 utils.py:327(stringify_path)
        3    0.000    0.000    0.000    0.000 __init__.py:82(find_spec)
        1    0.000    0.000    0.000    0.000 well_known_types.py:172(GetCurrentTime)
      100    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
       27    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:878(__exit__)
       27    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:874(__enter__)
        1    0.000    0.000    0.000    0.000 well_known_types.py:242(FromDatetime)
        1    0.000    0.000    0.000    0.000 sock_client.py:121(_sendall_with_error_handle)
        1    0.000    0.000    0.000    0.000 enums.py:81(__eq__)
        1    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_md5}
        1    0.000    0.000    0.000    0.000 warnings.py:57(_is_path_in_lightning)
       24    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1346(_path_importer_cache)
        3    0.000    0.000    0.000    0.000 __init__.py:57(find_spec)
       10    0.000    0.000    0.000    0.000 {built-in method sys.intern}
        2    0.000    0.000    0.000    0.000 registry.py:222(get_filesystem_class)
        1    0.000    0.000    0.000    0.000 {method 'send' of '_socket.socket' objects}
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:736(find_spec)
        1    0.000    0.000    0.000    0.000 pathlib.py:742(__str__)
        3    0.000    0.000    0.000    0.000 import_hooks.py:233(find_spec)
       20    0.000    0.000    0.000    0.000 {method 'is_file' of 'posix.DirEntry' objects}
        3    0.000    0.000    0.000    0.000 __init__.py:24(_module_matches_namespace)
        3    0.000    0.000    0.000    0.000 __init__.py:66(find_spec)
       21    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 re.py:250(compile)
       20    0.000    0.000    0.000    0.000 {method 'is_dir' of 'posix.DirEntry' objects}
       24    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
       27    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}
        1    0.000    0.000    0.000    0.000 pathlib.py:303(splitroot)
       27    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}
        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:92(__getattr__)
       20    0.000    0.000    0.000    0.000 {method 'is_symlink' of 'posix.DirEntry' objects}
        1    0.000    0.000    0.000    0.000 calendar.py:655(timegm)
        1    0.000    0.000    0.000    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
        1    0.000    0.000    0.000    0.000 core.py:541(split_protocol)
        1    0.000    0.000    0.000    0.000 config.py:99(apply_config)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 re.py:289(_compile)
        3    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
       21    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:68(_relax_case)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.locals}
        3    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}
        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:811(find_spec)
        1    0.000    0.000    0.000    0.000 warnings.py:403(__init__)
        1    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
        3    0.000    0.000    0.000    0.000 __init__.py:33(_module_matches_namespace)
        1    0.000    0.000    0.000    0.000 types.py:171(__get__)
        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:351(__init__)
        1    0.000    0.000    0.000    0.000 pathlib.py:725(_format_parsed_parts)
        4    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
        2    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 local.py:68(<listcomp>)
        1    0.000    0.000    0.000    0.000 pathlib.py:1193(absolute)
        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
       13    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        6    0.000    0.000    0.000    0.000 {method 'partition' of 'str' objects}
        3    0.000    0.000    0.000    0.000 six.py:194(find_spec)
        1    0.000    0.000    0.000    0.000 trainer.py:1241(is_global_zero)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
        1    0.000    0.000    0.000    0.000 {built-in method utcnow}
        6    0.000    0.000    0.000    0.000 {built-in method builtins.len}
        1    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 pathlib.py:1001(is_absolute)
        1    0.000    0.000    0.000    0.000 pathlib.py:1089(_init)
        1    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
        1    0.000    0.000    0.000    0.000 model_checkpoint.py:608(__resolve_ckpt_dir)
        3    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}
        3    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}
        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
        2    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
        3    0.000    0.000    0.000    0.000 _compat.py:52(find_spec)
        3    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 enum.py:792(value)
        1    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}
        1    0.000    0.000    0.000    0.000 core.py:395(<dictcomp>)
        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
        3    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
        3    0.000    0.000    0.000    0.000 __init__.py:89(<lambda>)
        2    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}
        2    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}
        1    0.000    0.000    0.000    0.000 {method '__exit__' of 'posix.ScandirIterator' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
        1    0.000    0.000    0.000    0.000 spec.py:214(_get_kwargs_from_urls)
        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 spec.py:67(<genexpr>)
        1    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}
        1    0.000    0.000    0.000    0.000 {built-in method posix.fspath}
        1    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
        1    0.000    0.000    0.000    0.000 single_device.py:81(is_global_zero)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
        1    0.000    0.000    0.000    0.000 single_device.py:90(broadcast)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.setup
         7 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 hooks.py:420(setup)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.configure_optimizers
         1231 function calls (1036 primitive calls) in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.001    0.001 FlavourClassificationTransformerEncoder.py:66(configure_optimizers)
        1    0.000    0.000    0.001    0.001 lr_scheduler.py:1260(__init__)
        1    0.000    0.000    0.001    0.001 lr_scheduler.py:57(_check_verbose_deprecated_warning)
        1    0.000    0.000    0.001    0.001 {built-in method _warnings.warn}
        1    0.000    0.000    0.001    0.001 warnings.py:96(_showwarnmsg)
        1    0.000    0.000    0.001    0.001 warnings.py:20(_showwarnmsg_impl)
        1    0.000    0.000    0.001    0.001 warnings.py:117(_formatwarnmsg)
        1    0.000    0.000    0.001    0.001 warnings.py:40(_custom_format_warning)
        1    0.000    0.000    0.001    0.001 warnings.py:15(formatwarning)
        1    0.000    0.000    0.001    0.001 warnings.py:35(_formatwarnmsg_impl)
        1    0.000    0.000    0.001    0.001 linecache.py:26(getline)
        1    0.000    0.000    0.001    0.001 vararg_kernel.py:127(_monkey_patched_getlines)
        1    0.000    0.000    0.001    0.001 linecache.py:36(getlines)
        1    0.000    0.000    0.001    0.001 linecache.py:80(updatecache)
        1    0.000    0.000    0.000    0.000 tokenize.py:388(open)
        1    0.000    0.000    0.000    0.000 adam.py:31(__init__)
        1    0.000    0.000    0.000    0.000 optimizer.py:339(__init__)
        1    0.000    0.000    0.000    0.000 {built-in method io.open}
       41    0.000    0.000    0.000    0.000 module.py:2233(parameters)
        1    0.000    0.000    0.000    0.000 {method 'readlines' of '_io._IOBase' objects}
       41    0.000    0.000    0.000    0.000 module.py:2258(named_parameters)
       41    0.000    0.000    0.000    0.000 module.py:2219(_named_members)
        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}
        1    0.000    0.000    0.000    0.000 _compile.py:21(inner)
   242/47    0.000    0.000    0.000    0.000 module.py:2395(named_modules)
        1    0.000    0.000    0.000    0.000 eval_frame.py:596(_fn)
        1    0.000    0.000    0.000    0.000 optimizer.py:987(add_param_group)
        1    0.000    0.000    0.000    0.000 redirect.py:644(write)
        1    0.000    0.000    0.000    0.000 wandb_run.py:2310(<lambda>)
        1    0.000    0.000    0.000    0.000 wandb_run.py:390(wrapper_fn)
        1    0.000    0.000    0.000    0.000 wandb_run.py:1429(_console_raw_callback)
        1    0.000    0.000    0.000    0.000 interface.py:749(publish_output_raw)
        1    0.000    0.000    0.000    0.000 tokenize.py:295(detect_encoding)
        1    0.000    0.000    0.000    0.000 {built-in method posix.stat}
        1    0.000    0.000    0.000    0.000 decorators.py:38(disable)
      160    0.000    0.000    0.000    0.000 _tensor.py:1055(__hash__)
        1    0.000    0.000    0.000    0.000 optimizer.py:514(_patch_step_function)
        1    0.000    0.000    0.000    0.000 interface_shared.py:76(_publish_output_raw)
       86    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
        1    0.000    0.000    0.000    0.000 interface_sock.py:45(_publish)
        2    0.000    0.000    0.000    0.000 tokenize.py:319(read_or_stop)
        1    0.000    0.000    0.000    0.000 pathlib.py:1079(__new__)
        1    0.000    0.000    0.000    0.000 optimizer.py:462(profile_hook_step)
        2    0.000    0.000    0.000    0.000 {method 'readline' of '_io.BufferedReader' objects}
       12    0.000    0.000    0.000    0.000 codecs.py:319(decode)
        1    0.000    0.000    0.000    0.000 sock_client.py:219(send_record_publish)
        1    0.000    0.000    0.000    0.000 pathlib.py:702(_from_parts)
        1    0.000    0.000    0.000    0.000 sock_client.py:153(send_server_request)
        1    0.000    0.000    0.000    0.000 sock_client.py:145(_send_message)
        1    0.000    0.000    0.000    0.000 pathlib.py:682(_parse_args)
       46    0.000    0.000    0.000    0.000 module.py:2286(<lambda>)
       12    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}
        1    0.000    0.000    0.000    0.000 eval_frame.py:562(__init__)
        1    0.000    0.000    0.000    0.000 pathlib.py:64(parse_parts)
        1    0.000    0.000    0.000    0.000 well_known_types.py:172(GetCurrentTime)
        1    0.000    0.000    0.000    0.000 eval_frame.py:565(__call__)
        2    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)
      161    0.000    0.000    0.000    0.000 {built-in method builtins.id}
        1    0.000    0.000    0.000    0.000 eval_frame.py:265(__init__)
        1    0.000    0.000    0.000    0.000 sock_client.py:121(_sendall_with_error_handle)
        1    0.000    0.000    0.000    0.000 well_known_types.py:242(FromDatetime)
        1    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
       52    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
       92    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
        2    0.000    0.000    0.000    0.000 tokenize.py:325(find_cookie)
        1    0.000    0.000    0.000    0.000 warnings.py:57(_is_path_in_lightning)
       18    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        1    0.000    0.000    0.000    0.000 {method 'send' of '_socket.socket' objects}
        1    0.000    0.000    0.000    0.000 typing_extensions.py:1710(args)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        3    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}
        1    0.000    0.000    0.000    0.000 pathlib.py:742(__str__)
        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}
       41    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        3    0.000    0.000    0.000    0.000 eval_frame.py:240(innermost_fn)
        1    0.000    0.000    0.000    0.000 calendar.py:655(timegm)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
        1    0.000    0.000    0.000    0.000 codecs.py:309(__init__)
        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:92(__getattr__)
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
       11    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}
       10    0.000    0.000    0.000    0.000 {built-in method sys.intern}
        1    0.000    0.000    0.000    0.000 pathlib.py:303(splitroot)
        2    0.000    0.000    0.000    0.000 functools.py:65(wraps)
        2    0.000    0.000    0.000    0.000 warnings.py:403(__init__)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 typing_extensions.py:1569(__init__)
        1    0.000    0.000    0.000    0.000 pathlib.py:725(_format_parsed_parts)
        1    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
       10    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}
        1    0.000    0.000    0.000    0.000 lr_scheduler.py:1368(_init_is_better)
        1    0.000    0.000    0.000    0.000 typing_extensions.py:1714(kwargs)
        2    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
        9    0.000    0.000    0.000    0.000 {built-in method builtins.len}
        1    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
       13    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
        1    0.000    0.000    0.000    0.000 {built-in method utcnow}
        1    0.000    0.000    0.000    0.000 pathlib.py:1193(absolute)
        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)
        2    0.000    0.000    0.000    0.000 {built-in method torch._C._dynamo.eval_frame.set_eval_frame}
        1    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}
        1    0.000    0.000    0.000    0.000 inspect.py:73(isclass)
        1    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
        2    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
        1    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}
        2    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}
        1    0.000    0.000    0.000    0.000 typing_extensions.py:1592(__init__)
        1    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}
        1    0.000    0.000    0.000    0.000 lr_scheduler.py:1304(<listcomp>)
        1    0.000    0.000    0.000    0.000 lr_scheduler.py:1310(_reset)
        1    0.000    0.000    0.000    0.000 pathlib.py:1089(_init)
        1    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}
        1    0.000    0.000    0.000    0.000 pathlib.py:1001(is_absolute)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.callable}
        1    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}
        1    0.000    0.000    0.000    0.000 eval_frame.py:232(nothing)
        1    0.000    0.000    0.000    0.000 typing.py:1375(cast)
        1    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
        1    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 {built-in method posix.fspath}
        1    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}
        1    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_fit_start
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 callback.py:64(on_fit_start)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)



Profile stats for: [Callback]TQDMProgressBar.on_fit_start
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 callback.py:64(on_fit_start)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_fit_start
         6711 function calls (5397 primitive calls) in 0.002 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.002    0.002 model_summary.py:59(on_fit_start)
       12    0.000    0.000    0.002    0.000 {built-in method builtins.sum}
      250    0.000    0.000    0.001    0.000 module.py:2233(parameters)
      250    0.000    0.000    0.001    0.000 module.py:2258(named_parameters)
      250    0.000    0.000    0.001    0.000 module.py:2219(_named_members)
        1    0.000    0.000    0.001    0.001 model_summary.py:312(_get_summary_data)
        3    0.000    0.000    0.001    0.000 model_summary.py:255(total_parameters)
      123    0.000    0.000    0.001    0.000 model_summary.py:257(<genexpr>)
        2    0.000    0.000    0.001    0.000 model_summary.py:247(param_nums)
        2    0.000    0.000    0.001    0.000 model_summary.py:249(<listcomp>)
        6    0.000    0.000    0.001    0.000 model_summary.py:135(num_parameters)
       86    0.000    0.000    0.001    0.000 model_summary.py:138(<genexpr>)
      240    0.000    0.000    0.001    0.000 model_summary.py:457(_is_lazy_weight_tensor)
 1358/284    0.000    0.000    0.000    0.000 module.py:2395(named_modules)
  493/253    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
        1    0.000    0.000    0.000    0.000 model_summary.py:265(total_layer_params)
        1    0.000    0.000    0.000    0.000 model_summary.py:259(trainable_parameters)
        1    0.000    0.000    0.000    0.000 model_summary.py:269(model_size)
       41    0.000    0.000    0.000    0.000 model_summary.py:261(<genexpr>)
      240    0.000    0.000    0.000    0.000 parameter.py:8(__instancecheck__)
        1    0.000    0.000    0.000    0.000 model_summary.py:80(summarize)
      517    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
      480    0.000    0.000    0.000    0.000 _tensor.py:1055(__hash__)
        1    0.000    0.000    0.000    0.000 __init__.py:1436(info)
        1    0.000    0.000    0.000    0.000 __init__.py:1565(_log)
        1    0.000    0.000    0.000    0.000 model_summary.py:73(_summary)
      274    0.000    0.000    0.000    0.000 module.py:2286(<lambda>)
        1    0.000    0.000    0.000    0.000 __init__.py:1591(handle)
        1    0.000    0.000    0.000    0.000 model_summary.py:470(summarize)
        1    0.000    0.000    0.000    0.000 __init__.py:1645(callHandlers)
        1    0.000    0.000    0.000    0.000 __init__.py:939(handle)
        1    0.000    0.000    0.000    0.000 model_summary.py:204(__init__)
        1    0.000    0.000    0.000    0.000 __init__.py:1071(emit)
        1    0.000    0.000    0.000    0.000 model_summary.py:273(summarize)
        1    0.000    0.000    0.000    0.000 redirect.py:644(write)
        1    0.000    0.000    0.000    0.000 model_summary.py:371(_format_summary_table)
        1    0.000    0.000    0.000    0.000 wandb_run.py:2310(<lambda>)
        1    0.000    0.000    0.000    0.000 wandb_run.py:390(wrapper_fn)
        1    0.000    0.000    0.000    0.000 wandb_run.py:1429(_console_raw_callback)
        1    0.000    0.000    0.000    0.000 interface.py:749(publish_output_raw)
      549    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
      480    0.000    0.000    0.000    0.000 {built-in method builtins.id}
        4    0.000    0.000    0.000    0.000 model_summary.py:274(<genexpr>)
        3    0.000    0.000    0.000    0.000 model_summary.py:71(__init__)
        3    0.000    0.000    0.000    0.000 model_summary.py:81(_register_hook)
      160    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C.TensorBase' objects}
      240    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x7f133e5c8040}
        1    0.000    0.000    0.000    0.000 interface_shared.py:76(_publish_output_raw)
        6    0.000    0.000    0.000    0.000 model_summary.py:419(get_human_readable_count)
        3    0.000    0.000    0.000    0.000 module.py:1463(register_forward_hook)
        1    0.000    0.000    0.000    0.000 interface_sock.py:45(_publish)
        1    0.000    0.000    0.000    0.000 sock_client.py:219(send_record_publish)
      242    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        1    0.000    0.000    0.000    0.000 sock_client.py:153(send_server_request)
        1    0.000    0.000    0.000    0.000 __init__.py:1550(makeRecord)
        1    0.000    0.000    0.000    0.000 sock_client.py:145(_send_message)
        1    0.000    0.000    0.000    0.000 __init__.py:282(__init__)
       80    0.000    0.000    0.000    0.000 {built-in method math.prod}
        3    0.000    0.000    0.000    0.000 hooks.py:24(__init__)
       10    0.000    0.000    0.000    0.000 {built-in method builtins.max}
        1    0.000    0.000    0.000    0.000 well_known_types.py:172(GetCurrentTime)
       24    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
        1    0.000    0.000    0.000    0.000 sock_client.py:121(_sendall_with_error_handle)
        6    0.000    0.000    0.000    0.000 model_summary.py:113(detach_hook)
        1    0.000    0.000    0.000    0.000 well_known_types.py:242(FromDatetime)
        1    0.000    0.000    0.000    0.000 model_summary.py:235(layer_types)
        1    0.000    0.000    0.000    0.000 __init__.py:916(format)
        1    0.000    0.000    0.000    0.000 __init__.py:1689(isEnabledFor)
       20    0.000    0.000    0.000    0.000 model_summary.py:385(<genexpr>)
        1    0.000    0.000    0.000    0.000 model_summary.py:218(named_modules)
        1    0.000    0.000    0.000    0.000 __init__.py:650(format)
        6    0.000    0.000    0.000    0.000 hooks.py:35(remove)
        1    0.000    0.000    0.000    0.000 __init__.py:1514(findCaller)
        1    0.000    0.000    0.000    0.000 model_summary.py:392(<listcomp>)
        1    0.000    0.000    0.000    0.000 __init__.py:1060(flush)
        1    0.000    0.000    0.000    0.000 {method 'send' of '_socket.socket' objects}
        3    0.000    0.000    0.000    0.000 model_summary.py:78(__del__)
        4    0.000    0.000    0.000    0.000 module.py:2348(named_children)
        1    0.000    0.000    0.000    0.000 model_summary.py:237(<listcomp>)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 model_summary.py:282(<listcomp>)
        1    0.000    0.000    0.000    0.000 posixpath.py:117(splitext)
        1    0.000    0.000    0.000    0.000 posixpath.py:140(basename)
        1    0.000    0.000    0.000    0.000 model_summary.py:251(training_modes)
       31    0.000    0.000    0.000    0.000 {built-in method builtins.len}
        1    0.000    0.000    0.000    0.000 calendar.py:655(timegm)
        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:92(__getattr__)
        1    0.000    0.000    0.000    0.000 __init__.py:628(usesTime)
        1    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)
        1    0.000    0.000    0.000    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
        5    0.000    0.000    0.000    0.000 {built-in method math.log10}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        9    0.000    0.000    0.000    0.000 hooks.py:33(<genexpr>)
        1    0.000    0.000    0.000    0.000 model_summary.py:253(<listcomp>)
        1    0.000    0.000    0.000    0.000 trainer.py:1195(precision)
        1    0.000    0.000    0.000    0.000 __init__.py:634(formatMessage)
        1    0.000    0.000    0.000    0.000 genericpath.py:121(_splitext)
       20    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        2    0.000    0.000    0.000    0.000 __init__.py:896(acquire)
        1    0.000    0.000    0.000    0.000 model_summary.py:231(layer_names)
        6    0.000    0.000    0.000    0.000 {built-in method builtins.min}
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        2    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 __init__.py:421(usesTime)
        1    0.000    0.000    0.000    0.000 __init__.py:218(_acquireLock)
        1    0.000    0.000    0.000    0.000 __init__.py:432(format)
        1    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}
        2    0.000    0.000    0.000    0.000 __init__.py:903(release)
        1    0.000    0.000    0.000    0.000 __init__.py:160(<lambda>)
        1    0.000    0.000    0.000    0.000 __init__.py:227(_releaseLock)
        1    0.000    0.000    0.000    0.000 trainer.py:1241(is_global_zero)
        3    0.000    0.000    0.000    0.000 model_summary.py:130(layer_type)
        1    0.000    0.000    0.000    0.000 model_summary.py:415(get_formatted_model_size)
        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
        1    0.000    0.000    0.000    0.000 posixpath.py:52(normcase)
        1    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
        3    0.000    0.000    0.000    0.000 model_summary.py:140(training)
        3    0.000    0.000    0.000    0.000 {method 'count' of 'str' objects}
        6    0.000    0.000    0.000    0.000 {built-in method math.ceil}
        1    0.000    0.000    0.000    0.000 __init__.py:429(_format)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
        4    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
        4    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        2    0.000    0.000    0.000    0.000 module.py:243(example_input_array)
        1    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
        1    0.000    0.000    0.000    0.000 threading.py:1358(current_thread)
        2    0.000    0.000    0.000    0.000 __init__.py:791(filter)
        1    0.000    0.000    0.000    0.000 {built-in method utcnow}
        1    0.000    0.000    0.000    0.000 __init__.py:1675(getEffectiveLevel)
        3    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}
        1    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 __init__.py:119(getLevelName)
        1    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
        5    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}
        5    0.000    0.000    0.000    0.000 {built-in method math.floor}
        1    0.000    0.000    0.000    0.000 threading.py:1093(name)
        3    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
        1    0.000    0.000    0.000    0.000 module.py:215(trainer)
        1    0.000    0.000    0.000    0.000 __init__.py:358(getMessage)
        3    0.000    0.000    0.000    0.000 {built-in method posix.fspath}
        1    0.000    0.000    0.000    0.000 model_summary.py:323(<listcomp>)
        1    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 process.py:189(name)
        2    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
        1    0.000    0.000    0.000    0.000 {built-in method time.time}
        1    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
        1    0.000    0.000    0.000    0.000 {built-in method sys._getframe}
        1    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:93(precision_plugin)
        1    0.000    0.000    0.000    0.000 process.py:37(current_process)
        1    0.000    0.000    0.000    0.000 __init__.py:1276(disable)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
        1    0.000    0.000    0.000    0.000 single_device.py:81(is_global_zero)
        1    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 callback.py:64(on_fit_start)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_fit_start
         7 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 hooks.py:30(on_fit_start)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_sanity_check_start
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 callback.py:70(on_sanity_check_start)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_sanity_check_start
         686 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.001    0.001 tqdm_progress.py:249(on_sanity_check_start)
        1    0.000    0.000    0.001    0.001 tqdm_progress.py:185(init_sanity_tqdm)
        2    0.000    0.000    0.001    0.000 std.py:663(__new__)
        2    0.000    0.000    0.001    0.000 std.py:760(get_lock)
        1    0.000    0.000    0.001    0.001 std.py:90(__init__)
        1    0.000    0.000    0.001    0.001 std.py:116(create_mp_lock)
        1    0.000    0.000    0.001    0.001 context.py:70(RLock)
        2    0.000    0.000    0.000    0.000 tqdm_progress.py:40(__init__)
        2    0.000    0.000    0.000    0.000 std.py:952(__init__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1002(_find_and_load)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:967(_find_and_load_unlocked)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:659(_load_unlocked)
        1    0.000    0.000    0.000    0.000 std.py:1325(refresh)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:844(exec_module)
        1    0.000    0.000    0.000    0.000 std.py:1464(display)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:916(get_code)
        1    0.000    0.000    0.000    0.000 _monitor.py:30(__init__)
        1    0.000    0.000    0.000    0.000 synchronize.py:186(__init__)
        1    0.000    0.000    0.000    0.000 synchronize.py:50(__init__)
        1    0.000    0.000    0.000    0.000 threading.py:880(start)
        1    0.000    0.000    0.000    0.000 std.py:457(print_status)
        5    0.000    0.000    0.000    0.000 std.py:102(acquire)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:220(_call_with_frames_removed)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}
        1    0.000    0.000    0.000    0.000 synchronize.py:10(<module>)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:645(_compile_bytecode)
        1    0.000    0.000    0.000    0.000 {built-in method marshal.loads}
        8    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}
        1    0.000    0.000    0.000    0.000 threading.py:563(wait)
        1    0.000    0.000    0.000    0.000 std.py:1150(__str__)
        1    0.000    0.000    0.000    0.000 threading.py:280(wait)
        1    0.000    0.000    0.000    0.000 std.py:451(fp_write)
        2    0.000    0.000    0.000    0.000 utils.py:194(inner)
        1    0.000    0.000    0.000    0.000 synchronize.py:114(_make_name)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 tempfile.py:149(__next__)
        4    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:901(_find_spec)
        1    0.000    0.000    0.000    0.000 redirect.py:644(write)
        1    0.000    0.000    0.000    0.000 wandb_run.py:2304(<lambda>)
        1    0.000    0.000    0.000    0.000 wandb_run.py:390(wrapper_fn)
        1    0.000    0.000    0.000    0.000 wandb_run.py:1429(_console_raw_callback)
        1    0.000    0.000    0.000    0.000 std.py:464(format_meter)
        2    0.000    0.000    0.000    0.000 utils.py:333(_screen_shape_linux)
        1    0.000    0.000    0.000    0.000 interface.py:749(publish_output_raw)
        1    0.000    0.000    0.000    0.000 utils.py:378(disp_len)
        1    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1415(find_spec)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1383(_get_spec)
        1    0.000    0.000    0.000    0.000 utils.py:374(_text_width)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1036(get_data)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1514(find_spec)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.sum}
        1    0.000    0.000    0.000    0.000 tempfile.py:138(rng)
       51    0.000    0.000    0.000    0.000 utils.py:375(<genexpr>)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:558(module_from_spec)
        1    0.000    0.000    0.000    0.000 interface_shared.py:76(_publish_output_raw)
        1    0.000    0.000    0.000    0.000 threading.py:802(__init__)
        1    0.000    0.000    0.000    0.000 interface_sock.py:45(_publish)
        1    0.000    0.000    0.000    0.000 random.py:117(__init__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:486(_init_module_attrs)
        1    0.000    0.000    0.000    0.000 std.py:438(status_printer)
        3    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
        2    0.000    0.000    0.000    0.000 utils.py:213(__init__)
        1    0.000    0.000    0.000    0.000 sock_client.py:219(send_record_publish)
        1    0.000    0.000    0.000    0.000 random.py:126(seed)
        1    0.000    0.000    0.000    0.000 std.py:1446(format_dict)
        2    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}
        1    0.000    0.000    0.000    0.000 std.py:679(_get_free_pos)
        1    0.000    0.000    0.000    0.000 sock_client.py:153(send_server_request)
        1    0.000    0.000    0.000    0.000 tempfile.py:152(<listcomp>)
        1    0.000    0.000    0.000    0.000 sock_client.py:145(_send_message)
       50    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}
        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:361(cache_from_source)
        8    0.000    0.000    0.000    0.000 random.py:343(choice)
        1    0.000    0.000    0.000    0.000 {method 'read' of '_io.BufferedReader' objects}
        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7f134a551a60}
        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:385(cached)
        1    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)
        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:135(_path_stat)
        1    0.000    0.000    0.000    0.000 std.py:682(<setcomp>)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:491(_get_cached)
        1    0.000    0.000    0.000    0.000 well_known_types.py:172(GetCurrentTime)
        1    0.000    0.000    0.000    0.000 {built-in method io.open_code}
        2    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
        3    0.000    0.000    0.000    0.000 {built-in method posix.stat}
        2    0.000    0.000    0.000    0.000 threading.py:528(__init__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:156(__enter__)
        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:121(_path_join)
        3    0.000    0.000    0.000    0.000 _weakrefset.py:63(__iter__)
        3    0.000    0.000    0.000    0.000 _weakrefset.py:86(add)
        8    0.000    0.000    0.000    0.000 random.py:237(_randbelow_with_getrandbits)
        4    0.000    0.000    0.000    0.000 std.py:110(__enter__)
        2    0.000    0.000    0.000    0.000 utils.py:347(<listcomp>)
        1    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)
        1    0.000    0.000    0.000    0.000 std.py:153(__init__)
        1    0.000    0.000    0.000    0.000 sock_client.py:121(_sendall_with_error_handle)
        1    0.000    0.000    0.000    0.000 well_known_types.py:242(FromDatetime)
        2    0.000    0.000    0.000    0.000 threading.py:228(__init__)
        5    0.000    0.000    0.000    0.000 std.py:106(release)
        4    0.000    0.000    0.000    0.000 std.py:113(__exit__)
        4    0.000    0.000    0.000    0.000 utils.py:187(disable_on_exception)
        2    0.000    0.000    0.000    0.000 os.py:674(__getitem__)
        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:398(parent)
       23    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1509(_get_spec)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:166(_get_module_lock)
        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:127(_path_split)
        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:123(<listcomp>)
        1    0.000    0.000    0.000    0.000 std.py:186(__format__)
        1    0.000    0.000    0.000    0.000 _weakrefset.py:111(remove)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:154(_path_isfile)
        1    0.000    0.000    0.000    0.000 _weakrefset.py:27(__exit__)
       17    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
        2    0.000    0.000    0.000    0.000 functools.py:392(__get__)
        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}
        2    0.000    0.000    0.000    0.000 utils.py:156(__init__)
        1    0.000    0.000    0.000    0.000 {method 'send' of '_socket.socket' objects}
        2    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
        2    0.000    0.000    0.000    0.000 utils.py:266(_supports_unicode)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:145(_path_is_mode_type)
        4    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:560(_classify_pyc)
        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1033(_handle_fromlist)
        1    0.000    0.000    0.000    0.000 synchronize.py:360(Barrier)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1077(path_stats)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.max}
        1    0.000    0.000    0.000    0.000 std.py:400(format_interval)
        6    0.000    0.000    0.000    0.000 utils.py:152(wrapper_setattr)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:87(acquire)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:696(spec_from_file_location)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:160(__exit__)
        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:79(_unpack_uint32)
        5    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
        2    0.000    0.000    0.000    0.000 os.py:754(encode)
        1    0.000    0.000    0.000    0.000 {built-in method fromtimestamp}
        1    0.000    0.000    0.000    0.000 calendar.py:655(timegm)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:593(_validate_timestamp_pyc)
        1    0.000    0.000    0.000    0.000 context.py:233(get_context)
       10    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}
        1    0.000    0.000    0.000    0.000 synchronize.py:46(SemLock)
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:92(__getattr__)
        1    0.000    0.000    0.000    0.000 _weakrefset.py:53(_commit_removals)
        1    0.000    0.000    0.000    0.000 utils.py:273(_is_ascii)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:112(release)
        1    0.000    0.000    0.000    0.000 synchronize.py:142(BoundedSemaphore)
        4    0.000    0.000    0.000    0.000 utils.py:222(__eq__)
       15    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}
        7    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:231(_verbose_message)
        3    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)
        1    0.000    0.000    0.000    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
        1    0.000    0.000    0.000    0.000 utils.py:125(__eq__)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:58(__init__)
        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:129(<genexpr>)
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:173(is_disabled)
        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:878(__exit__)
        3    0.000    0.000    0.000    0.000 std.py:226(__init__)
        3    0.000    0.000    0.000    0.000 std.py:1157(__hash__)
       16    0.000    0.000    0.000    0.000 {built-in method builtins.len}
        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:874(__enter__)
       12    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
        9    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
        1    0.000    0.000    0.000    0.000 threading.py:268(_acquire_restore)
        1    0.000    0.000    0.000    0.000 import_hooks.py:233(find_spec)
        1    0.000    0.000    0.000    0.000 threading.py:1162(daemon)
        1    0.000    0.000    0.000    0.000 threading.py:256(__enter__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:185(cb)
        1    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
        1    0.000    0.000    0.000    0.000 threading.py:271(_is_owned)
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:169(is_enabled)
        1    0.000    0.000    0.000    0.000 weakref.py:348(__new__)
        1    0.000    0.000    0.000    0.000 _weakrefset.py:17(__init__)
        6    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
       14    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:811(find_spec)
        1    0.000    0.000    0.000    0.000 threading.py:1229(_make_invoke_excepthook)
        2    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
        2    0.000    0.000    0.000    0.000 std.py:1153(_comparable)
        1    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}
        1    0.000    0.000    0.000    0.000 synchronize.py:210(Condition)
        4    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}
        1    0.000    0.000    0.000    0.000 weakref.py:353(__init__)
        1    0.000    0.000    0.000    0.000 threading.py:265(_release_save)
        1    0.000    0.000    0.000    0.000 __init__.py:82(find_spec)
        3    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:523(_check_name_wrapper)
        1    0.000    0.000    0.000    0.000 utils.py:108(__init__)
        1    0.000    0.000    0.000    0.000 threading.py:757(_newname)
        1    0.000    0.000    0.000    0.000 utils.py:252(_is_utf)
        1    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)
        1    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:35(_new_module)
        1    0.000    0.000    0.000    0.000 {built-in method atexit.register}
        5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        3    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
        1    0.000    0.000    0.000    0.000 _weakrefset.py:21(__enter__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1006(__init__)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1346(_path_importer_cache)
        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)
        1    0.000    0.000    0.000    0.000 threading.py:1358(current_thread)
        7    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}
        4    0.000    0.000    0.000    0.000 {built-in method builtins.id}
        6    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
        1    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
        8    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
        5    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}
        7    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}
        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}
        1    0.000    0.000    0.000    0.000 synchronize.py:321(Event)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:351(__init__)
        5    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:137(val_progress_bar)
        1    0.000    0.000    0.000    0.000 threading.py:1147(daemon)
        1    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
        2    0.000    0.000    0.000    0.000 {method 'setter' of 'property' objects}
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:165(process_position)
        3    0.000    0.000    0.000    0.000 {built-in method from_bytes}
        1    0.000    0.000    0.000    0.000 {built-in method utcnow}
        1    0.000    0.000    0.000    0.000 std.py:231(__call__)
        1    0.000    0.000    0.000    0.000 utils.py:282(_screen_shape_wrapper)
        1    0.000    0.000    0.000    0.000 threading.py:259(__exit__)
        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}
        1    0.000    0.000    0.000    0.000 std.py:167(colour)
        1    0.000    0.000    0.000    0.000 std.py:98(<listcomp>)
        1    0.000    0.000    0.000    0.000 utils.py:112(__format__)
        1    0.000    0.000    0.000    0.000 synchronize.py:123(Semaphore)
        1    0.000    0.000    0.000    0.000 util.py:48(debug)
        1    0.000    0.000    0.000    0.000 std.py:163(colour)
        2    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:127(train_progress_bar)
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:161(refresh_rate)
        4    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
        1    0.000    0.000    0.000    0.000 progress_bar.py:60(sanity_check_description)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
        3    0.000    0.000    0.000    0.000 threading.py:536(is_set)
        3    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
        1    0.000    0.000    0.000    0.000 synchronize.py:159(Lock)
        1    0.000    0.000    0.000    0.000 context.py:197(get_start_method)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}
        1    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:152(__init__)
        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}
        3    0.000    0.000    0.000    0.000 {built-in method posix.fspath}
        1    0.000    0.000    0.000    0.000 synchronize.py:184(RLock)
        1    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}
        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
        1    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:406(has_location)
        1    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:841(create_module)
        1    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
        1    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
        1    0.000    0.000    0.000    0.000 {built-in method time.time}
        1    0.000    0.000    0.000    0.000 process.py:37(current_process)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1031(get_filename)
        1    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:736(find_spec)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:68(_relax_case)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)



Profile stats for: [Callback]ModelSummary.on_sanity_check_start
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 callback.py:70(on_sanity_check_start)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 callback.py:70(on_sanity_check_start)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningDataModule]PMTfiedDataModule.val_dataloader
         605 function calls (516 primitive calls) in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 PMTfiedDataModule.py:77(val_dataloader)
      2/1    0.000    0.000    0.000    0.000 data.py:287(wrapper)
        1    0.000    0.000    0.000    0.000 dataloader.py:227(__init__)
        2    0.000    0.000    0.000    0.000 inspect.py:3111(signature)
        2    0.000    0.000    0.000    0.000 inspect.py:2859(from_callable)
        2    0.000    0.000    0.000    0.000 inspect.py:2246(_signature_from_callable)
       37    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)
        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}
        2    0.000    0.000    0.000    0.000 inspect.py:2152(_signature_from_function)
     45/3    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)
     45/3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}
    23/22    0.000    0.000    0.000    0.000 data.py:334(wrapper)
       21    0.000    0.000    0.000    0.000 inspect.py:2498(__init__)
       21    0.000    0.000    0.000    0.000 data.py:295(<genexpr>)
    20/19    0.000    0.000    0.000    0.000 dataloader.py:418(__setattr__)
        2    0.000    0.000    0.000    0.000 inspect.py:2781(__init__)
       21    0.000    0.000    0.000    0.000 enum.py:358(__call__)
        1    0.000    0.000    0.000    0.000 dataloader.py:487(check_worker_number_rationality)
        1    0.000    0.000    0.000    0.000 sampler.py:133(__init__)
        1    0.000    0.000    0.000    0.000 sampler.py:262(__init__)
       23    0.000    0.000    0.000    0.000 inspect.py:2830(<genexpr>)
        2    0.000    0.000    0.000    0.000 inspect.py:494(unwrap)
       50    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        1    0.000    0.000    0.000    0.000 {built-in method posix.sched_getaffinity}
        2    0.000    0.000    0.000    0.000 data.py:303(<dictcomp>)
        2    0.000    0.000    0.000    0.000 sampler.py:146(num_samples)
       61    0.000    0.000    0.000    0.000 inspect.py:2548(name)
       37    0.000    0.000    0.000    0.000 _collections_abc.py:262(__subclasshook__)
      8/6    0.000    0.000    0.000    0.000 {built-in method builtins.len}
       27    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
       21    0.000    0.000    0.000    0.000 enum.py:670(__new__)
       21    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {built-in method torch.set_vital}
        1    0.000    0.000    0.000    0.000 dataloader.py:394(multiprocessing_context)
        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        2    0.000    0.000    0.000    0.000 inspect.py:514(_is_wrapper)
       21    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
       19    0.000    0.000    0.000    0.000 inspect.py:2560(kind)
       19    0.000    0.000    0.000    0.000 inspect.py:2552(default)
        4    0.000    0.000    0.000    0.000 inspect.py:159(isfunction)
        2    0.000    0.000    0.000    0.000 dataset.py:422(__len__)
        2    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}
        1    0.000    0.000    0.000    0.000 dataloader.py:442(_auto_collation)
        2    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}
        2    0.000    0.000    0.000    0.000 {built-in method builtins.id}
        2    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
        1    0.000    0.000    0.000    0.000 {method 'index' of 'tuple' objects}
        2    0.000    0.000    0.000    0.000 inspect.py:2865(parameters)
        2    0.000    0.000    0.000    0.000 {built-in method builtins.callable}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_validation_model_eval
         158991 function calls (140700 primitive calls) in 0.083 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.003    0.000    0.082    0.000 hooks.py:162(on_validation_model_eval)
      201    0.000    0.000    0.076    0.000 module.py:2459(eval)
 9246/201    0.015    0.000    0.075    0.000 module.py:2437(train)
     9246    0.032    0.000    0.044    0.000 module.py:1731(__setattr__)
    18291    0.006    0.000    0.015    0.000 module.py:2339(children)
36984/27738    0.005    0.000    0.011    0.000 {built-in method builtins.isinstance}
    18291    0.007    0.000    0.009    0.000 module.py:2348(named_children)
     9246    0.005    0.000    0.007    0.000 parameter.py:8(__instancecheck__)
    27939    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}
      201    0.001    0.000    0.002    0.000 trainer.py:1203(model)
      201    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
     9246    0.001    0.000    0.001    0.000 {function _ParameterMeta.__instancecheck__ at 0x7f133e5c8040}
      201    0.000    0.000    0.001    0.000 {built-in method builtins.next}
     9045    0.001    0.000    0.001    0.000 {method 'add' of 'set' objects}
      201    0.001    0.000    0.001    0.000 profiler.py:55(profile)
     9246    0.001    0.000    0.001    0.000 {method 'items' of 'collections.OrderedDict' objects}
      201    0.001    0.000    0.001    0.000 strategy.py:351(model)
      201    0.000    0.000    0.000    0.000 module.py:215(trainer)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_validation_start
         2010 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 callback.py:211(on_validation_start)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_validation_start
         72019 function calls in 0.344 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.004    0.000    0.343    0.002 tqdm_progress.py:287(on_validation_start)
      200    0.013    0.000    0.332    0.002 tqdm_progress.py:223(init_validation_tqdm)
      200    0.003    0.000    0.304    0.002 tqdm_progress.py:40(__init__)
      200    0.015    0.000    0.300    0.001 std.py:952(__init__)
      200    0.001    0.000    0.248    0.001 std.py:1325(refresh)
      200    0.001    0.000    0.246    0.001 std.py:1464(display)
     1200    0.002    0.000    0.204    0.000 utils.py:194(inner)
      400    0.002    0.000    0.177    0.000 std.py:1441(moveto)
      600    0.006    0.000    0.165    0.000 redirect.py:644(write)
      600    0.004    0.000    0.159    0.000 wandb_run.py:2304(<lambda>)
      600    0.003    0.000    0.155    0.000 wandb_run.py:390(wrapper_fn)
      600    0.006    0.000    0.152    0.000 wandb_run.py:1429(_console_raw_callback)
      600    0.016    0.000    0.145    0.000 interface.py:749(publish_output_raw)
      600    0.006    0.000    0.110    0.000 interface_shared.py:76(_publish_output_raw)
      600    0.004    0.000    0.104    0.000 interface_sock.py:45(_publish)
      600    0.005    0.000    0.100    0.000 sock_client.py:219(send_record_publish)
      600    0.001    0.000    0.094    0.000 sock_client.py:153(send_server_request)
      600    0.005    0.000    0.094    0.000 sock_client.py:145(_send_message)
      600    0.002    0.000    0.086    0.000 sock_client.py:121(_sendall_with_error_handle)
      600    0.084    0.000    0.084    0.000 {method 'send' of '_socket.socket' objects}
     1000    0.038    0.000    0.038    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
      200    0.001    0.000    0.038    0.000 std.py:457(print_status)
      200    0.005    0.000    0.030    0.000 std.py:1150(__str__)
      200    0.000    0.000    0.029    0.000 std.py:451(fp_write)
      400    0.010    0.000    0.026    0.000 utils.py:333(_screen_shape_linux)
      200    0.013    0.000    0.019    0.000 std.py:464(format_meter)
      200    0.004    0.000    0.013    0.000 std.py:663(__new__)
      600    0.003    0.000    0.013    0.000 well_known_types.py:172(GetCurrentTime)
      400    0.009    0.000    0.010    0.000 {built-in method fcntl.ioctl}
      600    0.004    0.000    0.010    0.000 well_known_types.py:242(FromDatetime)
      200    0.001    0.000    0.007    0.000 utils.py:378(disp_len)
      400    0.003    0.000    0.006    0.000 utils.py:347(<listcomp>)
      200    0.000    0.000    0.006    0.000 utils.py:374(_text_width)
      200    0.002    0.000    0.006    0.000 std.py:1446(format_dict)
      200    0.001    0.000    0.006    0.000 utils.py:213(__init__)
      200    0.001    0.000    0.006    0.000 {built-in method builtins.sum}
      600    0.006    0.000    0.006    0.000 enum_type_wrapper.py:92(__getattr__)
     9200    0.004    0.000    0.005    0.000 utils.py:375(<genexpr>)
      400    0.001    0.000    0.005    0.000 std.py:110(__enter__)
      200    0.004    0.000    0.005    0.000 tqdm_progress.py:137(val_progress_bar)
      600    0.002    0.000    0.003    0.000 std.py:102(acquire)
      400    0.003    0.000    0.003    0.000 os.py:674(__getitem__)
      600    0.003    0.000    0.003    0.000 calendar.py:655(timegm)
      200    0.002    0.000    0.003    0.000 std.py:438(status_printer)
      400    0.002    0.000    0.003    0.000 utils.py:266(_supports_unicode)
      200    0.002    0.000    0.003    0.000 utils.py:156(__init__)
      200    0.001    0.000    0.002    0.000 _weakrefset.py:86(add)
      201    0.001    0.000    0.002    0.000 trainer.py:1429(sanity_checking)
      400    0.001    0.000    0.002    0.000 {method 'format' of 'str' objects}
      600    0.002    0.000    0.002    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
      200    0.002    0.000    0.002    0.000 std.py:153(__init__)
      400    0.001    0.000    0.002    0.000 std.py:113(__exit__)
     3800    0.002    0.000    0.002    0.000 {built-in method builtins.getattr}
      200    0.001    0.000    0.002    0.000 functools.py:392(__get__)
      200    0.001    0.000    0.002    0.000 {method 'add' of 'set' objects}
      201    0.001    0.000    0.001    0.000 enums.py:81(__eq__)
      600    0.001    0.000    0.001    0.000 std.py:106(release)
      600    0.001    0.000    0.001    0.000 interface_sock.py:41(_assign)
      200    0.001    0.000    0.001    0.000 {built-in method fromtimestamp}
      600    0.001    0.000    0.001    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
      200    0.000    0.000    0.001    0.000 utils.py:273(_is_ascii)
     9000    0.001    0.000    0.001    0.000 {built-in method unicodedata.east_asian_width}
     1000    0.001    0.000    0.001    0.000 {built-in method builtins.hasattr}
      600    0.001    0.000    0.001    0.000 std.py:226(__init__)
      400    0.001    0.000    0.001    0.000 utils.py:187(disable_on_exception)
      200    0.001    0.000    0.001    0.000 tqdm_progress.py:173(is_disabled)
      200    0.001    0.000    0.001    0.000 std.py:400(format_interval)
      200    0.001    0.000    0.001    0.000 std.py:1147(__del__)
      402    0.000    0.000    0.001    0.000 types.py:171(__get__)
      600    0.001    0.000    0.001    0.000 utils.py:152(wrapper_setattr)
      800    0.000    0.000    0.001    0.000 utils.py:222(__eq__)
     1200    0.001    0.000    0.001    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
      400    0.001    0.000    0.001    0.000 os.py:754(encode)
      600    0.001    0.000    0.001    0.000 {built-in method utcnow}
      600    0.001    0.000    0.001    0.000 {method 'acquire' of '_thread.RLock' objects}
      200    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}
      200    0.001    0.000    0.001    0.000 progress_bar.py:54(trainer)
      200    0.001    0.000    0.001    0.000 std.py:186(__format__)
      402    0.001    0.000    0.001    0.000 enum.py:792(value)
      600    0.000    0.000    0.001    0.000 utils.py:139(__getattr__)
      600    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 std.py:760(get_lock)
      600    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 _monitor.py:94(report)
      600    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
      600    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}
      200    0.000    0.000    0.000    0.000 tqdm_progress.py:169(is_enabled)
      600    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
     1400    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      200    0.000    0.000    0.000    0.000 std.py:1157(__hash__)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      400    0.000    0.000    0.000    0.000 utils.py:370(_term_move_up)
      200    0.000    0.000    0.000    0.000 utils.py:252(_is_utf)
      801    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
      400    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}
      200    0.000    0.000    0.000    0.000 std.py:231(__call__)
      600    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      600    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
      600    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
      600    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
      200    0.000    0.000    0.000    0.000 tqdm_progress.py:161(refresh_rate)
      200    0.000    0.000    0.000    0.000 utils.py:282(_screen_shape_wrapper)
      600    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
      600    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.max}
      600    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
      200    0.000    0.000    0.000    0.000 utils.py:108(__init__)
      600    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
      200    0.000    0.000    0.000    0.000 tqdm_progress.py:165(process_position)
      200    0.000    0.000    0.000    0.000 threading.py:536(is_set)
      200    0.000    0.000    0.000    0.000 utils.py:112(__format__)
      200    0.000    0.000    0.000    0.000 std.py:167(colour)
      200    0.000    0.000    0.000    0.000 {built-in method time.time}
      200    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
      200    0.000    0.000    0.000    0.000 std.py:1265(close)
      402    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.id}
      200    0.000    0.000    0.000    0.000 progress_bar.py:68(validation_description)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 std.py:163(colour)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)



Profile stats for: [Callback]ModelSummary.on_validation_start
         2010 function calls in 0.002 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      201    0.001    0.000    0.001    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 callback.py:211(on_validation_start)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start
         2010 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 callback.py:211(on_validation_start)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_validation_start
         1407 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 hooks.py:50(on_validation_start)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Strategy]SingleDeviceStrategy.on_validation_start
         1407 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 strategy.py:549(on_validation_start)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_validation_epoch_start
         2010 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 callback.py:124(on_validation_epoch_start)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_validation_epoch_start
         2010 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.001    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 callback.py:124(on_validation_epoch_start)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_validation_epoch_start
         2010 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 callback.py:124(on_validation_epoch_start)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start
         2010 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 callback.py:124(on_validation_epoch_start)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_validation_epoch_start
         1407 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 hooks.py:241(on_validation_epoch_start)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [_EvaluationLoop].val_next
         18707 function calls (17099 primitive calls) in 0.096 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
  804/201    0.001    0.000    0.096    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.095    0.000 combined_loader.py:339(__next__)
      201    0.001    0.000    0.094    0.000 combined_loader.py:128(__next__)
      201    0.008    0.000    0.093    0.000 dataloader.py:625(__next__)
      201    0.007    0.000    0.033    0.000 profiler.py:693(__exit__)
      201    0.002    0.000    0.026    0.000 _ops.py:887(__call__)
      201    0.005    0.000    0.025    0.000 profiler.py:687(__enter__)
      201    0.001    0.000    0.020    0.000 _ops.py:1047(__call__)
      201    0.001    0.000    0.019    0.000 dataloader.py:1297(_next_data)
      201    0.003    0.000    0.019    0.000 _ops.py:943(_must_dispatch_in_python)
      201    0.019    0.000    0.019    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
      201    0.002    0.000    0.017    0.000 dataloader.py:1264(_get_data)
      201    0.002    0.000    0.016    0.000 _pytree.py:1181(tree_any)
      201    0.000    0.000    0.014    0.000 {built-in method builtins.any}
      201    0.000    0.000    0.014    0.000 dataloader.py:1118(_try_get_data)
      201    0.002    0.000    0.014    0.000 queue.py:154(get)
      406    0.011    0.000    0.011    0.000 {method 'acquire' of '_thread.lock' objects}
 1407/402    0.006    0.000    0.011    0.000 _pytree.py:874(tree_iter)
        1    0.000    0.000    0.011    0.011 threading.py:280(wait)
      201    0.006    0.000    0.008    0.000 profiler.py:676(__init__)
      201    0.005    0.000    0.005    0.000 {built-in method torch._ops.profiler.}
      804    0.001    0.000    0.004    0.000 _pytree.py:656(_is_leaf)
      201    0.003    0.000    0.003    0.000 _ops.py:945(<lambda>)
     1407    0.001    0.000    0.003    0.000 _pytree.py:649(_get_node_type)
      201    0.002    0.000    0.002    0.000 typing.py:271(inner)
     1407    0.002    0.000    0.002    0.000 _pytree.py:638(_is_namedtuple_instance)
      201    0.000    0.000    0.001    0.000 dataloader.py:1366(_process_data)
      201    0.000    0.000    0.001    0.000 threading.py:1133(is_alive)
      201    0.000    0.000    0.001    0.000 dataloader.py:1346(_try_put_index)
      201    0.001    0.000    0.001    0.000 _pytree.py:423(_dict_flatten)
      201    0.000    0.000    0.001    0.000 evaluation_loop.py:346(_on_after_fetch)
      201    0.000    0.000    0.000    0.000 threading.py:1066(_wait_for_tstate_lock)
      201    0.000    0.000    0.000    0.000 threading.py:351(notify)
     2212    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 threading.py:256(__enter__)
      201    0.000    0.000    0.000    0.000 queue.py:217(_get)
      202    0.000    0.000    0.000    0.000 queue.py:209(_qsize)
      201    0.000    0.000    0.000    0.000 dataloader.py:619(_next_index)
      402    0.000    0.000    0.000    0.000 _pytree.py:395(_tuple_flatten)
      202    0.000    0.000    0.000    0.000 threading.py:271(_is_owned)
      603    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
      201    0.000    0.000    0.000    0.000 threading.py:259(__exit__)
      201    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)
      201    0.000    0.000    0.000    0.000 states.py:67(dataloader_prefix)
      201    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}
      201    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 threading.py:536(is_set)
      201    0.000    0.000    0.000    0.000 __init__.py:129(annotate)
      201    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}
      202    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
      201    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      201    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 threading.py:268(_acquire_restore)
        1    0.000    0.000    0.000    0.000 threading.py:265(_release_save)
        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}
        1    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_before_batch_transfer
         2807 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      401    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      401    0.000    0.000    0.001    0.000 {built-in method builtins.next}
      401    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      401    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      401    0.000    0.000    0.000    0.000 hooks.py:613(on_before_batch_transfer)
      401    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      401    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Strategy]SingleDeviceStrategy.batch_to_device
         20451 function calls (20050 primitive calls) in 0.221 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      401    0.004    0.000    0.221    0.001 strategy.py:262(batch_to_device)
      401    0.000    0.000    0.215    0.001 module.py:354(_apply_batch_transfer_handler)
      401    0.001    0.000    0.215    0.001 module.py:336(_call_batch_hook)
      401    0.002    0.000    0.208    0.001 call.py:137(_call_lightning_module_hook)
      401    0.000    0.000    0.204    0.001 contextlib.py:114(__enter__)
      401    0.000    0.000    0.204    0.001 {built-in method builtins.next}
      401    0.000    0.000    0.204    0.001 profiler.py:55(profile)
      401    0.001    0.000    0.203    0.001 advanced.py:65(start)
      401    0.202    0.001    0.202    0.001 {method 'enable' of '_lsprof.Profiler' objects}
      401    0.000    0.000    0.006    0.000 data_connector.py:349(get_instance)
      802    0.001    0.000    0.006    0.000 model_helpers.py:29(is_overridden)
      802    0.002    0.000    0.004    0.000 overrides.py:10(is_overridden)
     2406    0.002    0.000    0.002    0.000 {built-in method builtins.getattr}
      401    0.001    0.000    0.001    0.000 module.py:1731(__setattr__)
      401    0.001    0.000    0.001    0.000 single_device.py:71(root_device)
4411/4010    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}
      401    0.000    0.000    0.001    0.000 contextlib.py:261(helper)
      401    0.000    0.000    0.000    0.000 parameter.py:8(__instancecheck__)
      401    0.000    0.000    0.000    0.000 contextlib.py:86(__init__)
     1604    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      401    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      401    0.000    0.000    0.000    0.000 __init__.py:1424(debug)
     1203    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      802    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      401    0.000    0.000    0.000    0.000 __init__.py:1689(isEnabledFor)
      401    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      401    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x7f133e5c8040}
      401    0.000    0.000    0.000    0.000 {built-in method builtins.callable}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.transfer_batch_to_device
         20060 function calls in 0.189 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      401    0.003    0.000    0.188    0.000 hooks.py:564(transfer_batch_to_device)
      401    0.006    0.000    0.185    0.000 apply_func.py:71(move_data_to_device)
      401    0.004    0.000    0.176    0.000 apply_func.py:23(apply_to_collection)
      401    0.002    0.000    0.166    0.000 apply_func.py:70(<dictcomp>)
     1604    0.012    0.000    0.164    0.000 apply_func.py:91(batch_to)
     1604    0.152    0.000    0.152    0.000 {method 'to' of 'torch._C.TensorBase' objects}
     5614    0.004    0.000    0.009    0.000 {built-in method builtins.isinstance}
     2005    0.000    0.000    0.005    0.000 abc.py:117(__instancecheck__)
     2005    0.005    0.000    0.005    0.000 {built-in method _abc._abc_instancecheck}
      401    0.000    0.000    0.004    0.000 {built-in method builtins.all}
     2005    0.001    0.000    0.003    0.000 apply_func.py:69(<genexpr>)
      401    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      401    0.000    0.000    0.001    0.000 {built-in method builtins.next}
      401    0.000    0.000    0.001    0.000 profiler.py:55(profile)
      401    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      401    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      401    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      401    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}
      401    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        2    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)
        2    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}
        2    0.000    0.000    0.000    0.000 apply_func.py:63(__subclasshook__)
        2    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        2    0.000    0.000    0.000    0.000 {built-in method builtins.callable}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_after_batch_transfer
         2807 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      401    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      401    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      401    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      401    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      401    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      401    0.000    0.000    0.000    0.000 hooks.py:641(on_after_batch_transfer)
      401    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_validation_batch_start
         2010 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 callback.py:142(on_validation_batch_start)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_validation_batch_start
         158455 function calls in 0.116 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.004    0.000    0.115    0.001 tqdm_progress.py:292(on_validation_batch_start)
      402    0.001    0.000    0.103    0.000 std.py:1325(refresh)
      402    0.001    0.000    0.101    0.000 std.py:1464(display)
      201    0.001    0.000    0.059    0.000 std.py:1360(reset)
     2404    0.001    0.000    0.056    0.000 utils.py:194(inner)
     1202    0.001    0.000    0.047    0.000 redirect.py:644(write)
     1202    0.001    0.000    0.046    0.000 wandb_run.py:2304(<lambda>)
     1202    0.001    0.000    0.046    0.000 wandb_run.py:390(wrapper_fn)
      201    0.000    0.000    0.045    0.000 std.py:1382(set_description)
     1202    0.002    0.000    0.044    0.000 wandb_run.py:1429(_console_raw_callback)
     1202    0.005    0.000    0.042    0.000 interface.py:749(publish_output_raw)
      800    0.002    0.000    0.038    0.000 std.py:1441(moveto)
      402    0.002    0.000    0.033    0.000 std.py:457(print_status)
      402    0.001    0.000    0.029    0.000 std.py:1150(__str__)
     1202    0.002    0.000    0.028    0.000 interface_shared.py:76(_publish_output_raw)
     1202    0.001    0.000    0.026    0.000 interface_sock.py:45(_publish)
     1202    0.001    0.000    0.023    0.000 sock_client.py:219(send_record_publish)
     1202    0.000    0.000    0.021    0.000 sock_client.py:153(send_server_request)
     1202    0.004    0.000    0.021    0.000 sock_client.py:145(_send_message)
      402    0.001    0.000    0.021    0.000 std.py:451(fp_write)
      402    0.008    0.000    0.020    0.000 std.py:464(format_meter)
     1202    0.002    0.000    0.015    0.000 sock_client.py:121(_sendall_with_error_handle)
     1202    0.013    0.000    0.013    0.000 {method 'send' of '_socket.socket' objects}
      402    0.000    0.000    0.011    0.000 utils.py:378(disp_len)
      402    0.001    0.000    0.010    0.000 utils.py:374(_text_width)
      402    0.002    0.000    0.009    0.000 {built-in method builtins.sum}
      402    0.001    0.000    0.008    0.000 std.py:1446(format_dict)
     1202    0.008    0.000    0.008    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
    22723    0.005    0.000    0.007    0.000 utils.py:375(<genexpr>)
     1202    0.001    0.000    0.007    0.000 well_known_types.py:172(GetCurrentTime)
      804    0.004    0.000    0.006    0.000 utils.py:273(_is_ascii)
      402    0.002    0.000    0.006    0.000 utils.py:333(_screen_shape_linux)
     1202    0.002    0.000    0.006    0.000 well_known_types.py:242(FromDatetime)
      201    0.002    0.000    0.005    0.000 progress_bar.py:90(total_val_batches_current_dataloader)
      402    0.003    0.000    0.003    0.000 {built-in method fcntl.ioctl}
      804    0.002    0.000    0.003    0.000 {method 'format' of 'str' objects}
      603    0.001    0.000    0.003    0.000 enums.py:81(__eq__)
    35774    0.002    0.000    0.002    0.000 {built-in method builtins.ord}
     1202    0.002    0.000    0.002    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
    22321    0.002    0.000    0.002    0.000 {built-in method unicodedata.east_asian_width}
      403    0.000    0.000    0.002    0.000 trainer.py:1429(sanity_checking)
     1202    0.002    0.000    0.002    0.000 enum_type_wrapper.py:92(__getattr__)
     1202    0.002    0.000    0.002    0.000 calendar.py:655(timegm)
      402    0.002    0.000    0.002    0.000 std.py:400(format_interval)
      200    0.000    0.000    0.001    0.000 trainer.py:1535(num_val_batches)
     1202    0.001    0.000    0.001    0.000 interface_sock.py:41(_assign)
      402    0.000    0.000    0.001    0.000 utils.py:347(<listcomp>)
     1206    0.001    0.000    0.001    0.000 types.py:171(__get__)
      201    0.001    0.000    0.001    0.000 trainer.py:1178(lightning_module)
     1202    0.001    0.000    0.001    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
     2404    0.001    0.000    0.001    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
      402    0.001    0.000    0.001    0.000 std.py:186(__format__)
      402    0.001    0.000    0.001    0.000 os.py:674(__getitem__)
     1206    0.001    0.000    0.001    0.000 enum.py:792(value)
      201    0.001    0.000    0.001    0.000 progress_bar.py:145(has_dataloader_changed)
     1202    0.001    0.000    0.001    0.000 {built-in method posix.getpid}
      402    0.000    0.000    0.001    0.000 std.py:102(acquire)
     3606    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}
      402    0.000    0.000    0.001    0.000 std.py:106(release)
     1202    0.001    0.000    0.001    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
     1202    0.001    0.000    0.001    0.000 {built-in method utcnow}
     1202    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
      402    0.000    0.000    0.000    0.000 std.py:153(__init__)
      402    0.000    0.000    0.000    0.000 {built-in method fromtimestamp}
      201    0.000    0.000    0.000    0.000 tqdm_progress.py:440(convert_inf)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      402    0.000    0.000    0.000    0.000 os.py:754(encode)
     2010    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
     2806    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      402    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      800    0.000    0.000    0.000    0.000 utils.py:370(_term_move_up)
      402    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)
      804    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
      603    0.000    0.000    0.000    0.000 tqdm_progress.py:131(val_progress_bar)
     1202    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      402    0.000    0.000    0.000    0.000 std.py:231(__call__)
     1202    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
     1202    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
     1206    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
      402    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
      402    0.000    0.000    0.000    0.000 {built-in method builtins.max}
      603    0.000    0.000    0.000    0.000 std.py:226(__init__)
     1206    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
      402    0.000    0.000    0.000    0.000 utils.py:112(__format__)
      201    0.000    0.000    0.000    0.000 {built-in method math.isinf}
     1202    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
      603    0.000    0.000    0.000    0.000 {built-in method time.time}
      402    0.000    0.000    0.000    0.000 utils.py:108(__init__)
      804    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      402    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      402    0.000    0.000    0.000    0.000 progress_bar.py:54(trainer)
      402    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      402    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
      402    0.000    0.000    0.000    0.000 std.py:167(colour)
      402    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
      402    0.000    0.000    0.000    0.000 std.py:163(colour)
      402    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
      201    0.000    0.000    0.000    0.000 {built-in method math.isnan}
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 progress_bar.py:68(validation_description)
        1    0.000    0.000    0.000    0.000 trainer.py:1528(num_sanity_val_batches)
        1    0.000    0.000    0.000    0.000 evaluation_loop.py:84(max_batches)
        1    0.000    0.000    0.000    0.000 evaluation_loop.py:90(<listcomp>)
        2    0.000    0.000    0.000    0.000 {built-in method builtins.min}
        1    0.000    0.000    0.000    0.000 trainer.py:1533(<listcomp>)
        1    0.000    0.000    0.000    0.000 progress_bar.py:60(sanity_check_description)



Profile stats for: [Callback]ModelSummary.on_validation_batch_start
         2010 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 callback.py:142(on_validation_batch_start)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start
         2010 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 callback.py:142(on_validation_batch_start)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_validation_batch_start
         1407 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.001    0.000 {built-in method builtins.next}
      201    0.001    0.000    0.001    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 hooks.py:93(on_validation_batch_start)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Strategy]SingleDeviceStrategy.validation_step
         1388493 function calls (1353180 primitive calls) in 2.877 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.002    0.000    2.882    0.014 strategy.py:400(validation_step)
      201    0.014    0.000    2.872    0.014 FlavourClassificationTransformerEncoder.py:97(validation_step)
 9648/201    0.009    0.000    2.637    0.013 module.py:1549(_wrapped_call_impl)
 9648/201    0.044    0.000    2.636    0.013 module.py:1555(_call_impl)
      201    0.012    0.000    2.632    0.013 FlavourClassificationTransformerEncoder.py:55(forward)
      603    0.044    0.000    2.434    0.004 EncoderBlock.py:57(forward)
      603    0.171    0.000    1.041    0.002 XFormersAttention.py:33(forward)
     1206    0.204    0.000    0.862    0.001 LayerNormalisation.py:17(forward)
    12663    0.020    0.000    0.775    0.000 __init__.py:1436(info)
    12663    0.018    0.000    0.750    0.000 __init__.py:1565(_log)
    12663    0.009    0.000    0.515    0.000 __init__.py:1591(handle)
    12663    0.017    0.000    0.502    0.000 __init__.py:1645(callHandlers)
    12663    0.014    0.000    0.484    0.000 __init__.py:939(handle)
    12663    0.008    0.000    0.454    0.000 __init__.py:1178(emit)
    12663    0.013    0.000    0.446    0.000 __init__.py:1071(emit)
      603    0.035    0.000    0.319    0.001 FFN.py:16(forward)
    12663    0.014    0.000    0.301    0.000 __init__.py:1060(flush)
     4020    0.008    0.000    0.287    0.000 linear.py:116(forward)
     4020    0.274    0.000    0.274    0.000 {built-in method torch._C._nn.linear}
    12663    0.274    0.000    0.274    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
     1206    0.007    0.000    0.252    0.000 __init__.py:189(memory_efficient_attention)
     1206    0.003    0.000    0.242    0.000 __init__.py:457(_memory_efficient_attention)
     1206    0.009    0.000    0.237    0.000 __init__.py:475(_memory_efficient_attention_forward)
    12663    0.012    0.000    0.175    0.000 __init__.py:1550(makeRecord)
     9246    0.164    0.000    0.164    0.000 {method 'any' of 'torch._C.TensorBase' objects}
    12663    0.072    0.000    0.163    0.000 __init__.py:282(__init__)
      402    0.014    0.000    0.151    0.000 module.py:382(log)
    12663    0.007    0.000    0.130    0.000 __init__.py:916(format)
     1809    0.003    0.000    0.128    0.000 {built-in method builtins.print}
     9246    0.127    0.000    0.127    0.000 {built-in method torch.isnan}
     3618    0.003    0.000    0.126    0.000 redirect.py:644(write)
    12663    0.018    0.000    0.123    0.000 __init__.py:650(format)
     3618    0.002    0.000    0.122    0.000 wandb_run.py:2304(<lambda>)
     1206    0.002    0.000    0.121    0.000 dispatch.py:126(_dispatch_fw)
     3618    0.003    0.000    0.121    0.000 wandb_run.py:390(wrapper_fn)
     3618    0.004    0.000    0.117    0.000 wandb_run.py:1429(_console_raw_callback)
     3618    0.013    0.000    0.111    0.000 interface.py:749(publish_output_raw)
     1206    0.005    0.000    0.110    0.000 dispatch.py:55(_run_priority_list)
      402    0.013    0.000    0.084    0.000 result.py:355(log)
     1206    0.004    0.000    0.075    0.000 cutlass.py:211(apply)
     3618    0.005    0.000    0.074    0.000 interface_shared.py:76(_publish_output_raw)
     1206    0.007    0.000    0.073    0.000 attn_bias.py:707(from_seqlens)
     1206    0.009    0.000    0.071    0.000 cutlass.py:275(apply_bmhk)
     2412    0.031    0.000    0.071    0.000 common.py:348(not_supported_reasons)
    12663    0.022    0.000    0.068    0.000 __init__.py:582(formatTime)
     3618    0.004    0.000    0.068    0.000 interface_sock.py:45(_publish)
     1407    0.003    0.000    0.062    0.000 _ops.py:1047(__call__)
     3618    0.004    0.000    0.061    0.000 sock_client.py:219(send_record_publish)
     1206    0.006    0.000    0.060    0.000 flash.py:629(not_supported_reasons)
     3618    0.001    0.000    0.055    0.000 sock_client.py:153(send_server_request)
     3618    0.008    0.000    0.054    0.000 sock_client.py:145(_send_message)
     1206    0.054    0.000    0.054    0.000 {built-in method torch._ops.aten._efficient_attention_forward}
1618/1610    0.004    0.000    0.047    0.000 apply_func.py:23(apply_to_collection)
     1206    0.003    0.000    0.046    0.000 cutlass.py:326(not_supported_reasons)
     1206    0.004    0.000    0.045    0.000 attn_bias.py:350(from_seqlens)
    12663    0.026    0.000    0.042    0.000 __init__.py:1514(findCaller)
     3618    0.005    0.000    0.041    0.000 __init__.py:438(get_device_capability)
      402    0.000    0.000    0.040    0.000 result.py:424(update_metrics)
     1206    0.004    0.000    0.039    0.000 attn_bias.py:329(_get_seqstart)
     3618    0.004    0.000    0.039    0.000 sock_client.py:121(_sendall_with_error_handle)
      402    0.002    0.000    0.039    0.000 result.py:264(forward)
     2412    0.037    0.000    0.037    0.000 {method 'reshape' of 'torch._C.TensorBase' objects}
      402    0.006    0.000    0.037    0.000 metric.py:476(wrapped_func)
     3618    0.006    0.000    0.036    0.000 __init__.py:455(get_device_properties)
86587/82111    0.015    0.000    0.036    0.000 {built-in method builtins.isinstance}
     1210    0.034    0.000    0.034    0.000 {built-in method torch.tensor}
     2814    0.034    0.000    0.034    0.000 {method 'item' of 'torch._C.TensorBase' objects}
     3618    0.034    0.000    0.034    0.000 {method 'send' of '_socket.socket' objects}
     1608    0.032    0.000    0.032    0.000 {method 'mean' of 'torch._C.TensorBase' objects}
     1809    0.032    0.000    0.032    0.000 {method 'sum' of 'torch._C.TensorBase' objects}
    12663    0.011    0.000    0.030    0.000 posixpath.py:117(splitext)
  944/806    0.003    0.000    0.029    0.000 apply_func.py:84(_apply_to_collection_slow)
     1809    0.028    0.000    0.028    0.000 {built-in method torch.zeros}
      402    0.022    0.000    0.027    0.000 result.py:207(update)
      201    0.004    0.000    0.025    0.000 functional.py:3014(cross_entropy)
    12663    0.025    0.000    0.025    0.000 {built-in method time.strftime}
    12663    0.013    0.000    0.024    0.000 posixpath.py:140(basename)
     1206    0.014    0.000    0.024    0.000 common.py:120(validate_inputs)
    12663    0.022    0.000    0.022    0.000 {built-in method time.localtime}
      603    0.002    0.000    0.020    0.000 activation.py:103(forward)
      201    0.020    0.000    0.020    0.000 {built-in method torch._C._nn.cross_entropy_loss}
     1206    0.020    0.000    0.020    0.000 {built-in method torch.sqrt}
    12663    0.005    0.000    0.020    0.000 __init__.py:634(formatMessage)
     1206    0.019    0.000    0.019    0.000 {method 'var' of 'torch._C.TensorBase' objects}
     2412    0.005    0.000    0.019    0.000 attn_bias.py:90(_get_default_bias_device)
     3618    0.009    0.000    0.019    0.000 _utils.py:9(_get_device_index)
      603    0.019    0.000    0.019    0.000 {built-in method torch.all}
     3618    0.003    0.000    0.019    0.000 well_known_types.py:172(GetCurrentTime)
      603    0.018    0.000    0.018    0.000 {built-in method torch.stack}
      603    0.001    0.000    0.018    0.000 functional.py:1489(relu)
     1809    0.003    0.000    0.018    0.000 dropout.py:58(forward)
      603    0.017    0.000    0.017    0.000 {built-in method torch.relu}
    12663    0.013    0.000    0.017    0.000 genericpath.py:121(_splitext)
     1206    0.005    0.000    0.016    0.000 cutlass.py:49(_minimum_gemm_alignment)
    12663    0.004    0.000    0.015    0.000 __init__.py:432(format)
     1809    0.007    0.000    0.015    0.000 functional.py:1279(dropout)
     3618    0.005    0.000    0.015    0.000 well_known_types.py:242(FromDatetime)
    25326    0.008    0.000    0.015    0.000 __init__.py:896(acquire)
     2238    0.004    0.000    0.014    0.000 typing.py:719(__instancecheck__)
     1206    0.003    0.000    0.014    0.000 __init__.py:115(is_available)
      603    0.013    0.000    0.013    0.000 {built-in method torch.argmax}
      402    0.002    0.000    0.013    0.000 module.py:654(__to_tensor)
    19497    0.012    0.000    0.012    0.000 module.py:1716(__getattr__)
    12663    0.004    0.000    0.012    0.000 __init__.py:628(usesTime)
     3819    0.003    0.000    0.011    0.000 {built-in method builtins.any}
      603    0.002    0.000    0.011    0.000 _tensor.py:982(__format__)
    12663    0.011    0.000    0.011    0.000 __init__.py:429(_format)
    16281    0.010    0.000    0.010    0.000 {built-in method posix.getpid}
6788/2255    0.001    0.000    0.010    0.000 abc.py:121(__subclasscheck__)
     2238    0.003    0.000    0.010    0.000 typing.py:848(__subclasscheck__)
      201    0.002    0.000    0.010    0.000 profiler.py:693(__exit__)
    25326    0.007    0.000    0.010    0.000 __init__.py:903(release)
6788/2255    0.009    0.000    0.010    0.000 {built-in method _abc._abc_subclasscheck}
     1206    0.009    0.000    0.009    0.000 {method 'transpose' of 'torch._C.TensorBase' objects}
     1206    0.001    0.000    0.009    0.000 __init__.py:111(_nvml_based_avail)
    37989    0.009    0.000    0.009    0.000 {method 'rfind' of 'str' objects}
     1206    0.007    0.000    0.008    0.000 dispatch.py:79(_dispatch_fw_priority_list)
    12663    0.005    0.000    0.008    0.000 __init__.py:160(<lambda>)
    44929    0.008    0.000    0.008    0.000 {built-in method builtins.hasattr}
     1206    0.002    0.000    0.008    0.000 os.py:771(getenv)
     9648    0.008    0.000    0.008    0.000 {built-in method torch._C._get_tracing_state}
     1350    0.000    0.000    0.008    0.000 abc.py:117(__instancecheck__)
     3618    0.007    0.000    0.008    0.000 _utils.py:764(_get_device_index)
    12663    0.005    0.000    0.008    0.000 __init__.py:421(usesTime)
    25326    0.008    0.000    0.008    0.000 __init__.py:791(filter)
      201    0.000    0.000    0.008    0.000 _ops.py:887(__call__)
      402    0.002    0.000    0.007    0.000 result.py:340(_extract_batch_size)
     1350    0.002    0.000    0.007    0.000 {built-in method _abc._abc_instancecheck}
     3618    0.007    0.000    0.007    0.000 {method 'unsqueeze' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.007    0.004 result.py:415(register_key)
      402    0.007    0.000    0.007    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
      603    0.000    0.000    0.007    0.000 {built-in method builtins.next}
      402    0.000    0.000    0.007    0.000 trainer.py:1642(_results)
    12663    0.005    0.000    0.006    0.000 threading.py:1358(current_thread)
      402    0.001    0.000    0.006    0.000 trainer.py:1564(_active_loop)
    25327    0.006    0.000    0.006    0.000 {method 'acquire' of '_thread.RLock' objects}
      402    0.003    0.000    0.006    0.000 <string>:2(__init__)
     1206    0.002    0.000    0.006    0.000 _collections_abc.py:760(get)
        2    0.000    0.000    0.006    0.003 result.py:306(to)
    12663    0.004    0.000    0.006    0.000 __init__.py:119(getLevelName)
     2252    0.001    0.000    0.006    0.000 {built-in method builtins.issubclass}
      201    0.000    0.000    0.006    0.000 profiler.py:687(__enter__)
      201    0.001    0.000    0.006    0.000 data.py:61(extract_batch_size)
     3618    0.006    0.000    0.006    0.000 {built-in method torch.cuda._get_device_properties}
     1809    0.006    0.000    0.006    0.000 {method 'view' of 'torch._C.TensorBase' objects}
     3618    0.003    0.000    0.006    0.000 common.py:482(check_lastdim_alignment_stride1)
    12663    0.003    0.000    0.005    0.000 posixpath.py:41(_get_sep)
    12663    0.004    0.000    0.005    0.000 posixpath.py:52(normcase)
      201    0.005    0.000    0.005    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
     3618    0.005    0.000    0.005    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
     2070    0.005    0.000    0.005    0.000 result.py:294(__setattr__)
    12663    0.005    0.000    0.005    0.000 __init__.py:358(getMessage)
      201    0.000    0.000    0.005    0.000 _ops.py:943(_must_dispatch_in_python)
    12663    0.005    0.000    0.005    0.000 __init__.py:1689(isEnabledFor)
     1608    0.002    0.000    0.005    0.000 enums.py:81(__eq__)
2613/1005    0.002    0.000    0.005    0.000 data.py:42(_extract_batch_size)
     3618    0.004    0.000    0.005    0.000 calendar.py:655(timegm)
     3618    0.005    0.000    0.005    0.000 enum_type_wrapper.py:92(__getattr__)
     1206    0.002    0.000    0.005    0.000 os.py:674(__getitem__)
      201    0.000    0.000    0.005    0.000 _pytree.py:1181(tree_any)
      402    0.001    0.000    0.005    0.000 fx_validator.py:191(check_logging_and_get_default_levels)
     2414    0.002    0.000    0.004    0.000 {built-in method builtins.all}
    12148    0.004    0.000    0.004    0.000 {built-in method builtins.getattr}
     1809    0.004    0.000    0.004    0.000 {built-in method torch.dropout}
      402    0.002    0.000    0.004    0.000 precision.py:173(val_step_context)
     2412    0.002    0.000    0.004    0.000 common.py:32(is_available)
      402    0.001    0.000    0.004    0.000 result.py:57(__post_init__)
      804    0.003    0.000    0.004    0.000 result.py:90(_generate_sync_fn)
      804    0.001    0.000    0.004    0.000 trainer.py:1381(training)
      201    0.000    0.000    0.004    0.000 contextlib.py:114(__enter__)
    37989    0.004    0.000    0.004    0.000 {built-in method posix.fspath}
      201    0.000    0.000    0.004    0.000 functional.py:1858(softmax)
      402    0.002    0.000    0.004    0.000 memory.py:24(recursive_detach)
 1407/402    0.001    0.000    0.004    0.000 _pytree.py:874(tree_iter)
    12663    0.004    0.000    0.004    0.000 {built-in method sys._getframe}
      900    0.002    0.000    0.003    0.000 apply_func.py:17(is_dataclass_instance)
    25733    0.003    0.000    0.003    0.000 {method 'get' of 'dict' objects}
      402    0.000    0.000    0.003    0.000 contextlib.py:123(__exit__)
     1206    0.003    0.000    0.003    0.000 cutlass.py:136(_custom_mask_type)
     4824    0.001    0.000    0.003    0.000 __init__.py:834(device_count)
      201    0.003    0.000    0.003    0.000 {method 'softmax' of 'torch._C.TensorBase' objects}
      402    0.001    0.000    0.003    0.000 result.py:122(__post_init__)
      201    0.003    0.000    0.003    0.000 {method 'float' of 'torch._C.TensorBase' objects}
    25326    0.003    0.000    0.003    0.000 {built-in method _thread.get_ident}
     8446    0.003    0.000    0.003    0.000 {method 'stride' of 'torch._C.TensorBase' objects}
     1206    0.002    0.000    0.003    0.000 attn_bias.py:656(to)
    12663    0.003    0.000    0.003    0.000 {method 'find' of 'str' objects}
      201    0.000    0.000    0.003    0.000 module.py:262(current_epoch)
     3618    0.001    0.000    0.003    0.000 __init__.py:284(_lazy_init)
      804    0.003    0.000    0.003    0.000 {method 'detach' of 'torch._C.TensorBase' objects}
     2412    0.002    0.000    0.003    0.000 common.py:331(shape_not_supported_reasons)
     6030    0.002    0.000    0.003    0.000 __init__.py:106(_is_compiled)
    12663    0.003    0.000    0.003    0.000 threading.py:1093(name)
     7236    0.003    0.000    0.003    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
    12663    0.003    0.000    0.003    0.000 {built-in method time.time}
     3618    0.003    0.000    0.003    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
    16281    0.003    0.000    0.003    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      402    0.002    0.000    0.003    0.000 result.py:127(_parse_reduce_fx)
      201    0.003    0.000    0.003    0.000 {built-in method torch._ops.profiler.}
    25327    0.002    0.000    0.002    0.000 {method 'release' of '_thread.RLock' objects}
     1809    0.002    0.000    0.002    0.000 _VF.py:26(__getattr__)
     3618    0.002    0.000    0.002    0.000 interface_sock.py:41(_assign)
      201    0.002    0.000    0.002    0.000 trainer.py:1467(current_epoch)
     1206    0.002    0.000    0.002    0.000 common.py:96(normalize_bmhk)
      201    0.001    0.000    0.002    0.000 precision.py:68(forward_context)
    12663    0.002    0.000    0.002    0.000 process.py:189(name)
      201    0.000    0.000    0.002    0.000 contextlib.py:261(helper)
      410    0.001    0.000    0.002    0.000 grad_mode.py:184(__init__)
     2412    0.001    0.000    0.002    0.000 cutlass.py:87(_get_tensor_bias)
      201    0.001    0.000    0.002    0.000 profiler.py:55(profile)
     3618    0.001    0.000    0.002    0.000 __init__.py:237(is_initialized)
     3216    0.001    0.000    0.002    0.000 types.py:171(__get__)
      400    0.001    0.000    0.002    0.000 <string>:2(__eq__)
     4824    0.002    0.000    0.002    0.000 common.py:192(<genexpr>)
      201    0.001    0.000    0.002    0.000 contextlib.py:86(__init__)
    12663    0.002    0.000    0.002    0.000 process.py:37(current_process)
     1206    0.001    0.000    0.002    0.000 cutlass.py:66(_get_seqlen_info)
     3618    0.002    0.000    0.002    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
      402    0.002    0.000    0.002    0.000 {method 'squeeze' of 'torch._C.TensorBase' objects}
     1206    0.001    0.000    0.002    0.000 flash.py:511(_check_needs_no_topleft)
     4824    0.002    0.000    0.002    0.000 {built-in method builtins.max}
     1206    0.000    0.000    0.001    0.000 cutlass.py:98(_check_bias_alignment)
     4824    0.001    0.000    0.001    0.000 __init__.py:461(<genexpr>)
     4824    0.001    0.000    0.001    0.000 common.py:131(<genexpr>)
      402    0.000    0.000    0.001    0.000 memory.py:40(detach_and_move)
     4824    0.001    0.000    0.001    0.000 common.py:71(device)
     3618    0.001    0.000    0.001    0.000 {built-in method utcnow}
      804    0.000    0.000    0.001    0.000 _pytree.py:656(_is_leaf)
     1407    0.000    0.000    0.001    0.000 _pytree.py:649(_get_node_type)
      402    0.000    0.000    0.001    0.000 trainer.py:1554(_evaluation_loop)
      402    0.001    0.000    0.001    0.000 fx_validator.py:151(check_logging)
     1206    0.001    0.000    0.001    0.000 os.py:754(encode)
      402    0.001    0.000    0.001    0.000 fx_validator.py:177(check_logging_levels)
     3618    0.001    0.000    0.001    0.000 {built-in method _struct.pack}
     4824    0.001    0.000    0.001    0.000 common.py:122(<genexpr>)
      402    0.000    0.000    0.001    0.000 result.py:148(sync)
      900    0.000    0.000    0.001    0.000 dataclasses.py:1047(is_dataclass)
      402    0.000    0.000    0.001    0.000 trainer.py:1429(sanity_checking)
     4824    0.001    0.000    0.001    0.000 common.py:152(<genexpr>)
     9857    0.001    0.000    0.001    0.000 {built-in method builtins.len}
      201    0.001    0.000    0.001    0.000 advanced.py:71(stop)
     3220    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_unary}
     1206    0.001    0.000    0.001    0.000 os.py:758(decode)
        2    0.000    0.000    0.001    0.000 result.py:187(__init__)
     1407    0.001    0.000    0.001    0.000 _pytree.py:638(_is_namedtuple_instance)
      402    0.001    0.000    0.001    0.000 logger_connector.py:213(should_reset_tensors)
     5555    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}
     2412    0.001    0.000    0.001    0.000 attn_bias.py:316(to)
      201    0.001    0.000    0.001    0.000 _reduction.py:7(get_enum)
     3618    0.001    0.000    0.001    0.000 flash.py:533(_check_strides_for_bmghk)
      402    0.001    0.000    0.001    0.000 fx_validator.py:166(get_default_logging_levels)
    116/8    0.000    0.000    0.001    0.000 copy.py:128(deepcopy)
     3618    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_isInBadFork}
      402    0.000    0.000    0.001    0.000 result.py:74(op)
     1214    0.001    0.000    0.001    0.000 {built-in method torch._C._set_grad_enabled}
      201    0.001    0.000    0.001    0.000 contextlib.py:688(__init__)
      404    0.000    0.000    0.001    0.000 result.py:536(_get_default_dtype)
      201    0.000    0.000    0.001    0.000 profiler.py:676(__init__)
     3618    0.001    0.000    0.001    0.000 {built-in method time.monotonic}
     3618    0.001    0.000    0.001    0.000 {method '__exit__' of '_thread.lock' objects}
      400    0.000    0.000    0.001    0.000 trainer.py:1425(evaluating)
      201    0.000    0.000    0.001    0.000 container.py:317(__iter__)
     3823    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)
        4    0.000    0.000    0.000    0.000 metric.py:196(add_state)
     3216    0.000    0.000    0.000    0.000 enum.py:792(value)
      402    0.000    0.000    0.000    0.000 grad_mode.py:196(__exit__)
     2412    0.000    0.000    0.000    0.000 {built-in method builtins.min}
        4    0.000    0.000    0.000    0.000 _tensor.py:83(__deepcopy__)
      201    0.000    0.000    0.000    0.000 _ops.py:945(<lambda>)
     1206    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
      808    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.TensorBase' objects}
     3618    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
     3618    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
      201    0.000    0.000    0.000    0.000 _pytree.py:423(_dict_flatten)
      900    0.000    0.000    0.000    0.000 apply_func.py:11(is_namedtuple)
      402    0.000    0.000    0.000    0.000 {built-in method torch.is_floating_point}
     1206    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}
      402    0.000    0.000    0.000    0.000 {built-in method torch.numel}
     3618    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
        2    0.000    0.000    0.000    0.000 metric.py:101(__init__)
      402    0.000    0.000    0.000    0.000 grad_mode.py:193(__enter__)
      603    0.000    0.000    0.000    0.000 {method '__format__' of 'int' objects}
      201    0.000    0.000    0.000    0.000 module.py:215(trainer)
      402    0.000    0.000    0.000    0.000 strategy.py:351(model)
      605    0.000    0.000    0.000    0.000 result.py:163(is_mean_reduction)
      603    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        4    0.000    0.000    0.000    0.000 apply_func.py:69(<genexpr>)
      406    0.000    0.000    0.000    0.000 {built-in method torch.get_default_dtype}
      400    0.000    0.000    0.000    0.000 states.py:63(evaluating)
      402    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
     1206    0.000    0.000    0.000    0.000 cutlass.py:41(_uses_tensorcores)
      6/4    0.000    0.000    0.000    0.000 copy.py:258(_reconstruct)
      603    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}
      414    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}
     1206    0.000    0.000    0.000    0.000 dispatch.py:27(_get_use_fa3)
        8    0.000    0.000    0.000    0.000 apply_func.py:71(move_data_to_device)
      203    0.000    0.000    0.000    0.000 typing.py:271(inner)
        4    0.000    0.000    0.000    0.000 storage.py:907(_deepcopy)
     10/8    0.000    0.000    0.000    0.000 copy.py:226(_deepcopy_dict)
     1206    0.000    0.000    0.000    0.000 result.py:70(op)
      402    0.000    0.000    0.000    0.000 _pytree.py:395(_tuple_flatten)
        8    0.000    0.000    0.000    0.000 apply_func.py:91(batch_to)
      804    0.000    0.000    0.000    0.000 result.py:60(should)
      201    0.000    0.000    0.000    0.000 strategy.py:93(precision_plugin)
      804    0.000    0.000    0.000    0.000 result.py:80(group)
        2    0.000    0.000    0.000    0.000 inspect.py:3111(signature)
        2    0.000    0.000    0.000    0.000 inspect.py:2859(from_callable)
        8    0.000    0.000    0.000    0.000 {method 'to' of 'torch._C.TensorBase' objects}
      4/2    0.000    0.000    0.000    0.000 inspect.py:2246(_signature_from_callable)
        4    0.000    0.000    0.000    0.000 storage.py:140(__deepcopy__)
        4    0.000    0.000    0.000    0.000 storage.py:156(clone)
      201    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_variadic}
      402    0.000    0.000    0.000    0.000 typing.py:1375(cast)
      409    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {built-in method builtins.iter}
      201    0.000    0.000    0.000    0.000 contextlib.py:691(__enter__)
      201    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}
        2    0.000    0.000    0.000    0.000 inspect.py:2152(_signature_from_function)
      559    0.000    0.000    0.000    0.000 _collections_abc.py:409(__subclasshook__)
      201    0.000    0.000    0.000    0.000 __init__.py:129(annotate)
        4    0.000    0.000    0.000    0.000 {method 'copy_' of 'torch._C.StorageBase' objects}
      201    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        2    0.000    0.000    0.000    0.000 module.py:429(__init__)
      201    0.000    0.000    0.000    0.000 contextlib.py:694(__exit__)
      4/2    0.000    0.000    0.000    0.000 copy.py:209(_deepcopy_tuple)
      201    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}
        6    0.000    0.000    0.000    0.000 {method '__reduce_ex__' of 'object' objects}
        4    0.000    0.000    0.000    0.000 {method 'new_empty' of 'torch._C.TensorBase' objects}
        4    0.000    0.000    0.000    0.000 _tensor.py:242(_typed_storage)
        4    0.000    0.000    0.000    0.000 dataclasses.py:1024(fields)
      4/2    0.000    0.000    0.000    0.000 copy.py:210(<listcomp>)
        2    0.000    0.000    0.000    0.000 metric.py:475(_wrap_update)
        4    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)
        2    0.000    0.000    0.000    0.000 result.py:273(_wrap_compute)
        2    0.000    0.000    0.000    0.000 inspect.py:1840(_signature_bound_method)
       26    0.000    0.000    0.000    0.000 copy.py:242(_keep_alive)
        4    0.000    0.000    0.000    0.000 grad_mode.py:80(__enter__)
      214    0.000    0.000    0.000    0.000 {built-in method builtins.id}
        4    0.000    0.000    0.000    0.000 inspect.py:2781(__init__)
        6    0.000    0.000    0.000    0.000 inspect.py:2498(__init__)
      186    0.000    0.000    0.000    0.000 _collections_abc.py:315(__subclasshook__)
        4    0.000    0.000    0.000    0.000 storage.py:712(_new_wrapped_storage)
       38    0.000    0.000    0.000    0.000 dataclasses.py:1039(<genexpr>)
       12    0.000    0.000    0.000    0.000 copy.py:263(<genexpr>)
        4    0.000    0.000    0.000    0.000 {method 'set_' of 'torch._C.TensorBase' objects}
       58    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}
        8    0.000    0.000    0.000    0.000 storage.py:629(__init__)
        2    0.000    0.000    0.000    0.000 inspect.py:2873(replace)
        2    0.000    0.000    0.000    0.000 inspect.py:494(unwrap)
        4    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}
        2    0.000    0.000    0.000    0.000 copyreg.py:103(_slotnames)
        8    0.000    0.000    0.000    0.000 storage.py:557(__new__)
        4    0.000    0.000    0.000    0.000 grad_mode.py:84(__exit__)
        4    0.000    0.000    0.000    0.000 grad_mode.py:75(__init__)
       10    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 _contextlib.py:154(__new__)
        4    0.000    0.000    0.000    0.000 {method 'untyped_storage' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 result.py:171(is_max_reduction)
        6    0.000    0.000    0.000    0.000 enum.py:358(__call__)
        1    0.000    0.000    0.000    0.000 __init__.py:218(_acquireLock)
        4    0.000    0.000    0.000    0.000 {method 'contiguous' of 'torch._C.TensorBase' objects}
        8    0.000    0.000    0.000    0.000 inspect.py:2830(<genexpr>)
       48    0.000    0.000    0.000    0.000 copy.py:182(_deepcopy_atomic)
        4    0.000    0.000    0.000    0.000 copyreg.py:94(__newobj__)
        4    0.000    0.000    0.000    0.000 {built-in method torch._C._has_storage}
        1    0.000    0.000    0.000    0.000 __init__.py:1276(disable)
       16    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
        4    0.000    0.000    0.000    0.000 {method 'nbytes' of 'torch._C.StorageBase' objects}
       28    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
        1    0.000    0.000    0.000    0.000 result.py:502(reset)
       22    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 functools.py:65(wraps)
        6    0.000    0.000    0.000    0.000 enum.py:670(__new__)
        4    0.000    0.000    0.000    0.000 inspect.py:159(isfunction)
        6    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}
        2    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}
        1    0.000    0.000    0.000    0.000 __init__.py:227(_releaseLock)
        2    0.000    0.000    0.000    0.000 inspect.py:514(_is_wrapper)
        4    0.000    0.000    0.000    0.000 {method 'is_conj' of 'torch._C.TensorBase' objects}
        8    0.000    0.000    0.000    0.000 {built-in method builtins.callable}
       10    0.000    0.000    0.000    0.000 inspect.py:2548(name)
       14    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
        2    0.000    0.000    0.000    0.000 result.py:175(is_min_reduction)
        4    0.000    0.000    0.000    0.000 {method 'is_neg' of 'torch._C.TensorBase' objects}
        4    0.000    0.000    0.000    0.000 {method 'storage_offset' of 'torch._C.TensorBase' objects}
        8    0.000    0.000    0.000    0.000 inspect.py:2560(kind)
        4    0.000    0.000    0.000    0.000 storage.py:30(__init__)
        2    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}
        4    0.000    0.000    0.000    0.000 inspect.py:2552(default)
        2    0.000    0.000    0.000    0.000 {method '__setstate__' of 'functools.partial' objects}
        2    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}
        4    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 __init__.py:1675(getEffectiveLevel)
        2    0.000    0.000    0.000    0.000 inspect.py:2865(parameters)



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_validation_batch_end
         2010 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 callback.py:152(on_validation_batch_end)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_validation_batch_end
         83546 function calls in 0.068 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.002    0.000    0.067    0.000 tqdm_progress.py:309(on_validation_batch_end)
      201    0.000    0.000    0.064    0.000 tqdm_progress.py:451(_update_n)
      201    0.001    0.000    0.064    0.000 std.py:1325(refresh)
      201    0.001    0.000    0.062    0.000 std.py:1464(display)
     1202    0.001    0.000    0.033    0.000 utils.py:194(inner)
      601    0.001    0.000    0.026    0.000 redirect.py:644(write)
      601    0.000    0.000    0.026    0.000 wandb_run.py:2304(<lambda>)
      400    0.002    0.000    0.025    0.000 std.py:1441(moveto)
      601    0.001    0.000    0.025    0.000 wandb_run.py:390(wrapper_fn)
      601    0.001    0.000    0.025    0.000 wandb_run.py:1429(_console_raw_callback)
      601    0.003    0.000    0.023    0.000 interface.py:749(publish_output_raw)
      201    0.001    0.000    0.018    0.000 std.py:1150(__str__)
      201    0.000    0.000    0.017    0.000 std.py:457(print_status)
      601    0.001    0.000    0.015    0.000 interface_shared.py:76(_publish_output_raw)
      601    0.001    0.000    0.014    0.000 interface_sock.py:45(_publish)
      601    0.001    0.000    0.013    0.000 sock_client.py:219(send_record_publish)
      601    0.000    0.000    0.012    0.000 sock_client.py:153(send_server_request)
      601    0.001    0.000    0.011    0.000 sock_client.py:145(_send_message)
      201    0.004    0.000    0.011    0.000 std.py:464(format_meter)
      201    0.000    0.000    0.010    0.000 std.py:451(fp_write)
      601    0.001    0.000    0.008    0.000 sock_client.py:121(_sendall_with_error_handle)
      601    0.007    0.000    0.007    0.000 {method 'send' of '_socket.socket' objects}
      201    0.002    0.000    0.007    0.000 std.py:1446(format_dict)
      201    0.000    0.000    0.006    0.000 utils.py:378(disp_len)
      201    0.000    0.000    0.006    0.000 utils.py:374(_text_width)
      201    0.001    0.000    0.006    0.000 {built-in method builtins.sum}
      601    0.005    0.000    0.005    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
      201    0.002    0.000    0.004    0.000 utils.py:333(_screen_shape_linux)
    14276    0.003    0.000    0.004    0.000 utils.py:375(<genexpr>)
      601    0.001    0.000    0.004    0.000 well_known_types.py:172(GetCurrentTime)
      601    0.001    0.000    0.003    0.000 well_known_types.py:242(FromDatetime)
      402    0.002    0.000    0.003    0.000 utils.py:273(_is_ascii)
      201    0.002    0.000    0.002    0.000 {built-in method fcntl.ioctl}
      402    0.001    0.000    0.002    0.000 {method 'format' of 'str' objects}
    14075    0.001    0.000    0.001    0.000 {built-in method unicodedata.east_asian_width}
      601    0.001    0.000    0.001    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
      601    0.001    0.000    0.001    0.000 enum_type_wrapper.py:92(__getattr__)
      601    0.001    0.000    0.001    0.000 calendar.py:655(timegm)
    17887    0.001    0.000    0.001    0.000 {built-in method builtins.ord}
      402    0.001    0.000    0.001    0.000 std.py:400(format_interval)
      201    0.000    0.000    0.001    0.000 tqdm_progress.py:425(_should_update)
      201    0.000    0.000    0.001    0.000 utils.py:347(<listcomp>)
      601    0.001    0.000    0.001    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
      201    0.000    0.000    0.001    0.000 std.py:102(acquire)
      201    0.000    0.000    0.001    0.000 os.py:674(__getitem__)
     1202    0.001    0.000    0.001    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
      201    0.000    0.000    0.000    0.000 std.py:186(__format__)
      601    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 std.py:106(release)
      201    0.000    0.000    0.000    0.000 tqdm_progress.py:169(is_enabled)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
     1803    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
      601    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
      201    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}
      601    0.000    0.000    0.000    0.000 {built-in method utcnow}
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 std.py:153(__init__)
      601    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
      601    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 {built-in method now}
      201    0.000    0.000    0.000    0.000 os.py:754(encode)
      201    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
      601    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)
     1403    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      402    0.000    0.000    0.000    0.000 tqdm_progress.py:161(refresh_rate)
      400    0.000    0.000    0.000    0.000 utils.py:370(_term_move_up)
      201    0.000    0.000    0.000    0.000 std.py:231(__call__)
      402    0.000    0.000    0.000    0.000 tqdm_progress.py:131(val_progress_bar)
      402    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
     1005    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
      601    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
      601    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
      201    0.000    0.000    0.000    0.000 utils.py:108(__init__)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      402    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      201    0.000    0.000    0.000    0.000 {built-in method builtins.max}
      201    0.000    0.000    0.000    0.000 utils.py:112(__format__)
      201    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
      601    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
      603    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
      201    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
      201    0.000    0.000    0.000    0.000 std.py:167(colour)
      201    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
      201    0.000    0.000    0.000    0.000 {built-in method time.time}
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 std.py:163(colour)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      201    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}



Profile stats for: [Callback]ModelSummary.on_validation_batch_end
         2010 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 callback.py:152(on_validation_batch_end)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end
         2010 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 callback.py:152(on_validation_batch_end)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_validation_batch_end
         1407 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 hooks.py:103(on_validation_batch_end)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_validation_epoch_end
         2010 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 callback.py:127(on_validation_epoch_end)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_validation_epoch_end
         2010 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 callback.py:127(on_validation_epoch_end)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_validation_epoch_end
         2010 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.001    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 callback.py:127(on_validation_epoch_end)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end
         2010 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 callback.py:127(on_validation_epoch_end)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_validation_epoch_end
         1407 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 hooks.py:244(on_validation_epoch_end)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_validation_end
         2010 function calls in 0.002 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.001    0.000    0.001    0.000 early_stopping.py:192(on_validation_end)
      201    0.001    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_validation_end
         151045 function calls (151031 primitive calls) in 0.111 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.003    0.000    0.110    0.001 tqdm_progress.py:323(on_validation_end)
      401    0.001    0.000    0.060    0.000 std.py:1464(display)
      201    0.002    0.000    0.047    0.000 std.py:1265(close)
     1804    0.002    0.000    0.044    0.000 utils.py:194(inner)
      201    0.003    0.000    0.041    0.000 std.py:1402(set_postfix)
     1003    0.001    0.000    0.037    0.000 redirect.py:644(write)
     1003    0.000    0.000    0.036    0.000 wandb_run.py:2304(<lambda>)
     1003    0.001    0.000    0.036    0.000 wandb_run.py:390(wrapper_fn)
     1003    0.001    0.000    0.035    0.000 wandb_run.py:1429(_console_raw_callback)
      201    0.000    0.000    0.034    0.000 std.py:1325(refresh)
     1003    0.004    0.000    0.033    0.000 interface.py:749(publish_output_raw)
      401    0.001    0.000    0.028    0.000 std.py:457(print_status)
     1003    0.001    0.000    0.022    0.000 interface_shared.py:76(_publish_output_raw)
     1003    0.001    0.000    0.020    0.000 interface_sock.py:45(_publish)
      401    0.001    0.000    0.020    0.000 std.py:451(fp_write)
      201    0.001    0.000    0.019    0.000 progress_bar.py:177(get_metrics)
     1003    0.001    0.000    0.019    0.000 sock_client.py:219(send_record_publish)
     1003    0.000    0.000    0.017    0.000 sock_client.py:153(send_server_request)
      400    0.001    0.000    0.017    0.000 std.py:1441(moveto)
     1003    0.003    0.000    0.017    0.000 sock_client.py:145(_send_message)
      200    0.001    0.000    0.014    0.000 std.py:1150(__str__)
     1003    0.001    0.000    0.012    0.000 sock_client.py:121(_sendall_with_error_handle)
      201    0.000    0.000    0.010    0.000 trainer.py:1632(progress_bar_metrics)
     1003    0.010    0.000    0.010    0.000 {method 'send' of '_socket.socket' objects}
      201    0.000    0.000    0.010    0.000 logger_connector.py:250(progress_bar_metrics)
      202    0.000    0.000    0.009    0.000 std.py:1286(fp_write)
      200    0.003    0.000    0.009    0.000 std.py:464(format_meter)
      201    0.002    0.000    0.008    0.000 std.py:686(_decr_instances)
      401    0.000    0.000    0.008    0.000 utils.py:378(disp_len)
      201    0.004    0.000    0.008    0.000 progress_bar.py:210(get_standard_metrics)
      201    0.000    0.000    0.007    0.000 logger_connector.py:229(metrics)
      401    0.000    0.000    0.007    0.000 utils.py:374(_text_width)
      401    0.002    0.000    0.007    0.000 {built-in method builtins.sum}
      603    0.000    0.000    0.006    0.000 trainer.py:1642(_results)
      603    0.001    0.000    0.006    0.000 trainer.py:1564(_active_loop)
     1003    0.001    0.000    0.006    0.000 well_known_types.py:172(GetCurrentTime)
      801    0.005    0.000    0.005    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
    19463    0.003    0.000    0.005    0.000 utils.py:375(<genexpr>)
     1003    0.001    0.000    0.005    0.000 well_known_types.py:242(FromDatetime)
      200    0.001    0.000    0.004    0.000 std.py:1446(format_dict)
     2010    0.002    0.000    0.004    0.000 enums.py:81(__eq__)
      201    0.001    0.000    0.004    0.000 result.py:476(metrics)
      201    0.001    0.000    0.003    0.000 utilities.py:25(_version)
      200    0.001    0.000    0.003    0.000 utils.py:333(_screen_shape_linux)
      401    0.002    0.000    0.003    0.000 _weakrefset.py:63(__iter__)
      400    0.002    0.000    0.003    0.000 utils.py:273(_is_ascii)
      201    0.001    0.000    0.003    0.000 wandb.py:572(version)
      201    0.001    0.000    0.002    0.000 wandb_run.py:357(wrapper)
     4813    0.001    0.000    0.002    0.000 {built-in method builtins.isinstance}
      603    0.000    0.000    0.002    0.000 trainer.py:1381(training)
      199    0.001    0.000    0.002    0.000 tqdm_progress.py:46(format_num)
      402    0.000    0.000    0.002    0.000 result.py:430(_get_cache)
      201    0.000    0.000    0.002    0.000 _weakrefset.py:111(remove)
      200    0.001    0.000    0.002    0.000 {built-in method fcntl.ioctl}
     1003    0.002    0.000    0.002    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
    19062    0.002    0.000    0.002    0.000 {built-in method unicodedata.east_asian_width}
      603    0.000    0.000    0.002    0.000 trainer.py:1554(_evaluation_loop)
     3819    0.001    0.000    0.002    0.000 types.py:171(__get__)
      400    0.001    0.000    0.001    0.000 {method 'format' of 'str' objects}
      603    0.000    0.000    0.001    0.000 trainer.py:1429(sanity_checking)
     1003    0.001    0.000    0.001    0.000 calendar.py:655(timegm)
     1003    0.001    0.000    0.001    0.000 enum_type_wrapper.py:92(__getattr__)
      402    0.001    0.000    0.001    0.000 {method 'detach' of 'torch._C.TensorBase' objects}
      402    0.000    0.000    0.001    0.000 {method 'remove' of 'set' objects}
      602    0.001    0.000    0.001    0.000 std.py:102(acquire)
      402    0.000    0.000    0.001    0.000 std.py:110(__enter__)
      199    0.001    0.000    0.001    0.000 std.py:419(format_num)
      400    0.000    0.000    0.001    0.000 abc.py:117(__instancecheck__)
    18203    0.001    0.000    0.001    0.000 {built-in method builtins.ord}
      201    0.001    0.000    0.001    0.000 wandb_run.py:881(id)
      400    0.001    0.000    0.001    0.000 {built-in method _abc._abc_instancecheck}
     1003    0.001    0.000    0.001    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
      602    0.001    0.000    0.001    0.000 std.py:106(release)
     2006    0.001    0.000    0.001    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
      201    0.000    0.000    0.001    0.000 _weakrefset.py:27(__exit__)
     1003    0.001    0.000    0.001    0.000 interface_sock.py:41(_assign)
      400    0.001    0.000    0.001    0.000 std.py:400(format_interval)
      200    0.000    0.000    0.001    0.000 utils.py:347(<listcomp>)
      402    0.000    0.000    0.001    0.000 std.py:113(__exit__)
     1204    0.001    0.000    0.001    0.000 {built-in method posix.getpid}
      201    0.000    0.000    0.001    0.000 {method 'join' of 'str' objects}
      201    0.000    0.000    0.001    0.000 trainer.py:1178(lightning_module)
     3611    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}
      200    0.000    0.000    0.001    0.000 os.py:674(__getitem__)
      201    0.000    0.000    0.000    0.000 utils.py:125(__eq__)
     1003    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
      402    0.000    0.000    0.000    0.000 result.py:465(_forked_name)
      600    0.000    0.000    0.000    0.000 trainer.py:1425(evaluating)
      201    0.000    0.000    0.000    0.000 _weakrefset.py:53(_commit_removals)
     1003    0.000    0.000    0.000    0.000 {built-in method utcnow}
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 std.py:186(__format__)
     3819    0.000    0.000    0.000    0.000 enum.py:792(value)
      601    0.000    0.000    0.000    0.000 std.py:1428(<genexpr>)
      201    0.000    0.000    0.000    0.000 _weakrefset.py:17(__init__)
     1003    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
     4020    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      401    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}
     3007    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      402    0.000    0.000    0.000    0.000 std.py:1153(_comparable)
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
     1003    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      201    0.000    0.000    0.000    0.000 _weakrefset.py:21(__enter__)
      603    0.000    0.000    0.000    0.000 result.py:463(<genexpr>)
      200    0.000    0.000    0.000    0.000 std.py:153(__init__)
      602    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
      200    0.000    0.000    0.000    0.000 {built-in method now}
      200    0.000    0.000    0.000    0.000 os.py:754(encode)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 std.py:708(<lambda>)
      801    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      201    0.000    0.000    0.000    0.000 std.py:1157(__hash__)
      402    0.000    0.000    0.000    0.000 result.py:158(forked_name)
      201    0.000    0.000    0.000    0.000 result.py:461(valid_items)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}
     1003    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
      600    0.000    0.000    0.000    0.000 states.py:63(evaluating)
     1003    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
      401    0.000    0.000    0.000    0.000 {built-in method builtins.max}
      398    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}
      602    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
      601    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      803    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
      200    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)
      400    0.000    0.000    0.000    0.000 utils.py:370(_term_move_up)
     1003    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
     1000    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
      200    0.000    0.000    0.000    0.000 std.py:231(__call__)
      602    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
      201    0.000    0.000    0.000    0.000 progress_bar.py:150(reset_dataloader_idx_tracker)
      201    0.000    0.000    0.000    0.000 tqdm_progress.py:121(train_progress_bar)
      201    0.000    0.000    0.000    0.000 tqdm_progress.py:131(val_progress_bar)
      602    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      400    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}
      201    0.000    0.000    0.000    0.000 {built-in method builtins.id}
      200    0.000    0.000    0.000    0.000 utils.py:112(__format__)
      402    0.000    0.000    0.000    0.000 result.py:154(forked)
      201    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
      201    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
      603    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 utils.py:108(__init__)
      200    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
      402    0.000    0.000    0.000    0.000 trainer.py:1590(loggers)
      200    0.000    0.000    0.000    0.000 std.py:167(colour)
      402    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}
      200    0.000    0.000    0.000    0.000 {built-in method time.time}
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 std.py:163(colour)
      201    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
      8/1    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)
      8/1    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}



Profile stats for: [Callback]ModelSummary.on_validation_end
         2010 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 callback.py:214(on_validation_end)
      201    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end
         9620 function calls in 0.013 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.013    0.000 model_checkpoint.py:326(on_validation_end)
      201    0.004    0.000    0.010    0.000 model_checkpoint.py:413(_should_skip_saving_checkpoint)
      200    0.001    0.000    0.005    0.000 trainer.py:1458(global_step)
      200    0.002    0.000    0.004    0.000 training_epoch_loop.py:99(global_step)
      200    0.001    0.000    0.003    0.000 model_checkpoint.py:423(_should_save_on_train_epoch_end)
      601    0.001    0.000    0.001    0.000 enums.py:81(__eq__)
      200    0.001    0.000    0.001    0.000 progress.py:274(optimizer_steps)
      400    0.000    0.000    0.001    0.000 trainer.py:1535(num_val_batches)
      201    0.000    0.000    0.001    0.000 trainer.py:1429(sanity_checking)
     1202    0.000    0.000    0.001    0.000 types.py:171(__get__)
      401    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
     1202    0.000    0.000    0.000    0.000 enum.py:792(value)
      801    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
     1202    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
      401    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.sum}
      200    0.000    0.000    0.000    0.000 module.py:295(automatic_optimization)
      401    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_validation_end
         1407 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 hooks.py:53(on_validation_end)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Strategy]SingleDeviceStrategy.on_validation_end
         1407 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      201    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      201    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      201    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      201    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      201    0.000    0.000    0.000    0.000 strategy.py:565(on_validation_end)
      201    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      201    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_sanity_check_end
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 callback.py:73(on_sanity_check_end)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_sanity_check_end
         14 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:254(on_sanity_check_end)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        2    0.000    0.000    0.000    0.000 std.py:1265(close)
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:131(val_progress_bar)
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:121(train_progress_bar)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_sanity_check_end
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 callback.py:73(on_sanity_check_end)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 callback.py:73(on_sanity_check_end)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningDataModule]PMTfiedDataModule.train_dataloader
         478 function calls (473 primitive calls) in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 PMTfiedDataModule.py:67(train_dataloader)
      2/1    0.000    0.000    0.000    0.000 data.py:287(wrapper)
        1    0.000    0.000    0.000    0.000 dataloader.py:227(__init__)
        2    0.000    0.000    0.000    0.000 inspect.py:3111(signature)
        2    0.000    0.000    0.000    0.000 inspect.py:2859(from_callable)
        2    0.000    0.000    0.000    0.000 inspect.py:2246(_signature_from_callable)
        2    0.000    0.000    0.000    0.000 inspect.py:2152(_signature_from_function)
    23/22    0.000    0.000    0.000    0.000 data.py:334(wrapper)
       21    0.000    0.000    0.000    0.000 inspect.py:2498(__init__)
    20/19    0.000    0.000    0.000    0.000 dataloader.py:418(__setattr__)
       21    0.000    0.000    0.000    0.000 data.py:295(<genexpr>)
       37    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
        2    0.000    0.000    0.000    0.000 inspect.py:2781(__init__)
        1    0.000    0.000    0.000    0.000 dataloader.py:487(check_worker_number_rationality)
        1    0.000    0.000    0.000    0.000 sampler.py:262(__init__)
       21    0.000    0.000    0.000    0.000 enum.py:358(__call__)
       27    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)
        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}
        1    0.000    0.000    0.000    0.000 {built-in method posix.sched_getaffinity}
       23    0.000    0.000    0.000    0.000 inspect.py:2830(<genexpr>)
       50    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        1    0.000    0.000    0.000    0.000 sampler.py:133(__init__)
        2    0.000    0.000    0.000    0.000 inspect.py:494(unwrap)
       61    0.000    0.000    0.000    0.000 inspect.py:2548(name)
        2    0.000    0.000    0.000    0.000 data.py:303(<dictcomp>)
        2    0.000    0.000    0.000    0.000 sampler.py:146(num_samples)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method torch.set_vital}
       21    0.000    0.000    0.000    0.000 enum.py:670(__new__)
        1    0.000    0.000    0.000    0.000 dataloader.py:394(multiprocessing_context)
       21    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}
      8/6    0.000    0.000    0.000    0.000 {built-in method builtins.len}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
       21    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}
       19    0.000    0.000    0.000    0.000 inspect.py:2560(kind)
       19    0.000    0.000    0.000    0.000 inspect.py:2552(default)
        4    0.000    0.000    0.000    0.000 inspect.py:159(isfunction)
        2    0.000    0.000    0.000    0.000 inspect.py:514(_is_wrapper)
        2    0.000    0.000    0.000    0.000 dataset.py:422(__len__)
        2    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}
        2    0.000    0.000    0.000    0.000 {built-in method builtins.id}
        1    0.000    0.000    0.000    0.000 dataloader.py:442(_auto_collation)
        2    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}
        2    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
        2    0.000    0.000    0.000    0.000 inspect.py:2865(parameters)
        2    0.000    0.000    0.000    0.000 {built-in method builtins.callable}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {method 'index' of 'tuple' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_train_start
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 callback.py:205(on_train_start)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}



Profile stats for: [Callback]TQDMProgressBar.on_train_start
         266 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.001    0.001 tqdm_progress.py:259(on_train_start)
        1    0.000    0.000    0.001    0.001 tqdm_progress.py:197(init_train_tqdm)
        1    0.000    0.000    0.001    0.001 tqdm_progress.py:40(__init__)
        1    0.000    0.000    0.001    0.001 std.py:952(__init__)
        1    0.000    0.000    0.001    0.001 std.py:1325(refresh)
        1    0.000    0.000    0.001    0.001 std.py:1464(display)
        1    0.000    0.000    0.000    0.000 std.py:457(print_status)
        1    0.000    0.000    0.000    0.000 std.py:451(fp_write)
        2    0.000    0.000    0.000    0.000 utils.py:194(inner)
        1    0.000    0.000    0.000    0.000 redirect.py:644(write)
        1    0.000    0.000    0.000    0.000 wandb_run.py:2304(<lambda>)
        1    0.000    0.000    0.000    0.000 wandb_run.py:390(wrapper_fn)
        1    0.000    0.000    0.000    0.000 wandb_run.py:1429(_console_raw_callback)
        1    0.000    0.000    0.000    0.000 interface.py:749(publish_output_raw)
        1    0.000    0.000    0.000    0.000 interface_shared.py:76(_publish_output_raw)
        2    0.000    0.000    0.000    0.000 utils.py:333(_screen_shape_linux)
        1    0.000    0.000    0.000    0.000 std.py:1150(__str__)
        1    0.000    0.000    0.000    0.000 interface_sock.py:45(_publish)
        1    0.000    0.000    0.000    0.000 sock_client.py:219(send_record_publish)
        1    0.000    0.000    0.000    0.000 std.py:464(format_meter)
        1    0.000    0.000    0.000    0.000 std.py:663(__new__)
        1    0.000    0.000    0.000    0.000 sock_client.py:153(send_server_request)
        1    0.000    0.000    0.000    0.000 sock_client.py:145(_send_message)
        1    0.000    0.000    0.000    0.000 utils.py:378(disp_len)
        1    0.000    0.000    0.000    0.000 well_known_types.py:172(GetCurrentTime)
        1    0.000    0.000    0.000    0.000 sock_client.py:121(_sendall_with_error_handle)
        1    0.000    0.000    0.000    0.000 utils.py:374(_text_width)
        2    0.000    0.000    0.000    0.000 utils.py:347(<listcomp>)
        1    0.000    0.000    0.000    0.000 well_known_types.py:242(FromDatetime)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.sum}
        2    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}
        3    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
        1    0.000    0.000    0.000    0.000 utils.py:213(__init__)
       44    0.000    0.000    0.000    0.000 utils.py:375(<genexpr>)
        1    0.000    0.000    0.000    0.000 std.py:1446(format_dict)
        1    0.000    0.000    0.000    0.000 {method 'send' of '_socket.socket' objects}
        2    0.000    0.000    0.000    0.000 std.py:110(__enter__)
        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:92(__getattr__)
        2    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
        2    0.000    0.000    0.000    0.000 os.py:674(__getitem__)
        3    0.000    0.000    0.000    0.000 std.py:102(acquire)
        1    0.000    0.000    0.000    0.000 std.py:438(status_printer)
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:173(is_disabled)
        1    0.000    0.000    0.000    0.000 _weakrefset.py:86(add)
        1    0.000    0.000    0.000    0.000 functools.py:392(__get__)
        2    0.000    0.000    0.000    0.000 utils.py:266(_supports_unicode)
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:169(is_enabled)
        1    0.000    0.000    0.000    0.000 {built-in method fromtimestamp}
        1    0.000    0.000    0.000    0.000 calendar.py:655(timegm)
        2    0.000    0.000    0.000    0.000 utils.py:187(disable_on_exception)
       13    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        1    0.000    0.000    0.000    0.000 utils.py:156(__init__)
        1    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
        2    0.000    0.000    0.000    0.000 std.py:113(__exit__)
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:127(train_progress_bar)
        1    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
        2    0.000    0.000    0.000    0.000 os.py:754(encode)
        3    0.000    0.000    0.000    0.000 std.py:106(release)
        1    0.000    0.000    0.000    0.000 std.py:400(format_interval)
        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
        3    0.000    0.000    0.000    0.000 std.py:226(__init__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 utils.py:273(_is_ascii)
       43    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 std.py:153(__init__)
        1    0.000    0.000    0.000    0.000 std.py:186(__format__)
        4    0.000    0.000    0.000    0.000 utils.py:222(__eq__)
        3    0.000    0.000    0.000    0.000 utils.py:152(wrapper_setattr)
        1    0.000    0.000    0.000    0.000 std.py:1147(__del__)
        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
        1    0.000    0.000    0.000    0.000 std.py:760(get_lock)
        1    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:161(refresh_rate)
        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)
        3    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)
        1    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
        2    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
        1    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}
        1    0.000    0.000    0.000    0.000 std.py:1157(__hash__)
        1    0.000    0.000    0.000    0.000 utils.py:252(_is_utf)
        3    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {built-in method utcnow}
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}
        1    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
        3    0.000    0.000    0.000    0.000 {built-in method builtins.len}
        1    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:165(process_position)
        1    0.000    0.000    0.000    0.000 utils.py:108(__init__)
        1    0.000    0.000    0.000    0.000 utils.py:282(_screen_shape_wrapper)
        3    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
        1    0.000    0.000    0.000    0.000 std.py:231(__call__)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
        3    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
        3    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
        1    0.000    0.000    0.000    0.000 utils.py:112(__format__)
        1    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.max}
        1    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
        1    0.000    0.000    0.000    0.000 {built-in method time.time}
        1    0.000    0.000    0.000    0.000 progress_bar.py:64(train_description)
        1    0.000    0.000    0.000    0.000 std.py:167(colour)
        1    0.000    0.000    0.000    0.000 std.py:163(colour)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 threading.py:536(is_set)
        1    0.000    0.000    0.000    0.000 std.py:1265(close)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.id}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}



Profile stats for: [Callback]ModelSummary.on_train_start
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 callback.py:205(on_train_start)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start
         11 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 model_checkpoint.py:280(on_train_start)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_train_start
         7 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 hooks.py:44(on_train_start)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Strategy]SingleDeviceStrategy.on_train_start
         7 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 strategy.py:545(on_train_start)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_train_epoch_start
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.001    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 callback.py:92(on_train_epoch_start)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_train_epoch_start
         145286 function calls in 0.087 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.002    0.000    0.086    0.000 tqdm_progress.py:263(on_train_epoch_start)
      400    0.001    0.000    0.082    0.000 std.py:1325(refresh)
      400    0.001    0.000    0.080    0.000 std.py:1464(display)
      200    0.001    0.000    0.053    0.000 std.py:1360(reset)
      400    0.001    0.000    0.043    0.000 std.py:1150(__str__)
      400    0.001    0.000    0.036    0.000 std.py:457(print_status)
      400    0.023    0.000    0.034    0.000 std.py:464(format_meter)
      200    0.000    0.000    0.030    0.000 std.py:1382(set_description)
      400    0.001    0.000    0.022    0.000 std.py:451(fp_write)
      800    0.000    0.000    0.022    0.000 utils.py:194(inner)
      400    0.000    0.000    0.018    0.000 redirect.py:644(write)
      400    0.000    0.000    0.017    0.000 wandb_run.py:2304(<lambda>)
      400    0.000    0.000    0.017    0.000 wandb_run.py:390(wrapper_fn)
      400    0.001    0.000    0.017    0.000 wandb_run.py:1429(_console_raw_callback)
      400    0.002    0.000    0.016    0.000 interface.py:749(publish_output_raw)
      400    0.000    0.000    0.012    0.000 utils.py:378(disp_len)
      400    0.000    0.000    0.012    0.000 utils.py:374(_text_width)
      400    0.003    0.000    0.011    0.000 {built-in method builtins.sum}
      400    0.001    0.000    0.010    0.000 interface_shared.py:76(_publish_output_raw)
      400    0.000    0.000    0.009    0.000 interface_sock.py:45(_publish)
      400    0.000    0.000    0.009    0.000 sock_client.py:219(send_record_publish)
    35243    0.006    0.000    0.009    0.000 utils.py:375(<genexpr>)
      400    0.001    0.000    0.008    0.000 std.py:1446(format_dict)
      400    0.000    0.000    0.008    0.000 sock_client.py:153(send_server_request)
      400    0.001    0.000    0.008    0.000 sock_client.py:145(_send_message)
      400    0.002    0.000    0.007    0.000 utils.py:333(_screen_shape_linux)
      400    0.001    0.000    0.006    0.000 sock_client.py:121(_sendall_with_error_handle)
      800    0.004    0.000    0.006    0.000 utils.py:273(_is_ascii)
      400    0.005    0.000    0.005    0.000 {method 'send' of '_socket.socket' objects}
      400    0.003    0.000    0.003    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
      400    0.003    0.000    0.003    0.000 {built-in method fcntl.ioctl}
      800    0.002    0.000    0.003    0.000 {method 'format' of 'str' objects}
    34843    0.003    0.000    0.003    0.000 {built-in method unicodedata.east_asian_width}
      400    0.000    0.000    0.003    0.000 well_known_types.py:172(GetCurrentTime)
      400    0.001    0.000    0.002    0.000 well_known_types.py:242(FromDatetime)
    34800    0.002    0.000    0.002    0.000 {built-in method builtins.ord}
      400    0.000    0.000    0.001    0.000 utils.py:347(<listcomp>)
      400    0.001    0.000    0.001    0.000 os.py:674(__getitem__)
      400    0.001    0.000    0.001    0.000 std.py:186(__format__)
      400    0.001    0.000    0.001    0.000 std.py:400(format_interval)
      400    0.001    0.000    0.001    0.000 enum_type_wrapper.py:92(__getattr__)
      400    0.001    0.000    0.001    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
      400    0.000    0.000    0.001    0.000 std.py:102(acquire)
      400    0.001    0.000    0.001    0.000 {built-in method fromtimestamp}
      400    0.001    0.000    0.001    0.000 calendar.py:655(timegm)
      400    0.001    0.000    0.001    0.000 std.py:106(release)
      200    0.000    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.001    0.000 tqdm_progress.py:440(convert_inf)
      400    0.000    0.000    0.001    0.000 std.py:153(__init__)
      400    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
      200    0.000    0.000    0.000    0.000 progress_bar.py:80(total_train_batches)
      400    0.000    0.000    0.000    0.000 os.py:754(encode)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      800    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
      400    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      400    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
      400    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      400    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
      400    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
      800    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
     1200    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
      400    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      400    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
      600    0.000    0.000    0.000    0.000 std.py:226(__init__)
      400    0.000    0.000    0.000    0.000 {built-in method utcnow}
     1200    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
      200    0.000    0.000    0.000    0.000 {built-in method math.isinf}
      400    0.000    0.000    0.000    0.000 {built-in method builtins.max}
      400    0.000    0.000    0.000    0.000 std.py:231(__call__)
     1200    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      600    0.000    0.000    0.000    0.000 tqdm_progress.py:121(train_progress_bar)
      400    0.000    0.000    0.000    0.000 utils.py:112(__format__)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
     1200    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
      200    0.000    0.000    0.000    0.000 progress_bar.py:54(trainer)
      400    0.000    0.000    0.000    0.000 utils.py:108(__init__)
      600    0.000    0.000    0.000    0.000 {built-in method time.time}
      400    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
      800    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      400    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
      200    0.000    0.000    0.000    0.000 trainer.py:1467(current_epoch)
      400    0.000    0.000    0.000    0.000 std.py:167(colour)
      400    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
      400    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
      400    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      400    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      200    0.000    0.000    0.000    0.000 {built-in method math.isnan}
      400    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
      400    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
      400    0.000    0.000    0.000    0.000 std.py:163(colour)
      200    0.000    0.000    0.000    0.000 trainer.py:1523(num_training_batches)
      400    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_train_epoch_start
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 callback.py:92(on_train_epoch_start)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 callback.py:92(on_train_epoch_start)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_train_epoch_start
         28600 function calls in 0.027 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.001    0.000    0.026    0.000 FlavourClassificationTransformerEncoder.py:133(on_train_epoch_start)
      400    0.001    0.000    0.025    0.000 __init__.py:1436(info)
      400    0.001    0.000    0.024    0.000 __init__.py:1565(_log)
      400    0.000    0.000    0.017    0.000 __init__.py:1591(handle)
      400    0.001    0.000    0.016    0.000 __init__.py:1645(callHandlers)
      400    0.000    0.000    0.016    0.000 __init__.py:939(handle)
      400    0.000    0.000    0.015    0.000 __init__.py:1178(emit)
      400    0.001    0.000    0.014    0.000 __init__.py:1071(emit)
      400    0.000    0.000    0.010    0.000 __init__.py:1060(flush)
      400    0.009    0.000    0.009    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
      400    0.000    0.000    0.006    0.000 __init__.py:1550(makeRecord)
      400    0.003    0.000    0.005    0.000 __init__.py:282(__init__)
      400    0.000    0.000    0.004    0.000 __init__.py:916(format)
      400    0.001    0.000    0.004    0.000 __init__.py:650(format)
      400    0.001    0.000    0.002    0.000 __init__.py:582(formatTime)
      400    0.001    0.000    0.001    0.000 __init__.py:1514(findCaller)
      400    0.000    0.000    0.001    0.000 posixpath.py:117(splitext)
      400    0.001    0.000    0.001    0.000 {built-in method time.strftime}
      400    0.000    0.000    0.001    0.000 posixpath.py:140(basename)
      400    0.000    0.000    0.001    0.000 module.py:262(current_epoch)
      400    0.000    0.000    0.001    0.000 __init__.py:634(formatMessage)
      400    0.001    0.000    0.001    0.000 {built-in method time.localtime}
      400    0.000    0.000    0.001    0.000 genericpath.py:121(_splitext)
      400    0.000    0.000    0.000    0.000 __init__.py:432(format)
      800    0.000    0.000    0.000    0.000 __init__.py:896(acquire)
      400    0.000    0.000    0.000    0.000 __init__.py:628(usesTime)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      400    0.000    0.000    0.000    0.000 __init__.py:429(_format)
      800    0.000    0.000    0.000    0.000 __init__.py:903(release)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      400    0.000    0.000    0.000    0.000 __init__.py:421(usesTime)
      400    0.000    0.000    0.000    0.000 __init__.py:160(<lambda>)
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
     1200    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}
      400    0.000    0.000    0.000    0.000 threading.py:1358(current_thread)
     1200    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      400    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      400    0.000    0.000    0.000    0.000 __init__.py:119(getLevelName)
      400    0.000    0.000    0.000    0.000 module.py:215(trainer)
      800    0.000    0.000    0.000    0.000 __init__.py:791(filter)
      400    0.000    0.000    0.000    0.000 posixpath.py:52(normcase)
      400    0.000    0.000    0.000    0.000 trainer.py:1467(current_epoch)
      800    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
      400    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)
      400    0.000    0.000    0.000    0.000 __init__.py:358(getMessage)
     1000    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      400    0.000    0.000    0.000    0.000 __init__.py:1689(isEnabledFor)
     1200    0.000    0.000    0.000    0.000 {built-in method posix.fspath}
      800    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
      400    0.000    0.000    0.000    0.000 threading.py:1093(name)
      400    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}
      400    0.000    0.000    0.000    0.000 {built-in method sys._getframe}
      800    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
      400    0.000    0.000    0.000    0.000 {built-in method time.time}
      800    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
      400    0.000    0.000    0.000    0.000 process.py:189(name)
      400    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      400    0.000    0.000    0.000    0.000 process.py:37(current_process)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: run_training_epoch
         926429 function calls (923292 primitive calls) in 103.078 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.003    0.000  103.078    0.515 training_epoch_loop.py:135(run)
    23284    0.027    0.000   67.509    0.003 {built-in method builtins.next}
      200    0.004    0.000   67.219    0.336 training_epoch_loop.py:192(advance)
      200    0.000    0.000   67.201    0.336 fetchers.py:119(__next__)
      200    0.000    0.000   67.201    0.336 fetchers.py:55(__next__)
      200    0.004    0.000   67.200    0.336 training_epoch_loop.py:186(_on_before_fetch)
      200    0.002    0.000   67.196    0.336 advanced.py:65(start)
      200   67.193    0.336   67.193    0.336 {method 'enable' of '_lsprof.Profiler' objects}
      200    0.005    0.000   35.823    0.179 training_epoch_loop.py:176(on_run_start)
 1194/199    0.006    0.000   35.818    0.180 {built-in method builtins.iter}
      199    0.001    0.000   35.817    0.180 fetchers.py:102(__iter__)
      199    0.003    0.000   35.816    0.180 fetchers.py:49(__iter__)
      199    0.066    0.000   35.792    0.180 combined_loader.py:347(__iter__)
      199    0.002    0.000   28.575    0.144 combined_loader.py:90(__iter__)
      199    0.005    0.000   28.573    0.144 combined_loader.py:41(__iter__)
      199    0.001    0.000   28.569    0.144 combined_loader.py:43(<listcomp>)
      199    0.001    0.000   28.566    0.144 dataloader.py:427(__iter__)
      199    0.002    0.000   28.565    0.144 dataloader.py:383(_get_iterator)
      199    0.137    0.001   28.561    0.144 dataloader.py:989(__init__)
     1592    0.067    0.000   26.866    0.017 process.py:110(start)
     1592    0.016    0.000   26.658    0.017 context.py:222(_Popen)
     1592    0.032    0.000   26.642    0.017 context.py:274(_Popen)
     1592    0.018    0.000   26.608    0.017 popen_fork.py:15(__init__)
     1592    0.095    0.000   26.563    0.017 popen_fork.py:62(_launch)
     1592   26.320    0.017   26.353    0.017 {built-in method posix.fork}
      199    0.001    0.000    7.125    0.036 dataloader.py:1476(__del__)
      199    0.017    0.000    7.124    0.036 dataloader.py:1399(_shutdown_workers)
     1592    0.005    0.000    6.601    0.004 process.py:142(join)
     1592    0.007    0.000    6.594    0.004 popen_fork.py:36(wait)
     1592    0.006    0.000    6.553    0.004 connection.py:921(wait)
     1592    0.005    0.000    6.530    0.004 selectors.py:403(select)
     1592    6.509    0.004    6.520    0.004 {method 'poll' of 'select.poll' objects}
     1791    0.102    0.000    1.133    0.001 context.py:100(Queue)
     1791    0.091    0.000    1.006    0.001 queues.py:37(__init__)
     6368    0.345    0.000    0.721    0.000 synchronize.py:50(__init__)
     3781    0.031    0.000    0.640    0.000 context.py:65(Lock)
     3781    0.020    0.000    0.604    0.000 synchronize.py:161(__init__)
     1990    0.008    0.000    0.455    0.000 threading.py:880(start)
     1990    0.009    0.000    0.454    0.000 queues.py:86(put)
     1791    0.027    0.000    0.422    0.000 queues.py:161(_start_thread)
    12139    0.382    0.000    0.382    0.000 {method 'acquire' of '_thread.lock' objects}
     1990    0.006    0.000    0.360    0.000 threading.py:563(wait)
     1990    0.008    0.000    0.352    0.000 threading.py:280(wait)
     1592    0.003    0.000    0.331    0.000 dataloader.py:1373(_mark_worker_as_unavailable)
     6368    0.031    0.000    0.278    0.000 synchronize.py:114(_make_name)
     6368    0.067    0.000    0.225    0.000 tempfile.py:149(__next__)
     1592    0.076    0.000    0.133    0.000 process.py:61(_cleanup)
     6368    0.021    0.000    0.132    0.000 tempfile.py:152(<listcomp>)
      199    0.007    0.000    0.129    0.001 dataloader.py:1085(_reset)
     1791    0.009    0.000    0.115    0.000 context.py:85(BoundedSemaphore)
     3184    0.004    0.000    0.112    0.000 dataloader.py:1346(_try_put_index)
    50944    0.061    0.000    0.111    0.000 random.py:343(choice)
     1791    0.001    0.000    0.104    0.000 synchronize.py:144(__init__)
     8159    0.017    0.000    0.098    0.000 util.py:171(register_after_fork)
     3582    0.087    0.000    0.094    0.000 util.py:186(__init__)
     1791    0.032    0.000    0.092    0.000 connection.py:520(Pipe)
    34228    0.027    0.000    0.091    0.000 popen_fork.py:24(poll)
     1990    0.087    0.000    0.087    0.000 {built-in method _thread.start_new_thread}
     8159    0.043    0.000    0.078    0.000 weakref.py:165(__setitem__)
     1791    0.048    0.000    0.069    0.000 queues.py:71(_reset)
    32636    0.061    0.000    0.061    0.000 {built-in method posix.waitpid}
     3184    0.001    0.000    0.057    0.000 dataloader.py:619(_next_index)
      597    0.005    0.000    0.056    0.000 sampler.py:275(__iter__)
     1592    0.033    0.000    0.055    0.000 process.py:80(__init__)
     4975    0.019    0.000    0.051    0.000 sampler.py:153(__iter__)
     1990    0.021    0.000    0.050    0.000 threading.py:802(__init__)
     4975    0.048    0.000    0.048    0.000 {built-in method posix.pipe}
      199    0.001    0.000    0.048    0.000 context.py:90(Event)
      199    0.001    0.000    0.047    0.000 synchronize.py:323(__init__)
    50944    0.033    0.000    0.045    0.000 random.py:237(_randbelow_with_getrandbits)
      199    0.001    0.000    0.044    0.000 threading.py:1028(join)
      199    0.001    0.000    0.043    0.000 threading.py:1066(_wait_for_tstate_lock)
     4577    0.041    0.000    0.041    0.000 threading.py:228(__init__)
      796    0.002    0.000    0.036    0.000 context.py:80(Semaphore)
     3383    0.012    0.000    0.036    0.000 util.py:205(__call__)
      796    0.000    0.000    0.033    0.000 synchronize.py:125(__init__)
     1592    0.022    0.000    0.032    0.000 __init__.py:227(_releaseLock)
    11940    0.023    0.000    0.030    0.000 <frozen importlib._bootstrap>:398(parent)
      199    0.001    0.000    0.028    0.000 context.py:75(Condition)
      200    0.001    0.000    0.028    0.000 training_epoch_loop.py:116(done)
      199    0.001    0.000    0.027    0.000 synchronize.py:212(__init__)
      200    0.006    0.000    0.027    0.000 training_epoch_loop.py:106(_is_training_done)
     1592    0.015    0.000    0.027    0.000 util.py:433(_flush_std_streams)
     3582    0.026    0.000    0.026    0.000 connection.py:121(__init__)
     2189    0.006    0.000    0.026    0.000 threading.py:528(__init__)
     6368    0.025    0.000    0.025    0.000 {built-in method posix.close}
     1791    0.002    0.000    0.024    0.000 queues.py:140(close)
     6368    0.017    0.000    0.022    0.000 tempfile.py:138(rng)
     8159    0.013    0.000    0.022    0.000 weakref.py:348(__new__)
54924/53133    0.011    0.000    0.021    0.000 {built-in method builtins.len}
      199    0.002    0.000    0.020    0.000 fetchers.py:139(reset)
1290/1138    0.001    0.000    0.019    0.000 signal_handling.py:64(handler)
     1290    0.018    0.000    0.018    0.000 {built-in method torch._C._error_if_any_worker_fails}
      200    0.010    0.000    0.018    0.000 training_epoch_loop.py:99(global_step)
      199    0.006    0.000    0.018    0.000 fetchers.py:71(reset)
     8177    0.011    0.000    0.018    0.000 {built-in method builtins.isinstance}
      199    0.005    0.000    0.014    0.000 dataloader.py:564(__init__)
     1791    0.003    0.000    0.014    0.000 queues.py:204(_finalize_close)
     8159    0.013    0.000    0.013    0.000 weakref.py:353(__init__)
      199    0.007    0.000    0.013    0.000 queue.py:34(__init__)
  398/199    0.000    0.000    0.012    0.000 data.py:47(sized_len)
     3582    0.007    0.000    0.012    0.000 _weakrefset.py:86(add)
    21492    0.012    0.000    0.012    0.000 {built-in method posix.getpid}
      200    0.003    0.000    0.011    0.000 loop.py:32(restarting)
      199    0.001    0.000    0.011    0.000 combined_loader.py:355(__len__)
     3980    0.005    0.000    0.011    0.000 threading.py:351(notify)
     3184    0.011    0.000    0.011    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
      398    0.011    0.000    0.011    0.000 {built-in method torch.empty}
     7960    0.009    0.000    0.011    0.000 {method 'join' of 'str' objects}
     5174    0.011    0.000    0.011    0.000 {method 'add' of 'set' objects}
      199    0.003    0.000    0.011    0.000 dataloader.py:609(_reset)
      199    0.002    0.000    0.010    0.000 combined_loader.py:96(__len__)
     5970    0.004    0.000    0.010    0.000 threading.py:256(__enter__)
      199    0.003    0.000    0.010    0.000 synchronize.py:334(set)
     1592    0.010    0.000    0.010    0.000 {method 'release' of '_thread.RLock' objects}
     9751    0.009    0.000    0.009    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
      398    0.009    0.000    0.009    0.000 {built-in method torch.randperm}
     1592    0.001    0.000    0.009    0.000 util.py:461(close_fds)
     1592    0.002    0.000    0.008    0.000 selectors.py:352(register)
     1592    0.002    0.000    0.008    0.000 synchronize.py:327(is_set)
    87786    0.008    0.000    0.008    0.000 {method 'getrandbits' of '_random.Random' objects}
     3383    0.007    0.000    0.008    0.000 queues.py:153(cancel_join_thread)
      398    0.008    0.000    0.008    0.000 {method 'random_' of 'torch._C.TensorBase' objects}
     1791    0.002    0.000    0.008    0.000 dataloader.py:1080(<genexpr>)
      199    0.001    0.000    0.007    0.000 combined_loader.py:404(_get_iterables_lengths)
    11940    0.007    0.000    0.007    0.000 {method 'rpartition' of 'str' objects}
      996    0.001    0.000    0.007    0.000 abc.py:117(__instancecheck__)
      199    0.000    0.000    0.007    0.000 combined_loader.py:405(<listcomp>)
     4378    0.006    0.000    0.006    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
     5970    0.006    0.000    0.006    0.000 {method '__enter__' of '_thread.lock' objects}
     4975    0.004    0.000    0.006    0.000 weakref.py:106(remove)
      996    0.006    0.000    0.006    0.000 {built-in method _abc._abc_instancecheck}
     5771    0.006    0.000    0.006    0.000 {method 'append' of 'collections.deque' objects}
     1791    0.002    0.000    0.006    0.000 synchronize.py:229(__enter__)
     1592    0.005    0.000    0.006    0.000 process.py:234(ident)
      199    0.002    0.000    0.006    0.000 __init__.py:876(current_device)
     1592    0.003    0.000    0.005    0.000 selectors.py:235(register)
     1592    0.005    0.000    0.005    0.000 {method 'copy' of 'dict' objects}
     6169    0.005    0.000    0.005    0.000 {built-in method _thread.allocate_lock}
      200    0.002    0.000    0.005    0.000 training_epoch_loop.py:147(reset)
     5970    0.002    0.000    0.005    0.000 threading.py:259(__exit__)
      199    0.005    0.000    0.005    0.000 {built-in method torch._C._set_worker_pids}
      200    0.004    0.000    0.005    0.000 trainer.py:1178(lightning_module)
      199    0.002    0.000    0.004    0.000 dataloader.py:458(__len__)
     3582    0.004    0.000    0.004    0.000 context.py:233(get_context)
     4179    0.004    0.000    0.004    0.000 {method 'release' of '_thread.lock' objects}
      199    0.004    0.000    0.004    0.000 {built-in method torch._C._remove_worker_pids}
     1990    0.004    0.000    0.004    0.000 threading.py:1229(_make_invoke_excepthook)
     1592    0.002    0.000    0.004    0.000 selectors.py:348(__init__)
    50944    0.004    0.000    0.004    0.000 {method 'bit_length' of 'int' objects}
     6368    0.004    0.000    0.004    0.000 synchronize.py:90(_make_methods)
      199    0.001    0.000    0.004    0.000 synchronize.py:296(notify_all)
     1791    0.001    0.000    0.004    0.000 synchronize.py:94(__enter__)
     5970    0.002    0.000    0.004    0.000 threading.py:271(_is_owned)
     2388    0.003    0.000    0.003    0.000 threading.py:1358(current_thread)
     4776    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}
     5970    0.003    0.000    0.003    0.000 {method '__exit__' of '_thread.lock' objects}
      200    0.002    0.000    0.003    0.000 training_epoch_loop.py:331(_num_ready_batches_reached)
     1592    0.002    0.000    0.003    0.000 process.py:153(is_alive)
     1791    0.003    0.000    0.003    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}
     6368    0.003    0.000    0.003    0.000 {built-in method builtins.getattr}
    16915    0.003    0.000    0.003    0.000 util.py:48(debug)
      200    0.001    0.000    0.003    0.000 progress.py:204(reset_on_run)
     1990    0.002    0.000    0.002    0.000 threading.py:1162(daemon)
      200    0.002    0.000    0.002    0.000 progress.py:274(optimizer_steps)
     1592    0.001    0.000    0.002    0.000 selectors.py:203(__exit__)
      800    0.002    0.000    0.002    0.000 progress.py:172(reset_on_run)
     1791    0.001    0.000    0.002    0.000 synchronize.py:232(__exit__)
     8557    0.002    0.000    0.002    0.000 {built-in method builtins.id}
     4975    0.002    0.000    0.002    0.000 {built-in method _weakref._remove_dead_weakref}
      398    0.002    0.000    0.002    0.000 {method 'item' of 'torch._C.TensorBase' objects}
      199    0.002    0.000    0.002    0.000 {built-in method torch._C._cuda_getDevice}
      199    0.001    0.000    0.002    0.000 synchronize.py:270(notify)
      199    0.001    0.000    0.002    0.000 sampler.py:298(__len__)
      199    0.002    0.000    0.002    0.000 {built-in method torch._C._get_privateuse1_backend_name}
      199    0.001    0.000    0.002    0.000 dataloader.py:487(check_worker_number_rationality)
     1990    0.001    0.000    0.002    0.000 _weakrefset.py:39(_remove)
     3184    0.002    0.000    0.002    0.000 process.py:94(<genexpr>)
     1990    0.001    0.000    0.002    0.000 threading.py:268(_acquire_restore)
      199    0.002    0.000    0.002    0.000 queue.py:206(_init)
      199    0.000    0.000    0.002    0.000 __init__.py:115(is_available)
      199    0.001    0.000    0.002    0.000 combined_loader.py:68(__init__)
      199    0.000    0.000    0.002    0.000 threading.py:542(set)
      199    0.001    0.000    0.002    0.000 __init__.py:284(_lazy_init)
      199    0.002    0.000    0.002    0.000 threading.py:757(_newname)
     1592    0.001    0.000    0.002    0.000 selectors.py:216(_fileobj_lookup)
     1592    0.001    0.000    0.002    0.000 selectors.py:210(__init__)
     1592    0.001    0.000    0.002    0.000 selectors.py:269(close)
     1592    0.001    0.000    0.002    0.000 __init__.py:218(_acquireLock)
     5174    0.001    0.000    0.001    0.000 {method 'discard' of 'set' objects}
      796    0.001    0.000    0.001    0.000 dataset.py:422(__len__)
      199    0.001    0.000    0.001    0.000 signal_handling.py:48(_set_SIGCHLD_handler)
      199    0.001    0.000    0.001    0.000 dataloader.py:94(_get_distributed_settings)
     1791    0.001    0.000    0.001    0.000 synchronize.py:97(__exit__)
      597    0.000    0.000    0.001    0.000 sampler.py:146(num_samples)
      200    0.001    0.000    0.001    0.000 {built-in method builtins.vars}
      199    0.000    0.000    0.001    0.000 __init__.py:111(_nvml_based_avail)
     1592    0.001    0.000    0.001    0.000 selectors.py:276(_key_from_fd)
     6567    0.001    0.000    0.001    0.000 context.py:187(get_context)
     6368    0.001    0.000    0.001    0.000 context.py:197(get_start_method)
      398    0.001    0.000    0.001    0.000 {method 'tolist' of 'torch._C.TensorBase' objects}
     1592    0.001    0.000    0.001    0.000 <string>:1(<lambda>)
     6368    0.001    0.000    0.001    0.000 process.py:99(_check_closed)
      199    0.001    0.000    0.001    0.000 combined_loader.py:29(__init__)
      199    0.000    0.000    0.001    0.000 os.py:771(getenv)
     1592    0.001    0.000    0.001    0.000 selectors.py:21(_fileobj_to_fd)
      200    0.001    0.000    0.001    0.000 trainer.py:1125(strategy)
      199    0.001    0.000    0.001    0.000 {built-in method posix.sched_getaffinity}
      199    0.000    0.000    0.001    0.000 sampler.py:171(__len__)
     6368    0.001    0.000    0.001    0.000 process.py:37(current_process)
      199    0.000    0.000    0.001    0.000 _collections_abc.py:760(get)
     1990    0.001    0.000    0.001    0.000 threading.py:265(_release_save)
      199    0.001    0.000    0.001    0.000 __init__.py:237(is_initialized)
      200    0.000    0.000    0.001    0.000 progress.py:282(reset_on_run)
      400    0.000    0.000    0.001    0.000 progress.py:114(reset)
      199    0.000    0.000    0.001    0.000 os.py:674(__getitem__)
      199    0.001    0.000    0.001    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}
      200    0.001    0.000    0.001    0.000 trainer.py:1523(num_training_batches)
      200    0.001    0.000    0.001    0.000 module.py:295(automatic_optimization)
     2189    0.001    0.000    0.001    0.000 threading.py:1147(daemon)
      599    0.001    0.000    0.001    0.000 loop.py:27(restarting)
      199    0.000    0.000    0.001    0.000 threading.py:992(_stop)
      199    0.000    0.000    0.001    0.000 {built-in method builtins.max}
      199    0.001    0.000    0.001    0.000 util.py:229(cancel)
     1592    0.001    0.000    0.001    0.000 connection.py:937(<listcomp>)
      199    0.001    0.000    0.001    0.000 dataloader.py:390(multiprocessing_context)
      199    0.000    0.000    0.001    0.000 threading.py:381(notify_all)
     1592    0.001    0.000    0.001    0.000 {built-in method math.ceil}
      600    0.000    0.000    0.001    0.000 progress.py:87(reset)
      200    0.000    0.000    0.001    0.000 progress.py:249(reset_on_run)
     4179    0.001    0.000    0.001    0.000 threading.py:536(is_set)
     1592    0.001    0.000    0.001    0.000 {built-in method select.poll}
     1592    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
     2388    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
     3383    0.000    0.000    0.000    0.000 util.py:44(sub_debug)
     1592    0.000    0.000    0.000    0.000 selectors.py:64(__init__)
     1592    0.000    0.000    0.000    0.000 process.py:205(daemon)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      199    0.000    0.000    0.000    0.000 dataloader.py:1101(<listcomp>)
      398    0.000    0.000    0.000    0.000 dataloader.py:446(_index_sampler)
     1592    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
     1592    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}
     1592    0.000    0.000    0.000    0.000 process.py:189(name)
      995    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
     1791    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}
      398    0.000    0.000    0.000    0.000 combined_loader.py:100(<genexpr>)
     1592    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1000    0.000    0.000    0.000    0.000 progress.py:56(reset)
     1791    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
     1990    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}
      199    0.000    0.000    0.000    0.000 distributed_c10d.py:996(is_initialized)
     1592    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}
     1990    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}
     1791    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}
     1592    0.000    0.000    0.000    0.000 {built-in method posix.waitstatus_to_exitcode}
      199    0.000    0.000    0.000    0.000 os.py:754(encode)
      398    0.000    0.000    0.000    0.000 __init__.py:106(_is_compiled)
      597    0.000    0.000    0.000    0.000 dataloader.py:442(_auto_collation)
     1592    0.000    0.000    0.000    0.000 selectors.py:200(__enter__)
      199    0.000    0.000    0.000    0.000 __init__.py:834(device_count)
      199    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isInBadFork}
      398    0.000    0.000    0.000    0.000 connection.py:134(__del__)
      199    0.000    0.000    0.000    0.000 distributed_c10d.py:608(WORLD)
      199    0.000    0.000    0.000    0.000 os.py:758(decode)
      398    0.000    0.000    0.000    0.000 fetchers.py:38(combined_loader)
      199    0.000    0.000    0.000    0.000 __init__.py:10(is_available)
      199    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)
      200    0.000    0.000    0.000    0.000 utilities.py:113(_is_max_limit_reached)
      199    0.000    0.000    0.000    0.000 {built-in method builtins.min}
      200    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}
      199    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}
      199    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
      199    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}
      200    0.000    0.000    0.000    0.000 trainer.py:1467(current_epoch)
      199    0.000    0.000    0.000    0.000 distributed_c10d.py:480(default_pg)
      199    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}
      199    0.000    0.000    0.000    0.000 combined_loader.py:308(flattened)



Profile stats for: [_TrainingEpochLoop].train_dataloader_next
         20017 function calls (18417 primitive calls) in 0.181 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
  800/200    0.001    0.000    0.180    0.001 {built-in method builtins.next}
      200    0.002    0.000    0.180    0.001 combined_loader.py:339(__next__)
      200    0.001    0.000    0.172    0.001 combined_loader.py:72(__next__)
      200    0.011    0.000    0.171    0.001 dataloader.py:625(__next__)
      200    0.006    0.000    0.083    0.000 profiler.py:687(__enter__)
      200    0.001    0.000    0.077    0.000 _ops.py:1047(__call__)
      200    0.076    0.000    0.076    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
      200    0.006    0.000    0.034    0.000 profiler.py:693(__exit__)
      200    0.001    0.000    0.033    0.000 dataloader.py:1297(_next_data)
      200    0.002    0.000    0.031    0.000 dataloader.py:1264(_get_data)
      200    0.002    0.000    0.028    0.000 _ops.py:887(__call__)
      200    0.000    0.000    0.028    0.000 dataloader.py:1118(_try_get_data)
      200    0.002    0.000    0.027    0.000 queue.py:154(get)
      404    0.024    0.000    0.024    0.000 {method 'acquire' of '_thread.lock' objects}
        1    0.000    0.000    0.024    0.024 threading.py:280(wait)
      200    0.003    0.000    0.019    0.000 _ops.py:943(_must_dispatch_in_python)
      200    0.002    0.000    0.016    0.000 _pytree.py:1181(tree_any)
      200    0.000    0.000    0.014    0.000 {built-in method builtins.any}
 1400/400    0.006    0.000    0.011    0.000 _pytree.py:874(tree_iter)
      200    0.007    0.000    0.010    0.000 profiler.py:676(__init__)
      200    0.007    0.000    0.007    0.000 {built-in method torch._ops.profiler.}
      800    0.001    0.000    0.004    0.000 _pytree.py:656(_is_leaf)
      200    0.001    0.000    0.004    0.000 _pytree.py:862(tree_unflatten)
      200    0.003    0.000    0.003    0.000 _ops.py:945(<lambda>)
     1400    0.001    0.000    0.003    0.000 _pytree.py:649(_get_node_type)
      200    0.003    0.000    0.003    0.000 _pytree.py:785(unflatten)
      200    0.002    0.000    0.002    0.000 typing.py:271(inner)
     1000    0.000    0.000    0.002    0.000 {built-in method builtins.isinstance}
     1400    0.002    0.000    0.002    0.000 _pytree.py:638(_is_namedtuple_instance)
      200    0.000    0.000    0.002    0.000 abc.py:117(__instancecheck__)
      200    0.002    0.000    0.002    0.000 {built-in method _abc._abc_instancecheck}
      200    0.001    0.000    0.001    0.000 threading.py:1133(is_alive)
      200    0.001    0.000    0.001    0.000 training_epoch_loop.py:189(_on_after_fetch)
      200    0.000    0.000    0.001    0.000 dataloader.py:1366(_process_data)
      200    0.001    0.000    0.001    0.000 dataloader.py:1346(_try_put_index)
      200    0.000    0.000    0.000    0.000 _pytree.py:423(_dict_flatten)
      200    0.000    0.000    0.000    0.000 threading.py:1066(_wait_for_tstate_lock)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 threading.py:351(notify)
     2401    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      200    0.000    0.000    0.000    0.000 queue.py:217(_get)
      200    0.000    0.000    0.000    0.000 threading.py:256(__enter__)
      400    0.000    0.000    0.000    0.000 _pytree.py:395(_tuple_flatten)
      201    0.000    0.000    0.000    0.000 queue.py:209(_qsize)
      200    0.000    0.000    0.000    0.000 dataloader.py:619(_next_index)
      201    0.000    0.000    0.000    0.000 threading.py:271(_is_owned)
      200    0.000    0.000    0.000    0.000 threading.py:536(is_set)
      200    0.000    0.000    0.000    0.000 threading.py:259(__exit__)
      200    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)
      200    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}
      200    0.000    0.000    0.000    0.000 __init__.py:129(annotate)
      200    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}
      200    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}
      200    0.000    0.000    0.000    0.000 _pytree.py:701(is_leaf)
      201    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)
        1    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}
        1    0.000    0.000    0.000    0.000 _collections_abc.py:283(__subclasshook__)
        1    0.000    0.000    0.000    0.000 threading.py:268(_acquire_restore)
        1    0.000    0.000    0.000    0.000 threading.py:265(_release_save)
        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}
        1    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_train_batch_start
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 callback.py:76(on_train_batch_start)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_train_batch_start
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 callback.py:76(on_train_batch_start)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_train_batch_start
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 callback.py:76(on_train_batch_start)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.001    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.001    0.000 profiler.py:55(profile)
      200    0.001    0.000    0.001    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 callback.py:76(on_train_batch_start)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_train_batch_start
         1400 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.001    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.001    0.000 profiler.py:55(profile)
      200    0.001    0.000    0.001    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 hooks.py:68(on_train_batch_start)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Strategy]SingleDeviceStrategy.on_train_batch_start
         1400 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 strategy.py:577(on_train_batch_start)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: run_training_batch
         11800 function calls (11600 primitive calls) in 18.677 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.003    0.000   18.675    0.093 automatic.py:161(run)
      200    0.002    0.000   18.662    0.093 automatic.py:243(_optimizer_step)
      200    0.001    0.000   18.659    0.093 call.py:137(_call_lightning_module_hook)
      200    0.000    0.000   18.656    0.093 contextlib.py:114(__enter__)
      200    0.000    0.000   18.656    0.093 {built-in method builtins.next}
      200    0.000    0.000   18.656    0.093 profiler.py:55(profile)
      200    0.001    0.000   18.656    0.093 advanced.py:65(start)
      200   18.655    0.093   18.655    0.093 {method 'enable' of '_lsprof.Profiler' objects}
      200    0.003    0.000    0.010    0.000 automatic.py:197(_make_closure)
      200    0.002    0.000    0.004    0.000 automatic.py:115(__init__)
      200    0.002    0.000    0.002    0.000 automatic.py:228(_make_backward_fn)
      200    0.002    0.000    0.002    0.000 closure.py:41(__init__)
      200    0.001    0.000    0.001    0.000 automatic.py:209(_make_zero_grad_fn)
      200    0.000    0.000    0.001    0.000 trainer.py:1183(optimizers)
      400    0.000    0.000    0.001    0.000 fit_loop.py:427(_should_accumulate)
      200    0.000    0.000    0.001    0.000 module.py:1731(__setattr__)
      200    0.001    0.000    0.001    0.000 strategy.py:101(optimizers)
      400    0.000    0.000    0.001    0.000 training_epoch_loop.py:336(_should_accumulate)
  600/400    0.000    0.000    0.001    0.000 {built-in method builtins.isinstance}
      200    0.000    0.000    0.000    0.000 parameter.py:8(__instancecheck__)
      400    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 contextlib.py:261(helper)
      400    0.000    0.000    0.000    0.000 training_epoch_loop.py:331(_num_ready_batches_reached)
      200    0.000    0.000    0.000    0.000 contextlib.py:86(__init__)
     1400    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 __init__.py:1424(debug)
      400    0.000    0.000    0.000    0.000 training_epoch_loop.py:327(_accumulated_batches_reached)
      200    0.000    0.000    0.000    0.000 automatic.py:205(_make_step_fn)
      400    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
      200    0.000    0.000    0.000    0.000 progress.py:142(increment_ready)
      200    0.000    0.000    0.000    0.000 trainer.py:1467(current_epoch)
      600    0.000    0.000    0.000    0.000 strategy.py:468(handles_gradient_accumulation)
      200    0.000    0.000    0.000    0.000 module.py:295(automatic_optimization)
      400    0.000    0.000    0.000    0.000 trainer.py:1523(num_training_batches)
      200    0.000    0.000    0.000    0.000 __init__.py:1689(isEnabledFor)
      400    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      600    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x7f133e5c8040}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.callable}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.optimizer_step
         18600 function calls (18400 primitive calls) in 18.650 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.002    0.000   18.650    0.093 module.py:1277(optimizer_step)
      200    0.002    0.000   18.648    0.093 optimizer.py:84(step)
      200    0.002    0.000   18.646    0.093 strategy.py:219(optimizer_step)
      200    0.003    0.000   18.644    0.093 precision.py:112(optimizer_step)
      200    0.009    0.000   18.641    0.093 optimizer.py:464(wrapper)
      200    0.008    0.000   18.627    0.093 optimizer.py:70(_use_grad)
      200    0.006    0.000   18.618    0.093 adam.py:192(step)
      200    0.000    0.000   18.590    0.093 precision.py:95(_wrap_closure)
      200    0.001    0.000   18.590    0.093 automatic.py:142(__call__)
      200    0.001    0.000   18.589    0.093 _contextlib.py:113(decorate_context)
      200    0.000    0.000   18.587    0.093 automatic.py:126(closure)
      200    0.000    0.000   18.587    0.093 automatic.py:305(_training_step)
      200    0.001    0.000   18.586    0.093 call.py:294(_call_strategy_hook)
      200    0.000    0.000   18.583    0.093 contextlib.py:114(__enter__)
      200    0.000    0.000   18.583    0.093 {built-in method builtins.next}
      200    0.000    0.000   18.583    0.093 profiler.py:55(profile)
      200    0.000    0.000   18.583    0.093 advanced.py:65(start)
      200   18.583    0.093   18.583    0.093 {method 'enable' of '_lsprof.Profiler' objects}
      200    0.006    0.000    0.021    0.000 optimizer.py:410(_cuda_graph_capture_health_check)
      200    0.002    0.000    0.011    0.000 __init__.py:115(is_available)
      200    0.002    0.000    0.008    0.000 __init__.py:111(_nvml_based_avail)
      200    0.002    0.000    0.007    0.000 os.py:771(getenv)
      200    0.001    0.000    0.004    0.000 _collections_abc.py:760(get)
      200    0.000    0.000    0.004    0.000 profiler.py:687(__enter__)
      200    0.002    0.000    0.004    0.000 os.py:674(__getitem__)
      200    0.000    0.000    0.003    0.000 _ops.py:1047(__call__)
      200    0.003    0.000    0.003    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
      200    0.002    0.000    0.002    0.000 _utils.py:856(is_compiling)
      400    0.001    0.000    0.001    0.000 _contextlib.py:154(__new__)
      200    0.001    0.000    0.001    0.000 grad_mode.py:184(__init__)
      200    0.000    0.000    0.001    0.000 os.py:758(decode)
      200    0.000    0.000    0.001    0.000 graphs.py:24(is_current_stream_capturing)
      200    0.000    0.000    0.001    0.000 module.py:1731(__setattr__)
      200    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_isCurrentStreamCapturing}
      200    0.001    0.000    0.001    0.000 __init__.py:34(is_built)
      600    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}
      200    0.001    0.000    0.001    0.000 {method 'decode' of 'bytes' objects}
      200    0.000    0.000    0.001    0.000 profiler.py:676(__init__)
      400    0.000    0.000    0.001    0.000 grad_mode.py:135(__enter__)
      200    0.000    0.000    0.001    0.000 os.py:754(encode)
      400    0.000    0.000    0.000    0.000 __init__.py:106(_is_compiled)
 1000/800    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
      600    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}
      200    0.000    0.000    0.000    0.000 contextlib.py:261(helper)
      800    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}
      200    0.000    0.000    0.000    0.000 parameter.py:8(__instancecheck__)
      200    0.000    0.000    0.000    0.000 contextlib.py:86(__init__)
      200    0.000    0.000    0.000    0.000 _contextlib.py:146(clone)
      200    0.000    0.000    0.000    0.000 __init__.py:834(device_count)
      200    0.000    0.000    0.000    0.000 __init__.py:213(is_compiling)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 typing.py:271(inner)
      200    0.000    0.000    0.000    0.000 __init__.py:1424(debug)
      200    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
      400    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      600    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 decorators.py:140(graph_break)
      400    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
      400    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      600    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}
      400    0.000    0.000    0.000    0.000 {built-in method builtins.callable}
      200    0.000    0.000    0.000    0.000 optimizer.py:34(do_nothing_closure)
      200    0.000    0.000    0.000    0.000 __init__.py:1689(isEnabledFor)
      200    0.000    0.000    0.000    0.000 strategy.py:93(precision_plugin)
      600    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 typing.py:1375(cast)
      200    0.000    0.000    0.000    0.000 __init__.py:129(annotate)
      200    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)
      200    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x7f133e5c8040}



Profile stats for: [Strategy]SingleDeviceStrategy.training_step
         5897881 function calls (5875921 primitive calls) in 9.228 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.003    0.000    9.268    0.046 strategy.py:379(training_step)
      200    0.010    0.000    9.257    0.046 FlavourClassificationTransformerEncoder.py:81(training_step)
 9600/200    0.016    0.000    9.070    0.045 module.py:1549(_wrapped_call_impl)
 9600/200    0.060    0.000    9.070    0.045 module.py:1555(_call_impl)
      200    0.012    0.000    9.066    0.045 FlavourClassificationTransformerEncoder.py:55(forward)
      600    0.063    0.000    8.917    0.015 EncoderBlock.py:57(forward)
      600    0.942    0.002    6.738    0.011 XFormersAttention.py:33(forward)
    13200    0.026    0.000    3.636    0.000 __init__.py:189(memory_efficient_attention)
    13200    0.067    0.000    3.600    0.000 __init__.py:457(_memory_efficient_attention)
    13200    0.043    0.000    3.413    0.000 function.py:558(apply)
    13200    0.196    0.000    3.269    0.000 {built-in method apply}
    13200    0.096    0.000    3.074    0.000 __init__.py:76(forward)
    26400    0.045    0.000    1.850    0.000 dispatch.py:55(_run_priority_list)
    13200    0.037    0.000    1.826    0.000 __init__.py:489(_memory_efficient_attention_forward_requires_grad)
     1200    0.758    0.001    1.394    0.001 LayerNormalisation.py:17(forward)
    52800    0.436    0.000    1.018    0.000 common.py:348(not_supported_reasons)
    13200    0.024    0.000    1.002    0.000 dispatch.py:146(_dispatch_bw)
    13200    0.013    0.000    0.913    0.000 dispatch.py:126(_dispatch_fw)
    12600    0.020    0.000    0.810    0.000 __init__.py:1436(info)
    12600    0.018    0.000    0.785    0.000 __init__.py:1565(_log)
    92400    0.083    0.000    0.768    0.000 __init__.py:438(get_device_capability)
    92400    0.082    0.000    0.685    0.000 __init__.py:455(get_device_properties)
    13200    0.032    0.000    0.596    0.000 cutlass.py:211(apply)
    13200    0.074    0.000    0.563    0.000 cutlass.py:275(apply_bmhk)
    13200    0.027    0.000    0.558    0.000 attn_bias.py:707(from_seqlens)
    12600    0.009    0.000    0.547    0.000 __init__.py:1591(handle)
    12600    0.017    0.000    0.533    0.000 __init__.py:1645(callHandlers)
    12600    0.014    0.000    0.516    0.000 __init__.py:939(handle)
    26400    0.023    0.000    0.505    0.000 common.py:450(not_supported_reasons)
    13200    0.056    0.000    0.502    0.000 flash.py:752(not_supported_reasons)
    12600    0.008    0.000    0.485    0.000 __init__.py:1178(emit)
      600    0.176    0.000    0.481    0.001 FFN.py:16(forward)
    12600    0.014    0.000    0.478    0.000 __init__.py:1071(emit)
    13200    0.029    0.000    0.450    0.000 cutlass.py:377(not_supported_reasons)
    39600    0.433    0.000    0.433    0.000 {method 'reshape' of 'torch._C.TensorBase' objects}
    13400    0.016    0.000    0.431    0.000 _ops.py:1047(__call__)
    13200    0.024    0.000    0.427    0.000 cutlass.py:326(not_supported_reasons)
    13200    0.035    0.000    0.424    0.000 flash.py:629(not_supported_reasons)
    13200    0.412    0.000    0.412    0.000 {built-in method torch._ops.aten._efficient_attention_forward}
    92400    0.184    0.000    0.412    0.000 _utils.py:9(_get_device_index)
    13200    0.027    0.000    0.405    0.000 attn_bias.py:350(from_seqlens)
    13200    0.028    0.000    0.368    0.000 attn_bias.py:329(_get_seqstart)
    13202    0.327    0.000    0.327    0.000 {built-in method torch.tensor}
    12600    0.014    0.000    0.309    0.000 __init__.py:1060(flush)
    26400    0.087    0.000    0.305    0.000 cutlass.py:49(_minimum_gemm_alignment)
    12600    0.282    0.000    0.282    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
     4000    0.010    0.000    0.269    0.000 linear.py:116(forward)
     4000    0.255    0.000    0.255    0.000 {built-in method torch._C._nn.linear}
    15400    0.238    0.000    0.238    0.000 {method 'item' of 'torch._C.TensorBase' objects}
     2000    0.005    0.000    0.214    0.000 {built-in method builtins.print}
     4000    0.008    0.000    0.208    0.000 redirect.py:644(write)
    13200    0.105    0.000    0.200    0.000 common.py:120(validate_inputs)
     4000    0.006    0.000    0.200    0.000 wandb_run.py:2304(<lambda>)
     4000    0.005    0.000    0.194    0.000 wandb_run.py:390(wrapper_fn)
     4000    0.010    0.000    0.189    0.000 wandb_run.py:1429(_console_raw_callback)
    92400    0.166    0.000    0.186    0.000 _utils.py:764(_get_device_index)
    14400    0.185    0.000    0.185    0.000 {method 'sum' of 'torch._C.TensorBase' objects}
    12600    0.011    0.000    0.177    0.000 __init__.py:1550(makeRecord)
     4000    0.029    0.000    0.176    0.000 interface.py:749(publish_output_raw)
    14400    0.174    0.000    0.174    0.000 {built-in method torch.zeros}
    12600    0.074    0.000    0.166    0.000 __init__.py:282(__init__)
    12600    0.007    0.000    0.153    0.000 __init__.py:916(format)
    12600    0.019    0.000    0.146    0.000 __init__.py:650(format)
     9200    0.142    0.000    0.142    0.000 {method 'any' of 'torch._C.TensorBase' objects}
1181979/1180151    0.131    0.000    0.141    0.000 {built-in method builtins.isinstance}
    92400    0.074    0.000    0.133    0.000 common.py:482(check_lastdim_alignment_stride1)
     9200    0.126    0.000    0.126    0.000 {built-in method torch.isnan}
    13200    0.122    0.000    0.123    0.000 __init__.py:503(_detect_lse_packed_or_raise)
    26400    0.038    0.000    0.123    0.000 attn_bias.py:90(_get_default_bias_device)
      200    0.015    0.000    0.114    0.001 module.py:382(log)
     4000    0.010    0.000    0.106    0.000 interface_shared.py:76(_publish_output_raw)
    39600    0.105    0.000    0.105    0.000 {method 'unsqueeze' of 'torch._C.TensorBase' objects}
     4000    0.008    0.000    0.095    0.000 interface_sock.py:45(_publish)
    12600    0.022    0.000    0.090    0.000 __init__.py:582(formatTime)
    13200    0.023    0.000    0.086    0.000 utils.py:31(unwrap_dead_wrappers)
    13200    0.011    0.000    0.085    0.000 __init__.py:115(is_available)
     4000    0.009    0.000    0.082    0.000 sock_client.py:219(send_record_publish)
    92400    0.077    0.000    0.077    0.000 {built-in method torch.cuda._get_device_properties}
    39800    0.025    0.000    0.073    0.000 {built-in method builtins.any}
     4000    0.002    0.000    0.071    0.000 sock_client.py:153(send_server_request)
     4000    0.012    0.000    0.069    0.000 sock_client.py:145(_send_message)
   105600    0.027    0.000    0.066    0.000 __init__.py:834(device_count)
    13200    0.065    0.000    0.065    0.000 {method 'transpose' of 'torch._C.TensorBase' objects}
   198002    0.063    0.000    0.063    0.000 {method 'stride' of 'torch._C.TensorBase' objects}
   118800    0.030    0.000    0.063    0.000 utils.py:33(<genexpr>)
     1800    0.003    0.000    0.061    0.000 dropout.py:58(forward)
    26400    0.059    0.000    0.059    0.000 common.py:96(normalize_bmhk)
    13200    0.008    0.000    0.059    0.000 __init__.py:111(_nvml_based_avail)
     1800    0.007    0.000    0.058    0.000 functional.py:1279(dropout)
    92400    0.022    0.000    0.055    0.000 __init__.py:284(_lazy_init)
    52800    0.030    0.000    0.054    0.000 common.py:331(shape_not_supported_reasons)
    13200    0.006    0.000    0.051    0.000 os.py:771(getenv)
     4000    0.006    0.000    0.048    0.000 sock_client.py:121(_sendall_with_error_handle)
     1800    0.047    0.000    0.047    0.000 {built-in method torch.dropout}
   118800    0.029    0.000    0.046    0.000 __init__.py:106(_is_compiled)
    12600    0.046    0.000    0.046    0.000 {built-in method time.strftime}
    13200    0.008    0.000    0.045    0.000 _collections_abc.py:760(get)
    12600    0.027    0.000    0.043    0.000 __init__.py:1514(findCaller)
     4000    0.042    0.000    0.042    0.000 {method 'send' of '_socket.socket' objects}
    13200    0.016    0.000    0.036    0.000 os.py:674(__getitem__)
      200    0.009    0.000    0.034    0.000 result.py:355(log)
    52800    0.018    0.000    0.034    0.000 cutlass.py:87(_get_tensor_bias)
    52800    0.021    0.000    0.034    0.000 common.py:32(is_available)
    92400    0.020    0.000    0.033    0.000 __init__.py:237(is_initialized)
   132000    0.033    0.000    0.033    0.000 common.py:71(device)
     4000    0.006    0.000    0.031    0.000 well_known_types.py:172(GetCurrentTime)
  805/801    0.002    0.000    0.031    0.000 apply_func.py:23(apply_to_collection)
    12600    0.012    0.000    0.031    0.000 posixpath.py:117(splitext)
    26401    0.012    0.000    0.030    0.000 {built-in method builtins.all}
   105600    0.028    0.000    0.028    0.000 {built-in method builtins.max}
    26400    0.008    0.000    0.028    0.000 cutlass.py:98(_check_bias_alignment)
     1400    0.028    0.000    0.028    0.000 {method 'mean' of 'torch._C.TensorBase' objects}
    13200    0.016    0.000    0.027    0.000 attn_bias.py:656(to)
      600    0.003    0.000    0.025    0.000 _tensor.py:982(__format__)
    13200    0.019    0.000    0.025    0.000 cutlass.py:136(_custom_mask_type)
    12600    0.013    0.000    0.025    0.000 posixpath.py:140(basename)
    13200    0.023    0.000    0.025    0.000 dispatch.py:79(_dispatch_fw_priority_list)
   157252    0.024    0.000    0.024    0.000 {built-in method builtins.hasattr}
     4000    0.010    0.000    0.023    0.000 well_known_types.py:242(FromDatetime)
    12600    0.023    0.000    0.023    0.000 {built-in method time.localtime}
      600    0.021    0.000    0.021    0.000 {built-in method torch.stack}
     1200    0.021    0.000    0.021    0.000 {method 'var' of 'torch._C.TensorBase' objects}
    12600    0.005    0.000    0.020    0.000 __init__.py:634(formatMessage)
    39600    0.018    0.000    0.018    0.000 {built-in method torch._C._functorch.unwrap_if_dead}
    26400    0.011    0.000    0.018    0.000 flash.py:511(_check_needs_no_topleft)
  470/401    0.002    0.000    0.018    0.000 apply_func.py:84(_apply_to_collection_slow)
    12600    0.013    0.000    0.017    0.000 genericpath.py:121(_splitext)
      600    0.002    0.000    0.016    0.000 activation.py:103(forward)
    19400    0.016    0.000    0.016    0.000 module.py:1716(__getattr__)
    63642    0.016    0.000    0.016    0.000 {built-in method builtins.getattr}
      200    0.003    0.000    0.016    0.000 result.py:502(reset)
    13200    0.015    0.000    0.016    0.000 cutlass.py:66(_get_seqlen_info)
    52800    0.016    0.000    0.016    0.000 common.py:131(<genexpr>)
      200    0.005    0.000    0.015    0.000 functional.py:3014(cross_entropy)
    12600    0.004    0.000    0.015    0.000 __init__.py:432(format)
    25200    0.008    0.000    0.015    0.000 __init__.py:896(acquire)
    52800    0.014    0.000    0.014    0.000 common.py:192(<genexpr>)
     1200    0.014    0.000    0.014    0.000 {built-in method torch.sqrt}
      600    0.001    0.000    0.014    0.000 functional.py:1489(relu)
    92400    0.013    0.000    0.013    0.000 {built-in method torch._C._cuda_isInBadFork}
    13200    0.007    0.000    0.013    0.000 os.py:754(encode)
    52800    0.013    0.000    0.013    0.000 common.py:122(<genexpr>)
      199    0.004    0.000    0.013    0.000 result.py:256(reset)
      600    0.013    0.000    0.013    0.000 {built-in method torch.relu}
    12600    0.004    0.000    0.012    0.000 __init__.py:628(usesTime)
    52800    0.012    0.000    0.012    0.000 common.py:152(<genexpr>)
      200    0.001    0.000    0.012    0.000 profiler.py:693(__exit__)
      798    0.011    0.000    0.011    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
      200    0.001    0.000    0.011    0.000 signature_utils.py:18(is_param_in_hook_signature)
      200    0.000    0.000    0.011    0.000 result.py:424(update_metrics)
    13200    0.011    0.000    0.011    0.000 {built-in method torch._C._are_functorch_transforms_active}
    12600    0.011    0.000    0.011    0.000 __init__.py:429(_format)
      200    0.001    0.000    0.011    0.000 result.py:264(forward)
      600    0.011    0.000    0.011    0.000 {built-in method torch.all}
    16600    0.010    0.000    0.010    0.000 {built-in method posix.getpid}
      200    0.002    0.000    0.010    0.000 inspect.py:1129(getfullargspec)
    81864    0.010    0.000    0.010    0.000 {method 'append' of 'list' objects}
      200    0.001    0.000    0.010    0.000 _ops.py:887(__call__)
    92602    0.010    0.000    0.010    0.000 _jit_internal.py:1130(is_scripting)
     4000    0.010    0.000    0.010    0.000 enum_type_wrapper.py:92(__getattr__)
      200    0.002    0.000    0.010    0.000 metric.py:476(wrapped_func)
      200    0.003    0.000    0.010    0.000 module.py:654(__to_tensor)
     1800    0.010    0.000    0.010    0.000 {method 'view' of 'torch._C.TensorBase' objects}
      200    0.010    0.000    0.010    0.000 {built-in method torch._C._nn.cross_entropy_loss}
    25200    0.007    0.000    0.010    0.000 __init__.py:903(release)
    26400    0.010    0.000    0.010    0.000 __init__.py:461(<genexpr>)
    52800    0.009    0.000    0.009    0.000 {built-in method builtins.min}
      199    0.003    0.000    0.009    0.000 metric.py:689(reset)
    37800    0.009    0.000    0.009    0.000 {method 'rfind' of 'str' objects}
    12600    0.005    0.000    0.009    0.000 __init__.py:160(<lambda>)
     9600    0.008    0.000    0.008    0.000 {built-in method torch._C._get_tracing_state}
      914    0.004    0.000    0.008    0.000 typing.py:719(__instancecheck__)
    26400    0.008    0.000    0.008    0.000 attn_bias.py:316(to)
    12600    0.005    0.000    0.008    0.000 __init__.py:421(usesTime)
    25200    0.008    0.000    0.008    0.000 __init__.py:791(filter)
    39600    0.008    0.000    0.008    0.000 flash.py:533(_check_strides_for_bmghk)
  402/201    0.002    0.000    0.008    0.000 inspect.py:2246(_signature_from_callable)
    13200    0.004    0.000    0.008    0.000 __init__.py:1148(are_deterministic_algorithms_enabled)
    26400    0.005    0.000    0.007    0.000 __init__.py:69(_unserialize_op)
    13200    0.004    0.000    0.007    0.000 os.py:758(decode)
     4000    0.007    0.000    0.007    0.000 calendar.py:655(timegm)
      200    0.000    0.000    0.007    0.000 _ops.py:943(_must_dispatch_in_python)
     4000    0.007    0.000    0.007    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
      200    0.000    0.000    0.006    0.000 _pytree.py:1181(tree_any)
      200    0.002    0.000    0.006    0.000 result.py:207(update)
    12600    0.005    0.000    0.006    0.000 threading.py:1358(current_thread)
    12600    0.005    0.000    0.006    0.000 __init__.py:119(getLevelName)
    25200    0.006    0.000    0.006    0.000 {method 'acquire' of '_thread.RLock' objects}
      600    0.000    0.000    0.006    0.000 {built-in method builtins.next}
      200    0.003    0.000    0.006    0.000 <string>:2(__init__)
      201    0.002    0.000    0.006    0.000 inspect.py:2152(_signature_from_function)
      200    0.006    0.000    0.006    0.000 {built-in method torch.argmax}
    12600    0.003    0.000    0.006    0.000 posixpath.py:41(_get_sep)
     4000    0.005    0.000    0.005    0.000 interface_sock.py:41(_assign)
    12600    0.004    0.000    0.005    0.000 posixpath.py:52(normcase)
    12600    0.005    0.000    0.005    0.000 __init__.py:358(getMessage)
    12600    0.005    0.000    0.005    0.000 __init__.py:1689(isEnabledFor)
      914    0.002    0.000    0.005    0.000 typing.py:848(__subclasscheck__)
    13200    0.005    0.000    0.005    0.000 {method 'encode' of 'str' objects}
    35804    0.005    0.000    0.005    0.000 {built-in method builtins.len}
 1400/400    0.002    0.000    0.004    0.000 _pytree.py:874(tree_iter)
      400    0.002    0.000    0.004    0.000 precision.py:167(train_step_context)
    13200    0.004    0.000    0.004    0.000 function.py:591(_is_setup_context_defined)
    13200    0.004    0.000    0.004    0.000 function.py:34(save_for_backward)
    26400    0.004    0.000    0.004    0.000 cutlass.py:41(_uses_tensorcores)
      200    0.000    0.000    0.004    0.000 contextlib.py:114(__enter__)
    37800    0.004    0.000    0.004    0.000 {built-in method posix.fspath}
      200    0.000    0.000    0.004    0.000 profiler.py:687(__enter__)
    26303    0.004    0.000    0.004    0.000 {method 'get' of 'dict' objects}
    12600    0.004    0.000    0.004    0.000 {built-in method sys._getframe}
     4000    0.004    0.000    0.004    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
    13200    0.003    0.000    0.003    0.000 {method 'decode' of 'bytes' objects}
     8000    0.003    0.000    0.003    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
      600    0.001    0.000    0.003    0.000 trainer.py:1381(training)
      200    0.000    0.000    0.003    0.000 trainer.py:1642(_results)
    25200    0.003    0.000    0.003    0.000 {built-in method _thread.get_ident}
    13200    0.003    0.000    0.003    0.000 {built-in method torch._C._get_deterministic_algorithms}
      200    0.003    0.000    0.003    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
    12600    0.003    0.000    0.003    0.000 {method 'find' of 'str' objects}
      672    0.000    0.000    0.003    0.000 abc.py:117(__instancecheck__)
    26400    0.003    0.000    0.003    0.000 __init__.py:63(_serialize_op)
    12600    0.003    0.000    0.003    0.000 {built-in method time.time}
      400    0.000    0.000    0.003    0.000 contextlib.py:123(__exit__)
      200    0.001    0.000    0.003    0.000 result.py:122(__post_init__)
    16600    0.003    0.000    0.003    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      200    0.003    0.000    0.003    0.000 {built-in method torch._ops.profiler.}
      400    0.003    0.000    0.003    0.000 result.py:90(_generate_sync_fn)
      448    0.002    0.000    0.003    0.000 apply_func.py:17(is_dataclass_instance)
    12600    0.003    0.000    0.003    0.000 threading.py:1093(name)
      200    0.001    0.000    0.003    0.000 fx_validator.py:191(check_logging_and_get_default_levels)
      672    0.003    0.000    0.003    0.000 {built-in method _abc._abc_instancecheck}
      200    0.002    0.000    0.003    0.000 memory.py:24(recursive_detach)
      600    0.001    0.000    0.003    0.000 enums.py:81(__eq__)
      200    0.000    0.000    0.003    0.000 result.py:57(__post_init__)
     1800    0.002    0.000    0.003    0.000 _VF.py:26(__getattr__)
    25200    0.002    0.000    0.002    0.000 {method 'release' of '_thread.RLock' objects}
      798    0.002    0.000    0.002    0.000 {method 'detach' of 'torch._C.TensorBase' objects}
      200    0.000    0.000    0.002    0.000 trainer.py:1564(_active_loop)
      200    0.002    0.000    0.002    0.000 result.py:127(_parse_reduce_fx)
    12600    0.002    0.000    0.002    0.000 process.py:189(name)
      200    0.001    0.000    0.002    0.000 precision.py:68(forward_context)
      921    0.000    0.000    0.002    0.000 {built-in method builtins.issubclass}
     4000    0.002    0.000    0.002    0.000 {built-in method utcnow}
      603    0.001    0.000    0.002    0.000 inspect.py:2498(__init__)
      200    0.002    0.000    0.002    0.000 container.py:317(__iter__)
     4000    0.002    0.000    0.002    0.000 {built-in method _struct.pack}
     4000    0.002    0.000    0.002    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
    13200    0.002    0.000    0.002    0.000 dispatch.py:142(_is_cutlassB_faster_than_flash)
      800    0.000    0.000    0.002    0.000 _pytree.py:656(_is_leaf)
     1400    0.001    0.000    0.002    0.000 _pytree.py:649(_get_node_type)
    12600    0.002    0.000    0.002    0.000 process.py:37(current_process)
      200    0.000    0.000    0.002    0.000 contextlib.py:261(helper)
      914    0.000    0.000    0.001    0.000 abc.py:121(__subclasscheck__)
    13200    0.001    0.000    0.001    0.000 dispatch.py:27(_get_use_fa3)
     2622    0.001    0.000    0.001    0.000 result.py:294(__setattr__)
      200    0.000    0.000    0.001    0.000 profiler.py:55(profile)
      202    0.001    0.000    0.001    0.000 inspect.py:2781(__init__)
        1    0.000    0.000    0.001    0.001 result.py:415(register_key)
      200    0.000    0.000    0.001    0.000 module.py:262(current_epoch)
      200    0.000    0.000    0.001    0.000 _ops.py:945(<lambda>)
      914    0.001    0.000    0.001    0.000 {built-in method _abc._abc_subclasscheck}
      200    0.001    0.000    0.001    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.001    0.000 contextlib.py:86(__init__)
      200    0.001    0.000    0.001    0.000 {method 'squeeze' of 'torch._C.TensorBase' objects}
     3002    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_unary}
     1400    0.001    0.000    0.001    0.000 _pytree.py:638(_is_namedtuple_instance)
      400    0.001    0.000    0.001    0.000 strategy.py:351(model)
        1    0.000    0.000    0.001    0.001 result.py:306(to)
      200    0.001    0.000    0.001    0.000 _reduction.py:7(get_enum)
     1200    0.001    0.000    0.001    0.000 types.py:171(__get__)
      199    0.001    0.000    0.001    0.000 <string>:2(__eq__)
      200    0.000    0.000    0.001    0.000 fit_loop.py:140(_results)
      200    0.001    0.000    0.001    0.000 fx_validator.py:151(check_logging)
      204    0.000    0.000    0.001    0.000 grad_mode.py:184(__init__)
      200    0.001    0.000    0.001    0.000 logger_connector.py:213(should_reset_tensors)
      200    0.000    0.000    0.001    0.000 result.py:148(sync)
      200    0.000    0.000    0.001    0.000 memory.py:40(detach_and_move)
      200    0.001    0.000    0.001    0.000 fx_validator.py:177(check_logging_levels)
      200    0.000    0.000    0.001    0.000 profiler.py:676(__init__)
      200    0.001    0.000    0.001    0.000 contextlib.py:688(__init__)
     4000    0.001    0.000    0.001    0.000 {built-in method time.monotonic}
     4000    0.001    0.000    0.001    0.000 {method '__exit__' of '_thread.lock' objects}
      402    0.001    0.000    0.001    0.000 {method 'to' of 'torch._C.TensorBase' objects}
      448    0.000    0.000    0.001    0.000 dataclasses.py:1047(is_dataclass)
      603    0.000    0.000    0.001    0.000 enum.py:358(__call__)
      200    0.001    0.000    0.001    0.000 trainer.py:1467(current_epoch)
      200    0.000    0.000    0.000    0.000 _pytree.py:423(_dict_flatten)
        1    0.000    0.000    0.000    0.000 result.py:187(__init__)
     4000    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
      804    0.000    0.000    0.000    0.000 inspect.py:2830(<genexpr>)
     4000    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
      427    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}
      604    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}
      201    0.000    0.000    0.000    0.000 result.py:536(_get_default_dtype)
      600    0.000    0.000    0.000    0.000 {method '__format__' of 'int' objects}
      200    0.000    0.000    0.000    0.000 result.py:74(op)
     58/4    0.000    0.000    0.000    0.000 copy.py:128(deepcopy)
      200    0.000    0.000    0.000    0.000 fx_validator.py:166(get_default_logging_levels)
      200    0.000    0.000    0.000    0.000 module.py:215(trainer)
      200    0.000    0.000    0.000    0.000 {built-in method torch.numel}
      200    0.000    0.000    0.000    0.000 <string>:1(<lambda>)
        2    0.000    0.000    0.000    0.000 metric.py:196(add_state)
      600    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {built-in method torch.is_floating_point}
     1200    0.000    0.000    0.000    0.000 enum.py:792(value)
      200    0.000    0.000    0.000    0.000 grad_mode.py:196(__exit__)
     1400    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
        2    0.000    0.000    0.000    0.000 _tensor.py:83(__deepcopy__)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 grad_mode.py:193(__enter__)
      402    0.000    0.000    0.000    0.000 inspect.py:159(isfunction)
      448    0.000    0.000    0.000    0.000 apply_func.py:11(is_namedtuple)
        1    0.000    0.000    0.000    0.000 metric.py:101(__init__)
      600    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}
      603    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}
      603    0.000    0.000    0.000    0.000 enum.py:670(__new__)
      400    0.000    0.000    0.000    0.000 _pytree.py:395(_tuple_flatten)
     1205    0.000    0.000    0.000    0.000 inspect.py:2548(name)
      201    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:93(precision_plugin)
      201    0.000    0.000    0.000    0.000 typing.py:271(inner)
      200    0.000    0.000    0.000    0.000 result.py:340(_extract_batch_size)
      202    0.000    0.000    0.000    0.000 {built-in method torch.get_default_dtype}
      403    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}
      3/2    0.000    0.000    0.000    0.000 copy.py:258(_reconstruct)
      208    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
      206    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.iter}
      600    0.000    0.000    0.000    0.000 result.py:70(op)
      200    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_variadic}
        4    0.000    0.000    0.000    0.000 apply_func.py:71(move_data_to_device)
      400    0.000    0.000    0.000    0.000 result.py:60(should)
      5/4    0.000    0.000    0.000    0.000 copy.py:226(_deepcopy_dict)
      400    0.000    0.000    0.000    0.000 result.py:80(group)
      200    0.000    0.000    0.000    0.000 __init__.py:129(annotate)
      200    0.000    0.000    0.000    0.000 result.py:97(__call__)
      604    0.000    0.000    0.000    0.000 inspect.py:2560(kind)
        2    0.000    0.000    0.000    0.000 storage.py:907(_deepcopy)
        1    0.000    0.000    0.000    0.000 inspect.py:3111(signature)
        4    0.000    0.000    0.000    0.000 apply_func.py:91(batch_to)
      200    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
      602    0.000    0.000    0.000    0.000 inspect.py:2552(default)
        1    0.000    0.000    0.000    0.000 inspect.py:2859(from_callable)
      200    0.000    0.000    0.000    0.000 contextlib.py:691(__enter__)
      600    0.000    0.000    0.000    0.000 inspect.py:2556(annotation)
      200    0.000    0.000    0.000    0.000 result.py:143(sync)
      200    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}
      200    0.000    0.000    0.000    0.000 contextlib.py:694(__exit__)
        2    0.000    0.000    0.000    0.000 storage.py:140(__deepcopy__)
      404    0.000    0.000    0.000    0.000 {built-in method builtins.callable}
      200    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}
      200    0.000    0.000    0.000    0.000 typing.py:1375(cast)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 inspect.py:2869(return_annotation)
        2    0.000    0.000    0.000    0.000 storage.py:156(clone)
      201    0.000    0.000    0.000    0.000 inspect.py:2865(parameters)
      210    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 result.py:101(no_op)
        1    0.000    0.000    0.000    0.000 metric.py:475(_wrap_update)
      2/1    0.000    0.000    0.000    0.000 copy.py:209(_deepcopy_tuple)
        2    0.000    0.000    0.000    0.000 {method 'copy_' of 'torch._C.StorageBase' objects}
        2    0.000    0.000    0.000    0.000 dataclasses.py:1024(fields)
        1    0.000    0.000    0.000    0.000 module.py:429(__init__)
        2    0.000    0.000    0.000    0.000 _tensor.py:242(_typed_storage)
        2    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)
       13    0.000    0.000    0.000    0.000 copy.py:242(_keep_alive)
      107    0.000    0.000    0.000    0.000 {built-in method builtins.id}
      2/1    0.000    0.000    0.000    0.000 copy.py:210(<listcomp>)
        1    0.000    0.000    0.000    0.000 inspect.py:1840(_signature_bound_method)
        2    0.000    0.000    0.000    0.000 grad_mode.py:80(__enter__)
        1    0.000    0.000    0.000    0.000 result.py:273(_wrap_compute)
       19    0.000    0.000    0.000    0.000 dataclasses.py:1039(<genexpr>)
        2    0.000    0.000    0.000    0.000 storage.py:712(_new_wrapped_storage)
        6    0.000    0.000    0.000    0.000 copy.py:263(<genexpr>)
        3    0.000    0.000    0.000    0.000 {method '__reduce_ex__' of 'object' objects}
        2    0.000    0.000    0.000    0.000 {method 'set_' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 {method 'new_empty' of 'torch._C.TensorBase' objects}
        4    0.000    0.000    0.000    0.000 storage.py:629(__init__)
        5    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 inspect.py:494(unwrap)
        4    0.000    0.000    0.000    0.000 storage.py:557(__new__)
        2    0.000    0.000    0.000    0.000 grad_mode.py:84(__exit__)
        1    0.000    0.000    0.000    0.000 inspect.py:2873(replace)
        1    0.000    0.000    0.000    0.000 result.py:171(is_max_reduction)
        2    0.000    0.000    0.000    0.000 apply_func.py:69(<genexpr>)
        2    0.000    0.000    0.000    0.000 grad_mode.py:75(__init__)
        2    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}
        2    0.000    0.000    0.000    0.000 _contextlib.py:154(__new__)
        2    0.000    0.000    0.000    0.000 {method 'untyped_storage' of 'torch._C.TensorBase' objects}
       24    0.000    0.000    0.000    0.000 copy.py:182(_deepcopy_atomic)
        2    0.000    0.000    0.000    0.000 {built-in method torch._C._has_storage}
        2    0.000    0.000    0.000    0.000 functools.py:65(wraps)
        2    0.000    0.000    0.000    0.000 copyreg.py:94(__newobj__)
       14    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
        3    0.000    0.000    0.000    0.000 _collections_abc.py:315(__subclasshook__)
        2    0.000    0.000    0.000    0.000 {method 'contiguous' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 inspect.py:514(_is_wrapper)
        2    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 {method 'nbytes' of 'torch._C.StorageBase' objects}
        2    0.000    0.000    0.000    0.000 {method 'is_conj' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 result.py:175(is_min_reduction)
        2    0.000    0.000    0.000    0.000 {method 'storage_offset' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 {method 'is_neg' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 storage.py:30(__init__)
        1    0.000    0.000    0.000    0.000 result.py:163(is_mean_reduction)
        7    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method '__setstate__' of 'functools.partial' objects}
        2    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_before_zero_grad
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 callback.py:285(on_before_zero_grad)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_before_zero_grad
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 callback.py:285(on_before_zero_grad)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_before_zero_grad
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.001    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 callback.py:285(on_before_zero_grad)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 callback.py:285(on_before_zero_grad)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_before_zero_grad
         1400 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 hooks.py:259(on_before_zero_grad)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.optimizer_zero_grad
         13834 function calls (12834 primitive calls) in 0.021 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.002    0.000    0.021    0.000 module.py:1310(optimizer_zero_grad)
      200    0.001    0.000    0.019    0.000 _compile.py:21(inner)
      200    0.001    0.000    0.018    0.000 eval_frame.py:596(_fn)
      200    0.005    0.000    0.016    0.000 optimizer.py:911(zero_grad)
      200    0.001    0.000    0.005    0.000 profiler.py:693(__exit__)
      200    0.000    0.000    0.004    0.000 profiler.py:687(__enter__)
      200    0.000    0.000    0.004    0.000 _ops.py:887(__call__)
      200    0.000    0.000    0.004    0.000 _ops.py:1047(__call__)
      200    0.004    0.000    0.004    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
      200    0.000    0.000    0.004    0.000 _ops.py:943(_must_dispatch_in_python)
      200    0.000    0.000    0.003    0.000 _pytree.py:1181(tree_any)
      200    0.000    0.000    0.003    0.000 {built-in method builtins.any}
 1400/400    0.001    0.000    0.003    0.000 _pytree.py:874(tree_iter)
     1400    0.000    0.000    0.001    0.000 _pytree.py:649(_get_node_type)
      800    0.000    0.000    0.001    0.000 _pytree.py:656(_is_leaf)
      200    0.001    0.000    0.001    0.000 profiler.py:676(__init__)
      200    0.001    0.000    0.001    0.000 {built-in method torch._ops.profiler.}
     1400    0.001    0.000    0.001    0.000 _pytree.py:638(_is_namedtuple_instance)
      207    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}
      203    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 _pytree.py:423(_dict_flatten)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 typing.py:271(inner)
      200    0.000    0.000    0.000    0.000 _ops.py:945(<lambda>)
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      400    0.000    0.000    0.000    0.000 {built-in method torch._C._dynamo.eval_frame.set_eval_frame}
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      600    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      400    0.000    0.000    0.000    0.000 _pytree.py:395(_tuple_flatten)
     1400    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      202    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
        1    0.000    0.000    0.000    0.000 decorators.py:38(disable)
      200    0.000    0.000    0.000    0.000 __init__.py:129(annotate)
      200    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}
        1    0.000    0.000    0.000    0.000 eval_frame.py:562(__init__)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 eval_frame.py:565(__call__)
      200    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)
      200    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 eval_frame.py:265(__init__)
        1    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)
        3    0.000    0.000    0.000    0.000 eval_frame.py:240(innermost_fn)
        5    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}
        1    0.000    0.000    0.000    0.000 functools.py:65(wraps)
        1    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 inspect.py:73(isclass)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.callable}
        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 eval_frame.py:232(nothing)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.id}



Profile stats for: [Strategy]SingleDeviceStrategy.backward
         7000 function calls (6800 primitive calls) in 8.850 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.001    0.000    8.850    0.044 strategy.py:191(backward)
      200    0.000    0.000    8.849    0.044 precision.py:45(pre_backward)
      200    0.001    0.000    8.849    0.044 call.py:185(_call_callback_hooks)
      200    0.000    0.000    8.846    0.044 contextlib.py:114(__enter__)
      200    0.000    0.000    8.846    0.044 {built-in method builtins.next}
      200    0.000    0.000    8.846    0.044 profiler.py:55(profile)
      200    0.000    0.000    8.846    0.044 advanced.py:65(start)
      200    8.846    0.044    8.846    0.044 {method 'enable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.001    0.000 module.py:1731(__setattr__)
      200    0.000    0.000    0.000    0.000 early_stopping.py:130(state_key)
  600/400    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
      200    0.000    0.000    0.000    0.000 parameter.py:8(__instancecheck__)
      200    0.000    0.000    0.000    0.000 callback.py:48(_generate_state_key)
      200    0.000    0.000    0.000    0.000 contextlib.py:261(helper)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.repr}
      200    0.000    0.000    0.000    0.000 contextlib.py:86(__init__)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 __init__.py:1424(debug)
      200    0.000    0.000    0.000    0.000 module.py:215(trainer)
      600    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 strategy.py:345(pre_backward)
      200    0.000    0.000    0.000    0.000 strategy.py:93(precision_plugin)
      400    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
      200    0.000    0.000    0.000    0.000 __init__.py:1689(isEnabledFor)
      600    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x7f133e5c8040}
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.callable}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_before_backward
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 callback.py:274(on_before_backward)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_before_backward
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 callback.py:274(on_before_backward)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_before_backward
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 callback.py:274(on_before_backward)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.001    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 callback.py:274(on_before_backward)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_before_backward
         1400 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 hooks.py:280(on_before_backward)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_after_backward
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 callback.py:277(on_after_backward)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)



Profile stats for: [Callback]TQDMProgressBar.on_after_backward
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.001    0.000 {built-in method builtins.next}
      200    0.001    0.000    0.001    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 callback.py:277(on_after_backward)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_after_backward
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 callback.py:277(on_after_backward)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 callback.py:277(on_after_backward)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_after_backward
         1400 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 hooks.py:289(on_after_backward)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_before_optimizer_step
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 callback.py:280(on_before_optimizer_step)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_before_optimizer_step
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 callback.py:280(on_before_optimizer_step)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_before_optimizer_step
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 callback.py:280(on_before_optimizer_step)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step
         2000 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 callback.py:280(on_before_optimizer_step)



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_before_optimizer_step
         1400 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 hooks.py:298(on_before_optimizer_step)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.configure_gradient_clipping
         55000 function calls in 0.199 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.198    0.001 module.py:1218(configure_gradient_clipping)
      200    0.004    0.000    0.198    0.001 module.py:1150(clip_gradients)
      200    0.001    0.000    0.187    0.001 precision.py:143(clip_gradients)
      200    0.006    0.000    0.185    0.001 precision.py:162(clip_grad_by_norm)
      200    0.008    0.000    0.179    0.001 clip_grad.py:19(_no_grad_wrapper)
      200    0.014    0.000    0.169    0.001 clip_grad.py:25(clip_grad_norm_)
      200    0.068    0.000    0.068    0.000 {built-in method torch._foreach_norm}
      200    0.016    0.000    0.016    0.000 {built-in method torch._C._linalg.linalg_vector_norm}
      400    0.001    0.000    0.016    0.000 _foreach_utils.py:43(_has_foreach_support)
      200    0.000    0.000    0.013    0.000 _tensor.py:35(wrapped)
      200    0.003    0.000    0.012    0.000 _tensor.py:964(__rdiv__)
      400    0.010    0.000    0.011    0.000 _foreach_utils.py:39(_device_has_foreach_support)
      200    0.010    0.000    0.010    0.000 {built-in method torch.stack}
      200    0.009    0.000    0.009    0.000 {method 'reciprocal' of 'torch._C.TensorBase' objects}
      200    0.008    0.000    0.008    0.000 clip_grad.py:53(<listcomp>)
      200    0.007    0.000    0.007    0.000 {built-in method torch._foreach_mul_}
      200    0.001    0.000    0.006    0.000 _contextlib.py:113(decorate_context)
      200    0.001    0.000    0.005    0.000 clip_grad.py:74(<listcomp>)
      200    0.001    0.000    0.005    0.000 enums.py:34(supported_type)
     8200    0.004    0.000    0.004    0.000 {method 'to' of 'torch._C.TensorBase' objects}
      200    0.004    0.000    0.004    0.000 {built-in method torch.clamp}
      200    0.001    0.000    0.004    0.000 _foreach_utils.py:32(_group_tensors_by_device_and_dtype)
      400    0.001    0.000    0.004    0.000 {built-in method builtins.all}
      200    0.002    0.000    0.002    0.000 {built-in method torch._C._group_tensors_by_device_and_dtype}
    16400    0.002    0.000    0.002    0.000 _foreach_utils.py:44(<genexpr>)
      200    0.000    0.000    0.002    0.000 {built-in method builtins.any}
      600    0.000    0.000    0.002    0.000 enums.py:36(<genexpr>)
      200    0.002    0.000    0.002    0.000 enum.py:434(__iter__)
      400    0.001    0.000    0.001    0.000 grad_mode.py:80(__enter__)
      400    0.001    0.000    0.001    0.000 enums.py:81(__eq__)
      800    0.001    0.000    0.001    0.000 grad_mode.py:184(__init__)
      200    0.000    0.000    0.001    0.000 enum.py:358(__call__)
      400    0.000    0.000    0.001    0.000 grad_mode.py:84(__exit__)
      600    0.001    0.000    0.001    0.000 enum.py:438(<genexpr>)
     8200    0.001    0.000    0.001    0.000 precision.py:126(main_params)
     1200    0.001    0.000    0.001    0.000 types.py:171(__get__)
      200    0.001    0.000    0.001    0.000 enum.py:670(__new__)
      400    0.001    0.000    0.001    0.000 grad_mode.py:75(__init__)
      400    0.000    0.000    0.001    0.000 _foreach_utils.py:8(_get_foreach_kernels_supported_devices)
      200    0.000    0.000    0.001    0.000 _contextlib.py:146(clone)
      400    0.000    0.000    0.000    0.000 _contextlib.py:154(__new__)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      800    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      400    0.000    0.000    0.000    0.000 {built-in method torch._C._get_privateuse1_backend_name}
     1200    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}
     1200    0.000    0.000    0.000    0.000 enum.py:792(value)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      800    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
      800    0.000    0.000    0.000    0.000 module.py:215(trainer)
      200    0.000    0.000    0.000    0.000 trainer.py:1129(precision_plugin)
     1000    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
      800    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)
      400    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
      200    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function}
      200    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}
      400    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 module.py:230(fabric)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:93(precision_plugin)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_train_batch_end
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 callback.py:81(on_train_batch_end)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_train_batch_end
         175762 function calls (175758 primitive calls) in 0.166 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.005    0.000    0.165    0.001 tqdm_progress.py:269(on_train_batch_end)
      400    0.003    0.000    0.119    0.000 std.py:1325(refresh)
      400    0.002    0.000    0.113    0.000 std.py:1464(display)
      200    0.002    0.000    0.089    0.000 tqdm_progress.py:451(_update_n)
      400    0.004    0.000    0.060    0.000 std.py:1150(__str__)
      400    0.001    0.000    0.051    0.000 std.py:457(print_status)
      200    0.004    0.000    0.042    0.000 std.py:1402(set_postfix)
      400    0.001    0.000    0.033    0.000 std.py:451(fp_write)
      800    0.001    0.000    0.032    0.000 utils.py:194(inner)
      400    0.013    0.000    0.029    0.000 std.py:464(format_meter)
      200    0.001    0.000    0.027    0.000 progress_bar.py:177(get_metrics)
      400    0.007    0.000    0.026    0.000 std.py:1446(format_dict)
      400    0.001    0.000    0.024    0.000 redirect.py:644(write)
      400    0.000    0.000    0.024    0.000 wandb_run.py:2304(<lambda>)
      400    0.000    0.000    0.023    0.000 wandb_run.py:390(wrapper_fn)
      400    0.002    0.000    0.023    0.000 wandb_run.py:1429(_console_raw_callback)
      400    0.003    0.000    0.021    0.000 interface.py:749(publish_output_raw)
      400    0.011    0.000    0.019    0.000 utils.py:333(_screen_shape_linux)
      400    0.001    0.000    0.017    0.000 utils.py:378(disp_len)
      400    0.000    0.000    0.015    0.000 utils.py:374(_text_width)
      400    0.003    0.000    0.015    0.000 {built-in method builtins.sum}
      400    0.001    0.000    0.014    0.000 interface_shared.py:76(_publish_output_raw)
      200    0.000    0.000    0.013    0.000 trainer.py:1632(progress_bar_metrics)
      200    0.005    0.000    0.013    0.000 progress_bar.py:210(get_standard_metrics)
      200    0.001    0.000    0.013    0.000 logger_connector.py:250(progress_bar_metrics)
      400    0.001    0.000    0.013    0.000 interface_sock.py:45(_publish)
      400    0.001    0.000    0.012    0.000 sock_client.py:219(send_record_publish)
    38484    0.008    0.000    0.011    0.000 utils.py:375(<genexpr>)
      400    0.000    0.000    0.011    0.000 sock_client.py:153(send_server_request)
      400    0.001    0.000    0.010    0.000 sock_client.py:145(_send_message)
      200    0.000    0.000    0.010    0.000 logger_connector.py:229(metrics)
      200    0.002    0.000    0.008    0.000 utilities.py:25(_version)
      400    0.001    0.000    0.008    0.000 sock_client.py:121(_sendall_with_error_handle)
      200    0.001    0.000    0.007    0.000 result.py:476(metrics)
      400    0.007    0.000    0.007    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
      800    0.005    0.000    0.007    0.000 utils.py:273(_is_ascii)
      400    0.007    0.000    0.007    0.000 {method 'send' of '_socket.socket' objects}
      200    0.002    0.000    0.006    0.000 wandb.py:572(version)
      400    0.006    0.000    0.006    0.000 {built-in method fcntl.ioctl}
      600    0.000    0.000    0.004    0.000 trainer.py:1642(_results)
      200    0.001    0.000    0.004    0.000 wandb_run.py:357(wrapper)
      800    0.003    0.000    0.004    0.000 {method 'format' of 'str' objects}
     1200    0.001    0.000    0.003    0.000 trainer.py:1381(training)
    38084    0.003    0.000    0.003    0.000 {built-in method unicodedata.east_asian_width}
      400    0.000    0.000    0.003    0.000 well_known_types.py:172(GetCurrentTime)
     1200    0.001    0.000    0.003    0.000 enums.py:81(__eq__)
      400    0.001    0.000    0.003    0.000 well_known_types.py:242(FromDatetime)
      400    0.001    0.000    0.002    0.000 std.py:102(acquire)
      200    0.002    0.000    0.002    0.000 wandb_run.py:881(id)
     4196    0.001    0.000    0.002    0.000 {built-in method builtins.isinstance}
      600    0.000    0.000    0.002    0.000 trainer.py:1564(_active_loop)
      199    0.001    0.000    0.002    0.000 tqdm_progress.py:46(format_num)
    34800    0.002    0.000    0.002    0.000 {built-in method builtins.ord}
      400    0.001    0.000    0.002    0.000 utils.py:347(<listcomp>)
      800    0.002    0.000    0.002    0.000 std.py:400(format_interval)
      400    0.002    0.000    0.002    0.000 std.py:153(__init__)
      200    0.002    0.000    0.002    0.000 result.py:461(valid_items)
      200    0.001    0.000    0.002    0.000 tqdm_progress.py:425(_should_update)
      600    0.000    0.000    0.002    0.000 fit_loop.py:140(_results)
      399    0.000    0.000    0.002    0.000 abc.py:117(__instancecheck__)
      200    0.000    0.000    0.002    0.000 result.py:465(_forked_name)
      200    0.000    0.000    0.001    0.000 result.py:430(_get_cache)
      399    0.001    0.000    0.001    0.000 {built-in method _abc._abc_instancecheck}
      199    0.001    0.000    0.001    0.000 std.py:419(format_num)
      400    0.001    0.000    0.001    0.000 os.py:674(__getitem__)
      200    0.001    0.000    0.001    0.000 result.py:158(forked_name)
      400    0.001    0.000    0.001    0.000 enum_type_wrapper.py:92(__getattr__)
      200    0.001    0.000    0.001    0.000 {method 'detach' of 'torch._C.TensorBase' objects}
      400    0.001    0.000    0.001    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
      400    0.001    0.000    0.001    0.000 result.py:463(<genexpr>)
     2400    0.001    0.000    0.001    0.000 types.py:171(__get__)
      400    0.001    0.000    0.001    0.000 std.py:186(__format__)
      200    0.001    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      400    0.001    0.000    0.001    0.000 std.py:231(__call__)
      400    0.001    0.000    0.001    0.000 calendar.py:655(timegm)
     1000    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}
      400    0.001    0.000    0.001    0.000 std.py:106(release)
      400    0.001    0.000    0.001    0.000 {method 'acquire' of '_thread.RLock' objects}
      200    0.000    0.000    0.001    0.000 {method 'join' of 'str' objects}
      400    0.001    0.000    0.001    0.000 {built-in method now}
      400    0.001    0.000    0.001    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
      400    0.001    0.000    0.001    0.000 {method 'sub' of 're.Pattern' objects}
      400    0.001    0.000    0.001    0.000 interface_sock.py:41(_assign)
      400    0.000    0.000    0.001    0.000 os.py:754(encode)
      800    0.001    0.000    0.001    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
      400    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)
     1600    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
      400    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
      200    0.000    0.000    0.000    0.000 tqdm_progress.py:169(is_enabled)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      599    0.000    0.000    0.000    0.000 std.py:1428(<genexpr>)
      600    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      400    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
      600    0.000    0.000    0.000    0.000 tqdm_progress.py:121(train_progress_bar)
      400    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
     2400    0.000    0.000    0.000    0.000 enum.py:792(value)
     2000    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
     2000    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      400    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
     2400    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
      800    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      400    0.000    0.000    0.000    0.000 tqdm_progress.py:161(refresh_rate)
      400    0.000    0.000    0.000    0.000 trainer.py:1590(loggers)
      400    0.000    0.000    0.000    0.000 {built-in method builtins.max}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}
      400    0.000    0.000    0.000    0.000 utils.py:108(__init__)
      400    0.000    0.000    0.000    0.000 {built-in method utcnow}
      400    0.000    0.000    0.000    0.000 utils.py:112(__format__)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      400    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      398    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}
      400    0.000    0.000    0.000    0.000 std.py:167(colour)
      399    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}
      400    0.000    0.000    0.000    0.000 {built-in method time.time}
      200    0.000    0.000    0.000    0.000 result.py:154(forked)
      400    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
      400    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
      400    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
      400    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
      400    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
      600    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
      400    0.000    0.000    0.000    0.000 std.py:163(colour)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      3/1    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)
      3/1    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}
      400    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
      400    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}



Profile stats for: [Callback]ModelSummary.on_train_batch_end
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 callback.py:81(on_train_batch_end)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end
         5600 function calls in 0.006 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.006    0.000 model_checkpoint.py:284(on_train_batch_end)
      200    0.004    0.000    0.006    0.000 model_checkpoint.py:413(_should_skip_saving_checkpoint)
      200    0.000    0.000    0.001    0.000 trainer.py:1458(global_step)
      200    0.000    0.000    0.001    0.000 trainer.py:1429(sanity_checking)
      200    0.000    0.000    0.001    0.000 training_epoch_loop.py:99(global_step)
      200    0.000    0.000    0.001    0.000 enums.py:81(__eq__)
      400    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      400    0.000    0.000    0.000    0.000 types.py:171(__get__)
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 progress.py:274(optimizer_steps)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
      400    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      400    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
      400    0.000    0.000    0.000    0.000 enum.py:792(value)
      400    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 module.py:295(automatic_optimization)
      200    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_train_batch_end
         1400 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 hooks.py:79(on_train_batch_end)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_validation_model_zero_grad
         151800 function calls (112800 primitive calls) in 0.069 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.002    0.000    0.069    0.000 hooks.py:158(on_validation_model_zero_grad)
      200    0.018    0.000    0.067    0.000 module.py:2500(zero_grad)
     8200    0.004    0.000    0.048    0.000 module.py:2233(parameters)
     8200    0.002    0.000    0.044    0.000 module.py:2258(named_parameters)
     8200    0.010    0.000    0.042    0.000 module.py:2219(_named_members)
48400/9400    0.019    0.000    0.022    0.000 module.py:2395(named_modules)
    17200    0.004    0.000    0.005    0.000 {method 'add' of 'set' objects}
     9200    0.004    0.000    0.004    0.000 module.py:2286(<lambda>)
    16000    0.002    0.000    0.004    0.000 _tensor.py:1055(__hash__)
    18400    0.002    0.000    0.002    0.000 {method 'items' of 'collections.OrderedDict' objects}
      200    0.000    0.000    0.001    0.000 {built-in method builtins.getattr}
    16000    0.001    0.000    0.001    0.000 {built-in method builtins.id}
      200    0.001    0.000    0.001    0.000 module.py:1716(__getattr__)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_train_epoch_end
         99712 function calls in 0.052 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.001    0.000    0.051    0.000 tqdm_progress.py:278(on_train_epoch_end)
      200    0.001    0.000    0.039    0.000 std.py:1402(set_postfix)
      200    0.000    0.000    0.035    0.000 std.py:1325(refresh)
      200    0.000    0.000    0.033    0.000 std.py:1464(display)
      200    0.000    0.000    0.019    0.000 std.py:457(print_status)
      200    0.001    0.000    0.014    0.000 std.py:1150(__str__)
      200    0.000    0.000    0.012    0.000 std.py:451(fp_write)
      400    0.000    0.000    0.011    0.000 utils.py:194(inner)
      200    0.001    0.000    0.011    0.000 progress_bar.py:177(get_metrics)
      200    0.000    0.000    0.010    0.000 redirect.py:644(write)
      200    0.000    0.000    0.009    0.000 wandb_run.py:2304(<lambda>)
      200    0.000    0.000    0.009    0.000 wandb_run.py:390(wrapper_fn)
      200    0.004    0.000    0.009    0.000 std.py:464(format_meter)
      200    0.000    0.000    0.009    0.000 wandb_run.py:1429(_console_raw_callback)
      200    0.001    0.000    0.008    0.000 interface.py:749(publish_output_raw)
      200    0.000    0.000    0.008    0.000 trainer.py:1632(progress_bar_metrics)
      200    0.000    0.000    0.008    0.000 logger_connector.py:250(progress_bar_metrics)
      200    0.000    0.000    0.007    0.000 utils.py:378(disp_len)
      200    0.000    0.000    0.006    0.000 utils.py:374(_text_width)
      200    0.002    0.000    0.006    0.000 {built-in method builtins.sum}
      200    0.000    0.000    0.006    0.000 interface_shared.py:76(_publish_output_raw)
      200    0.000    0.000    0.005    0.000 interface_sock.py:45(_publish)
      200    0.000    0.000    0.005    0.000 logger_connector.py:229(metrics)
      600    0.001    0.000    0.005    0.000 trainer.py:1642(_results)
      200    0.000    0.000    0.005    0.000 sock_client.py:219(send_record_publish)
    19262    0.003    0.000    0.005    0.000 utils.py:375(<genexpr>)
      200    0.000    0.000    0.004    0.000 sock_client.py:153(send_server_request)
      200    0.001    0.000    0.004    0.000 sock_client.py:145(_send_message)
      200    0.001    0.000    0.004    0.000 std.py:1446(format_dict)
      200    0.001    0.000    0.004    0.000 utils.py:333(_screen_shape_linux)
     1200    0.001    0.000    0.003    0.000 trainer.py:1381(training)
      200    0.000    0.000    0.003    0.000 sock_client.py:121(_sendall_with_error_handle)
      200    0.003    0.000    0.003    0.000 {method 'send' of '_socket.socket' objects}
     1200    0.001    0.000    0.003    0.000 enums.py:81(__eq__)
      400    0.002    0.000    0.003    0.000 utils.py:273(_is_ascii)
      200    0.001    0.000    0.002    0.000 result.py:476(metrics)
      200    0.001    0.000    0.002    0.000 progress_bar.py:210(get_standard_metrics)
      600    0.000    0.000    0.002    0.000 trainer.py:1564(_active_loop)
      200    0.002    0.000    0.002    0.000 {built-in method fcntl.ioctl}
      199    0.000    0.000    0.002    0.000 tqdm_progress.py:46(format_num)
      600    0.000    0.000    0.002    0.000 fit_loop.py:140(_results)
      200    0.002    0.000    0.002    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
      400    0.002    0.000    0.002    0.000 result.py:463(<genexpr>)
    19062    0.002    0.000    0.002    0.000 {built-in method unicodedata.east_asian_width}
      400    0.001    0.000    0.001    0.000 {method 'format' of 'str' objects}
      200    0.000    0.000    0.001    0.000 well_known_types.py:172(GetCurrentTime)
      200    0.000    0.000    0.001    0.000 utilities.py:25(_version)
      199    0.001    0.000    0.001    0.000 std.py:419(format_num)
      200    0.000    0.000    0.001    0.000 well_known_types.py:242(FromDatetime)
      200    0.001    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      200    0.001    0.000    0.001    0.000 std.py:106(release)
      200    0.000    0.000    0.001    0.000 wandb.py:572(version)
     2400    0.001    0.000    0.001    0.000 types.py:171(__get__)
    17400    0.001    0.000    0.001    0.000 {built-in method builtins.ord}
      200    0.000    0.000    0.001    0.000 wandb_run.py:357(wrapper)
     3396    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}
      400    0.001    0.000    0.001    0.000 std.py:400(format_interval)
      200    0.000    0.000    0.001    0.000 utils.py:347(<listcomp>)
      200    0.000    0.000    0.001    0.000 {method 'join' of 'str' objects}
      200    0.000    0.000    0.000    0.000 os.py:674(__getitem__)
      200    0.000    0.000    0.000    0.000 enum_type_wrapper.py:92(__getattr__)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
      200    0.000    0.000    0.000    0.000 std.py:186(__format__)
      200    0.000    0.000    0.000    0.000 calendar.py:655(timegm)
      200    0.000    0.000    0.000    0.000 std.py:102(acquire)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      599    0.000    0.000    0.000    0.000 std.py:1428(<genexpr>)
     2400    0.000    0.000    0.000    0.000 enum.py:792(value)
      200    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
      400    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      399    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)
      200    0.000    0.000    0.000    0.000 std.py:153(__init__)
      200    0.000    0.000    0.000    0.000 {built-in method now}
     2400    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
      400    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
     1400    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      200    0.000    0.000    0.000    0.000 os.py:754(encode)
     1000    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
      200    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}
      200    0.000    0.000    0.000    0.000 result.py:461(valid_items)
      400    0.000    0.000    0.000    0.000 tqdm_progress.py:121(train_progress_bar)
      200    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
      399    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}
      200    0.000    0.000    0.000    0.000 wandb_run.py:881(id)
      200    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)
      600    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
     1000    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
      200    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      200    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}
      200    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
      400    0.000    0.000    0.000    0.000 trainer.py:1590(loggers)
      200    0.000    0.000    0.000    0.000 std.py:231(__call__)
      200    0.000    0.000    0.000    0.000 {built-in method utcnow}
      200    0.000    0.000    0.000    0.000 utils.py:112(__format__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.max}
      200    0.000    0.000    0.000    0.000 result.py:430(_get_cache)
      200    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
      200    0.000    0.000    0.000    0.000 utils.py:108(__init__)
      200    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
      600    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
      398    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}
      200    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
      400    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
      200    0.000    0.000    0.000    0.000 std.py:167(colour)
      200    0.000    0.000    0.000    0.000 {built-in method time.time}
      399    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}
      400    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}
      200    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
      200    0.000    0.000    0.000    0.000 std.py:163(colour)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
      200    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}



Profile stats for: [Callback]ModelSummary.on_train_epoch_end
         2000 function calls in 0.001 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.001    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.000    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 callback.py:95(on_train_epoch_end)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_train_epoch_end
         66481 function calls (64321 primitive calls) in 0.100 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.004    0.000    0.099    0.000 FlavourClassificationTransformerEncoder.py:137(on_train_epoch_end)
      200    0.003    0.000    0.060    0.000 module.py:382(log)
      200    0.002    0.000    0.018    0.000 result.py:355(log)
      200    0.001    0.000    0.017    0.000 __init__.py:1436(info)
      200    0.000    0.000    0.016    0.000 __init__.py:1565(_log)
  805/801    0.001    0.000    0.014    0.000 apply_func.py:23(apply_to_collection)
      200    0.001    0.000    0.012    0.000 result.py:502(reset)
      200    0.000    0.000    0.011    0.000 result.py:424(update_metrics)
      199    0.001    0.000    0.011    0.000 result.py:256(reset)
      200    0.000    0.000    0.011    0.000 result.py:264(forward)
      200    0.000    0.000    0.011    0.000 __init__.py:1591(handle)
      200    0.001    0.000    0.011    0.000 signature_utils.py:18(is_param_in_hook_signature)
      200    0.001    0.000    0.011    0.000 metric.py:476(wrapped_func)
      200    0.001    0.000    0.011    0.000 __init__.py:1645(callHandlers)
      199    0.003    0.000    0.010    0.000 metric.py:689(reset)
      200    0.002    0.000    0.010    0.000 inspect.py:1129(getfullargspec)
      200    0.000    0.000    0.010    0.000 __init__.py:939(handle)
      200    0.010    0.000    0.010    0.000 {built-in method torch.stack}
      200    0.000    0.000    0.009    0.000 __init__.py:1178(emit)
      200    0.000    0.000    0.009    0.000 __init__.py:1071(emit)
      200    0.008    0.000    0.009    0.000 result.py:207(update)
      598    0.008    0.000    0.008    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
  402/201    0.001    0.000    0.007    0.000 inspect.py:2246(_signature_from_callable)
      200    0.001    0.000    0.007    0.000 module.py:654(__to_tensor)
      200    0.000    0.000    0.006    0.000 __init__.py:1060(flush)
      201    0.003    0.000    0.006    0.000 inspect.py:2152(_signature_from_function)
      200    0.005    0.000    0.005    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
  470/401    0.001    0.000    0.005    0.000 apply_func.py:84(_apply_to_collection_slow)
      200    0.000    0.000    0.004    0.000 __init__.py:1550(makeRecord)
      200    0.004    0.000    0.004    0.000 {method 'item' of 'torch._C.TensorBase' objects}
      200    0.004    0.000    0.004    0.000 {method 'mean' of 'torch._C.TensorBase' objects}
8579/6751    0.001    0.000    0.003    0.000 {built-in method builtins.isinstance}
      200    0.002    0.000    0.003    0.000 __init__.py:282(__init__)
      798    0.003    0.000    0.003    0.000 {method 'detach' of 'torch._C.TensorBase' objects}
      200    0.000    0.000    0.003    0.000 __init__.py:916(format)
      200    0.000    0.000    0.003    0.000 __init__.py:650(format)
      600    0.000    0.000    0.002    0.000 trainer.py:1381(training)
      914    0.000    0.000    0.002    0.000 typing.py:719(__instancecheck__)
      200    0.000    0.000    0.002    0.000 trainer.py:1642(_results)
      600    0.001    0.000    0.002    0.000 enums.py:81(__eq__)
      603    0.001    0.000    0.002    0.000 inspect.py:2498(__init__)
      200    0.000    0.000    0.001    0.000 __init__.py:582(formatTime)
      914    0.000    0.000    0.001    0.000 typing.py:848(__subclasscheck__)
      200    0.001    0.000    0.001    0.000 __init__.py:1514(findCaller)
     2622    0.001    0.000    0.001    0.000 result.py:294(__setattr__)
        1    0.000    0.000    0.001    0.001 result.py:415(register_key)
      200    0.000    0.000    0.001    0.000 memory.py:24(recursive_detach)
      200    0.000    0.000    0.001    0.000 fx_validator.py:191(check_logging_and_get_default_levels)
      202    0.001    0.000    0.001    0.000 inspect.py:2781(__init__)
      200    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      427    0.001    0.000    0.001    0.000 {built-in method builtins.setattr}
      200    0.000    0.000    0.001    0.000 trainer.py:1564(_active_loop)
      200    0.000    0.000    0.001    0.000 {built-in method builtins.next}
      200    0.001    0.000    0.001    0.000 {method 'clear' of 'list' objects}
        1    0.000    0.000    0.001    0.001 result.py:306(to)
      200    0.000    0.000    0.001    0.000 module.py:262(current_epoch)
      921    0.000    0.000    0.001    0.000 {built-in method builtins.issubclass}
      200    0.000    0.000    0.001    0.000 <string>:2(__init__)
      448    0.000    0.000    0.001    0.000 apply_func.py:17(is_dataclass_instance)
      204    0.000    0.000    0.001    0.000 grad_mode.py:184(__init__)
      200    0.001    0.000    0.001    0.000 {method 'squeeze' of 'torch._C.TensorBase' objects}
      400    0.000    0.000    0.001    0.000 result.py:90(_generate_sync_fn)
      200    0.000    0.000    0.001    0.000 fit_loop.py:140(_results)
      200    0.000    0.000    0.001    0.000 memory.py:40(detach_and_move)
      200    0.001    0.000    0.001    0.000 fx_validator.py:177(check_logging_levels)
     1252    0.001    0.000    0.001    0.000 {built-in method builtins.hasattr}
      199    0.000    0.000    0.001    0.000 <string>:2(__eq__)
      200    0.001    0.000    0.001    0.000 {built-in method time.strftime}
      200    0.000    0.000    0.001    0.000 posixpath.py:117(splitext)
      200    0.000    0.000    0.001    0.000 __init__.py:160(<lambda>)
     1200    0.000    0.000    0.001    0.000 types.py:171(__get__)
      200    0.000    0.000    0.001    0.000 posixpath.py:140(basename)
      402    0.001    0.000    0.001    0.000 {method 'to' of 'torch._C.TensorBase' objects}
      603    0.000    0.000    0.001    0.000 enum.py:358(__call__)
      200    0.000    0.000    0.001    0.000 result.py:148(sync)
      914    0.000    0.000    0.001    0.000 abc.py:121(__subclasscheck__)
      200    0.000    0.000    0.001    0.000 result.py:122(__post_init__)
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      448    0.000    0.000    0.000    0.000 dataclasses.py:1047(is_dataclass)
      200    0.000    0.000    0.000    0.000 result.py:57(__post_init__)
        1    0.000    0.000    0.000    0.000 result.py:187(__init__)
      200    0.000    0.000    0.000    0.000 {built-in method time.localtime}
      672    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)
      200    0.000    0.000    0.000    0.000 result.py:127(_parse_reduce_fx)
      200    0.000    0.000    0.000    0.000 __init__.py:634(formatMessage)
      804    0.000    0.000    0.000    0.000 inspect.py:2830(<genexpr>)
     58/4    0.000    0.000    0.000    0.000 copy.py:128(deepcopy)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 result.py:74(op)
      914    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}
      200    0.000    0.000    0.000    0.000 genericpath.py:121(_splitext)
      604    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}
      400    0.000    0.000    0.000    0.000 __init__.py:896(acquire)
      200    0.000    0.000    0.000    0.000 __init__.py:432(format)
      672    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}
      200    0.000    0.000    0.000    0.000 __init__.py:628(usesTime)
        2    0.000    0.000    0.000    0.000 metric.py:196(add_state)
      842    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
      200    0.000    0.000    0.000    0.000 <string>:1(<lambda>)
     1503    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        2    0.000    0.000    0.000    0.000 _tensor.py:83(__deepcopy__)
      200    0.000    0.000    0.000    0.000 __init__.py:429(_format)
      200    0.000    0.000    0.000    0.000 grad_mode.py:196(__exit__)
      201    0.000    0.000    0.000    0.000 result.py:536(_get_default_dtype)
      448    0.000    0.000    0.000    0.000 apply_func.py:11(is_namedtuple)
      200    0.000    0.000    0.000    0.000 module.py:215(trainer)
      200    0.000    0.000    0.000    0.000 {built-in method torch.numel}
      600    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}
      200    0.000    0.000    0.000    0.000 trainer.py:1467(current_epoch)
      400    0.000    0.000    0.000    0.000 __init__.py:903(release)
      402    0.000    0.000    0.000    0.000 inspect.py:159(isfunction)
      603    0.000    0.000    0.000    0.000 enum.py:670(__new__)
      200    0.000    0.000    0.000    0.000 __init__.py:421(usesTime)
     1400    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
      400    0.000    0.000    0.000    0.000 __init__.py:791(filter)
      603    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}
      200    0.000    0.000    0.000    0.000 __init__.py:119(getLevelName)
      200    0.000    0.000    0.000    0.000 {built-in method time.time}
     1200    0.000    0.000    0.000    0.000 enum.py:792(value)
      200    0.000    0.000    0.000    0.000 logger_connector.py:213(should_reset_tensors)
      200    0.000    0.000    0.000    0.000 posixpath.py:52(normcase)
      200    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
        1    0.000    0.000    0.000    0.000 metric.py:101(__init__)
      200    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)
     1205    0.000    0.000    0.000    0.000 inspect.py:2548(name)
      200    0.000    0.000    0.000    0.000 __init__.py:1689(isEnabledFor)
      200    0.000    0.000    0.000    0.000 threading.py:1358(current_thread)
      200    0.000    0.000    0.000    0.000 grad_mode.py:193(__enter__)
      200    0.000    0.000    0.000    0.000 {built-in method torch.is_floating_point}
      200    0.000    0.000    0.000    0.000 fx_validator.py:151(check_logging)
      200    0.000    0.000    0.000    0.000 fx_validator.py:166(get_default_logging_levels)
     1264    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
      3/2    0.000    0.000    0.000    0.000 copy.py:258(_reconstruct)
      208    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
      400    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
      200    0.000    0.000    0.000    0.000 {built-in method sys._getframe}
      201    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}
      200    0.000    0.000    0.000    0.000 __init__.py:358(getMessage)
        4    0.000    0.000    0.000    0.000 apply_func.py:71(move_data_to_device)
      600    0.000    0.000    0.000    0.000 {built-in method posix.fspath}
      5/4    0.000    0.000    0.000    0.000 copy.py:226(_deepcopy_dict)
      201    0.000    0.000    0.000    0.000 result.py:163(is_mean_reduction)
      202    0.000    0.000    0.000    0.000 {built-in method torch.get_default_dtype}
        2    0.000    0.000    0.000    0.000 storage.py:907(_deepcopy)
        4    0.000    0.000    0.000    0.000 apply_func.py:91(batch_to)
      604    0.000    0.000    0.000    0.000 inspect.py:2560(kind)
      600    0.000    0.000    0.000    0.000 result.py:70(op)
      206    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}
      200    0.000    0.000    0.000    0.000 result.py:340(_extract_batch_size)
      200    0.000    0.000    0.000    0.000 threading.py:1093(name)
      200    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}
      600    0.000    0.000    0.000    0.000 inspect.py:2556(annotation)
      602    0.000    0.000    0.000    0.000 inspect.py:2552(default)
      400    0.000    0.000    0.000    0.000 result.py:60(should)
      400    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
      200    0.000    0.000    0.000    0.000 process.py:189(name)
      200    0.000    0.000    0.000    0.000 process.py:37(current_process)
      400    0.000    0.000    0.000    0.000 result.py:80(group)
        2    0.000    0.000    0.000    0.000 storage.py:140(__deepcopy__)
      404    0.000    0.000    0.000    0.000 {built-in method builtins.callable}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 inspect.py:3111(signature)
      400    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
      203    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 inspect.py:2859(from_callable)
        2    0.000    0.000    0.000    0.000 storage.py:156(clone)
      200    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      200    0.000    0.000    0.000    0.000 inspect.py:2869(return_annotation)
      201    0.000    0.000    0.000    0.000 inspect.py:2865(parameters)
      210    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 typing.py:1375(cast)
        1    0.000    0.000    0.000    0.000 metric.py:475(_wrap_update)
      2/1    0.000    0.000    0.000    0.000 copy.py:209(_deepcopy_tuple)
        2    0.000    0.000    0.000    0.000 {method 'copy_' of 'torch._C.StorageBase' objects}
        2    0.000    0.000    0.000    0.000 _tensor.py:242(_typed_storage)
        2    0.000    0.000    0.000    0.000 dataclasses.py:1024(fields)
        1    0.000    0.000    0.000    0.000 module.py:429(__init__)
        2    0.000    0.000    0.000    0.000 {built-in method torch.tensor}
        3    0.000    0.000    0.000    0.000 {method '__reduce_ex__' of 'object' objects}
      2/1    0.000    0.000    0.000    0.000 copy.py:210(<listcomp>)
        1    0.000    0.000    0.000    0.000 result.py:273(_wrap_compute)
        2    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)
       13    0.000    0.000    0.000    0.000 copy.py:242(_keep_alive)
      107    0.000    0.000    0.000    0.000 {built-in method builtins.id}
        2    0.000    0.000    0.000    0.000 storage.py:712(_new_wrapped_storage)
       19    0.000    0.000    0.000    0.000 dataclasses.py:1039(<genexpr>)
        6    0.000    0.000    0.000    0.000 copy.py:263(<genexpr>)
        1    0.000    0.000    0.000    0.000 inspect.py:1840(_signature_bound_method)
        2    0.000    0.000    0.000    0.000 {method 'set_' of 'torch._C.TensorBase' objects}
        4    0.000    0.000    0.000    0.000 storage.py:629(__init__)
        2    0.000    0.000    0.000    0.000 grad_mode.py:80(__enter__)
        2    0.000    0.000    0.000    0.000 {method 'new_empty' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}
        2    0.000    0.000    0.000    0.000 apply_func.py:69(<genexpr>)
        1    0.000    0.000    0.000    0.000 typing.py:271(inner)
        5    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 storage.py:557(__new__)
        1    0.000    0.000    0.000    0.000 inspect.py:494(unwrap)
        1    0.000    0.000    0.000    0.000 inspect.py:2873(replace)
        2    0.000    0.000    0.000    0.000 grad_mode.py:84(__exit__)
        3    0.000    0.000    0.000    0.000 _collections_abc.py:315(__subclasshook__)
        2    0.000    0.000    0.000    0.000 grad_mode.py:75(__init__)
        1    0.000    0.000    0.000    0.000 result.py:171(is_max_reduction)
        2    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}
        2    0.000    0.000    0.000    0.000 {method 'untyped_storage' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 _contextlib.py:154(__new__)
       24    0.000    0.000    0.000    0.000 copy.py:182(_deepcopy_atomic)
        2    0.000    0.000    0.000    0.000 {built-in method torch._C._has_storage}
        2    0.000    0.000    0.000    0.000 copyreg.py:94(__newobj__)
       14    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
        2    0.000    0.000    0.000    0.000 functools.py:65(wraps)
        2    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 inspect.py:514(_is_wrapper)
        2    0.000    0.000    0.000    0.000 {method 'contiguous' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 {method 'stride' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 {method 'is_conj' of 'torch._C.TensorBase' objects}
        2    0.000    0.000    0.000    0.000 {method 'nbytes' of 'torch._C.StorageBase' objects}
        2    0.000    0.000    0.000    0.000 {method 'is_neg' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 result.py:175(is_min_reduction)
        2    0.000    0.000    0.000    0.000 storage.py:30(__init__)
        2    0.000    0.000    0.000    0.000 {method 'storage_offset' of 'torch._C.TensorBase' objects}
        7    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 {built-in method builtins.len}
        1    0.000    0.000    0.000    0.000 {method '__setstate__' of 'functools.partial' objects}
        2    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}
        2    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)
        2    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_train_epoch_end
         30538 function calls in 0.068 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.000    0.000    0.066    0.000 early_stopping.py:186(on_train_epoch_end)
      200    0.002    0.000    0.063    0.000 early_stopping.py:198(_run_early_stopping_check)
      200    0.014    0.000    0.035    0.000 early_stopping.py:218(_evaluate_stopping_criteria)
      200    0.000    0.000    0.022    0.000 trainer.py:1606(callback_metrics)
      200    0.000    0.000    0.022    0.000 logger_connector.py:236(callback_metrics)
      200    0.000    0.000    0.020    0.000 logger_connector.py:229(metrics)
      200    0.001    0.000    0.017    0.000 result.py:476(metrics)
      203    0.017    0.000    0.017    0.000 {built-in method torch.isfinite}
      400    0.001    0.000    0.012    0.000 result.py:430(_get_cache)
      200    0.001    0.000    0.009    0.000 result.py:276(wrapped_func)
      200    0.003    0.000    0.007    0.000 result.py:246(compute)
      200    0.004    0.000    0.004    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
     1400    0.002    0.000    0.004    0.000 enums.py:81(__eq__)
      600    0.000    0.000    0.004    0.000 trainer.py:1642(_results)
      200    0.000    0.000    0.004    0.000 apply_func.py:113(convert_tensors_to_scalars)
      200    0.003    0.000    0.003    0.000 {built-in method torch.lt}
      200    0.000    0.000    0.003    0.000 apply_func.py:23(apply_to_collection)
     1200    0.001    0.000    0.003    0.000 trainer.py:1381(training)
      200    0.000    0.000    0.003    0.000 apply_func.py:122(to_item)
      200    0.001    0.000    0.003    0.000 early_stopping.py:181(_should_skip_check)
      205    0.003    0.000    0.003    0.000 {method 'item' of 'torch._C.TensorBase' objects}
      200    0.001    0.000    0.002    0.000 trainer.py:1429(sanity_checking)
      200    0.002    0.000    0.002    0.000 early_stopping.py:142(_validate_condition_metric)
      600    0.000    0.000    0.002    0.000 trainer.py:1564(_active_loop)
     2800    0.001    0.000    0.002    0.000 types.py:171(__get__)
      600    0.000    0.000    0.002    0.000 fit_loop.py:140(_results)
      200    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.001    0.000 distributed.py:392(_distributed_is_initialized)
      200    0.001    0.000    0.001    0.000 early_stopping.py:161(monitor_op)
      200    0.001    0.000    0.001    0.000 {method 'squeeze' of 'torch._C.TensorBase' objects}
      200    0.000    0.000    0.001    0.000 result.py:64(should)
      200    0.001    0.000    0.001    0.000 result.py:90(_generate_sync_fn)
      200    0.001    0.000    0.001    0.000 {method 'detach' of 'torch._C.TensorBase' objects}
      200    0.000    0.000    0.001    0.000 trainer.py:1178(lightning_module)
      200    0.000    0.000    0.001    0.000 {built-in method builtins.next}
        3    0.000    0.000    0.001    0.000 early_stopping.py:268(_log_info)
        3    0.000    0.000    0.000    0.000 __init__.py:1436(info)
        3    0.000    0.000    0.000    0.000 __init__.py:1565(_log)
      200    0.000    0.000    0.000    0.000 profiler.py:55(profile)
      200    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
        3    0.000    0.000    0.000    0.000 __init__.py:1591(handle)
        3    0.000    0.000    0.000    0.000 __init__.py:1645(callHandlers)
     2206    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
        3    0.000    0.000    0.000    0.000 __init__.py:939(handle)
      200    0.000    0.000    0.000    0.000 {method 'to' of 'torch._C.TensorBase' objects}
      200    0.000    0.000    0.000    0.000 distributed_c10d.py:996(is_initialized)
     2800    0.000    0.000    0.000    0.000 enum.py:792(value)
        3    0.000    0.000    0.000    0.000 __init__.py:1071(emit)
      200    0.000    0.000    0.000    0.000 result.py:465(_forked_name)
        3    0.000    0.000    0.000    0.000 early_stopping.py:257(_improvement_message)
     2800    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
        3    0.000    0.000    0.000    0.000 redirect.py:644(write)
      600    0.000    0.000    0.000    0.000 result.py:463(<genexpr>)
      200    0.000    0.000    0.000    0.000 advanced.py:71(stop)
      200    0.000    0.000    0.000    0.000 imports.py:162(__bool__)
        3    0.000    0.000    0.000    0.000 wandb_run.py:2310(<lambda>)
        3    0.000    0.000    0.000    0.000 wandb_run.py:390(wrapper_fn)
        3    0.000    0.000    0.000    0.000 wandb_run.py:1429(_console_raw_callback)
      200    0.000    0.000    0.000    0.000 result.py:461(valid_items)
        3    0.000    0.000    0.000    0.000 interface.py:749(publish_output_raw)
      403    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      200    0.000    0.000    0.000    0.000 typing.py:271(inner)
      200    0.000    0.000    0.000    0.000 distributed_c10d.py:608(WORLD)
      800    0.000    0.000    0.000    0.000 result.py:143(sync)
      200    0.000    0.000    0.000    0.000 __init__.py:10(is_available)
      200    0.000    0.000    0.000    0.000 result.py:294(__setattr__)
      200    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      200    0.000    0.000    0.000    0.000 result.py:158(forked_name)
      200    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C.TensorBase' objects}
        3    0.000    0.000    0.000    0.000 interface_shared.py:76(_publish_output_raw)
        3    0.000    0.000    0.000    0.000 interface_sock.py:45(_publish)
      200    0.000    0.000    0.000    0.000 imports.py:154(_check_available)
        3    0.000    0.000    0.000    0.000 sock_client.py:219(send_record_publish)
      200    0.000    0.000    0.000    0.000 result.py:163(is_mean_reduction)
        3    0.000    0.000    0.000    0.000 sock_client.py:153(send_server_request)
        3    0.000    0.000    0.000    0.000 sock_client.py:145(_send_message)
        5    0.000    0.000    0.000    0.000 _tensor.py:982(__format__)
      406    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      409    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      200    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
      200    0.000    0.000    0.000    0.000 metric.py:181(update_called)
      400    0.000    0.000    0.000    0.000 result.py:97(__call__)
      400    0.000    0.000    0.000    0.000 result.py:60(should)
        3    0.000    0.000    0.000    0.000 __init__.py:1550(makeRecord)
        3    0.000    0.000    0.000    0.000 sock_client.py:121(_sendall_with_error_handle)
        3    0.000    0.000    0.000    0.000 __init__.py:282(__init__)
      200    0.000    0.000    0.000    0.000 distributed_c10d.py:480(default_pg)
        3    0.000    0.000    0.000    0.000 {method 'send' of '_socket.socket' objects}
      200    0.000    0.000    0.000    0.000 strategy.py:341(reduce_boolean_decision)
        3    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        3    0.000    0.000    0.000    0.000 well_known_types.py:172(GetCurrentTime)
      400    0.000    0.000    0.000    0.000 result.py:101(no_op)
      200    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 result.py:154(forked)
      200    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
        3    0.000    0.000    0.000    0.000 __init__.py:916(format)
      200    0.000    0.000    0.000    0.000 result.py:80(group)
        3    0.000    0.000    0.000    0.000 well_known_types.py:242(FromDatetime)
      200    0.000    0.000    0.000    0.000 result.py:70(op)
        3    0.000    0.000    0.000    0.000 __init__.py:650(format)
        3    0.000    0.000    0.000    0.000 __init__.py:1514(findCaller)
        6    0.000    0.000    0.000    0.000 __init__.py:791(filter)
        6    0.000    0.000    0.000    0.000 __init__.py:896(acquire)
        3    0.000    0.000    0.000    0.000 __init__.py:628(usesTime)
        7    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
        3    0.000    0.000    0.000    0.000 calendar.py:655(timegm)
        3    0.000    0.000    0.000    0.000 __init__.py:1689(isEnabledFor)
        3    0.000    0.000    0.000    0.000 __init__.py:1060(flush)
        3    0.000    0.000    0.000    0.000 enum_type_wrapper.py:92(__getattr__)
        3    0.000    0.000    0.000    0.000 posixpath.py:140(basename)
        3    0.000    0.000    0.000    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
        3    0.000    0.000    0.000    0.000 posixpath.py:117(splitext)
        3    0.000    0.000    0.000    0.000 __init__.py:634(formatMessage)
        5    0.000    0.000    0.000    0.000 {method '__format__' of 'float' objects}
        3    0.000    0.000    0.000    0.000 genericpath.py:121(_splitext)
        3    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
        3    0.000    0.000    0.000    0.000 trainer.py:1147(world_size)
        5    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}
        3    0.000    0.000    0.000    0.000 __init__.py:432(format)
        6    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
        6    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
        3    0.000    0.000    0.000    0.000 __init__.py:160(<lambda>)
        3    0.000    0.000    0.000    0.000 __init__.py:421(usesTime)
        3    0.000    0.000    0.000    0.000 posixpath.py:52(normcase)
        3    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
        3    0.000    0.000    0.000    0.000 {built-in method utcnow}
        9    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}
        6    0.000    0.000    0.000    0.000 __init__.py:903(release)
        1    0.000    0.000    0.000    0.000 __init__.py:218(_acquireLock)
        3    0.000    0.000    0.000    0.000 __init__.py:429(_format)
        3    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
        3    0.000    0.000    0.000    0.000 threading.py:1358(current_thread)
        3    0.000    0.000    0.000    0.000 __init__.py:119(getLevelName)
        3    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)
        3    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
        9    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        1    0.000    0.000    0.000    0.000 __init__.py:1675(getEffectiveLevel)
        3    0.000    0.000    0.000    0.000 __init__.py:358(getMessage)
        3    0.000    0.000    0.000    0.000 rank_zero.py:91(rank_prefixed_message)
        5    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}
        1    0.000    0.000    0.000    0.000 __init__.py:227(_releaseLock)
        3    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
        3    0.000    0.000    0.000    0.000 threading.py:1093(name)
        9    0.000    0.000    0.000    0.000 {built-in method posix.fspath}
        3    0.000    0.000    0.000    0.000 {built-in method sys._getframe}
        3    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}
        7    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
        6    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
        3    0.000    0.000    0.000    0.000 {built-in method time.time}
        6    0.000    0.000    0.000    0.000 {built-in method builtins.len}
        3    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
        3    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
        3    0.000    0.000    0.000    0.000 process.py:189(name)
        3    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
        3    0.000    0.000    0.000    0.000 process.py:37(current_process)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
        1    0.000    0.000    0.000    0.000 __init__.py:1276(disable)



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end
         108425 function calls (103843 primitive calls) in 0.229 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.002    0.000    0.227    0.001 model_checkpoint.py:317(on_train_epoch_end)
      200    0.000    0.000    0.130    0.001 model_checkpoint.py:368(_save_topk_checkpoint)
      200    0.000    0.000    0.130    0.001 model_checkpoint.py:698(_save_monitor_checkpoint)
        4    0.000    0.000    0.121    0.030 model_checkpoint.py:718(_update_best_and_save)
        4    0.000    0.000    0.118    0.030 model_checkpoint.py:387(_save_checkpoint)
        4    0.000    0.000    0.118    0.030 trainer.py:1346(save_checkpoint)
        4    0.000    0.000    0.118    0.030 checkpoint_connector.py:404(dump_checkpoint)
      201    0.001    0.000    0.114    0.001 {built-in method builtins.next}
      200    0.000    0.000    0.113    0.001 profiler.py:55(profile)
        4    0.000    0.000    0.113    0.028 call.py:167(_call_lightning_datamodule_hook)
        4    0.000    0.000    0.113    0.028 contextlib.py:114(__enter__)
        4    0.000    0.000    0.113    0.028 advanced.py:65(start)
        4    0.113    0.028    0.113    0.028 {method 'enable' of '_lsprof.Profiler' objects}
      200    0.001    0.000    0.090    0.000 model_checkpoint.py:667(_monitor_candidates)
 3680/480    0.009    0.000    0.075    0.000 copy.py:128(deepcopy)
 1000/200    0.001    0.000    0.074    0.000 copy.py:226(_deepcopy_dict)
      800    0.017    0.000    0.067    0.000 _tensor.py:83(__deepcopy__)
      800    0.001    0.000    0.028    0.000 storage.py:907(_deepcopy)
      800    0.002    0.000    0.019    0.000 storage.py:140(__deepcopy__)
      800    0.005    0.000    0.017    0.000 storage.py:156(clone)
      800    0.012    0.000    0.012    0.000 {method 'copy_' of 'torch._C.StorageBase' objects}
      200    0.000    0.000    0.010    0.000 trainer.py:1606(callback_metrics)
      200    0.000    0.000    0.010    0.000 logger_connector.py:236(callback_metrics)
      200    0.006    0.000    0.009    0.000 model_checkpoint.py:512(check_monitor_top_k)
      200    0.000    0.000    0.008    0.000 logger_connector.py:229(metrics)
      200    0.001    0.000    0.006    0.000 result.py:476(metrics)
      800    0.002    0.000    0.005    0.000 _tensor.py:242(_typed_storage)
     1800    0.002    0.000    0.004    0.000 enums.py:81(__eq__)
      600    0.000    0.000    0.004    0.000 trainer.py:1642(_results)
      800    0.002    0.000    0.003    0.000 storage.py:712(_new_wrapped_storage)
      800    0.003    0.000    0.003    0.000 {method 'new_empty' of 'torch._C.TensorBase' objects}
      200    0.000    0.000    0.003    0.000 apply_func.py:113(convert_tensors_to_scalars)
      400    0.003    0.000    0.003    0.000 {built-in method torch.tensor}
      800    0.003    0.000    0.003    0.000 {method 'set_' of 'torch._C.TensorBase' objects}
     1200    0.001    0.000    0.003    0.000 trainer.py:1381(training)
        4    0.000    0.000    0.003    0.001 checkpoint_connector.py:499(_get_loops_state_dict)
      200    0.000    0.000    0.003    0.000 apply_func.py:23(apply_to_collection)
    32/16    0.000    0.000    0.003    0.000 loop.py:52(state_dict)
      197    0.003    0.000    0.003    0.000 {built-in method torch.lt}
      200    0.001    0.000    0.003    0.000 model_checkpoint.py:413(_should_skip_saving_checkpoint)
      200    0.000    0.000    0.002    0.000 apply_func.py:122(to_item)
        4    0.000    0.000    0.002    0.001 model_checkpoint.py:654(_get_metric_interpolated_filepath_name)
     1600    0.002    0.000    0.002    0.000 storage.py:629(__init__)
      208    0.002    0.000    0.002    0.000 {method 'item' of 'torch._C.TensorBase' objects}
      196    0.001    0.000    0.002    0.000 contextlib.py:123(__exit__)
     2600    0.002    0.000    0.002    0.000 copy.py:242(_keep_alive)
     1600    0.001    0.000    0.002    0.000 grad_mode.py:184(__init__)
      600    0.000    0.000    0.002    0.000 trainer.py:1564(_active_loop)
      800    0.001    0.000    0.002    0.000 grad_mode.py:80(__enter__)
      200    0.000    0.000    0.002    0.000 model_checkpoint.py:423(_should_save_on_train_epoch_end)
     2331    0.002    0.000    0.002    0.000 {built-in method builtins.getattr}
      404    0.000    0.000    0.002    0.000 trainer.py:1458(global_step)
       36    0.000    0.000    0.002    0.000 progress.py:24(state_dict)
       36    0.000    0.000    0.002    0.000 dataclasses.py:1054(asdict)
      600    0.000    0.000    0.002    0.000 fit_loop.py:140(_results)
      800    0.001    0.000    0.002    0.000 grad_mode.py:84(__exit__)
   408/36    0.001    0.000    0.002    0.000 dataclasses.py:1078(_asdict_inner)
     1600    0.001    0.000    0.002    0.000 storage.py:557(__new__)
        4    0.000    0.000    0.001    0.000 model_checkpoint.py:770(file_exists)
        4    0.000    0.000    0.001    0.000 checkpoint_connector.py:496(_get_lightning_module_state_dict)
        4    0.000    0.000    0.001    0.000 strategy.py:473(lightning_module_state_dict)
     3600    0.001    0.000    0.001    0.000 types.py:171(__get__)
    184/4    0.001    0.000    0.001    0.000 module.py:1865(state_dict)
        4    0.000    0.000    0.001    0.000 spec.py:633(exists)
      404    0.001    0.000    0.001    0.000 training_epoch_loop.py:99(global_step)
        4    0.000    0.000    0.001    0.000 local.py:71(info)
8206/8202    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}
        4    0.001    0.000    0.001    0.000 {built-in method posix.stat}
      400    0.000    0.000    0.001    0.000 trainer.py:1535(num_val_batches)
      800    0.001    0.000    0.001    0.000 grad_mode.py:75(__init__)
      360    0.001    0.000    0.001    0.000 {method 'detach' of 'torch._C.TensorBase' objects}
     9721    0.001    0.000    0.001    0.000 {built-in method builtins.id}
      400    0.000    0.000    0.001    0.000 result.py:430(_get_cache)
      200    0.000    0.000    0.001    0.000 trainer.py:1429(sanity_checking)
     8160    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}
      800    0.001    0.000    0.001    0.000 {built-in method torch._C._has_storage}
        4    0.000    0.000    0.001    0.000 model_checkpoint.py:567(format_checkpoint_name)
      184    0.000    0.000    0.001    0.000 module.py:1826(_save_to_state_dict)
        4    0.000    0.000    0.001    0.000 model_checkpoint.py:531(_format_checkpoint_name)
        4    0.000    0.000    0.001    0.000 strategy.py:173(optimizer_state)
      800    0.001    0.000    0.001    0.000 {method 'untyped_storage' of 'torch._C.TensorBase' objects}
      800    0.001    0.000    0.001    0.000 _contextlib.py:154(__new__)
     1600    0.001    0.000    0.001    0.000 {built-in method torch._C._set_grad_enabled}
      608    0.000    0.000    0.001    0.000 trainer.py:1178(lightning_module)
        4    0.000    0.000    0.001    0.000 _compile.py:21(inner)
        4    0.000    0.000    0.001    0.000 re.py:233(findall)
        4    0.000    0.000    0.000    0.000 eval_frame.py:596(_fn)
        4    0.000    0.000    0.000    0.000 optimizer.py:631(state_dict)
        4    0.000    0.000    0.000    0.000 fit_loop.py:415(on_save_checkpoint)
     3600    0.000    0.000    0.000    0.000 enum.py:792(value)
        4    0.000    0.000    0.000    0.000 combined_loader.py:378(_state_dicts)
      800    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.TensorBase' objects}
     2400    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}
     2400    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7f134bf377c0}
        4    0.000    0.000    0.000    0.000 combined_loader.py:380(<listcomp>)
        4    0.000    0.000    0.000    0.000 typing.py:1141(__instancecheck__)
     3600    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
        4    0.000    0.000    0.000    0.000 re.py:289(_compile)
     2821    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
      444    0.000    0.000    0.000    0.000 dataclasses.py:1042(_is_dataclass_instance)
      128    0.000    0.000    0.000    0.000 dataclasses.py:1024(fields)
     1604    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}
2041/2038    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      200    0.000    0.000    0.000    0.000 result.py:465(_forked_name)
        4    0.000    0.000    0.000    0.000 optimizer.py:703(<listcomp>)
        4    0.000    0.000    0.000    0.000 optimizer.py:689(pack_group)
      600    0.000    0.000    0.000    0.000 result.py:463(<genexpr>)
      196    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 sre_compile.py:783(compile)
      800    0.000    0.000    0.000    0.000 {method 'is_conj' of 'torch._C.TensorBase' objects}
      404    0.000    0.000    0.000    0.000 progress.py:274(optimizer_steps)
      800    0.000    0.000    0.000    0.000 {method 'stride' of 'torch._C.TensorBase' objects}
      800    0.000    0.000    0.000    0.000 {method 'nbytes' of 'torch._C.StorageBase' objects}
      800    0.000    0.000    0.000    0.000 {method 'storage_offset' of 'torch._C.TensorBase' objects}
       10    0.000    0.000    0.000    0.000 typing.py:1065(_get_protocol_attrs)
      404    0.000    0.000    0.000    0.000 trainer.py:1467(current_epoch)
        5    0.000    0.000    0.000    0.000 typing.py:1082(_is_callable_members_only)
      833    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
      800    0.000    0.000    0.000    0.000 {method 'is_neg' of 'torch._C.TensorBase' objects}
      200    0.000    0.000    0.000    0.000 result.py:461(valid_items)
      404    0.000    0.000    0.000    0.000 module.py:295(automatic_optimization)
        4    0.000    0.000    0.000    0.000 {method 'findall' of 're.Pattern' objects}
      208    0.000    0.000    0.000    0.000 typing.py:271(inner)
      205    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
      647    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
        1    0.000    0.000    0.000    0.000 sre_parse.py:944(parse)
      808    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}
     1245    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
      800    0.000    0.000    0.000    0.000 storage.py:30(__init__)
        2    0.000    0.000    0.000    0.000 {built-in method builtins.max}
       11    0.000    0.000    0.000    0.000 {built-in method builtins.min}
      200    0.000    0.000    0.000    0.000 result.py:158(forked_name)
      196    0.000    0.000    0.000    0.000 model_checkpoint.py:677(_save_last_checkpoint)
     1080    0.000    0.000    0.000    0.000 copy.py:182(_deepcopy_atomic)
      2/1    0.000    0.000    0.000    0.000 sre_parse.py:436(_parse_sub)
      801    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {built-in method builtins.sum}
      616    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
      800    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)
      2/1    0.000    0.000    0.000    0.000 sre_parse.py:494(_parse)
      500    0.000    0.000    0.000    0.000 dataclasses.py:1039(<genexpr>)
        4    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
        4    0.000    0.000    0.000    0.000 optimizer.py:705(<dictcomp>)
        4    0.000    0.000    0.000    0.000 optimizer.py:691(<dictcomp>)
      200    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C.TensorBase' objects}
        4    0.000    0.000    0.000    0.000 optimizer.py:693(<dictcomp>)
        8    0.000    0.000    0.000    0.000 _tensor.py:982(__format__)
        1    0.000    0.000    0.000    0.000 sre_compile.py:622(_code)
        4    0.000    0.000    0.000    0.000 lr_scheduler.py:1383(state_dict)
        4    0.000    0.000    0.000    0.000 call.py:217(_call_callbacks_state_dict)
        1    0.000    0.000    0.000    0.000 decorators.py:38(disable)
        4    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)
        4    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}
        4    0.000    0.000    0.000    0.000 local.py:230(_strip_protocol)
        4    0.000    0.000    0.000    0.000 {built-in method torch.isnan}
        4    0.000    0.000    0.000    0.000 lr_scheduler.py:1384(<dictcomp>)
        1    0.000    0.000    0.000    0.000 typing.py:1200(_proto_hook)
      552    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
        4    0.000    0.000    0.000    0.000 optimizer.py:699(<listcomp>)
      196    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
      200    0.000    0.000    0.000    0.000 result.py:154(forked)
      3/1    0.000    0.000    0.000    0.000 sre_compile.py:87(_compile)
      197    0.000    0.000    0.000    0.000 strategy.py:341(reduce_boolean_decision)
      376    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}
        1    0.000    0.000    0.000    0.000 eval_frame.py:565(__call__)
        1    0.000    0.000    0.000    0.000 sre_compile.py:560(_compile_info)
        4    0.000    0.000    0.000    0.000 posixpath.py:71(join)
        8    0.000    0.000    0.000    0.000 callback.py:48(_generate_state_key)
      164    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
        4    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}
        1    0.000    0.000    0.000    0.000 eval_frame.py:562(__init__)
        9    0.000    0.000    0.000    0.000 {built-in method builtins.all}
        4    0.000    0.000    0.000    0.000 early_stopping.py:130(state_key)
        1    0.000    0.000    0.000    0.000 eval_frame.py:265(__init__)
        4    0.000    0.000    0.000    0.000 model_checkpoint.py:256(state_key)
        1    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)
        8    0.000    0.000    0.000    0.000 {built-in method builtins.repr}
        1    0.000    0.000    0.000    0.000 sre_compile.py:292(_optimize_charset)
        8    0.000    0.000    0.000    0.000 hparams_mixin.py:152(hparams)
      128    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}
       15    0.000    0.000    0.000    0.000 typing.py:1084(<genexpr>)
        4    0.000    0.000    0.000    0.000 early_stopping.py:165(state_dict)
        1    0.000    0.000    0.000    0.000 sre_parse.py:356(_escape)
      2/1    0.000    0.000    0.000    0.000 sre_compile.py:485(_get_literal_prefix)
        1    0.000    0.000    0.000    0.000 enum.py:977(__and__)
      4/2    0.000    0.000    0.000    0.000 sre_parse.py:175(getwidth)
        1    0.000    0.000    0.000    0.000 sre_parse.py:225(__init__)
       16    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}
       14    0.000    0.000    0.000    0.000 sre_parse.py:165(__getitem__)
        4    0.000    0.000    0.000    0.000 trainer.py:1183(optimizers)
        4    0.000    0.000    0.000    0.000 contextlib.py:261(helper)
        1    0.000    0.000    0.000    0.000 sre_parse.py:97(closegroup)
        1    0.000    0.000    0.000    0.000 sre_parse.py:85(opengroup)
        8    0.000    0.000    0.000    0.000 sre_parse.py:255(get)
        4    0.000    0.000    0.000    0.000 trainer.py:1203(model)
        4    0.000    0.000    0.000    0.000 model_checkpoint.py:335(state_dict)
       11    0.000    0.000    0.000    0.000 sre_parse.py:234(__next)
        2    0.000    0.000    0.000    0.000 enum.py:358(__call__)
        4    0.000    0.000    0.000    0.000 trainer.py:1129(precision_plugin)
        7    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)
        4    0.000    0.000    0.000    0.000 local.py:280(make_path_posix)
        4    0.000    0.000    0.000    0.000 training_epoch_loop.py:317(on_save_checkpoint)
        3    0.000    0.000    0.000    0.000 sre_parse.py:112(__init__)
        4    0.000    0.000    0.000    0.000 contextlib.py:86(__init__)
        4    0.000    0.000    0.000    0.000 __init__.py:1424(debug)
        8    0.000    0.000    0.000    0.000 typing.py:1149(<genexpr>)
        2    0.000    0.000    0.000    0.000 enum.py:670(__new__)
       32    0.000    0.000    0.000    0.000 loop.py:40(on_save_checkpoint)
        4    0.000    0.000    0.000    0.000 {method '__format__' of 'float' objects}
        8    0.000    0.000    0.000    0.000 {built-in method torch._C._dynamo.eval_frame.set_eval_frame}
        4    0.000    0.000    0.000    0.000 {method '__format__' of 'int' objects}
        1    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)
        4    0.000    0.000    0.000    0.000 utils.py:327(stringify_path)
        8    0.000    0.000    0.000    0.000 model_checkpoint.py:547(<lambda>)
       10    0.000    0.000    0.000    0.000 {method 'keys' of 'mappingproxy' objects}
        4    0.000    0.000    0.000    0.000 trainer.py:1191(lr_scheduler_configs)
        1    0.000    0.000    0.000    0.000 sre_parse.py:433(_uniq)
        4    0.000    0.000    0.000    0.000 strategy.py:101(optimizers)
        5    0.000    0.000    0.000    0.000 sre_parse.py:287(tell)
        1    0.000    0.000    0.000    0.000 sre_parse.py:296(_class_escape)
        7    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}
        8    0.000    0.000    0.000    0.000 sre_parse.py:250(match)
        1    0.000    0.000    0.000    0.000 sre_compile.py:447(_simple)
        4    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)
        5    0.000    0.000    0.000    0.000 sre_parse.py:161(__len__)
        4    0.000    0.000    0.000    0.000 __init__.py:1689(isEnabledFor)
       17    0.000    0.000    0.000    0.000 {built-in method builtins.callable}
        4    0.000    0.000    0.000    0.000 sre_parse.py:82(groups)
        8    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}
       20    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
        1    0.000    0.000    0.000    0.000 sre_compile.py:265(_compile_charset)
        5    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}
        3    0.000    0.000    0.000    0.000 eval_frame.py:240(innermost_fn)
        4    0.000    0.000    0.000    0.000 strategy.py:93(precision_plugin)
        8    0.000    0.000    0.000    0.000 callback.py:232(state_dict)
        4    0.000    0.000    0.000    0.000 sre_parse.py:173(append)
        4    0.000    0.000    0.000    0.000 combined_loader.py:308(flattened)
        1    0.000    0.000    0.000    0.000 sre_compile.py:456(_generate_overlap_table)
        4    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {built-in method _sre.compile}
        4    0.000    0.000    0.000    0.000 strategy.py:351(model)
        1    0.000    0.000    0.000    0.000 functools.py:65(wraps)
        1    0.000    0.000    0.000    0.000 sre_parse.py:928(fix_flags)
        2    0.000    0.000    0.000    0.000 sre_compile.py:619(isstring)
        4    0.000    0.000    0.000    0.000 precision.py:138(state_dict)
       10    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        4    0.000    0.000    0.000    0.000 hooks.py:692(on_save_checkpoint)
        4    0.000    0.000    0.000    0.000 single_device.py:90(broadcast)
        2    0.000    0.000    0.000    0.000 sre_compile.py:81(_combine_flags)
        2    0.000    0.000    0.000    0.000 sre_compile.py:477(_get_iscased)
        5    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}
        4    0.000    0.000    0.000    0.000 {built-in method posix.fspath}
        1    0.000    0.000    0.000    0.000 {built-in method fromkeys}
        1    0.000    0.000    0.000    0.000 inspect.py:73(isclass)
        1    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
        3    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
        1    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}
        3    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}
        1    0.000    0.000    0.000    0.000 sre_parse.py:169(__setitem__)
        1    0.000    0.000    0.000    0.000 eval_frame.py:232(nothing)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}



Profile stats for: [LightningDataModule]PMTfiedDataModule.state_dict
         28 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        4    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        4    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        4    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        4    0.000    0.000    0.000    0.000 datamodule.py:150(state_dict)
        4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_save_checkpoint
         40 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        4    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        4    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        4    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        4    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        4    0.000    0.000    0.000    0.000 callback.py:250(on_save_checkpoint)
        4    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        4    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_save_checkpoint
         40 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        4    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        4    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        4    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        4    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        4    0.000    0.000    0.000    0.000 callback.py:250(on_save_checkpoint)
        4    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        4    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelSummary.on_save_checkpoint
         40 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        4    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        4    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        4    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        4    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        4    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        4    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        4    0.000    0.000    0.000    0.000 callback.py:250(on_save_checkpoint)



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint
         40 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        4    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        4    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        4    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        4    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        4    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        4    0.000    0.000    0.000    0.000 callback.py:250(on_save_checkpoint)
        4    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_save_checkpoint
         28 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        4    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        4    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        4    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        4    0.000    0.000    0.000    0.000 hooks.py:692(on_save_checkpoint)
        4    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.lr_scheduler_step
         2266 function calls in 0.012 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    0.002    0.000    0.011    0.000 module.py:1249(lr_scheduler_step)
      200    0.007    0.000    0.009    0.000 lr_scheduler.py:1316(step)
      200    0.002    0.000    0.002    0.000 lr_scheduler.py:1353(is_better)
      200    0.000    0.000    0.001    0.000 contextlib.py:123(__exit__)
      200    0.000    0.000    0.001    0.000 {built-in method builtins.next}
      200    0.000    0.000    0.001    0.000 profiler.py:55(profile)
      200    0.001    0.000    0.001    0.000 advanced.py:71(stop)
      200    0.001    0.000    0.001    0.000 lr_scheduler.py:1349(in_cooldown)
       33    0.000    0.000    0.000    0.000 lr_scheduler.py:1342(_reduce_lr)
      200    0.000    0.000    0.000    0.000 lr_scheduler.py:1340(<listcomp>)
      200    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
      200    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
       33    0.000    0.000    0.000    0.000 {built-in method builtins.max}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_train_end
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 callback.py:208(on_train_end)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.on_train_end
         486 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:283(on_train_end)
        1    0.000    0.000    0.000    0.000 std.py:1265(close)
        1    0.000    0.000    0.000    0.000 std.py:1464(display)
        1    0.000    0.000    0.000    0.000 std.py:1150(__str__)
        4    0.000    0.000    0.000    0.000 utils.py:194(inner)
        1    0.000    0.000    0.000    0.000 std.py:464(format_meter)
        3    0.000    0.000    0.000    0.000 redirect.py:644(write)
        3    0.000    0.000    0.000    0.000 wandb_run.py:2304(<lambda>)
        3    0.000    0.000    0.000    0.000 wandb_run.py:390(wrapper_fn)
        3    0.000    0.000    0.000    0.000 wandb_run.py:1429(_console_raw_callback)
        3    0.000    0.000    0.000    0.000 interface.py:749(publish_output_raw)
        2    0.000    0.000    0.000    0.000 std.py:1286(fp_write)
        1    0.000    0.000    0.000    0.000 std.py:457(print_status)
        3    0.000    0.000    0.000    0.000 interface_shared.py:76(_publish_output_raw)
        3    0.000    0.000    0.000    0.000 interface_sock.py:45(_publish)
        3    0.000    0.000    0.000    0.000 sock_client.py:219(send_record_publish)
        3    0.000    0.000    0.000    0.000 sock_client.py:153(send_server_request)
        3    0.000    0.000    0.000    0.000 sock_client.py:145(_send_message)
        1    0.000    0.000    0.000    0.000 std.py:451(fp_write)
        1    0.000    0.000    0.000    0.000 utils.py:378(disp_len)
        3    0.000    0.000    0.000    0.000 sock_client.py:121(_sendall_with_error_handle)
        1    0.000    0.000    0.000    0.000 utils.py:374(_text_width)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.sum}
        1    0.000    0.000    0.000    0.000 std.py:1446(format_dict)
        3    0.000    0.000    0.000    0.000 {method 'send' of '_socket.socket' objects}
        1    0.000    0.000    0.000    0.000 utils.py:333(_screen_shape_linux)
        1    0.000    0.000    0.000    0.000 std.py:686(_decr_instances)
       97    0.000    0.000    0.000    0.000 utils.py:375(<genexpr>)
        3    0.000    0.000    0.000    0.000 well_known_types.py:172(GetCurrentTime)
        3    0.000    0.000    0.000    0.000 well_known_types.py:242(FromDatetime)
        2    0.000    0.000    0.000    0.000 utils.py:273(_is_ascii)
        1    0.000    0.000    0.000    0.000 utils.py:347(<listcomp>)
        1    0.000    0.000    0.000    0.000 os.py:674(__getitem__)
        1    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}
        1    0.000    0.000    0.000    0.000 _weakrefset.py:63(__iter__)
        2    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
        1    0.000    0.000    0.000    0.000 os.py:754(encode)
       96    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}
        1    0.000    0.000    0.000    0.000 _weakrefset.py:111(remove)
        1    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
        2    0.000    0.000    0.000    0.000 std.py:110(__enter__)
        2    0.000    0.000    0.000    0.000 std.py:113(__exit__)
        3    0.000    0.000    0.000    0.000 calendar.py:655(timegm)
        2    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
       89    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
        3    0.000    0.000    0.000    0.000 {method 'utctimetuple' of 'datetime.datetime' objects}
        3    0.000    0.000    0.000    0.000 enum_type_wrapper.py:92(__getattr__)
        2    0.000    0.000    0.000    0.000 std.py:102(acquire)
        2    0.000    0.000    0.000    0.000 std.py:106(release)
        2    0.000    0.000    0.000    0.000 std.py:400(format_interval)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 _weakrefset.py:27(__exit__)
        3    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        6    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 utils.py:125(__eq__)
        1    0.000    0.000    0.000    0.000 std.py:186(__format__)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        3    0.000    0.000    0.000    0.000 interface_sock.py:41(_assign)
        2    0.000    0.000    0.000    0.000 std.py:1153(_comparable)
        1    0.000    0.000    0.000    0.000 _weakrefset.py:53(_commit_removals)
        1    0.000    0.000    0.000    0.000 _weakrefset.py:21(__enter__)
        3    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
        1    0.000    0.000    0.000    0.000 std.py:153(__init__)
        3    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}
       10    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        3    0.000    0.000    0.000    0.000 {built-in method utcnow}
        1    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}
        3    0.000    0.000    0.000    0.000 {built-in method _struct.pack}
        1    0.000    0.000    0.000    0.000 std.py:1157(__hash__)
        2    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
        1    0.000    0.000    0.000    0.000 {built-in method now}
        3    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
        1    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        7    0.000    0.000    0.000    0.000 {built-in method builtins.len}
        2    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
        5    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
        3    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
        1    0.000    0.000    0.000    0.000 _weakrefset.py:17(__init__)
        3    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
        2    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
        3    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
        1    0.000    0.000    0.000    0.000 utils.py:112(__format__)
        1    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
        1    0.000    0.000    0.000    0.000 utils.py:108(__init__)
        3    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}
        3    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}
        1    0.000    0.000    0.000    0.000 {built-in method builtins.max}
        2    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
        2    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
        1    0.000    0.000    0.000    0.000 tqdm_progress.py:121(train_progress_bar)
        3    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
        1    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
        1    0.000    0.000    0.000    0.000 std.py:167(colour)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {built-in method time.time}
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.id}
        1    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
        1    0.000    0.000    0.000    0.000 std.py:1301(<lambda>)
        1    0.000    0.000    0.000    0.000 std.py:163(colour)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)



Profile stats for: [Callback]ModelSummary.on_train_end
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 callback.py:208(on_train_end)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 callback.py:208(on_train_end)



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_train_end
         7 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 hooks.py:47(on_train_end)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}



Profile stats for: [Strategy]SingleDeviceStrategy.on_train_end
         7 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 strategy.py:561(on_train_end)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.on_fit_end
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 callback.py:67(on_fit_end)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)



Profile stats for: [Callback]TQDMProgressBar.on_fit_end
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 callback.py:67(on_fit_end)



Profile stats for: [Callback]ModelSummary.on_fit_end
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 callback.py:67(on_fit_end)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 callback.py:67(on_fit_end)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.on_fit_end
         7 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 hooks.py:37(on_fit_end)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [LightningDataModule]PMTfiedDataModule.teardown
         7 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 hooks.py:447(teardown)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]EarlyStopping{'monitor': 'val_acc', 'mode': 'min'}.teardown
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 callback.py:61(teardown)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]TQDMProgressBar.teardown
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 callback.py:61(teardown)



Profile stats for: [Callback]ModelSummary.teardown
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 callback.py:61(teardown)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}



Profile stats for: [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown
         10 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 trainer.py:1178(lightning_module)
        1    0.000    0.000    0.000    0.000 trainer.py:1125(strategy)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 strategy.py:360(lightning_module)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 callback.py:61(teardown)



Profile stats for: [LightningModule]FlavourClassificationTransformerEncoder.teardown
         7 function calls in 0.000 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)
        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}
        1    0.000    0.000    0.000    0.000 profiler.py:55(profile)
        1    0.000    0.000    0.000    0.000 advanced.py:71(stop)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 hooks.py:447(teardown)



wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: epoch_avg_train_loss ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           train_loss ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:              val_acc ‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:             val_loss ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:                epoch 199
wandb: epoch_avg_train_loss 0.97552
wandb:           train_loss 0.97552
wandb:  trainer/global_step 199
wandb:              val_acc 0.66667
wandb:             val_loss 1.10766
wandb: 
wandb: üöÄ View run polar-silence-1 at: https://wandb.ai/cyans-k-benhavns-universitet/%5B20250204_164249%5D%20Flavour%20Classification/runs/ys9snpro
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cyans-k-benhavns-universitet/%5B20250204_164249%5D%20Flavour%20Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250204_164258-ys9snpro/logs

| Parameter       | Value               |
|-----------------|---------------------|
| attention       | XFormers       |
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.005          |
| epochs          | 200            |
| batch_size      | 32             |

######## Execution time: 00:01:49 ########
