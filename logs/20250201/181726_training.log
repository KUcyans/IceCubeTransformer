2025-02-01 18:17:30,562 - INFO - Starting training with the following parameters:
2025-02-01 18:17:30,563 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product |
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.005          |
| epochs          | 300            |

2025-02-01 18:17:31,919 - INFO - Epoch 0: val_loss=1.0415, val_acc=66.67%
2025-02-01 18:17:32,594 - INFO - ####################Training epoch 0####################
2025-02-01 18:17:32,743 - INFO - Epoch 0: train_loss=1.1336
2025-02-01 18:17:34,135 - INFO - Epoch 0: val_loss=5.7106, val_acc=0.00%
2025-02-01 18:17:34,168 - INFO - ####################Training epoch 1####################
2025-02-01 18:17:35,207 - INFO - Epoch 1: train_loss=3.4867
2025-02-01 18:17:36,436 - INFO - Epoch 1: val_loss=1.8477, val_acc=66.67%
2025-02-01 18:17:36,517 - INFO - ####################Training epoch 2####################
2025-02-01 18:17:37,551 - INFO - Epoch 2: train_loss=2.3545
2025-02-01 18:17:38,783 - INFO - Epoch 2: val_loss=2.3387, val_acc=33.33%
2025-02-01 18:17:38,815 - INFO - ####################Training epoch 3####################
2025-02-01 18:17:39,868 - INFO - Epoch 3: train_loss=1.6069
2025-02-01 18:17:41,092 - INFO - Epoch 3: val_loss=2.4527, val_acc=33.33%
2025-02-01 18:17:41,122 - INFO - ####################Training epoch 4####################
2025-02-01 18:17:42,174 - INFO - Epoch 4: train_loss=1.6834
2025-02-01 18:17:43,410 - INFO - Epoch 4: val_loss=1.9076, val_acc=0.00%
2025-02-01 18:17:43,445 - INFO - ####################Training epoch 5####################
2025-02-01 18:17:44,480 - INFO - Epoch 5: train_loss=1.2131
2025-02-01 18:17:45,682 - INFO - Epoch 5: val_loss=1.3106, val_acc=33.33%
2025-02-01 18:17:45,686 - INFO - ####################Training epoch 6####################
2025-02-01 18:17:46,717 - INFO - Epoch 6: train_loss=1.1174
2025-02-01 18:17:47,937 - INFO - Epoch 6: val_loss=0.9962, val_acc=66.67%
2025-02-01 18:17:47,941 - INFO - ####################Training epoch 7####################
2025-02-01 18:17:48,957 - INFO - Epoch 7: train_loss=1.1600
2025-02-01 18:17:50,178 - INFO - Epoch 7: val_loss=1.0302, val_acc=66.67%
2025-02-01 18:17:50,182 - INFO - ####################Training epoch 8####################
2025-02-01 18:17:51,219 - INFO - Epoch 8: train_loss=1.1640
2025-02-01 18:17:52,447 - INFO - Epoch 8: val_loss=1.1686, val_acc=33.33%
2025-02-01 18:17:52,451 - INFO - ####################Training epoch 9####################
2025-02-01 18:17:53,482 - INFO - Epoch 9: train_loss=1.0898
2025-02-01 18:17:54,703 - INFO - Epoch 9: val_loss=1.4975, val_acc=33.33%
2025-02-01 18:17:54,707 - INFO - ####################Training epoch 10####################
2025-02-01 18:17:55,755 - INFO - Epoch 10: train_loss=1.1149
2025-02-01 18:17:56,987 - INFO - Epoch 10: val_loss=1.7361, val_acc=33.33%
2025-02-01 18:17:56,990 - INFO - ####################Training epoch 11####################
2025-02-01 18:17:58,026 - INFO - Epoch 11: train_loss=1.1372
2025-02-01 18:17:59,242 - INFO - Epoch 11: val_loss=1.8298, val_acc=0.00%
2025-02-01 18:17:59,271 - INFO - ####################Training epoch 12####################
2025-02-01 18:18:00,380 - INFO - Epoch 12: train_loss=1.1002
2025-02-01 18:18:01,664 - INFO - Epoch 12: val_loss=1.8586, val_acc=0.00%
2025-02-01 18:18:01,668 - INFO - ####################Training epoch 13####################
2025-02-01 18:18:02,705 - INFO - Epoch 13: train_loss=1.0661
2025-02-01 18:18:03,921 - INFO - Epoch 13: val_loss=1.8718, val_acc=33.33%
2025-02-01 18:18:03,925 - INFO - ####################Training epoch 14####################
2025-02-01 18:18:04,965 - INFO - Epoch 14: train_loss=1.0648
2025-02-01 18:18:06,209 - INFO - Epoch 14: val_loss=1.8793, val_acc=33.33%
2025-02-01 18:18:06,213 - INFO - ####################Training epoch 15####################
2025-02-01 18:18:07,256 - INFO - Epoch 15: train_loss=1.0699
2025-02-01 18:18:08,481 - INFO - Epoch 15: val_loss=1.9296, val_acc=33.33%
2025-02-01 18:18:08,485 - INFO - ####################Training epoch 16####################
2025-02-01 18:18:09,538 - INFO - Epoch 16: train_loss=1.0697
2025-02-01 18:18:10,765 - INFO - Epoch 16: val_loss=2.0230, val_acc=33.33%
2025-02-01 18:18:10,768 - INFO - ####################Training epoch 17####################
2025-02-01 18:18:11,818 - INFO - Epoch 17: train_loss=1.0615
2025-02-01 18:18:13,046 - INFO - Epoch 17: val_loss=2.1291, val_acc=33.33%
2025-02-01 18:18:13,050 - INFO - ####################Training epoch 18####################
2025-02-01 18:18:14,087 - INFO - Epoch 18: train_loss=1.0595
2025-02-01 18:18:15,310 - INFO - Epoch 18: val_loss=2.2267, val_acc=0.00%
2025-02-01 18:18:15,314 - INFO - ####################Training epoch 19####################
2025-02-01 18:18:16,353 - INFO - Epoch 19: train_loss=1.0589
2025-02-01 18:18:17,586 - INFO - Epoch 19: val_loss=2.2791, val_acc=0.00%
2025-02-01 18:18:17,590 - INFO - ####################Training epoch 20####################
2025-02-01 18:18:18,628 - INFO - Epoch 20: train_loss=1.0580
2025-02-01 18:18:19,846 - INFO - Epoch 20: val_loss=2.3116, val_acc=0.00%
2025-02-01 18:18:19,850 - INFO - ####################Training epoch 21####################
2025-02-01 18:18:20,897 - INFO - Epoch 21: train_loss=1.0548
2025-02-01 18:18:22,110 - INFO - Epoch 21: val_loss=2.3333, val_acc=0.00%
2025-02-01 18:18:22,113 - INFO - ####################Training epoch 22####################
2025-02-01 18:18:23,153 - INFO - Epoch 22: train_loss=1.0486
2025-02-01 18:18:24,394 - INFO - Epoch 22: val_loss=2.3514, val_acc=33.33%
2025-02-01 18:18:24,398 - INFO - ####################Training epoch 23####################
2025-02-01 18:18:25,453 - INFO - Epoch 23: train_loss=1.0437
2025-02-01 18:18:26,663 - INFO - Epoch 23: val_loss=2.3579, val_acc=33.33%
2025-02-01 18:18:26,666 - INFO - ####################Training epoch 24####################
2025-02-01 18:18:27,706 - INFO - Epoch 24: train_loss=1.0366
2025-02-01 18:18:28,914 - INFO - Epoch 24: val_loss=2.3871, val_acc=33.33%
2025-02-01 18:18:28,917 - INFO - ####################Training epoch 25####################
2025-02-01 18:18:29,961 - INFO - Epoch 25: train_loss=1.0344
2025-02-01 18:18:31,200 - INFO - Epoch 25: val_loss=2.3949, val_acc=33.33%
2025-02-01 18:18:31,204 - INFO - ####################Training epoch 26####################
2025-02-01 18:18:32,234 - INFO - Epoch 26: train_loss=1.0314
2025-02-01 18:18:33,454 - INFO - Epoch 26: val_loss=2.3982, val_acc=33.33%
2025-02-01 18:18:33,457 - INFO - ####################Training epoch 27####################
2025-02-01 18:18:34,509 - INFO - Epoch 27: train_loss=1.0309
2025-02-01 18:18:35,728 - INFO - Epoch 27: val_loss=2.4079, val_acc=33.33%
2025-02-01 18:18:35,731 - INFO - ####################Training epoch 28####################
2025-02-01 18:18:36,787 - INFO - Epoch 28: train_loss=1.0254
2025-02-01 18:18:38,027 - INFO - Epoch 28: val_loss=2.4216, val_acc=33.33%
2025-02-01 18:18:38,031 - INFO - ####################Training epoch 29####################
2025-02-01 18:18:39,084 - INFO - Epoch 29: train_loss=1.0232
2025-02-01 18:18:40,321 - INFO - Epoch 29: val_loss=2.4374, val_acc=33.33%
2025-02-01 18:18:40,325 - INFO - ####################Training epoch 30####################
2025-02-01 18:18:41,442 - INFO - Epoch 30: train_loss=1.0144
2025-02-01 18:18:42,213 - INFO - Epoch 30: val_loss=2.4611, val_acc=33.33%
2025-02-01 18:18:42,217 - INFO - ####################Training epoch 31####################
2025-02-01 18:18:43,067 - INFO - Epoch 31: train_loss=1.0061
2025-02-01 18:18:43,669 - INFO - Epoch 31: val_loss=2.4775, val_acc=33.33%
2025-02-01 18:18:43,673 - INFO - ####################Training epoch 32####################
2025-02-01 18:18:44,088 - INFO - Epoch 32: train_loss=1.0030
2025-02-01 18:18:44,692 - INFO - Epoch 32: val_loss=2.4796, val_acc=33.33%
2025-02-01 18:18:44,695 - INFO - ####################Training epoch 33####################
2025-02-01 18:18:45,116 - INFO - Epoch 33: train_loss=0.9942
2025-02-01 18:18:45,718 - INFO - Epoch 33: val_loss=2.4895, val_acc=33.33%
2025-02-01 18:18:45,722 - INFO - ####################Training epoch 34####################
2025-02-01 18:18:46,144 - INFO - Epoch 34: train_loss=0.9888
2025-02-01 18:18:46,745 - INFO - Epoch 34: val_loss=2.4506, val_acc=33.33%
2025-02-01 18:18:46,749 - INFO - ####################Training epoch 35####################
2025-02-01 18:18:47,166 - INFO - Epoch 35: train_loss=1.0182
2025-02-01 18:18:47,770 - INFO - Epoch 35: val_loss=2.5304, val_acc=33.33%
2025-02-01 18:18:47,773 - INFO - ####################Training epoch 36####################
2025-02-01 18:18:48,193 - INFO - Epoch 36: train_loss=0.9684
2025-02-01 18:18:48,793 - INFO - Epoch 36: val_loss=2.5668, val_acc=33.33%
2025-02-01 18:18:48,797 - INFO - ####################Training epoch 37####################
2025-02-01 18:18:49,216 - INFO - Epoch 37: train_loss=0.9503
2025-02-01 18:18:49,820 - INFO - Epoch 37: val_loss=2.5894, val_acc=33.33%
2025-02-01 18:18:49,823 - INFO - ####################Training epoch 38####################
2025-02-01 18:18:50,238 - INFO - Epoch 38: train_loss=0.9370
2025-02-01 18:18:50,844 - INFO - Epoch 38: val_loss=2.6136, val_acc=0.00%
2025-02-01 18:18:50,848 - INFO - ####################Training epoch 39####################
2025-02-01 18:18:51,269 - INFO - Epoch 39: train_loss=0.9286
2025-02-01 18:18:51,873 - INFO - Epoch 39: val_loss=2.6513, val_acc=0.00%
2025-02-01 18:18:51,876 - INFO - ####################Training epoch 40####################
2025-02-01 18:18:52,299 - INFO - Epoch 40: train_loss=0.9169
2025-02-01 18:18:52,900 - INFO - Epoch 40: val_loss=2.6673, val_acc=0.00%
2025-02-01 18:18:52,904 - INFO - ####################Training epoch 41####################
2025-02-01 18:18:53,321 - INFO - Epoch 41: train_loss=0.8936
2025-02-01 18:18:53,927 - INFO - Epoch 41: val_loss=2.7018, val_acc=0.00%
2025-02-01 18:18:53,930 - INFO - ####################Training epoch 42####################
2025-02-01 18:18:54,351 - INFO - Epoch 42: train_loss=0.8838
2025-02-01 18:18:55,049 - INFO - Epoch 42: val_loss=2.7310, val_acc=0.00%
2025-02-01 18:18:55,052 - INFO - ####################Training epoch 43####################
2025-02-01 18:18:55,475 - INFO - Epoch 43: train_loss=0.8604
2025-02-01 18:18:56,081 - INFO - Epoch 43: val_loss=2.7299, val_acc=0.00%
2025-02-01 18:18:56,084 - INFO - ####################Training epoch 44####################
2025-02-01 18:18:56,503 - INFO - Epoch 44: train_loss=0.8466
2025-02-01 18:18:57,115 - INFO - Epoch 44: val_loss=2.7835, val_acc=0.00%
2025-02-01 18:18:57,118 - INFO - ####################Training epoch 45####################
2025-02-01 18:18:57,542 - INFO - Epoch 45: train_loss=0.8352
2025-02-01 18:18:58,145 - INFO - Epoch 45: val_loss=2.7916, val_acc=0.00%
2025-02-01 18:18:58,149 - INFO - ####################Training epoch 46####################
2025-02-01 18:18:58,571 - INFO - Epoch 46: train_loss=0.8146
2025-02-01 18:18:59,175 - INFO - Epoch 46: val_loss=2.7915, val_acc=0.00%
2025-02-01 18:18:59,179 - INFO - ####################Training epoch 47####################
2025-02-01 18:18:59,596 - INFO - Epoch 47: train_loss=0.8059
2025-02-01 18:19:00,208 - INFO - Epoch 47: val_loss=2.8227, val_acc=0.00%
2025-02-01 18:19:00,212 - INFO - ####################Training epoch 48####################
2025-02-01 18:19:00,630 - INFO - Epoch 48: train_loss=0.7876
2025-02-01 18:19:01,236 - INFO - Epoch 48: val_loss=2.7931, val_acc=0.00%
2025-02-01 18:19:01,239 - INFO - ####################Training epoch 49####################
2025-02-01 18:19:01,663 - INFO - Epoch 49: train_loss=0.7562
2025-02-01 18:19:02,262 - INFO - Epoch 49: val_loss=2.8187, val_acc=0.00%
2025-02-01 18:19:02,266 - INFO - ####################Training epoch 50####################
2025-02-01 18:19:02,685 - INFO - Epoch 50: train_loss=0.7637
2025-02-01 18:19:03,295 - INFO - Epoch 50: val_loss=2.8003, val_acc=33.33%
2025-02-01 18:19:03,299 - INFO - ####################Training epoch 51####################
2025-02-01 18:19:03,718 - INFO - Epoch 51: train_loss=0.7597
2025-02-01 18:19:04,322 - INFO - Epoch 51: val_loss=2.7910, val_acc=33.33%
2025-02-01 18:19:04,326 - INFO - ####################Training epoch 52####################
2025-02-01 18:19:04,748 - INFO - Epoch 52: train_loss=0.7524
2025-02-01 18:19:05,355 - INFO - Epoch 52: val_loss=2.8257, val_acc=0.00%
2025-02-01 18:19:05,359 - INFO - ####################Training epoch 53####################
2025-02-01 18:19:05,781 - INFO - Epoch 53: train_loss=0.7523
2025-02-01 18:19:06,391 - INFO - Epoch 53: val_loss=2.8152, val_acc=33.33%
2025-02-01 18:19:06,395 - INFO - ####################Training epoch 54####################
2025-02-01 18:19:06,816 - INFO - Epoch 54: train_loss=0.7411
2025-02-01 18:19:07,418 - INFO - Epoch 54: val_loss=2.8470, val_acc=0.00%
2025-02-01 18:19:07,422 - INFO - ####################Training epoch 55####################
2025-02-01 18:19:07,843 - INFO - Epoch 55: train_loss=0.7227
2025-02-01 18:19:08,445 - INFO - Epoch 55: val_loss=2.7950, val_acc=33.33%
2025-02-01 18:19:08,449 - INFO - ####################Training epoch 56####################
2025-02-01 18:19:08,866 - INFO - Epoch 56: train_loss=0.7201
2025-02-01 18:19:09,475 - INFO - Epoch 56: val_loss=2.8083, val_acc=33.33%
2025-02-01 18:19:09,478 - INFO - ####################Training epoch 57####################
2025-02-01 18:19:09,899 - INFO - Epoch 57: train_loss=0.7179
2025-02-01 18:19:10,503 - INFO - Epoch 57: val_loss=2.7704, val_acc=33.33%
2025-02-01 18:19:10,506 - INFO - ####################Training epoch 58####################
2025-02-01 18:19:10,928 - INFO - Epoch 58: train_loss=0.7143
2025-02-01 18:19:11,531 - INFO - Epoch 58: val_loss=2.7791, val_acc=33.33%
2025-02-01 18:19:11,534 - INFO - ####################Training epoch 59####################
2025-02-01 18:19:11,952 - INFO - Epoch 59: train_loss=0.7177
2025-02-01 18:19:12,558 - INFO - Epoch 59: val_loss=2.7788, val_acc=33.33%
2025-02-01 18:19:12,562 - INFO - ####################Training epoch 60####################
2025-02-01 18:19:12,982 - INFO - Epoch 60: train_loss=0.7191
2025-02-01 18:19:13,586 - INFO - Epoch 60: val_loss=2.7704, val_acc=33.33%
2025-02-01 18:19:13,590 - INFO - ####################Training epoch 61####################
2025-02-01 18:19:14,009 - INFO - Epoch 61: train_loss=0.7048
2025-02-01 18:19:14,611 - INFO - Epoch 61: val_loss=2.7801, val_acc=33.33%
2025-02-01 18:19:14,615 - INFO - ####################Training epoch 62####################
2025-02-01 18:19:15,030 - INFO - Epoch 62: train_loss=0.7032
2025-02-01 18:19:15,637 - INFO - Epoch 62: val_loss=2.7738, val_acc=33.33%
2025-02-01 18:19:15,641 - INFO - ####################Training epoch 63####################
2025-02-01 18:19:16,060 - INFO - Epoch 63: train_loss=0.7071
2025-02-01 18:19:16,662 - INFO - Epoch 63: val_loss=2.7637, val_acc=33.33%
2025-02-01 18:19:16,666 - INFO - ####################Training epoch 64####################
2025-02-01 18:19:17,084 - INFO - Epoch 64: train_loss=0.6938
2025-02-01 18:19:17,684 - INFO - Epoch 64: val_loss=2.7817, val_acc=33.33%
2025-02-01 18:19:17,691 - INFO - ####################Training epoch 65####################
2025-02-01 18:19:18,109 - INFO - Epoch 65: train_loss=0.7046
2025-02-01 18:19:18,714 - INFO - Epoch 65: val_loss=2.7513, val_acc=33.33%
2025-02-01 18:19:18,718 - INFO - ####################Training epoch 66####################
2025-02-01 18:19:19,134 - INFO - Epoch 66: train_loss=0.7097
2025-02-01 18:19:19,736 - INFO - Epoch 66: val_loss=2.7697, val_acc=33.33%
2025-02-01 18:19:19,740 - INFO - ####################Training epoch 67####################
2025-02-01 18:19:20,162 - INFO - Epoch 67: train_loss=0.7175
2025-02-01 18:19:20,762 - INFO - Epoch 67: val_loss=2.7793, val_acc=33.33%
2025-02-01 18:19:20,766 - INFO - ####################Training epoch 68####################
2025-02-01 18:19:21,182 - INFO - Epoch 68: train_loss=0.7082
2025-02-01 18:19:21,787 - INFO - Epoch 68: val_loss=2.7987, val_acc=33.33%
2025-02-01 18:19:21,791 - INFO - ####################Training epoch 69####################
2025-02-01 18:19:22,207 - INFO - Epoch 69: train_loss=0.6870
2025-02-01 18:19:22,809 - INFO - Epoch 69: val_loss=2.7617, val_acc=33.33%
2025-02-01 18:19:22,812 - INFO - ####################Training epoch 70####################
2025-02-01 18:19:23,234 - INFO - Epoch 70: train_loss=0.6891
2025-02-01 18:19:23,839 - INFO - Epoch 70: val_loss=2.8201, val_acc=33.33%
2025-02-01 18:19:23,843 - INFO - ####################Training epoch 71####################
2025-02-01 18:19:24,258 - INFO - Epoch 71: train_loss=0.6926
2025-02-01 18:19:24,864 - INFO - Epoch 71: val_loss=2.7661, val_acc=33.33%
2025-02-01 18:19:24,868 - INFO - ####################Training epoch 72####################
2025-02-01 18:19:25,285 - INFO - Epoch 72: train_loss=0.7055
2025-02-01 18:19:25,889 - INFO - Epoch 72: val_loss=2.7922, val_acc=33.33%
2025-02-01 18:19:25,893 - INFO - ####################Training epoch 73####################
2025-02-01 18:19:26,316 - INFO - Epoch 73: train_loss=0.6773
2025-02-01 18:19:26,921 - INFO - Epoch 73: val_loss=2.7772, val_acc=33.33%
2025-02-01 18:19:26,924 - INFO - ####################Training epoch 74####################
2025-02-01 18:19:27,344 - INFO - Epoch 74: train_loss=0.6880
2025-02-01 18:19:27,950 - INFO - Epoch 74: val_loss=2.7848, val_acc=33.33%
2025-02-01 18:19:27,953 - INFO - ####################Training epoch 75####################
2025-02-01 18:19:28,373 - INFO - Epoch 75: train_loss=0.6840
2025-02-01 18:19:28,973 - INFO - Epoch 75: val_loss=2.7916, val_acc=33.33%
2025-02-01 18:19:28,977 - INFO - ####################Training epoch 76####################
2025-02-01 18:19:29,397 - INFO - Epoch 76: train_loss=0.6942
2025-02-01 18:19:29,999 - INFO - Epoch 76: val_loss=2.7949, val_acc=33.33%
2025-02-01 18:19:30,003 - INFO - ####################Training epoch 77####################
2025-02-01 18:19:30,420 - INFO - Epoch 77: train_loss=0.6799
2025-02-01 18:19:31,028 - INFO - Epoch 77: val_loss=2.8006, val_acc=33.33%
2025-02-01 18:19:31,032 - INFO - ####################Training epoch 78####################
2025-02-01 18:19:31,447 - INFO - Epoch 78: train_loss=0.7019
2025-02-01 18:19:32,049 - INFO - Epoch 78: val_loss=2.7597, val_acc=33.33%
2025-02-01 18:19:32,053 - INFO - ####################Training epoch 79####################
2025-02-01 18:19:32,473 - INFO - Epoch 79: train_loss=0.7039
2025-02-01 18:19:33,076 - INFO - Epoch 79: val_loss=2.7716, val_acc=33.33%
2025-02-01 18:19:33,080 - INFO - ####################Training epoch 80####################
2025-02-01 18:19:33,493 - INFO - Epoch 80: train_loss=0.6902
2025-02-01 18:19:34,100 - INFO - Epoch 80: val_loss=2.7951, val_acc=33.33%
2025-02-01 18:19:34,104 - INFO - ####################Training epoch 81####################
2025-02-01 18:19:34,522 - INFO - Epoch 81: train_loss=0.6923
2025-02-01 18:19:35,124 - INFO - Epoch 81: val_loss=2.7685, val_acc=33.33%
2025-02-01 18:19:35,128 - INFO - ####################Training epoch 82####################
2025-02-01 18:19:35,549 - INFO - Epoch 82: train_loss=0.6959
2025-02-01 18:19:36,152 - INFO - Epoch 82: val_loss=2.7840, val_acc=33.33%
2025-02-01 18:19:36,156 - INFO - ####################Training epoch 83####################
2025-02-01 18:19:36,573 - INFO - Epoch 83: train_loss=0.6901
2025-02-01 18:19:37,180 - INFO - Epoch 83: val_loss=2.7986, val_acc=33.33%
2025-02-01 18:19:37,184 - INFO - ####################Training epoch 84####################
2025-02-01 18:19:37,608 - INFO - Epoch 84: train_loss=0.6885
2025-02-01 18:19:38,206 - INFO - Epoch 84: val_loss=2.7914, val_acc=33.33%
2025-02-01 18:19:38,209 - INFO - ####################Training epoch 85####################
2025-02-01 18:19:38,635 - INFO - Epoch 85: train_loss=0.6966
2025-02-01 18:19:39,241 - INFO - Epoch 85: val_loss=2.7959, val_acc=33.33%
2025-02-01 18:19:39,245 - INFO - ####################Training epoch 86####################
2025-02-01 18:19:39,663 - INFO - Epoch 86: train_loss=0.6809
2025-02-01 18:19:40,272 - INFO - Epoch 86: val_loss=2.7758, val_acc=33.33%
2025-02-01 18:19:40,276 - INFO - ####################Training epoch 87####################
2025-02-01 18:19:40,694 - INFO - Epoch 87: train_loss=0.6870
2025-02-01 18:19:41,301 - INFO - Epoch 87: val_loss=2.7864, val_acc=33.33%
2025-02-01 18:19:41,304 - INFO - ####################Training epoch 88####################
2025-02-01 18:19:41,723 - INFO - Epoch 88: train_loss=0.6954
2025-02-01 18:19:42,330 - INFO - Epoch 88: val_loss=2.7805, val_acc=33.33%
2025-02-01 18:19:42,334 - INFO - ####################Training epoch 89####################
2025-02-01 18:19:42,754 - INFO - Epoch 89: train_loss=0.7023
2025-02-01 18:19:43,362 - INFO - Epoch 89: val_loss=2.7700, val_acc=33.33%
2025-02-01 18:19:43,365 - INFO - ####################Training epoch 90####################
2025-02-01 18:19:43,787 - INFO - Epoch 90: train_loss=0.6965
2025-02-01 18:19:44,391 - INFO - Epoch 90: val_loss=2.7733, val_acc=33.33%
2025-02-01 18:19:44,395 - INFO - ####################Training epoch 91####################
2025-02-01 18:19:44,816 - INFO - Epoch 91: train_loss=0.6918
2025-02-01 18:19:45,421 - INFO - Epoch 91: val_loss=2.7892, val_acc=33.33%
2025-02-01 18:19:45,425 - INFO - ####################Training epoch 92####################
2025-02-01 18:19:45,842 - INFO - Epoch 92: train_loss=0.6858
2025-02-01 18:19:46,449 - INFO - Epoch 92: val_loss=2.7754, val_acc=33.33%
2025-02-01 18:19:46,453 - INFO - ####################Training epoch 93####################
2025-02-01 18:19:46,868 - INFO - Epoch 93: train_loss=0.6901
2025-02-01 18:19:47,472 - INFO - Epoch 93: val_loss=2.8212, val_acc=33.33%
2025-02-01 18:19:47,475 - INFO - ####################Training epoch 94####################
2025-02-01 18:19:47,894 - INFO - Epoch 94: train_loss=0.6792
2025-02-01 18:19:48,499 - INFO - Epoch 94: val_loss=2.8027, val_acc=33.33%
2025-02-01 18:19:48,503 - INFO - ####################Training epoch 95####################
2025-02-01 18:19:48,920 - INFO - Epoch 95: train_loss=0.6829
2025-02-01 18:19:49,526 - INFO - Epoch 95: val_loss=2.7699, val_acc=33.33%
2025-02-01 18:19:49,530 - INFO - ####################Training epoch 96####################
2025-02-01 18:19:49,948 - INFO - Epoch 96: train_loss=0.6867
2025-02-01 18:19:50,551 - INFO - Epoch 96: val_loss=2.7535, val_acc=33.33%
2025-02-01 18:19:50,555 - INFO - ####################Training epoch 97####################
2025-02-01 18:19:50,979 - INFO - Epoch 97: train_loss=0.6827
2025-02-01 18:19:51,583 - INFO - Epoch 97: val_loss=2.7818, val_acc=33.33%
2025-02-01 18:19:51,587 - INFO - ####################Training epoch 98####################
2025-02-01 18:19:52,006 - INFO - Epoch 98: train_loss=0.6964
2025-02-01 18:19:52,613 - INFO - Epoch 98: val_loss=2.7814, val_acc=33.33%
2025-02-01 18:19:52,616 - INFO - ####################Training epoch 99####################
2025-02-01 18:19:53,033 - INFO - Epoch 99: train_loss=0.6921
2025-02-01 18:19:53,640 - INFO - Epoch 99: val_loss=2.8076, val_acc=33.33%
2025-02-01 18:19:53,644 - INFO - ####################Training epoch 100####################
2025-02-01 18:19:54,067 - INFO - Epoch 100: train_loss=0.6908
2025-02-01 18:19:54,672 - INFO - Epoch 100: val_loss=2.7764, val_acc=33.33%
2025-02-01 18:19:54,675 - INFO - ####################Training epoch 101####################
2025-02-01 18:19:55,094 - INFO - Epoch 101: train_loss=0.6820
2025-02-01 18:19:55,703 - INFO - Epoch 101: val_loss=2.7731, val_acc=33.33%
2025-02-01 18:19:55,707 - INFO - ####################Training epoch 102####################
2025-02-01 18:19:56,125 - INFO - Epoch 102: train_loss=0.6939
2025-02-01 18:19:56,728 - INFO - Epoch 102: val_loss=2.7549, val_acc=33.33%
2025-02-01 18:19:56,732 - INFO - ####################Training epoch 103####################
2025-02-01 18:19:57,154 - INFO - Epoch 103: train_loss=0.6811
2025-02-01 18:19:57,761 - INFO - Epoch 103: val_loss=2.7796, val_acc=33.33%
2025-02-01 18:19:57,764 - INFO - ####################Training epoch 104####################
2025-02-01 18:19:58,185 - INFO - Epoch 104: train_loss=0.6807
2025-02-01 18:19:58,794 - INFO - Epoch 104: val_loss=2.7977, val_acc=33.33%
2025-02-01 18:19:58,797 - INFO - ####################Training epoch 105####################
2025-02-01 18:19:59,214 - INFO - Epoch 105: train_loss=0.6877
2025-02-01 18:19:59,819 - INFO - Epoch 105: val_loss=2.7874, val_acc=33.33%
2025-02-01 18:19:59,823 - INFO - ####################Training epoch 106####################
2025-02-01 18:20:00,241 - INFO - Epoch 106: train_loss=0.6911
2025-02-01 18:20:00,847 - INFO - Epoch 106: val_loss=2.7852, val_acc=33.33%
2025-02-01 18:20:00,850 - INFO - ####################Training epoch 107####################
2025-02-01 18:20:01,269 - INFO - Epoch 107: train_loss=0.6832
2025-02-01 18:20:01,877 - INFO - Epoch 107: val_loss=2.7964, val_acc=33.33%
2025-02-01 18:20:01,880 - INFO - ####################Training epoch 108####################
2025-02-01 18:20:02,296 - INFO - Epoch 108: train_loss=0.7033
2025-02-01 18:20:02,900 - INFO - Epoch 108: val_loss=2.7768, val_acc=33.33%
2025-02-01 18:20:02,904 - INFO - ####################Training epoch 109####################
2025-02-01 18:20:03,326 - INFO - Epoch 109: train_loss=0.6793
2025-02-01 18:20:03,929 - INFO - Epoch 109: val_loss=2.7708, val_acc=33.33%
2025-02-01 18:20:03,933 - INFO - ####################Training epoch 110####################
2025-02-01 18:20:04,351 - INFO - Epoch 110: train_loss=0.6906
2025-02-01 18:20:04,959 - INFO - Epoch 110: val_loss=2.7835, val_acc=33.33%
2025-02-01 18:20:04,963 - INFO - ####################Training epoch 111####################
2025-02-01 18:20:05,384 - INFO - Epoch 111: train_loss=0.6698
2025-02-01 18:20:05,982 - INFO - Epoch 111: val_loss=2.7646, val_acc=33.33%
2025-02-01 18:20:05,986 - INFO - ####################Training epoch 112####################
2025-02-01 18:20:06,408 - INFO - Epoch 112: train_loss=0.6784
2025-02-01 18:20:07,010 - INFO - Epoch 112: val_loss=2.7932, val_acc=33.33%
2025-02-01 18:20:07,013 - INFO - ####################Training epoch 113####################
2025-02-01 18:20:07,428 - INFO - Epoch 113: train_loss=0.6902
2025-02-01 18:20:08,034 - INFO - Epoch 113: val_loss=2.7759, val_acc=33.33%
2025-02-01 18:20:08,038 - INFO - ####################Training epoch 114####################
2025-02-01 18:20:08,455 - INFO - Epoch 114: train_loss=0.6794
2025-02-01 18:20:09,059 - INFO - Epoch 114: val_loss=2.7701, val_acc=33.33%
2025-02-01 18:20:09,063 - INFO - ####################Training epoch 115####################
2025-02-01 18:20:09,484 - INFO - Epoch 115: train_loss=0.6929
2025-02-01 18:20:10,088 - INFO - Epoch 115: val_loss=2.7792, val_acc=33.33%
2025-02-01 18:20:10,092 - INFO - ####################Training epoch 116####################
2025-02-01 18:20:10,507 - INFO - Epoch 116: train_loss=0.6972
2025-02-01 18:20:11,117 - INFO - Epoch 116: val_loss=2.8161, val_acc=33.33%
2025-02-01 18:20:11,121 - INFO - ####################Training epoch 117####################
2025-02-01 18:20:11,542 - INFO - Epoch 117: train_loss=0.6951
2025-02-01 18:20:12,145 - INFO - Epoch 117: val_loss=2.7555, val_acc=33.33%
2025-02-01 18:20:12,149 - INFO - ####################Training epoch 118####################
2025-02-01 18:20:12,571 - INFO - Epoch 118: train_loss=0.6954
2025-02-01 18:20:13,175 - INFO - Epoch 118: val_loss=2.7625, val_acc=33.33%
2025-02-01 18:20:13,178 - INFO - ####################Training epoch 119####################
2025-02-01 18:20:13,600 - INFO - Epoch 119: train_loss=0.6857
2025-02-01 18:20:14,209 - INFO - Epoch 119: val_loss=2.7966, val_acc=33.33%
2025-02-01 18:20:14,212 - INFO - ####################Training epoch 120####################
2025-02-01 18:20:14,631 - INFO - Epoch 120: train_loss=0.6826
2025-02-01 18:20:15,233 - INFO - Epoch 120: val_loss=2.8060, val_acc=33.33%
2025-02-01 18:20:15,237 - INFO - ####################Training epoch 121####################
2025-02-01 18:20:15,657 - INFO - Epoch 121: train_loss=0.7036
2025-02-01 18:20:16,262 - INFO - Epoch 121: val_loss=2.7785, val_acc=33.33%
2025-02-01 18:20:16,266 - INFO - ####################Training epoch 122####################
2025-02-01 18:20:16,681 - INFO - Epoch 122: train_loss=0.6941
2025-02-01 18:20:17,288 - INFO - Epoch 122: val_loss=2.8053, val_acc=33.33%
2025-02-01 18:20:17,292 - INFO - ####################Training epoch 123####################
2025-02-01 18:20:17,710 - INFO - Epoch 123: train_loss=0.6913
2025-02-01 18:20:18,314 - INFO - Epoch 123: val_loss=2.7710, val_acc=33.33%
2025-02-01 18:20:18,317 - INFO - ####################Training epoch 124####################
2025-02-01 18:20:18,735 - INFO - Epoch 124: train_loss=0.6947
2025-02-01 18:20:19,340 - INFO - Epoch 124: val_loss=2.8041, val_acc=33.33%
2025-02-01 18:20:19,344 - INFO - ####################Training epoch 125####################
2025-02-01 18:20:19,761 - INFO - Epoch 125: train_loss=0.7056
2025-02-01 18:20:20,368 - INFO - Epoch 125: val_loss=2.7944, val_acc=33.33%
2025-02-01 18:20:20,372 - INFO - ####################Training epoch 126####################
2025-02-01 18:20:20,789 - INFO - Epoch 126: train_loss=0.6880
2025-02-01 18:20:21,395 - INFO - Epoch 126: val_loss=2.7698, val_acc=33.33%
2025-02-01 18:20:21,398 - INFO - ####################Training epoch 127####################
2025-02-01 18:20:21,819 - INFO - Epoch 127: train_loss=0.6906
2025-02-01 18:20:22,424 - INFO - Epoch 127: val_loss=2.7974, val_acc=33.33%
2025-02-01 18:20:22,428 - INFO - ####################Training epoch 128####################
2025-02-01 18:20:22,846 - INFO - Epoch 128: train_loss=0.7122
2025-02-01 18:20:23,452 - INFO - Epoch 128: val_loss=2.7858, val_acc=33.33%
2025-02-01 18:20:23,456 - INFO - ####################Training epoch 129####################
2025-02-01 18:20:23,873 - INFO - Epoch 129: train_loss=0.6803
2025-02-01 18:20:24,478 - INFO - Epoch 129: val_loss=2.7710, val_acc=33.33%
2025-02-01 18:20:24,482 - INFO - ####################Training epoch 130####################
2025-02-01 18:20:24,900 - INFO - Epoch 130: train_loss=0.6916
2025-02-01 18:20:25,505 - INFO - Epoch 130: val_loss=2.7778, val_acc=33.33%
2025-02-01 18:20:25,508 - INFO - ####################Training epoch 131####################
2025-02-01 18:20:25,927 - INFO - Epoch 131: train_loss=0.7026
2025-02-01 18:20:26,534 - INFO - Epoch 131: val_loss=2.7975, val_acc=33.33%
2025-02-01 18:20:26,538 - INFO - ####################Training epoch 132####################
2025-02-01 18:20:26,956 - INFO - Epoch 132: train_loss=0.6929
2025-02-01 18:20:27,560 - INFO - Epoch 132: val_loss=2.7813, val_acc=33.33%
2025-02-01 18:20:27,563 - INFO - ####################Training epoch 133####################
2025-02-01 18:20:27,988 - INFO - Epoch 133: train_loss=0.6931
2025-02-01 18:20:28,586 - INFO - Epoch 133: val_loss=2.7784, val_acc=33.33%
2025-02-01 18:20:28,590 - INFO - ####################Training epoch 134####################
2025-02-01 18:20:29,006 - INFO - Epoch 134: train_loss=0.6977
2025-02-01 18:20:29,611 - INFO - Epoch 134: val_loss=2.7786, val_acc=33.33%
2025-02-01 18:20:29,615 - INFO - ####################Training epoch 135####################
2025-02-01 18:20:30,030 - INFO - Epoch 135: train_loss=0.6990
2025-02-01 18:20:30,633 - INFO - Epoch 135: val_loss=2.7730, val_acc=33.33%
2025-02-01 18:20:30,636 - INFO - ####################Training epoch 136####################
2025-02-01 18:20:31,058 - INFO - Epoch 136: train_loss=0.6856
2025-02-01 18:20:31,662 - INFO - Epoch 136: val_loss=2.7760, val_acc=33.33%
2025-02-01 18:20:31,666 - INFO - ####################Training epoch 137####################
2025-02-01 18:20:32,085 - INFO - Epoch 137: train_loss=0.6919
2025-02-01 18:20:32,690 - INFO - Epoch 137: val_loss=2.7622, val_acc=33.33%
2025-02-01 18:20:32,694 - INFO - ####################Training epoch 138####################
2025-02-01 18:20:33,113 - INFO - Epoch 138: train_loss=0.6787
2025-02-01 18:20:33,715 - INFO - Epoch 138: val_loss=2.7854, val_acc=33.33%
2025-02-01 18:20:33,719 - INFO - ####################Training epoch 139####################
2025-02-01 18:20:34,139 - INFO - Epoch 139: train_loss=0.6984
2025-02-01 18:20:34,743 - INFO - Epoch 139: val_loss=2.8010, val_acc=33.33%
2025-02-01 18:20:34,747 - INFO - ####################Training epoch 140####################
2025-02-01 18:20:35,166 - INFO - Epoch 140: train_loss=0.6929
2025-02-01 18:20:35,775 - INFO - Epoch 140: val_loss=2.7701, val_acc=33.33%
2025-02-01 18:20:35,779 - INFO - ####################Training epoch 141####################
2025-02-01 18:20:36,198 - INFO - Epoch 141: train_loss=0.7001
2025-02-01 18:20:36,799 - INFO - Epoch 141: val_loss=2.7905, val_acc=33.33%
2025-02-01 18:20:36,803 - INFO - ####################Training epoch 142####################
2025-02-01 18:20:37,225 - INFO - Epoch 142: train_loss=0.6909
2025-02-01 18:20:37,831 - INFO - Epoch 142: val_loss=2.8197, val_acc=33.33%
2025-02-01 18:20:37,834 - INFO - ####################Training epoch 143####################
2025-02-01 18:20:38,250 - INFO - Epoch 143: train_loss=0.6941
2025-02-01 18:20:38,855 - INFO - Epoch 143: val_loss=2.7867, val_acc=33.33%
2025-02-01 18:20:38,859 - INFO - ####################Training epoch 144####################
2025-02-01 18:20:39,278 - INFO - Epoch 144: train_loss=0.6935
2025-02-01 18:20:39,884 - INFO - Epoch 144: val_loss=2.7906, val_acc=33.33%
2025-02-01 18:20:39,888 - INFO - ####################Training epoch 145####################
2025-02-01 18:20:40,308 - INFO - Epoch 145: train_loss=0.6870
2025-02-01 18:20:40,914 - INFO - Epoch 145: val_loss=2.7769, val_acc=33.33%
2025-02-01 18:20:40,918 - INFO - ####################Training epoch 146####################
2025-02-01 18:20:41,339 - INFO - Epoch 146: train_loss=0.7010
2025-02-01 18:20:41,946 - INFO - Epoch 146: val_loss=2.8024, val_acc=33.33%
2025-02-01 18:20:41,950 - INFO - ####################Training epoch 147####################
2025-02-01 18:20:42,370 - INFO - Epoch 147: train_loss=0.6975
2025-02-01 18:20:42,978 - INFO - Epoch 147: val_loss=2.8002, val_acc=33.33%
2025-02-01 18:20:42,982 - INFO - ####################Training epoch 148####################
2025-02-01 18:20:43,403 - INFO - Epoch 148: train_loss=0.6908
2025-02-01 18:20:44,005 - INFO - Epoch 148: val_loss=2.7642, val_acc=33.33%
2025-02-01 18:20:44,009 - INFO - ####################Training epoch 149####################
2025-02-01 18:20:44,431 - INFO - Epoch 149: train_loss=0.6994
2025-02-01 18:20:45,037 - INFO - Epoch 149: val_loss=2.7846, val_acc=33.33%
2025-02-01 18:20:45,041 - INFO - ####################Training epoch 150####################
2025-02-01 18:20:45,461 - INFO - Epoch 150: train_loss=0.6974
2025-02-01 18:20:46,065 - INFO - Epoch 150: val_loss=2.7799, val_acc=33.33%
2025-02-01 18:20:46,069 - INFO - ####################Training epoch 151####################
2025-02-01 18:20:46,489 - INFO - Epoch 151: train_loss=0.6959
2025-02-01 18:20:47,096 - INFO - Epoch 151: val_loss=2.8005, val_acc=33.33%
2025-02-01 18:20:47,099 - INFO - ####################Training epoch 152####################
2025-02-01 18:20:47,519 - INFO - Epoch 152: train_loss=0.6940
2025-02-01 18:20:48,125 - INFO - Epoch 152: val_loss=2.7737, val_acc=33.33%
2025-02-01 18:20:48,129 - INFO - ####################Training epoch 153####################
2025-02-01 18:20:48,553 - INFO - Epoch 153: train_loss=0.6929
2025-02-01 18:20:49,159 - INFO - Epoch 153: val_loss=2.7669, val_acc=33.33%
2025-02-01 18:20:49,163 - INFO - ####################Training epoch 154####################
2025-02-01 18:20:49,583 - INFO - Epoch 154: train_loss=0.6982
2025-02-01 18:20:50,186 - INFO - Epoch 154: val_loss=2.7875, val_acc=33.33%
2025-02-01 18:20:50,190 - INFO - ####################Training epoch 155####################
2025-02-01 18:20:50,610 - INFO - Epoch 155: train_loss=0.6871
2025-02-01 18:20:51,218 - INFO - Epoch 155: val_loss=2.8018, val_acc=33.33%
2025-02-01 18:20:51,222 - INFO - ####################Training epoch 156####################
2025-02-01 18:20:51,642 - INFO - Epoch 156: train_loss=0.6954
2025-02-01 18:20:52,249 - INFO - Epoch 156: val_loss=2.8182, val_acc=33.33%
2025-02-01 18:20:52,252 - INFO - ####################Training epoch 157####################
2025-02-01 18:20:52,678 - INFO - Epoch 157: train_loss=0.6801
2025-02-01 18:20:53,284 - INFO - Epoch 157: val_loss=2.8103, val_acc=33.33%
2025-02-01 18:20:53,288 - INFO - ####################Training epoch 158####################
2025-02-01 18:20:53,707 - INFO - Epoch 158: train_loss=0.6794
2025-02-01 18:20:54,312 - INFO - Epoch 158: val_loss=2.7742, val_acc=33.33%
2025-02-01 18:20:54,316 - INFO - ####################Training epoch 159####################
2025-02-01 18:20:54,733 - INFO - Epoch 159: train_loss=0.6878
2025-02-01 18:20:55,337 - INFO - Epoch 159: val_loss=2.7784, val_acc=33.33%
2025-02-01 18:20:55,341 - INFO - ####################Training epoch 160####################
2025-02-01 18:20:55,759 - INFO - Epoch 160: train_loss=0.6909
2025-02-01 18:20:56,358 - INFO - Epoch 160: val_loss=2.7893, val_acc=33.33%
2025-02-01 18:20:56,362 - INFO - ####################Training epoch 161####################
2025-02-01 18:20:56,781 - INFO - Epoch 161: train_loss=0.6781
2025-02-01 18:20:57,389 - INFO - Epoch 161: val_loss=2.7955, val_acc=33.33%
2025-02-01 18:20:57,392 - INFO - ####################Training epoch 162####################
2025-02-01 18:20:57,810 - INFO - Epoch 162: train_loss=0.6789
2025-02-01 18:20:58,413 - INFO - Epoch 162: val_loss=2.7832, val_acc=33.33%
2025-02-01 18:20:58,417 - INFO - ####################Training epoch 163####################
2025-02-01 18:20:58,837 - INFO - Epoch 163: train_loss=0.6961
2025-02-01 18:20:59,440 - INFO - Epoch 163: val_loss=2.7879, val_acc=33.33%
2025-02-01 18:20:59,443 - INFO - ####################Training epoch 164####################
2025-02-01 18:20:59,863 - INFO - Epoch 164: train_loss=0.6761
2025-02-01 18:21:00,468 - INFO - Epoch 164: val_loss=2.7840, val_acc=33.33%
2025-02-01 18:21:00,472 - INFO - ####################Training epoch 165####################
2025-02-01 18:21:00,889 - INFO - Epoch 165: train_loss=0.6935
2025-02-01 18:21:01,495 - INFO - Epoch 165: val_loss=2.7737, val_acc=33.33%
2025-02-01 18:21:01,499 - INFO - ####################Training epoch 166####################
2025-02-01 18:21:01,919 - INFO - Epoch 166: train_loss=0.6947
2025-02-01 18:21:02,527 - INFO - Epoch 166: val_loss=2.7756, val_acc=33.33%
2025-02-01 18:21:02,531 - INFO - ####################Training epoch 167####################
2025-02-01 18:21:02,944 - INFO - Epoch 167: train_loss=0.6844
2025-02-01 18:21:03,551 - INFO - Epoch 167: val_loss=2.7939, val_acc=33.33%
2025-02-01 18:21:03,555 - INFO - ####################Training epoch 168####################
2025-02-01 18:21:03,970 - INFO - Epoch 168: train_loss=0.6972
2025-02-01 18:21:04,574 - INFO - Epoch 168: val_loss=2.7815, val_acc=33.33%
2025-02-01 18:21:04,581 - INFO - ####################Training epoch 169####################
2025-02-01 18:21:05,001 - INFO - Epoch 169: train_loss=0.6817
2025-02-01 18:21:05,601 - INFO - Epoch 169: val_loss=2.7731, val_acc=33.33%
2025-02-01 18:21:05,605 - INFO - ####################Training epoch 170####################
2025-02-01 18:21:06,025 - INFO - Epoch 170: train_loss=0.6828
2025-02-01 18:21:06,626 - INFO - Epoch 170: val_loss=2.8098, val_acc=33.33%
2025-02-01 18:21:06,630 - INFO - ####################Training epoch 171####################
2025-02-01 18:21:07,047 - INFO - Epoch 171: train_loss=0.6852
2025-02-01 18:21:07,650 - INFO - Epoch 171: val_loss=2.7855, val_acc=33.33%
2025-02-01 18:21:07,654 - INFO - ####################Training epoch 172####################
2025-02-01 18:21:08,073 - INFO - Epoch 172: train_loss=0.6883
2025-02-01 18:21:08,674 - INFO - Epoch 172: val_loss=2.7883, val_acc=33.33%
2025-02-01 18:21:08,678 - INFO - ####################Training epoch 173####################
2025-02-01 18:21:09,095 - INFO - Epoch 173: train_loss=0.6765
2025-02-01 18:21:09,701 - INFO - Epoch 173: val_loss=2.7656, val_acc=33.33%
2025-02-01 18:21:09,705 - INFO - ####################Training epoch 174####################
2025-02-01 18:21:10,123 - INFO - Epoch 174: train_loss=0.6865
2025-02-01 18:21:10,726 - INFO - Epoch 174: val_loss=2.7926, val_acc=33.33%
2025-02-01 18:21:10,730 - INFO - ####################Training epoch 175####################
2025-02-01 18:21:11,148 - INFO - Epoch 175: train_loss=0.6940
2025-02-01 18:21:11,751 - INFO - Epoch 175: val_loss=2.8043, val_acc=33.33%
2025-02-01 18:21:11,755 - INFO - ####################Training epoch 176####################
2025-02-01 18:21:12,175 - INFO - Epoch 176: train_loss=0.6900
2025-02-01 18:21:12,779 - INFO - Epoch 176: val_loss=2.7801, val_acc=33.33%
2025-02-01 18:21:12,783 - INFO - ####################Training epoch 177####################
2025-02-01 18:21:13,201 - INFO - Epoch 177: train_loss=0.6872
2025-02-01 18:21:13,804 - INFO - Epoch 177: val_loss=2.7858, val_acc=33.33%
2025-02-01 18:21:13,808 - INFO - ####################Training epoch 178####################
2025-02-01 18:21:14,227 - INFO - Epoch 178: train_loss=0.6917
2025-02-01 18:21:14,827 - INFO - Epoch 178: val_loss=2.8154, val_acc=33.33%
2025-02-01 18:21:14,830 - INFO - ####################Training epoch 179####################
2025-02-01 18:21:15,250 - INFO - Epoch 179: train_loss=0.6839
2025-02-01 18:21:15,852 - INFO - Epoch 179: val_loss=2.7812, val_acc=33.33%
2025-02-01 18:21:15,856 - INFO - ####################Training epoch 180####################
2025-02-01 18:21:16,275 - INFO - Epoch 180: train_loss=0.6885
2025-02-01 18:21:16,877 - INFO - Epoch 180: val_loss=2.7533, val_acc=33.33%
2025-02-01 18:21:16,881 - INFO - ####################Training epoch 181####################
2025-02-01 18:21:17,301 - INFO - Epoch 181: train_loss=0.6916
2025-02-01 18:21:17,901 - INFO - Epoch 181: val_loss=2.7757, val_acc=33.33%
2025-02-01 18:21:17,905 - INFO - ####################Training epoch 182####################
2025-02-01 18:21:18,321 - INFO - Epoch 182: train_loss=0.6934
2025-02-01 18:21:18,922 - INFO - Epoch 182: val_loss=2.7939, val_acc=33.33%
2025-02-01 18:21:18,926 - INFO - ####################Training epoch 183####################
2025-02-01 18:21:19,346 - INFO - Epoch 183: train_loss=0.6917
2025-02-01 18:21:19,952 - INFO - Epoch 183: val_loss=2.8226, val_acc=33.33%
2025-02-01 18:21:19,956 - INFO - ####################Training epoch 184####################
2025-02-01 18:21:20,376 - INFO - Epoch 184: train_loss=0.7010
2025-02-01 18:21:20,976 - INFO - Epoch 184: val_loss=2.8075, val_acc=33.33%
2025-02-01 18:21:20,980 - INFO - ####################Training epoch 185####################
2025-02-01 18:21:21,403 - INFO - Epoch 185: train_loss=0.6869
2025-02-01 18:21:22,006 - INFO - Epoch 185: val_loss=2.7806, val_acc=33.33%
2025-02-01 18:21:22,010 - INFO - ####################Training epoch 186####################
2025-02-01 18:21:22,430 - INFO - Epoch 186: train_loss=0.6890
2025-02-01 18:21:23,033 - INFO - Epoch 186: val_loss=2.7768, val_acc=33.33%
2025-02-01 18:21:23,036 - INFO - ####################Training epoch 187####################
2025-02-01 18:21:23,457 - INFO - Epoch 187: train_loss=0.6889
2025-02-01 18:21:24,062 - INFO - Epoch 187: val_loss=2.7930, val_acc=33.33%
2025-02-01 18:21:24,066 - INFO - ####################Training epoch 188####################
2025-02-01 18:21:24,487 - INFO - Epoch 188: train_loss=0.6836
2025-02-01 18:21:25,089 - INFO - Epoch 188: val_loss=2.7578, val_acc=33.33%
2025-02-01 18:21:25,093 - INFO - ####################Training epoch 189####################
2025-02-01 18:21:25,513 - INFO - Epoch 189: train_loss=0.6938
2025-02-01 18:21:26,113 - INFO - Epoch 189: val_loss=2.7899, val_acc=33.33%
2025-02-01 18:21:26,117 - INFO - ####################Training epoch 190####################
2025-02-01 18:21:26,536 - INFO - Epoch 190: train_loss=0.6878
2025-02-01 18:21:27,141 - INFO - Epoch 190: val_loss=2.7987, val_acc=33.33%
2025-02-01 18:21:27,145 - INFO - ####################Training epoch 191####################
2025-02-01 18:21:27,566 - INFO - Epoch 191: train_loss=0.6926
2025-02-01 18:21:28,171 - INFO - Epoch 191: val_loss=2.7806, val_acc=33.33%
2025-02-01 18:21:28,175 - INFO - ####################Training epoch 192####################
2025-02-01 18:21:28,595 - INFO - Epoch 192: train_loss=0.6975
2025-02-01 18:21:29,199 - INFO - Epoch 192: val_loss=2.7677, val_acc=33.33%
2025-02-01 18:21:29,204 - INFO - ####################Training epoch 193####################
2025-02-01 18:21:29,623 - INFO - Epoch 193: train_loss=0.7004
2025-02-01 18:21:30,226 - INFO - Epoch 193: val_loss=2.7859, val_acc=33.33%
2025-02-01 18:21:30,230 - INFO - ####################Training epoch 194####################
2025-02-01 18:21:30,649 - INFO - Epoch 194: train_loss=0.6843
2025-02-01 18:21:31,249 - INFO - Epoch 194: val_loss=2.7770, val_acc=33.33%
2025-02-01 18:21:31,252 - INFO - ####################Training epoch 195####################
2025-02-01 18:21:31,669 - INFO - Epoch 195: train_loss=0.6962
2025-02-01 18:21:32,272 - INFO - Epoch 195: val_loss=2.8069, val_acc=33.33%
2025-02-01 18:21:32,276 - INFO - ####################Training epoch 196####################
2025-02-01 18:21:32,695 - INFO - Epoch 196: train_loss=0.6926
2025-02-01 18:21:33,299 - INFO - Epoch 196: val_loss=2.7779, val_acc=33.33%
2025-02-01 18:21:33,302 - INFO - ####################Training epoch 197####################
2025-02-01 18:21:33,721 - INFO - Epoch 197: train_loss=0.6896
2025-02-01 18:21:34,325 - INFO - Epoch 197: val_loss=2.7818, val_acc=33.33%
2025-02-01 18:21:34,329 - INFO - ####################Training epoch 198####################
2025-02-01 18:21:34,747 - INFO - Epoch 198: train_loss=0.6815
2025-02-01 18:21:35,349 - INFO - Epoch 198: val_loss=2.7851, val_acc=33.33%
2025-02-01 18:21:35,353 - INFO - ####################Training epoch 199####################
2025-02-01 18:21:35,773 - INFO - Epoch 199: train_loss=0.7020
2025-02-01 18:21:36,378 - INFO - Epoch 199: val_loss=2.7634, val_acc=33.33%
2025-02-01 18:21:36,381 - INFO - ####################Training epoch 200####################
2025-02-01 18:21:36,804 - INFO - Epoch 200: train_loss=0.7015
2025-02-01 18:21:37,411 - INFO - Epoch 200: val_loss=2.7883, val_acc=33.33%
2025-02-01 18:21:37,415 - INFO - ####################Training epoch 201####################
2025-02-01 18:21:37,834 - INFO - Epoch 201: train_loss=0.6945
2025-02-01 18:21:38,437 - INFO - Epoch 201: val_loss=2.7907, val_acc=33.33%
2025-02-01 18:21:38,441 - INFO - ####################Training epoch 202####################
2025-02-01 18:21:38,859 - INFO - Epoch 202: train_loss=0.7072
2025-02-01 18:21:39,462 - INFO - Epoch 202: val_loss=2.7960, val_acc=33.33%
2025-02-01 18:21:39,466 - INFO - ####################Training epoch 203####################
2025-02-01 18:21:39,884 - INFO - Epoch 203: train_loss=0.7001
2025-02-01 18:21:40,489 - INFO - Epoch 203: val_loss=2.7833, val_acc=33.33%
2025-02-01 18:21:40,496 - INFO - ####################Training epoch 204####################
2025-02-01 18:21:40,918 - INFO - Epoch 204: train_loss=0.6793
2025-02-01 18:21:41,525 - INFO - Epoch 204: val_loss=2.7892, val_acc=33.33%
2025-02-01 18:21:41,529 - INFO - ####################Training epoch 205####################
2025-02-01 18:21:41,949 - INFO - Epoch 205: train_loss=0.6717
2025-02-01 18:21:42,553 - INFO - Epoch 205: val_loss=2.7875, val_acc=33.33%
2025-02-01 18:21:42,556 - INFO - ####################Training epoch 206####################
2025-02-01 18:21:42,977 - INFO - Epoch 206: train_loss=0.6932
2025-02-01 18:21:43,581 - INFO - Epoch 206: val_loss=2.7867, val_acc=33.33%
2025-02-01 18:21:43,585 - INFO - ####################Training epoch 207####################
2025-02-01 18:21:44,002 - INFO - Epoch 207: train_loss=0.6996
2025-02-01 18:21:44,608 - INFO - Epoch 207: val_loss=2.7661, val_acc=33.33%
2025-02-01 18:21:44,612 - INFO - ####################Training epoch 208####################
2025-02-01 18:21:45,034 - INFO - Epoch 208: train_loss=0.7033
2025-02-01 18:21:45,639 - INFO - Epoch 208: val_loss=2.7747, val_acc=33.33%
2025-02-01 18:21:45,643 - INFO - ####################Training epoch 209####################
2025-02-01 18:21:46,062 - INFO - Epoch 209: train_loss=0.6801
2025-02-01 18:21:46,667 - INFO - Epoch 209: val_loss=2.7766, val_acc=33.33%
2025-02-01 18:21:46,671 - INFO - ####################Training epoch 210####################
2025-02-01 18:21:47,089 - INFO - Epoch 210: train_loss=0.6860
2025-02-01 18:21:47,698 - INFO - Epoch 210: val_loss=2.7765, val_acc=33.33%
2025-02-01 18:21:47,702 - INFO - ####################Training epoch 211####################
2025-02-01 18:21:48,122 - INFO - Epoch 211: train_loss=0.6929
2025-02-01 18:21:48,727 - INFO - Epoch 211: val_loss=2.8024, val_acc=33.33%
2025-02-01 18:21:48,731 - INFO - ####################Training epoch 212####################
2025-02-01 18:21:49,151 - INFO - Epoch 212: train_loss=0.6949
2025-02-01 18:21:49,756 - INFO - Epoch 212: val_loss=2.7854, val_acc=33.33%
2025-02-01 18:21:49,760 - INFO - ####################Training epoch 213####################
2025-02-01 18:21:50,180 - INFO - Epoch 213: train_loss=0.6896
2025-02-01 18:21:50,783 - INFO - Epoch 213: val_loss=2.7739, val_acc=33.33%
2025-02-01 18:21:50,787 - INFO - ####################Training epoch 214####################
2025-02-01 18:21:51,205 - INFO - Epoch 214: train_loss=0.6995
2025-02-01 18:21:51,807 - INFO - Epoch 214: val_loss=2.7707, val_acc=33.33%
2025-02-01 18:21:51,811 - INFO - ####################Training epoch 215####################
2025-02-01 18:21:52,231 - INFO - Epoch 215: train_loss=0.7028
2025-02-01 18:21:52,833 - INFO - Epoch 215: val_loss=2.7815, val_acc=33.33%
2025-02-01 18:21:52,836 - INFO - ####################Training epoch 216####################
2025-02-01 18:21:53,256 - INFO - Epoch 216: train_loss=0.6794
2025-02-01 18:21:53,858 - INFO - Epoch 216: val_loss=2.7814, val_acc=33.33%
2025-02-01 18:21:53,862 - INFO - ####################Training epoch 217####################
2025-02-01 18:21:54,282 - INFO - Epoch 217: train_loss=0.6853
2025-02-01 18:21:54,884 - INFO - Epoch 217: val_loss=2.7826, val_acc=33.33%
2025-02-01 18:21:54,888 - INFO - ####################Training epoch 218####################
2025-02-01 18:21:55,307 - INFO - Epoch 218: train_loss=0.6839
2025-02-01 18:21:55,913 - INFO - Epoch 218: val_loss=2.7630, val_acc=33.33%
2025-02-01 18:21:55,917 - INFO - ####################Training epoch 219####################
2025-02-01 18:21:56,337 - INFO - Epoch 219: train_loss=0.6867
2025-02-01 18:21:56,937 - INFO - Epoch 219: val_loss=2.7872, val_acc=33.33%
2025-02-01 18:21:56,941 - INFO - ####################Training epoch 220####################
2025-02-01 18:21:57,359 - INFO - Epoch 220: train_loss=0.6746
2025-02-01 18:21:57,965 - INFO - Epoch 220: val_loss=2.7822, val_acc=33.33%
2025-02-01 18:21:57,969 - INFO - ####################Training epoch 221####################
2025-02-01 18:21:58,387 - INFO - Epoch 221: train_loss=0.6758
2025-02-01 18:21:58,989 - INFO - Epoch 221: val_loss=2.7689, val_acc=33.33%
2025-02-01 18:21:58,993 - INFO - ####################Training epoch 222####################
2025-02-01 18:21:59,414 - INFO - Epoch 222: train_loss=0.6814
2025-02-01 18:22:00,017 - INFO - Epoch 222: val_loss=2.8038, val_acc=33.33%
2025-02-01 18:22:00,021 - INFO - ####################Training epoch 223####################
2025-02-01 18:22:00,442 - INFO - Epoch 223: train_loss=0.6740
2025-02-01 18:22:01,046 - INFO - Epoch 223: val_loss=2.7828, val_acc=33.33%
2025-02-01 18:22:01,050 - INFO - ####################Training epoch 224####################
2025-02-01 18:22:01,472 - INFO - Epoch 224: train_loss=0.7053
2025-02-01 18:22:02,076 - INFO - Epoch 224: val_loss=2.7898, val_acc=33.33%
2025-02-01 18:22:02,080 - INFO - ####################Training epoch 225####################
2025-02-01 18:22:02,500 - INFO - Epoch 225: train_loss=0.6696
2025-02-01 18:22:03,108 - INFO - Epoch 225: val_loss=2.7792, val_acc=33.33%
2025-02-01 18:22:03,112 - INFO - ####################Training epoch 226####################
2025-02-01 18:22:03,533 - INFO - Epoch 226: train_loss=0.6946
2025-02-01 18:22:04,132 - INFO - Epoch 226: val_loss=2.7812, val_acc=33.33%
2025-02-01 18:22:04,136 - INFO - ####################Training epoch 227####################
2025-02-01 18:22:04,558 - INFO - Epoch 227: train_loss=0.6813
2025-02-01 18:22:05,159 - INFO - Epoch 227: val_loss=2.7849, val_acc=33.33%
2025-02-01 18:22:05,162 - INFO - ####################Training epoch 228####################
2025-02-01 18:22:05,581 - INFO - Epoch 228: train_loss=0.6890
2025-02-01 18:22:06,185 - INFO - Epoch 228: val_loss=2.7871, val_acc=33.33%
2025-02-01 18:22:06,189 - INFO - ####################Training epoch 229####################
2025-02-01 18:22:06,608 - INFO - Epoch 229: train_loss=0.6904
2025-02-01 18:22:07,208 - INFO - Epoch 229: val_loss=2.7832, val_acc=33.33%
2025-02-01 18:22:07,212 - INFO - ####################Training epoch 230####################
2025-02-01 18:22:07,629 - INFO - Epoch 230: train_loss=0.6824
2025-02-01 18:22:08,232 - INFO - Epoch 230: val_loss=2.7894, val_acc=33.33%
2025-02-01 18:22:08,236 - INFO - ####################Training epoch 231####################
2025-02-01 18:22:08,656 - INFO - Epoch 231: train_loss=0.6852
2025-02-01 18:22:09,258 - INFO - Epoch 231: val_loss=2.7839, val_acc=33.33%
2025-02-01 18:22:09,262 - INFO - ####################Training epoch 232####################
2025-02-01 18:22:09,677 - INFO - Epoch 232: train_loss=0.6873
2025-02-01 18:22:10,281 - INFO - Epoch 232: val_loss=2.8053, val_acc=33.33%
2025-02-01 18:22:10,285 - INFO - ####################Training epoch 233####################
2025-02-01 18:22:10,705 - INFO - Epoch 233: train_loss=0.6831
2025-02-01 18:22:11,308 - INFO - Epoch 233: val_loss=2.7847, val_acc=33.33%
2025-02-01 18:22:11,311 - INFO - ####################Training epoch 234####################
2025-02-01 18:22:11,733 - INFO - Epoch 234: train_loss=0.6897
2025-02-01 18:22:12,336 - INFO - Epoch 234: val_loss=2.7794, val_acc=33.33%
2025-02-01 18:22:12,340 - INFO - ####################Training epoch 235####################
2025-02-01 18:22:12,759 - INFO - Epoch 235: train_loss=0.6835
2025-02-01 18:22:13,365 - INFO - Epoch 235: val_loss=2.7805, val_acc=33.33%
2025-02-01 18:22:13,368 - INFO - ####################Training epoch 236####################
2025-02-01 18:22:13,792 - INFO - Epoch 236: train_loss=0.6985
2025-02-01 18:22:14,394 - INFO - Epoch 236: val_loss=2.7632, val_acc=33.33%
2025-02-01 18:22:14,398 - INFO - ####################Training epoch 237####################
2025-02-01 18:22:14,817 - INFO - Epoch 237: train_loss=0.6911
2025-02-01 18:22:15,420 - INFO - Epoch 237: val_loss=2.7981, val_acc=33.33%
2025-02-01 18:22:15,423 - INFO - ####################Training epoch 238####################
2025-02-01 18:22:15,845 - INFO - Epoch 238: train_loss=0.6789
2025-02-01 18:22:16,453 - INFO - Epoch 238: val_loss=2.7892, val_acc=33.33%
2025-02-01 18:22:16,457 - INFO - ####################Training epoch 239####################
2025-02-01 18:22:16,879 - INFO - Epoch 239: train_loss=0.6920
2025-02-01 18:22:17,485 - INFO - Epoch 239: val_loss=2.8051, val_acc=33.33%
2025-02-01 18:22:17,489 - INFO - ####################Training epoch 240####################
2025-02-01 18:22:17,911 - INFO - Epoch 240: train_loss=0.6832
2025-02-01 18:22:18,513 - INFO - Epoch 240: val_loss=2.7732, val_acc=33.33%
2025-02-01 18:22:18,517 - INFO - ####################Training epoch 241####################
2025-02-01 18:22:18,935 - INFO - Epoch 241: train_loss=0.6932
2025-02-01 18:22:19,538 - INFO - Epoch 241: val_loss=2.7806, val_acc=33.33%
2025-02-01 18:22:19,542 - INFO - ####################Training epoch 242####################
2025-02-01 18:22:19,962 - INFO - Epoch 242: train_loss=0.6759
2025-02-01 18:22:20,567 - INFO - Epoch 242: val_loss=2.7873, val_acc=33.33%
2025-02-01 18:22:20,571 - INFO - ####################Training epoch 243####################
2025-02-01 18:22:20,991 - INFO - Epoch 243: train_loss=0.6794
2025-02-01 18:22:21,596 - INFO - Epoch 243: val_loss=2.7798, val_acc=33.33%
2025-02-01 18:22:21,600 - INFO - ####################Training epoch 244####################
2025-02-01 18:22:22,018 - INFO - Epoch 244: train_loss=0.7034
2025-02-01 18:22:22,622 - INFO - Epoch 244: val_loss=2.7743, val_acc=33.33%
2025-02-01 18:22:22,626 - INFO - ####################Training epoch 245####################
2025-02-01 18:22:23,046 - INFO - Epoch 245: train_loss=0.6894
2025-02-01 18:22:23,650 - INFO - Epoch 245: val_loss=2.7798, val_acc=33.33%
2025-02-01 18:22:23,654 - INFO - ####################Training epoch 246####################
2025-02-01 18:22:24,074 - INFO - Epoch 246: train_loss=0.6898
2025-02-01 18:22:24,675 - INFO - Epoch 246: val_loss=2.7756, val_acc=33.33%
2025-02-01 18:22:24,678 - INFO - ####################Training epoch 247####################
2025-02-01 18:22:25,096 - INFO - Epoch 247: train_loss=0.6747
2025-02-01 18:22:25,699 - INFO - Epoch 247: val_loss=2.7713, val_acc=33.33%
2025-02-01 18:22:25,703 - INFO - ####################Training epoch 248####################
2025-02-01 18:22:26,122 - INFO - Epoch 248: train_loss=0.6921
2025-02-01 18:22:26,723 - INFO - Epoch 248: val_loss=2.7795, val_acc=33.33%
2025-02-01 18:22:26,727 - INFO - ####################Training epoch 249####################
2025-02-01 18:22:27,146 - INFO - Epoch 249: train_loss=0.6967
2025-02-01 18:22:27,745 - INFO - Epoch 249: val_loss=2.7806, val_acc=33.33%
2025-02-01 18:22:27,749 - INFO - ####################Training epoch 250####################
2025-02-01 18:22:28,166 - INFO - Epoch 250: train_loss=0.6941
2025-02-01 18:22:28,768 - INFO - Epoch 250: val_loss=2.8169, val_acc=33.33%
2025-02-01 18:22:28,772 - INFO - ####################Training epoch 251####################
2025-02-01 18:22:29,194 - INFO - Epoch 251: train_loss=0.6881
2025-02-01 18:22:29,797 - INFO - Epoch 251: val_loss=2.7820, val_acc=33.33%
2025-02-01 18:22:29,801 - INFO - ####################Training epoch 252####################
2025-02-01 18:22:30,223 - INFO - Epoch 252: train_loss=0.6799
2025-02-01 18:22:30,826 - INFO - Epoch 252: val_loss=2.7800, val_acc=33.33%
2025-02-01 18:22:30,829 - INFO - ####################Training epoch 253####################
2025-02-01 18:22:31,251 - INFO - Epoch 253: train_loss=0.6890
2025-02-01 18:22:31,854 - INFO - Epoch 253: val_loss=2.7949, val_acc=33.33%
2025-02-01 18:22:31,858 - INFO - ####################Training epoch 254####################
2025-02-01 18:22:32,277 - INFO - Epoch 254: train_loss=0.6756
2025-02-01 18:22:32,881 - INFO - Epoch 254: val_loss=2.7945, val_acc=33.33%
2025-02-01 18:22:32,884 - INFO - ####################Training epoch 255####################
2025-02-01 18:22:33,302 - INFO - Epoch 255: train_loss=0.6893
2025-02-01 18:22:33,906 - INFO - Epoch 255: val_loss=2.7822, val_acc=33.33%
2025-02-01 18:22:33,909 - INFO - ####################Training epoch 256####################
2025-02-01 18:22:34,332 - INFO - Epoch 256: train_loss=0.6964
2025-02-01 18:22:34,933 - INFO - Epoch 256: val_loss=2.7826, val_acc=33.33%
2025-02-01 18:22:34,937 - INFO - ####################Training epoch 257####################
2025-02-01 18:22:35,355 - INFO - Epoch 257: train_loss=0.6890
2025-02-01 18:22:35,957 - INFO - Epoch 257: val_loss=2.7680, val_acc=33.33%
2025-02-01 18:22:35,961 - INFO - ####################Training epoch 258####################
2025-02-01 18:22:36,382 - INFO - Epoch 258: train_loss=0.6801
2025-02-01 18:22:36,982 - INFO - Epoch 258: val_loss=2.7777, val_acc=33.33%
2025-02-01 18:22:36,986 - INFO - ####################Training epoch 259####################
2025-02-01 18:22:37,404 - INFO - Epoch 259: train_loss=0.6907
2025-02-01 18:22:38,004 - INFO - Epoch 259: val_loss=2.7897, val_acc=33.33%
2025-02-01 18:22:38,008 - INFO - ####################Training epoch 260####################
2025-02-01 18:22:38,426 - INFO - Epoch 260: train_loss=0.6883
2025-02-01 18:22:39,027 - INFO - Epoch 260: val_loss=2.7947, val_acc=33.33%
2025-02-01 18:22:39,031 - INFO - ####################Training epoch 261####################
2025-02-01 18:22:39,448 - INFO - Epoch 261: train_loss=0.6819
2025-02-01 18:22:40,048 - INFO - Epoch 261: val_loss=2.7682, val_acc=33.33%
2025-02-01 18:22:40,052 - INFO - ####################Training epoch 262####################
2025-02-01 18:22:40,469 - INFO - Epoch 262: train_loss=0.6866
2025-02-01 18:22:41,072 - INFO - Epoch 262: val_loss=2.8137, val_acc=33.33%
2025-02-01 18:22:41,076 - INFO - ####################Training epoch 263####################
2025-02-01 18:22:41,496 - INFO - Epoch 263: train_loss=0.6940
2025-02-01 18:22:42,097 - INFO - Epoch 263: val_loss=2.7942, val_acc=33.33%
2025-02-01 18:22:42,101 - INFO - ####################Training epoch 264####################
2025-02-01 18:22:42,521 - INFO - Epoch 264: train_loss=0.6908
2025-02-01 18:22:43,121 - INFO - Epoch 264: val_loss=2.7690, val_acc=33.33%
2025-02-01 18:22:43,125 - INFO - ####################Training epoch 265####################
2025-02-01 18:22:43,545 - INFO - Epoch 265: train_loss=0.7068
2025-02-01 18:22:44,146 - INFO - Epoch 265: val_loss=2.7827, val_acc=33.33%
2025-02-01 18:22:44,150 - INFO - ####################Training epoch 266####################
2025-02-01 18:22:44,570 - INFO - Epoch 266: train_loss=0.6847
2025-02-01 18:22:45,176 - INFO - Epoch 266: val_loss=2.7945, val_acc=33.33%
2025-02-01 18:22:45,180 - INFO - ####################Training epoch 267####################
2025-02-01 18:22:45,596 - INFO - Epoch 267: train_loss=0.6918
2025-02-01 18:22:46,200 - INFO - Epoch 267: val_loss=2.7585, val_acc=33.33%
2025-02-01 18:22:46,203 - INFO - ####################Training epoch 268####################
2025-02-01 18:22:46,624 - INFO - Epoch 268: train_loss=0.6952
2025-02-01 18:22:47,226 - INFO - Epoch 268: val_loss=2.7988, val_acc=33.33%
2025-02-01 18:22:47,230 - INFO - ####################Training epoch 269####################
2025-02-01 18:22:47,646 - INFO - Epoch 269: train_loss=0.6856
2025-02-01 18:22:48,249 - INFO - Epoch 269: val_loss=2.7963, val_acc=33.33%
2025-02-01 18:22:48,253 - INFO - ####################Training epoch 270####################
2025-02-01 18:22:48,669 - INFO - Epoch 270: train_loss=0.6804
2025-02-01 18:22:49,271 - INFO - Epoch 270: val_loss=2.7919, val_acc=33.33%
2025-02-01 18:22:49,274 - INFO - ####################Training epoch 271####################
2025-02-01 18:22:49,698 - INFO - Epoch 271: train_loss=0.6896
2025-02-01 18:22:50,301 - INFO - Epoch 271: val_loss=2.7937, val_acc=33.33%
2025-02-01 18:22:50,304 - INFO - ####################Training epoch 272####################
2025-02-01 18:22:50,723 - INFO - Epoch 272: train_loss=0.6826
2025-02-01 18:22:51,329 - INFO - Epoch 272: val_loss=2.7581, val_acc=33.33%
2025-02-01 18:22:51,332 - INFO - ####################Training epoch 273####################
2025-02-01 18:22:51,753 - INFO - Epoch 273: train_loss=0.6836
2025-02-01 18:22:52,356 - INFO - Epoch 273: val_loss=2.8080, val_acc=33.33%
2025-02-01 18:22:52,359 - INFO - ####################Training epoch 274####################
2025-02-01 18:22:52,777 - INFO - Epoch 274: train_loss=0.6848
2025-02-01 18:22:53,379 - INFO - Epoch 274: val_loss=2.8074, val_acc=33.33%
2025-02-01 18:22:53,383 - INFO - ####################Training epoch 275####################
2025-02-01 18:22:53,800 - INFO - Epoch 275: train_loss=0.6741
2025-02-01 18:22:54,403 - INFO - Epoch 275: val_loss=2.7928, val_acc=33.33%
2025-02-01 18:22:54,406 - INFO - ####################Training epoch 276####################
2025-02-01 18:22:54,825 - INFO - Epoch 276: train_loss=0.6824
2025-02-01 18:22:55,429 - INFO - Epoch 276: val_loss=2.7860, val_acc=33.33%
2025-02-01 18:22:55,432 - INFO - ####################Training epoch 277####################
2025-02-01 18:22:55,852 - INFO - Epoch 277: train_loss=0.6801
2025-02-01 18:22:56,459 - INFO - Epoch 277: val_loss=2.7785, val_acc=33.33%
2025-02-01 18:22:56,463 - INFO - ####################Training epoch 278####################
2025-02-01 18:22:56,881 - INFO - Epoch 278: train_loss=0.6888
2025-02-01 18:22:57,482 - INFO - Epoch 278: val_loss=2.8050, val_acc=33.33%
2025-02-01 18:22:57,486 - INFO - ####################Training epoch 279####################
2025-02-01 18:22:57,906 - INFO - Epoch 279: train_loss=0.6788
2025-02-01 18:22:58,512 - INFO - Epoch 279: val_loss=2.8026, val_acc=33.33%
2025-02-01 18:22:58,516 - INFO - ####################Training epoch 280####################
2025-02-01 18:22:58,937 - INFO - Epoch 280: train_loss=0.6907
2025-02-01 18:22:59,543 - INFO - Epoch 280: val_loss=2.7554, val_acc=33.33%
2025-02-01 18:22:59,547 - INFO - ####################Training epoch 281####################
2025-02-01 18:22:59,967 - INFO - Epoch 281: train_loss=0.6830
2025-02-01 18:23:00,571 - INFO - Epoch 281: val_loss=2.7883, val_acc=33.33%
2025-02-01 18:23:00,575 - INFO - ####################Training epoch 282####################
2025-02-01 18:23:00,999 - INFO - Epoch 282: train_loss=0.7000
2025-02-01 18:23:01,604 - INFO - Epoch 282: val_loss=2.7712, val_acc=33.33%
2025-02-01 18:23:01,608 - INFO - ####################Training epoch 283####################
2025-02-01 18:23:02,028 - INFO - Epoch 283: train_loss=0.6981
2025-02-01 18:23:02,632 - INFO - Epoch 283: val_loss=2.8039, val_acc=33.33%
2025-02-01 18:23:02,636 - INFO - ####################Training epoch 284####################
2025-02-01 18:23:03,058 - INFO - Epoch 284: train_loss=0.6719
2025-02-01 18:23:03,667 - INFO - Epoch 284: val_loss=2.7825, val_acc=33.33%
2025-02-01 18:23:03,671 - INFO - ####################Training epoch 285####################
2025-02-01 18:23:04,091 - INFO - Epoch 285: train_loss=0.6904
2025-02-01 18:23:04,698 - INFO - Epoch 285: val_loss=2.8089, val_acc=33.33%
2025-02-01 18:23:04,702 - INFO - ####################Training epoch 286####################
2025-02-01 18:23:05,122 - INFO - Epoch 286: train_loss=0.6924
2025-02-01 18:23:05,725 - INFO - Epoch 286: val_loss=2.7894, val_acc=33.33%
2025-02-01 18:23:05,729 - INFO - ####################Training epoch 287####################
2025-02-01 18:23:06,149 - INFO - Epoch 287: train_loss=0.6870
2025-02-01 18:23:06,755 - INFO - Epoch 287: val_loss=2.7848, val_acc=33.33%
2025-02-01 18:23:06,758 - INFO - ####################Training epoch 288####################
2025-02-01 18:23:07,178 - INFO - Epoch 288: train_loss=0.6984
2025-02-01 18:23:07,784 - INFO - Epoch 288: val_loss=2.7820, val_acc=33.33%
2025-02-01 18:23:07,788 - INFO - ####################Training epoch 289####################
2025-02-01 18:23:08,208 - INFO - Epoch 289: train_loss=0.6877
2025-02-01 18:23:08,815 - INFO - Epoch 289: val_loss=2.7771, val_acc=33.33%
2025-02-01 18:23:08,819 - INFO - ####################Training epoch 290####################
2025-02-01 18:23:09,238 - INFO - Epoch 290: train_loss=0.7021
2025-02-01 18:23:09,846 - INFO - Epoch 290: val_loss=2.8223, val_acc=33.33%
2025-02-01 18:23:09,849 - INFO - ####################Training epoch 291####################
2025-02-01 18:23:10,271 - INFO - Epoch 291: train_loss=0.6900
2025-02-01 18:23:10,873 - INFO - Epoch 291: val_loss=2.7928, val_acc=33.33%
2025-02-01 18:23:10,877 - INFO - ####################Training epoch 292####################
2025-02-01 18:23:11,298 - INFO - Epoch 292: train_loss=0.6936
2025-02-01 18:23:11,903 - INFO - Epoch 292: val_loss=2.7752, val_acc=33.33%
2025-02-01 18:23:11,907 - INFO - ####################Training epoch 293####################
2025-02-01 18:23:12,327 - INFO - Epoch 293: train_loss=0.6827
2025-02-01 18:23:12,931 - INFO - Epoch 293: val_loss=2.8109, val_acc=33.33%
2025-02-01 18:23:12,934 - INFO - ####################Training epoch 294####################
2025-02-01 18:23:13,355 - INFO - Epoch 294: train_loss=0.6818
2025-02-01 18:23:13,962 - INFO - Epoch 294: val_loss=2.7771, val_acc=33.33%
2025-02-01 18:23:13,965 - INFO - ####################Training epoch 295####################
2025-02-01 18:23:14,386 - INFO - Epoch 295: train_loss=0.6798
2025-02-01 18:23:14,988 - INFO - Epoch 295: val_loss=2.7889, val_acc=33.33%
2025-02-01 18:23:14,992 - INFO - ####################Training epoch 296####################
2025-02-01 18:23:15,414 - INFO - Epoch 296: train_loss=0.6934
2025-02-01 18:23:16,019 - INFO - Epoch 296: val_loss=2.7857, val_acc=33.33%
2025-02-01 18:23:16,022 - INFO - ####################Training epoch 297####################
2025-02-01 18:23:16,443 - INFO - Epoch 297: train_loss=0.6797
2025-02-01 18:23:17,045 - INFO - Epoch 297: val_loss=2.7803, val_acc=33.33%
2025-02-01 18:23:17,049 - INFO - ####################Training epoch 298####################
2025-02-01 18:23:17,470 - INFO - Epoch 298: train_loss=0.6864
2025-02-01 18:23:18,073 - INFO - Epoch 298: val_loss=2.7868, val_acc=33.33%
2025-02-01 18:23:18,077 - INFO - ####################Training epoch 299####################
2025-02-01 18:23:18,495 - INFO - Epoch 299: train_loss=0.6936
2025-02-01 18:23:19,099 - INFO - Epoch 299: val_loss=2.7797, val_acc=33.33%
2025-02-01 18:23:19,272 - INFO - Model saved.
