2025-02-01 17:44:05,338 - INFO - Starting training with the following parameters:
2025-02-01 17:44:05,338 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product |
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.005          |
| epochs          | 300            |

2025-02-01 17:44:06,962 - INFO - Epoch 0: val_loss=1.0585, val_acc=66.67%
2025-02-01 17:44:07,624 - INFO - ####################Training epoch 0####################
2025-02-01 17:44:07,784 - INFO - Epoch 0: train_loss=1.2279
2025-02-01 17:44:09,175 - INFO - Epoch 0: val_loss=2.7505, val_acc=33.33%
2025-02-01 17:44:09,213 - INFO - ####################Training epoch 1####################
2025-02-01 17:44:10,248 - INFO - Epoch 1: train_loss=2.0394
2025-02-01 17:44:11,439 - INFO - Epoch 1: val_loss=4.0482, val_acc=33.33%
2025-02-01 17:44:11,466 - INFO - ####################Training epoch 2####################
2025-02-01 17:44:12,485 - INFO - Epoch 2: train_loss=2.6728
2025-02-01 17:44:13,698 - INFO - Epoch 2: val_loss=4.6279, val_acc=0.00%
2025-02-01 17:44:13,724 - INFO - ####################Training epoch 3####################
2025-02-01 17:44:14,742 - INFO - Epoch 3: train_loss=2.9341
2025-02-01 17:44:15,927 - INFO - Epoch 3: val_loss=2.5250, val_acc=0.00%
2025-02-01 17:44:15,956 - INFO - ####################Training epoch 4####################
2025-02-01 17:44:16,957 - INFO - Epoch 4: train_loss=1.7056
2025-02-01 17:44:18,154 - INFO - Epoch 4: val_loss=1.5184, val_acc=0.00%
2025-02-01 17:44:18,182 - INFO - ####################Training epoch 5####################
2025-02-01 17:44:19,196 - INFO - Epoch 5: train_loss=1.2132
2025-02-01 17:44:20,422 - INFO - Epoch 5: val_loss=1.1197, val_acc=66.67%
2025-02-01 17:44:20,426 - INFO - ####################Training epoch 6####################
2025-02-01 17:44:21,453 - INFO - Epoch 6: train_loss=1.1234
2025-02-01 17:44:22,653 - INFO - Epoch 6: val_loss=0.9428, val_acc=66.67%
2025-02-01 17:44:22,657 - INFO - ####################Training epoch 7####################
2025-02-01 17:44:23,684 - INFO - Epoch 7: train_loss=1.1488
2025-02-01 17:44:24,873 - INFO - Epoch 7: val_loss=0.8532, val_acc=66.67%
2025-02-01 17:44:24,876 - INFO - ####################Training epoch 8####################
2025-02-01 17:44:25,898 - INFO - Epoch 8: train_loss=1.2005
2025-02-01 17:44:27,108 - INFO - Epoch 8: val_loss=0.8033, val_acc=66.67%
2025-02-01 17:44:27,111 - INFO - ####################Training epoch 9####################
2025-02-01 17:44:28,122 - INFO - Epoch 9: train_loss=1.2597
2025-02-01 17:44:29,338 - INFO - Epoch 9: val_loss=0.7752, val_acc=66.67%
2025-02-01 17:44:29,341 - INFO - ####################Training epoch 10####################
2025-02-01 17:44:30,354 - INFO - Epoch 10: train_loss=1.3144
2025-02-01 17:44:31,544 - INFO - Epoch 10: val_loss=0.7569, val_acc=66.67%
2025-02-01 17:44:31,548 - INFO - ####################Training epoch 11####################
2025-02-01 17:44:32,555 - INFO - Epoch 11: train_loss=1.3650
2025-02-01 17:44:33,747 - INFO - Epoch 11: val_loss=0.7449, val_acc=66.67%
2025-02-01 17:44:33,751 - INFO - ####################Training epoch 12####################
2025-02-01 17:44:34,782 - INFO - Epoch 12: train_loss=1.4111
2025-02-01 17:44:36,060 - INFO - Epoch 12: val_loss=0.8352, val_acc=66.67%
2025-02-01 17:44:36,064 - INFO - ####################Training epoch 13####################
2025-02-01 17:44:37,160 - INFO - Epoch 13: train_loss=1.1956
2025-02-01 17:44:38,365 - INFO - Epoch 13: val_loss=1.1607, val_acc=33.33%
2025-02-01 17:44:38,368 - INFO - ####################Training epoch 14####################
2025-02-01 17:44:39,389 - INFO - Epoch 14: train_loss=1.1050
2025-02-01 17:44:40,612 - INFO - Epoch 14: val_loss=1.5222, val_acc=0.00%
2025-02-01 17:44:40,616 - INFO - ####################Training epoch 15####################
2025-02-01 17:44:41,641 - INFO - Epoch 15: train_loss=1.1729
2025-02-01 17:44:42,840 - INFO - Epoch 15: val_loss=1.5342, val_acc=0.00%
2025-02-01 17:44:42,843 - INFO - ####################Training epoch 16####################
2025-02-01 17:44:43,879 - INFO - Epoch 16: train_loss=1.1782
2025-02-01 17:44:45,079 - INFO - Epoch 16: val_loss=1.3432, val_acc=0.00%
2025-02-01 17:44:45,082 - INFO - ####################Training epoch 17####################
2025-02-01 17:44:46,114 - INFO - Epoch 17: train_loss=1.1232
2025-02-01 17:44:47,316 - INFO - Epoch 17: val_loss=1.1222, val_acc=33.33%
2025-02-01 17:44:47,319 - INFO - ####################Training epoch 18####################
2025-02-01 17:44:48,356 - INFO - Epoch 18: train_loss=1.0980
2025-02-01 17:44:49,567 - INFO - Epoch 18: val_loss=1.0452, val_acc=33.33%
2025-02-01 17:44:49,571 - INFO - ####################Training epoch 19####################
2025-02-01 17:44:50,591 - INFO - Epoch 19: train_loss=1.1011
2025-02-01 17:44:51,809 - INFO - Epoch 19: val_loss=1.0276, val_acc=33.33%
2025-02-01 17:44:51,813 - INFO - ####################Training epoch 20####################
2025-02-01 17:44:52,834 - INFO - Epoch 20: train_loss=1.1041
2025-02-01 17:44:54,051 - INFO - Epoch 20: val_loss=1.0846, val_acc=33.33%
2025-02-01 17:44:54,055 - INFO - ####################Training epoch 21####################
2025-02-01 17:44:55,071 - INFO - Epoch 21: train_loss=1.0970
2025-02-01 17:44:56,272 - INFO - Epoch 21: val_loss=1.2695, val_acc=33.33%
2025-02-01 17:44:56,276 - INFO - ####################Training epoch 22####################
2025-02-01 17:44:57,312 - INFO - Epoch 22: train_loss=1.0838
2025-02-01 17:44:58,513 - INFO - Epoch 22: val_loss=1.2520, val_acc=0.00%
2025-02-01 17:44:58,516 - INFO - ####################Training epoch 23####################
2025-02-01 17:44:59,536 - INFO - Epoch 23: train_loss=1.0886
2025-02-01 17:45:00,751 - INFO - Epoch 23: val_loss=1.1246, val_acc=0.00%
2025-02-01 17:45:00,755 - INFO - ####################Training epoch 24####################
2025-02-01 17:45:01,783 - INFO - Epoch 24: train_loss=1.1288
2025-02-01 17:45:02,993 - INFO - Epoch 24: val_loss=1.1060, val_acc=0.00%
2025-02-01 17:45:02,997 - INFO - ####################Training epoch 25####################
2025-02-01 17:45:04,040 - INFO - Epoch 25: train_loss=1.1419
2025-02-01 17:45:05,236 - INFO - Epoch 25: val_loss=1.1006, val_acc=0.00%
2025-02-01 17:45:05,239 - INFO - ####################Training epoch 26####################
2025-02-01 17:45:06,263 - INFO - Epoch 26: train_loss=1.1528
2025-02-01 17:45:07,461 - INFO - Epoch 26: val_loss=1.1000, val_acc=0.00%
2025-02-01 17:45:07,465 - INFO - ####################Training epoch 27####################
2025-02-01 17:45:08,481 - INFO - Epoch 27: train_loss=1.1621
2025-02-01 17:45:09,733 - INFO - Epoch 27: val_loss=1.1030, val_acc=0.00%
2025-02-01 17:45:09,738 - INFO - ####################Training epoch 28####################
2025-02-01 17:45:10,764 - INFO - Epoch 28: train_loss=1.1684
2025-02-01 17:45:11,989 - INFO - Epoch 28: val_loss=1.1065, val_acc=0.00%
2025-02-01 17:45:11,993 - INFO - ####################Training epoch 29####################
2025-02-01 17:45:13,006 - INFO - Epoch 29: train_loss=1.1755
2025-02-01 17:45:14,227 - INFO - Epoch 29: val_loss=1.1132, val_acc=0.00%
2025-02-01 17:45:14,230 - INFO - ####################Training epoch 30####################
2025-02-01 17:45:15,387 - INFO - Epoch 30: train_loss=1.1816
2025-02-01 17:45:16,146 - INFO - Epoch 30: val_loss=1.1162, val_acc=0.00%
2025-02-01 17:45:16,150 - INFO - ####################Training epoch 31####################
2025-02-01 17:45:17,001 - INFO - Epoch 31: train_loss=1.1826
2025-02-01 17:45:17,597 - INFO - Epoch 31: val_loss=1.1190, val_acc=0.00%
2025-02-01 17:45:17,601 - INFO - ####################Training epoch 32####################
2025-02-01 17:45:18,011 - INFO - Epoch 32: train_loss=1.1863
2025-02-01 17:45:18,613 - INFO - Epoch 32: val_loss=1.1242, val_acc=0.00%
2025-02-01 17:45:18,617 - INFO - ####################Training epoch 33####################
2025-02-01 17:45:19,032 - INFO - Epoch 33: train_loss=1.1899
2025-02-01 17:45:19,632 - INFO - Epoch 33: val_loss=1.1326, val_acc=0.00%
2025-02-01 17:45:19,636 - INFO - ####################Training epoch 34####################
2025-02-01 17:45:20,050 - INFO - Epoch 34: train_loss=1.1937
2025-02-01 17:45:20,649 - INFO - Epoch 34: val_loss=1.1376, val_acc=0.00%
2025-02-01 17:45:20,653 - INFO - ####################Training epoch 35####################
2025-02-01 17:45:21,066 - INFO - Epoch 35: train_loss=1.1953
2025-02-01 17:45:21,669 - INFO - Epoch 35: val_loss=1.1394, val_acc=0.00%
2025-02-01 17:45:21,673 - INFO - ####################Training epoch 36####################
2025-02-01 17:45:22,088 - INFO - Epoch 36: train_loss=1.1966
2025-02-01 17:45:22,686 - INFO - Epoch 36: val_loss=1.1393, val_acc=0.00%
2025-02-01 17:45:22,690 - INFO - ####################Training epoch 37####################
2025-02-01 17:45:23,109 - INFO - Epoch 37: train_loss=1.1961
2025-02-01 17:45:23,708 - INFO - Epoch 37: val_loss=1.0927, val_acc=33.33%
2025-02-01 17:45:23,712 - INFO - ####################Training epoch 38####################
2025-02-01 17:45:24,127 - INFO - Epoch 38: train_loss=1.3892
2025-02-01 17:45:24,728 - INFO - Epoch 38: val_loss=1.3366, val_acc=33.33%
2025-02-01 17:45:24,732 - INFO - ####################Training epoch 39####################
2025-02-01 17:45:25,146 - INFO - Epoch 39: train_loss=1.3897
2025-02-01 17:45:25,745 - INFO - Epoch 39: val_loss=1.3159, val_acc=33.33%
2025-02-01 17:45:25,749 - INFO - ####################Training epoch 40####################
2025-02-01 17:45:26,168 - INFO - Epoch 40: train_loss=1.4046
2025-02-01 17:45:26,768 - INFO - Epoch 40: val_loss=1.3035, val_acc=33.33%
2025-02-01 17:45:26,771 - INFO - ####################Training epoch 41####################
2025-02-01 17:45:27,187 - INFO - Epoch 41: train_loss=1.4211
2025-02-01 17:45:27,792 - INFO - Epoch 41: val_loss=1.3281, val_acc=33.33%
2025-02-01 17:45:27,795 - INFO - ####################Training epoch 42####################
2025-02-01 17:45:28,209 - INFO - Epoch 42: train_loss=1.4367
2025-02-01 17:45:28,808 - INFO - Epoch 42: val_loss=1.3240, val_acc=33.33%
2025-02-01 17:45:28,812 - INFO - ####################Training epoch 43####################
2025-02-01 17:45:29,341 - INFO - Epoch 43: train_loss=1.4192
2025-02-01 17:45:29,942 - INFO - Epoch 43: val_loss=1.3290, val_acc=33.33%
2025-02-01 17:45:29,946 - INFO - ####################Training epoch 44####################
2025-02-01 17:45:30,368 - INFO - Epoch 44: train_loss=1.4380
2025-02-01 17:45:30,974 - INFO - Epoch 44: val_loss=1.3249, val_acc=33.33%
2025-02-01 17:45:30,978 - INFO - ####################Training epoch 45####################
2025-02-01 17:45:31,393 - INFO - Epoch 45: train_loss=1.4420
2025-02-01 17:45:31,997 - INFO - Epoch 45: val_loss=1.3323, val_acc=33.33%
2025-02-01 17:45:32,001 - INFO - ####################Training epoch 46####################
2025-02-01 17:45:32,421 - INFO - Epoch 46: train_loss=1.4331
2025-02-01 17:45:33,026 - INFO - Epoch 46: val_loss=1.3280, val_acc=33.33%
2025-02-01 17:45:33,030 - INFO - ####################Training epoch 47####################
2025-02-01 17:45:33,445 - INFO - Epoch 47: train_loss=1.4412
2025-02-01 17:45:34,049 - INFO - Epoch 47: val_loss=1.3166, val_acc=33.33%
2025-02-01 17:45:34,053 - INFO - ####################Training epoch 48####################
2025-02-01 17:45:34,470 - INFO - Epoch 48: train_loss=1.4292
2025-02-01 17:45:35,072 - INFO - Epoch 48: val_loss=1.3148, val_acc=33.33%
2025-02-01 17:45:35,076 - INFO - ####################Training epoch 49####################
2025-02-01 17:45:35,498 - INFO - Epoch 49: train_loss=1.4338
2025-02-01 17:45:36,099 - INFO - Epoch 49: val_loss=1.3335, val_acc=33.33%
2025-02-01 17:45:36,103 - INFO - ####################Training epoch 50####################
2025-02-01 17:45:36,522 - INFO - Epoch 50: train_loss=1.4286
2025-02-01 17:45:37,125 - INFO - Epoch 50: val_loss=1.3276, val_acc=33.33%
2025-02-01 17:45:37,129 - INFO - ####################Training epoch 51####################
2025-02-01 17:45:37,545 - INFO - Epoch 51: train_loss=1.4349
2025-02-01 17:45:38,144 - INFO - Epoch 51: val_loss=1.3227, val_acc=33.33%
2025-02-01 17:45:38,147 - INFO - ####################Training epoch 52####################
2025-02-01 17:45:38,567 - INFO - Epoch 52: train_loss=1.4419
2025-02-01 17:45:39,170 - INFO - Epoch 52: val_loss=1.3353, val_acc=33.33%
2025-02-01 17:45:39,174 - INFO - ####################Training epoch 53####################
2025-02-01 17:45:39,589 - INFO - Epoch 53: train_loss=1.4340
2025-02-01 17:45:40,193 - INFO - Epoch 53: val_loss=1.3300, val_acc=33.33%
2025-02-01 17:45:40,197 - INFO - ####################Training epoch 54####################
2025-02-01 17:45:40,615 - INFO - Epoch 54: train_loss=1.4310
2025-02-01 17:45:41,217 - INFO - Epoch 54: val_loss=1.3133, val_acc=33.33%
2025-02-01 17:45:41,221 - INFO - ####################Training epoch 55####################
2025-02-01 17:45:41,641 - INFO - Epoch 55: train_loss=1.4269
2025-02-01 17:45:42,247 - INFO - Epoch 55: val_loss=1.3345, val_acc=33.33%
2025-02-01 17:45:42,250 - INFO - ####################Training epoch 56####################
2025-02-01 17:45:42,667 - INFO - Epoch 56: train_loss=1.4449
2025-02-01 17:45:43,269 - INFO - Epoch 56: val_loss=1.3277, val_acc=33.33%
2025-02-01 17:45:43,272 - INFO - ####################Training epoch 57####################
2025-02-01 17:45:43,690 - INFO - Epoch 57: train_loss=1.4439
2025-02-01 17:45:44,290 - INFO - Epoch 57: val_loss=1.3316, val_acc=33.33%
2025-02-01 17:45:44,294 - INFO - ####################Training epoch 58####################
2025-02-01 17:45:44,713 - INFO - Epoch 58: train_loss=1.4326
2025-02-01 17:45:45,317 - INFO - Epoch 58: val_loss=1.3309, val_acc=33.33%
2025-02-01 17:45:45,321 - INFO - ####################Training epoch 59####################
2025-02-01 17:45:45,738 - INFO - Epoch 59: train_loss=1.4391
2025-02-01 17:45:46,346 - INFO - Epoch 59: val_loss=1.3245, val_acc=33.33%
2025-02-01 17:45:46,350 - INFO - ####################Training epoch 60####################
2025-02-01 17:45:46,767 - INFO - Epoch 60: train_loss=1.4469
2025-02-01 17:45:47,369 - INFO - Epoch 60: val_loss=1.3177, val_acc=33.33%
2025-02-01 17:45:47,373 - INFO - ####################Training epoch 61####################
2025-02-01 17:45:47,791 - INFO - Epoch 61: train_loss=1.4315
2025-02-01 17:45:48,394 - INFO - Epoch 61: val_loss=1.3270, val_acc=33.33%
2025-02-01 17:45:48,398 - INFO - ####################Training epoch 62####################
2025-02-01 17:45:48,814 - INFO - Epoch 62: train_loss=1.4414
2025-02-01 17:45:49,419 - INFO - Epoch 62: val_loss=1.3280, val_acc=33.33%
2025-02-01 17:45:49,422 - INFO - ####################Training epoch 63####################
2025-02-01 17:45:49,841 - INFO - Epoch 63: train_loss=1.4493
2025-02-01 17:45:50,439 - INFO - Epoch 63: val_loss=1.3130, val_acc=33.33%
2025-02-01 17:45:50,443 - INFO - ####################Training epoch 64####################
2025-02-01 17:45:50,866 - INFO - Epoch 64: train_loss=1.4251
2025-02-01 17:45:51,464 - INFO - Epoch 64: val_loss=1.3213, val_acc=33.33%
2025-02-01 17:45:51,471 - INFO - ####################Training epoch 65####################
2025-02-01 17:45:51,886 - INFO - Epoch 65: train_loss=1.4416
2025-02-01 17:45:52,489 - INFO - Epoch 65: val_loss=1.3305, val_acc=33.33%
2025-02-01 17:45:52,493 - INFO - ####################Training epoch 66####################
2025-02-01 17:45:52,908 - INFO - Epoch 66: train_loss=1.4397
2025-02-01 17:45:53,509 - INFO - Epoch 66: val_loss=1.3299, val_acc=33.33%
2025-02-01 17:45:53,513 - INFO - ####################Training epoch 67####################
2025-02-01 17:45:53,934 - INFO - Epoch 67: train_loss=1.4341
2025-02-01 17:45:54,536 - INFO - Epoch 67: val_loss=1.3204, val_acc=33.33%
2025-02-01 17:45:54,540 - INFO - ####################Training epoch 68####################
2025-02-01 17:45:54,958 - INFO - Epoch 68: train_loss=1.4256
2025-02-01 17:45:55,561 - INFO - Epoch 68: val_loss=1.3151, val_acc=33.33%
2025-02-01 17:45:55,565 - INFO - ####################Training epoch 69####################
2025-02-01 17:45:55,981 - INFO - Epoch 69: train_loss=1.4409
2025-02-01 17:45:56,584 - INFO - Epoch 69: val_loss=1.3286, val_acc=33.33%
2025-02-01 17:45:56,588 - INFO - ####################Training epoch 70####################
2025-02-01 17:45:57,005 - INFO - Epoch 70: train_loss=1.4220
2025-02-01 17:45:57,605 - INFO - Epoch 70: val_loss=1.3217, val_acc=33.33%
2025-02-01 17:45:57,609 - INFO - ####################Training epoch 71####################
2025-02-01 17:45:58,023 - INFO - Epoch 71: train_loss=1.4344
2025-02-01 17:45:58,625 - INFO - Epoch 71: val_loss=1.2788, val_acc=33.33%
2025-02-01 17:45:58,629 - INFO - ####################Training epoch 72####################
2025-02-01 17:45:59,046 - INFO - Epoch 72: train_loss=1.4403
2025-02-01 17:45:59,643 - INFO - Epoch 72: val_loss=1.3399, val_acc=33.33%
2025-02-01 17:45:59,647 - INFO - ####################Training epoch 73####################
2025-02-01 17:46:00,066 - INFO - Epoch 73: train_loss=1.4372
2025-02-01 17:46:00,668 - INFO - Epoch 73: val_loss=1.3045, val_acc=33.33%
2025-02-01 17:46:00,672 - INFO - ####################Training epoch 74####################
2025-02-01 17:46:01,086 - INFO - Epoch 74: train_loss=1.4299
2025-02-01 17:46:01,688 - INFO - Epoch 74: val_loss=1.3190, val_acc=33.33%
2025-02-01 17:46:01,691 - INFO - ####################Training epoch 75####################
2025-02-01 17:46:02,111 - INFO - Epoch 75: train_loss=1.4410
2025-02-01 17:46:02,710 - INFO - Epoch 75: val_loss=1.3319, val_acc=33.33%
2025-02-01 17:46:02,714 - INFO - ####################Training epoch 76####################
2025-02-01 17:46:03,134 - INFO - Epoch 76: train_loss=1.4399
2025-02-01 17:46:03,733 - INFO - Epoch 76: val_loss=1.3426, val_acc=33.33%
2025-02-01 17:46:03,736 - INFO - ####################Training epoch 77####################
2025-02-01 17:46:04,154 - INFO - Epoch 77: train_loss=1.4292
2025-02-01 17:46:04,759 - INFO - Epoch 77: val_loss=1.3131, val_acc=33.33%
2025-02-01 17:46:04,762 - INFO - ####################Training epoch 78####################
2025-02-01 17:46:05,183 - INFO - Epoch 78: train_loss=1.4397
2025-02-01 17:46:05,788 - INFO - Epoch 78: val_loss=1.3258, val_acc=33.33%
2025-02-01 17:46:05,791 - INFO - ####################Training epoch 79####################
2025-02-01 17:46:06,211 - INFO - Epoch 79: train_loss=1.4289
2025-02-01 17:46:06,811 - INFO - Epoch 79: val_loss=1.3358, val_acc=33.33%
2025-02-01 17:46:06,814 - INFO - ####################Training epoch 80####################
2025-02-01 17:46:07,229 - INFO - Epoch 80: train_loss=1.4381
2025-02-01 17:46:07,832 - INFO - Epoch 80: val_loss=1.3093, val_acc=33.33%
2025-02-01 17:46:07,836 - INFO - ####################Training epoch 81####################
2025-02-01 17:46:08,252 - INFO - Epoch 81: train_loss=1.4344
2025-02-01 17:46:08,852 - INFO - Epoch 81: val_loss=1.3039, val_acc=33.33%
2025-02-01 17:46:08,855 - INFO - ####################Training epoch 82####################
2025-02-01 17:46:09,274 - INFO - Epoch 82: train_loss=1.4253
2025-02-01 17:46:09,876 - INFO - Epoch 82: val_loss=1.3276, val_acc=33.33%
2025-02-01 17:46:09,880 - INFO - ####################Training epoch 83####################
2025-02-01 17:46:10,297 - INFO - Epoch 83: train_loss=1.4445
2025-02-01 17:46:10,899 - INFO - Epoch 83: val_loss=1.3266, val_acc=33.33%
2025-02-01 17:46:10,902 - INFO - ####################Training epoch 84####################
2025-02-01 17:46:11,319 - INFO - Epoch 84: train_loss=1.4334
2025-02-01 17:46:11,918 - INFO - Epoch 84: val_loss=1.3097, val_acc=33.33%
2025-02-01 17:46:11,922 - INFO - ####################Training epoch 85####################
2025-02-01 17:46:12,341 - INFO - Epoch 85: train_loss=1.4321
2025-02-01 17:46:12,942 - INFO - Epoch 85: val_loss=1.3169, val_acc=33.33%
2025-02-01 17:46:12,946 - INFO - ####################Training epoch 86####################
2025-02-01 17:46:13,361 - INFO - Epoch 86: train_loss=1.4382
2025-02-01 17:46:13,960 - INFO - Epoch 86: val_loss=1.3295, val_acc=33.33%
2025-02-01 17:46:13,964 - INFO - ####################Training epoch 87####################
2025-02-01 17:46:14,379 - INFO - Epoch 87: train_loss=1.4441
2025-02-01 17:46:14,976 - INFO - Epoch 87: val_loss=1.3162, val_acc=33.33%
2025-02-01 17:46:14,980 - INFO - ####################Training epoch 88####################
2025-02-01 17:46:15,398 - INFO - Epoch 88: train_loss=1.4440
2025-02-01 17:46:15,999 - INFO - Epoch 88: val_loss=1.3216, val_acc=33.33%
2025-02-01 17:46:16,003 - INFO - ####################Training epoch 89####################
2025-02-01 17:46:16,420 - INFO - Epoch 89: train_loss=1.4486
2025-02-01 17:46:17,022 - INFO - Epoch 89: val_loss=1.3367, val_acc=33.33%
2025-02-01 17:46:17,026 - INFO - ####################Training epoch 90####################
2025-02-01 17:46:17,442 - INFO - Epoch 90: train_loss=1.4414
2025-02-01 17:46:18,041 - INFO - Epoch 90: val_loss=1.3285, val_acc=33.33%
2025-02-01 17:46:18,045 - INFO - ####################Training epoch 91####################
2025-02-01 17:46:18,464 - INFO - Epoch 91: train_loss=1.4304
2025-02-01 17:46:19,066 - INFO - Epoch 91: val_loss=1.3280, val_acc=33.33%
2025-02-01 17:46:19,070 - INFO - ####################Training epoch 92####################
2025-02-01 17:46:19,487 - INFO - Epoch 92: train_loss=1.4350
2025-02-01 17:46:20,093 - INFO - Epoch 92: val_loss=1.3221, val_acc=33.33%
2025-02-01 17:46:20,096 - INFO - ####################Training epoch 93####################
2025-02-01 17:46:20,516 - INFO - Epoch 93: train_loss=1.4326
2025-02-01 17:46:21,115 - INFO - Epoch 93: val_loss=1.3290, val_acc=33.33%
2025-02-01 17:46:21,118 - INFO - ####################Training epoch 94####################
2025-02-01 17:46:21,535 - INFO - Epoch 94: train_loss=1.4566
2025-02-01 17:46:22,136 - INFO - Epoch 94: val_loss=1.3320, val_acc=33.33%
2025-02-01 17:46:22,140 - INFO - ####################Training epoch 95####################
2025-02-01 17:46:22,559 - INFO - Epoch 95: train_loss=1.4379
2025-02-01 17:46:23,159 - INFO - Epoch 95: val_loss=1.3130, val_acc=33.33%
2025-02-01 17:46:23,163 - INFO - ####################Training epoch 96####################
2025-02-01 17:46:23,578 - INFO - Epoch 96: train_loss=1.4250
2025-02-01 17:46:24,178 - INFO - Epoch 96: val_loss=1.3202, val_acc=33.33%
2025-02-01 17:46:24,182 - INFO - ####################Training epoch 97####################
2025-02-01 17:46:24,602 - INFO - Epoch 97: train_loss=1.4249
2025-02-01 17:46:25,204 - INFO - Epoch 97: val_loss=1.3288, val_acc=33.33%
2025-02-01 17:46:25,208 - INFO - ####################Training epoch 98####################
2025-02-01 17:46:25,623 - INFO - Epoch 98: train_loss=1.4311
2025-02-01 17:46:26,224 - INFO - Epoch 98: val_loss=1.3378, val_acc=33.33%
2025-02-01 17:46:26,227 - INFO - ####################Training epoch 99####################
2025-02-01 17:46:26,642 - INFO - Epoch 99: train_loss=1.4295
2025-02-01 17:46:27,244 - INFO - Epoch 99: val_loss=1.3026, val_acc=33.33%
2025-02-01 17:46:27,248 - INFO - ####################Training epoch 100####################
2025-02-01 17:46:27,668 - INFO - Epoch 100: train_loss=1.4280
2025-02-01 17:46:28,266 - INFO - Epoch 100: val_loss=1.3239, val_acc=33.33%
2025-02-01 17:46:28,270 - INFO - ####################Training epoch 101####################
2025-02-01 17:46:28,686 - INFO - Epoch 101: train_loss=1.4405
2025-02-01 17:46:29,286 - INFO - Epoch 101: val_loss=1.3112, val_acc=33.33%
2025-02-01 17:46:29,289 - INFO - ####################Training epoch 102####################
2025-02-01 17:46:29,704 - INFO - Epoch 102: train_loss=1.4435
2025-02-01 17:46:30,306 - INFO - Epoch 102: val_loss=1.3112, val_acc=33.33%
2025-02-01 17:46:30,310 - INFO - ####################Training epoch 103####################
2025-02-01 17:46:30,725 - INFO - Epoch 103: train_loss=1.4385
2025-02-01 17:46:31,322 - INFO - Epoch 103: val_loss=1.3157, val_acc=33.33%
2025-02-01 17:46:31,326 - INFO - ####################Training epoch 104####################
2025-02-01 17:46:31,742 - INFO - Epoch 104: train_loss=1.4349
2025-02-01 17:46:32,345 - INFO - Epoch 104: val_loss=1.3378, val_acc=33.33%
2025-02-01 17:46:32,349 - INFO - ####################Training epoch 105####################
2025-02-01 17:46:32,765 - INFO - Epoch 105: train_loss=1.4420
2025-02-01 17:46:33,367 - INFO - Epoch 105: val_loss=1.3032, val_acc=33.33%
2025-02-01 17:46:33,371 - INFO - ####################Training epoch 106####################
2025-02-01 17:46:33,788 - INFO - Epoch 106: train_loss=1.4358
2025-02-01 17:46:34,390 - INFO - Epoch 106: val_loss=1.3388, val_acc=33.33%
2025-02-01 17:46:34,394 - INFO - ####################Training epoch 107####################
2025-02-01 17:46:34,810 - INFO - Epoch 107: train_loss=1.4384
2025-02-01 17:46:35,411 - INFO - Epoch 107: val_loss=1.3270, val_acc=33.33%
2025-02-01 17:46:35,415 - INFO - ####################Training epoch 108####################
2025-02-01 17:46:35,835 - INFO - Epoch 108: train_loss=1.4230
2025-02-01 17:46:36,432 - INFO - Epoch 108: val_loss=1.3273, val_acc=33.33%
2025-02-01 17:46:36,436 - INFO - ####################Training epoch 109####################
2025-02-01 17:46:36,855 - INFO - Epoch 109: train_loss=1.4454
2025-02-01 17:46:37,455 - INFO - Epoch 109: val_loss=1.3048, val_acc=33.33%
2025-02-01 17:46:37,459 - INFO - ####################Training epoch 110####################
2025-02-01 17:46:37,875 - INFO - Epoch 110: train_loss=1.4346
2025-02-01 17:46:38,478 - INFO - Epoch 110: val_loss=1.3282, val_acc=33.33%
2025-02-01 17:46:38,482 - INFO - ####################Training epoch 111####################
2025-02-01 17:46:38,899 - INFO - Epoch 111: train_loss=1.4443
2025-02-01 17:46:39,498 - INFO - Epoch 111: val_loss=1.3202, val_acc=33.33%
2025-02-01 17:46:39,502 - INFO - ####################Training epoch 112####################
2025-02-01 17:46:39,921 - INFO - Epoch 112: train_loss=1.4323
2025-02-01 17:46:40,520 - INFO - Epoch 112: val_loss=1.3274, val_acc=33.33%
2025-02-01 17:46:40,524 - INFO - ####################Training epoch 113####################
2025-02-01 17:46:40,941 - INFO - Epoch 113: train_loss=1.4384
2025-02-01 17:46:41,542 - INFO - Epoch 113: val_loss=1.3323, val_acc=33.33%
2025-02-01 17:46:41,545 - INFO - ####################Training epoch 114####################
2025-02-01 17:46:41,962 - INFO - Epoch 114: train_loss=1.4242
2025-02-01 17:46:42,562 - INFO - Epoch 114: val_loss=1.3186, val_acc=33.33%
2025-02-01 17:46:42,566 - INFO - ####################Training epoch 115####################
2025-02-01 17:46:42,983 - INFO - Epoch 115: train_loss=1.4295
2025-02-01 17:46:43,582 - INFO - Epoch 115: val_loss=1.3306, val_acc=33.33%
2025-02-01 17:46:43,586 - INFO - ####################Training epoch 116####################
2025-02-01 17:46:44,002 - INFO - Epoch 116: train_loss=1.4335
2025-02-01 17:46:44,603 - INFO - Epoch 116: val_loss=1.3320, val_acc=33.33%
2025-02-01 17:46:44,607 - INFO - ####################Training epoch 117####################
2025-02-01 17:46:45,020 - INFO - Epoch 117: train_loss=1.4398
2025-02-01 17:46:45,617 - INFO - Epoch 117: val_loss=1.3202, val_acc=33.33%
2025-02-01 17:46:45,621 - INFO - ####################Training epoch 118####################
2025-02-01 17:46:46,040 - INFO - Epoch 118: train_loss=1.4299
2025-02-01 17:46:46,638 - INFO - Epoch 118: val_loss=1.3214, val_acc=33.33%
2025-02-01 17:46:46,642 - INFO - ####################Training epoch 119####################
2025-02-01 17:46:47,060 - INFO - Epoch 119: train_loss=1.4420
2025-02-01 17:46:47,658 - INFO - Epoch 119: val_loss=1.3086, val_acc=33.33%
2025-02-01 17:46:47,662 - INFO - ####################Training epoch 120####################
2025-02-01 17:46:48,079 - INFO - Epoch 120: train_loss=1.4356
2025-02-01 17:46:48,677 - INFO - Epoch 120: val_loss=1.3327, val_acc=33.33%
2025-02-01 17:46:48,681 - INFO - ####################Training epoch 121####################
2025-02-01 17:46:49,097 - INFO - Epoch 121: train_loss=1.4309
2025-02-01 17:46:49,694 - INFO - Epoch 121: val_loss=1.3165, val_acc=33.33%
2025-02-01 17:46:49,697 - INFO - ####################Training epoch 122####################
2025-02-01 17:46:50,115 - INFO - Epoch 122: train_loss=1.4261
2025-02-01 17:46:50,718 - INFO - Epoch 122: val_loss=1.3170, val_acc=33.33%
2025-02-01 17:46:50,721 - INFO - ####################Training epoch 123####################
2025-02-01 17:46:51,139 - INFO - Epoch 123: train_loss=1.4371
2025-02-01 17:46:51,736 - INFO - Epoch 123: val_loss=1.3295, val_acc=33.33%
2025-02-01 17:46:51,740 - INFO - ####################Training epoch 124####################
2025-02-01 17:46:52,157 - INFO - Epoch 124: train_loss=1.4426
2025-02-01 17:46:52,756 - INFO - Epoch 124: val_loss=1.3252, val_acc=33.33%
2025-02-01 17:46:52,760 - INFO - ####################Training epoch 125####################
2025-02-01 17:46:53,177 - INFO - Epoch 125: train_loss=1.4229
2025-02-01 17:46:53,777 - INFO - Epoch 125: val_loss=1.3516, val_acc=33.33%
2025-02-01 17:46:53,781 - INFO - ####################Training epoch 126####################
2025-02-01 17:46:54,197 - INFO - Epoch 126: train_loss=1.4356
2025-02-01 17:46:54,796 - INFO - Epoch 126: val_loss=1.3162, val_acc=33.33%
2025-02-01 17:46:54,800 - INFO - ####################Training epoch 127####################
2025-02-01 17:46:55,216 - INFO - Epoch 127: train_loss=1.4324
2025-02-01 17:46:55,819 - INFO - Epoch 127: val_loss=1.3287, val_acc=33.33%
2025-02-01 17:46:55,822 - INFO - ####################Training epoch 128####################
2025-02-01 17:46:56,238 - INFO - Epoch 128: train_loss=1.4423
2025-02-01 17:46:56,836 - INFO - Epoch 128: val_loss=1.3232, val_acc=33.33%
2025-02-01 17:46:56,840 - INFO - ####################Training epoch 129####################
2025-02-01 17:46:57,256 - INFO - Epoch 129: train_loss=1.4351
2025-02-01 17:46:57,858 - INFO - Epoch 129: val_loss=1.3426, val_acc=33.33%
2025-02-01 17:46:57,862 - INFO - ####################Training epoch 130####################
2025-02-01 17:46:58,278 - INFO - Epoch 130: train_loss=1.4404
2025-02-01 17:46:58,880 - INFO - Epoch 130: val_loss=1.3237, val_acc=33.33%
2025-02-01 17:46:58,883 - INFO - ####################Training epoch 131####################
2025-02-01 17:46:59,298 - INFO - Epoch 131: train_loss=1.4308
2025-02-01 17:46:59,899 - INFO - Epoch 131: val_loss=1.3104, val_acc=33.33%
2025-02-01 17:46:59,903 - INFO - ####################Training epoch 132####################
2025-02-01 17:47:00,317 - INFO - Epoch 132: train_loss=1.4480
2025-02-01 17:47:00,919 - INFO - Epoch 132: val_loss=1.3244, val_acc=33.33%
2025-02-01 17:47:00,922 - INFO - ####################Training epoch 133####################
2025-02-01 17:47:01,341 - INFO - Epoch 133: train_loss=1.4344
2025-02-01 17:47:01,941 - INFO - Epoch 133: val_loss=1.3054, val_acc=33.33%
2025-02-01 17:47:01,945 - INFO - ####################Training epoch 134####################
2025-02-01 17:47:02,364 - INFO - Epoch 134: train_loss=1.4260
2025-02-01 17:47:02,964 - INFO - Epoch 134: val_loss=1.3262, val_acc=33.33%
2025-02-01 17:47:02,968 - INFO - ####################Training epoch 135####################
2025-02-01 17:47:03,383 - INFO - Epoch 135: train_loss=1.4293
2025-02-01 17:47:03,980 - INFO - Epoch 135: val_loss=1.3280, val_acc=33.33%
2025-02-01 17:47:03,984 - INFO - ####################Training epoch 136####################
2025-02-01 17:47:04,395 - INFO - Epoch 136: train_loss=1.4443
2025-02-01 17:47:04,999 - INFO - Epoch 136: val_loss=1.3168, val_acc=33.33%
2025-02-01 17:47:05,002 - INFO - ####################Training epoch 137####################
2025-02-01 17:47:05,418 - INFO - Epoch 137: train_loss=1.4429
2025-02-01 17:47:06,020 - INFO - Epoch 137: val_loss=1.3390, val_acc=33.33%
2025-02-01 17:47:06,024 - INFO - ####################Training epoch 138####################
2025-02-01 17:47:06,436 - INFO - Epoch 138: train_loss=1.4250
2025-02-01 17:47:07,037 - INFO - Epoch 138: val_loss=1.2901, val_acc=33.33%
2025-02-01 17:47:07,040 - INFO - ####################Training epoch 139####################
2025-02-01 17:47:07,457 - INFO - Epoch 139: train_loss=1.4371
2025-02-01 17:47:08,058 - INFO - Epoch 139: val_loss=1.2893, val_acc=33.33%
2025-02-01 17:47:08,062 - INFO - ####################Training epoch 140####################
2025-02-01 17:47:08,478 - INFO - Epoch 140: train_loss=1.4329
2025-02-01 17:47:09,081 - INFO - Epoch 140: val_loss=1.3322, val_acc=33.33%
2025-02-01 17:47:09,084 - INFO - ####################Training epoch 141####################
2025-02-01 17:47:09,500 - INFO - Epoch 141: train_loss=1.4328
2025-02-01 17:47:10,095 - INFO - Epoch 141: val_loss=1.3290, val_acc=33.33%
2025-02-01 17:47:10,099 - INFO - ####################Training epoch 142####################
2025-02-01 17:47:10,516 - INFO - Epoch 142: train_loss=1.4468
2025-02-01 17:47:11,116 - INFO - Epoch 142: val_loss=1.3308, val_acc=33.33%
2025-02-01 17:47:11,120 - INFO - ####################Training epoch 143####################
2025-02-01 17:47:11,537 - INFO - Epoch 143: train_loss=1.4479
2025-02-01 17:47:12,137 - INFO - Epoch 143: val_loss=1.3195, val_acc=33.33%
2025-02-01 17:47:12,141 - INFO - ####################Training epoch 144####################
2025-02-01 17:47:12,554 - INFO - Epoch 144: train_loss=1.4392
2025-02-01 17:47:13,150 - INFO - Epoch 144: val_loss=1.3317, val_acc=33.33%
2025-02-01 17:47:13,154 - INFO - ####################Training epoch 145####################
2025-02-01 17:47:13,571 - INFO - Epoch 145: train_loss=1.4515
2025-02-01 17:47:14,172 - INFO - Epoch 145: val_loss=1.3266, val_acc=33.33%
2025-02-01 17:47:14,176 - INFO - ####################Training epoch 146####################
2025-02-01 17:47:14,592 - INFO - Epoch 146: train_loss=1.4223
2025-02-01 17:47:15,197 - INFO - Epoch 146: val_loss=1.3295, val_acc=33.33%
2025-02-01 17:47:15,202 - INFO - ####################Training epoch 147####################
2025-02-01 17:47:15,616 - INFO - Epoch 147: train_loss=1.4208
2025-02-01 17:47:16,217 - INFO - Epoch 147: val_loss=1.3228, val_acc=33.33%
2025-02-01 17:47:16,221 - INFO - ####################Training epoch 148####################
2025-02-01 17:47:16,640 - INFO - Epoch 148: train_loss=1.4370
2025-02-01 17:47:17,243 - INFO - Epoch 148: val_loss=1.3125, val_acc=33.33%
2025-02-01 17:47:17,247 - INFO - ####################Training epoch 149####################
2025-02-01 17:47:17,663 - INFO - Epoch 149: train_loss=1.4424
2025-02-01 17:47:18,255 - INFO - Epoch 149: val_loss=1.2543, val_acc=33.33%
2025-02-01 17:47:18,258 - INFO - ####################Training epoch 150####################
2025-02-01 17:47:18,677 - INFO - Epoch 150: train_loss=1.4404
2025-02-01 17:47:19,275 - INFO - Epoch 150: val_loss=1.2382, val_acc=33.33%
2025-02-01 17:47:19,279 - INFO - ####################Training epoch 151####################
2025-02-01 17:47:19,693 - INFO - Epoch 151: train_loss=1.4229
2025-02-01 17:47:20,288 - INFO - Epoch 151: val_loss=1.3347, val_acc=33.33%
2025-02-01 17:47:20,292 - INFO - ####################Training epoch 152####################
2025-02-01 17:47:20,705 - INFO - Epoch 152: train_loss=1.4323
2025-02-01 17:47:21,307 - INFO - Epoch 152: val_loss=1.3385, val_acc=33.33%
2025-02-01 17:47:21,310 - INFO - ####################Training epoch 153####################
2025-02-01 17:47:21,726 - INFO - Epoch 153: train_loss=1.4332
2025-02-01 17:47:22,323 - INFO - Epoch 153: val_loss=1.3306, val_acc=33.33%
2025-02-01 17:47:22,327 - INFO - ####################Training epoch 154####################
2025-02-01 17:47:22,747 - INFO - Epoch 154: train_loss=1.4393
2025-02-01 17:47:23,347 - INFO - Epoch 154: val_loss=1.3219, val_acc=33.33%
2025-02-01 17:47:23,351 - INFO - ####################Training epoch 155####################
2025-02-01 17:47:23,760 - INFO - Epoch 155: train_loss=1.4461
2025-02-01 17:47:24,361 - INFO - Epoch 155: val_loss=1.2658, val_acc=33.33%
2025-02-01 17:47:24,365 - INFO - ####################Training epoch 156####################
2025-02-01 17:47:24,784 - INFO - Epoch 156: train_loss=1.4348
2025-02-01 17:47:25,375 - INFO - Epoch 156: val_loss=1.3135, val_acc=33.33%
2025-02-01 17:47:25,379 - INFO - ####################Training epoch 157####################
2025-02-01 17:47:25,794 - INFO - Epoch 157: train_loss=1.4327
2025-02-01 17:47:26,393 - INFO - Epoch 157: val_loss=1.3190, val_acc=33.33%
2025-02-01 17:47:26,397 - INFO - ####################Training epoch 158####################
2025-02-01 17:47:26,810 - INFO - Epoch 158: train_loss=1.4367
2025-02-01 17:47:27,411 - INFO - Epoch 158: val_loss=1.3286, val_acc=33.33%
2025-02-01 17:47:27,415 - INFO - ####################Training epoch 159####################
2025-02-01 17:47:27,832 - INFO - Epoch 159: train_loss=1.4390
2025-02-01 17:47:28,434 - INFO - Epoch 159: val_loss=1.3283, val_acc=33.33%
2025-02-01 17:47:28,437 - INFO - ####################Training epoch 160####################
2025-02-01 17:47:28,858 - INFO - Epoch 160: train_loss=1.4316
2025-02-01 17:47:29,457 - INFO - Epoch 160: val_loss=1.3002, val_acc=33.33%
2025-02-01 17:47:29,461 - INFO - ####################Training epoch 161####################
2025-02-01 17:47:29,881 - INFO - Epoch 161: train_loss=1.4463
2025-02-01 17:47:30,477 - INFO - Epoch 161: val_loss=1.3222, val_acc=33.33%
2025-02-01 17:47:30,481 - INFO - ####################Training epoch 162####################
2025-02-01 17:47:30,898 - INFO - Epoch 162: train_loss=1.4414
2025-02-01 17:47:31,499 - INFO - Epoch 162: val_loss=1.3273, val_acc=33.33%
2025-02-01 17:47:31,503 - INFO - ####################Training epoch 163####################
2025-02-01 17:47:31,923 - INFO - Epoch 163: train_loss=1.4387
2025-02-01 17:47:32,521 - INFO - Epoch 163: val_loss=1.3195, val_acc=33.33%
2025-02-01 17:47:32,524 - INFO - ####################Training epoch 164####################
2025-02-01 17:47:32,941 - INFO - Epoch 164: train_loss=1.4474
2025-02-01 17:47:33,544 - INFO - Epoch 164: val_loss=1.3283, val_acc=33.33%
2025-02-01 17:47:33,548 - INFO - ####################Training epoch 165####################
2025-02-01 17:47:33,964 - INFO - Epoch 165: train_loss=1.4514
2025-02-01 17:47:34,567 - INFO - Epoch 165: val_loss=1.2819, val_acc=33.33%
2025-02-01 17:47:34,571 - INFO - ####################Training epoch 166####################
2025-02-01 17:47:34,985 - INFO - Epoch 166: train_loss=1.4295
2025-02-01 17:47:35,583 - INFO - Epoch 166: val_loss=1.3210, val_acc=33.33%
2025-02-01 17:47:35,587 - INFO - ####################Training epoch 167####################
2025-02-01 17:47:36,005 - INFO - Epoch 167: train_loss=1.4392
2025-02-01 17:47:36,601 - INFO - Epoch 167: val_loss=1.3296, val_acc=33.33%
2025-02-01 17:47:36,605 - INFO - ####################Training epoch 168####################
2025-02-01 17:47:37,021 - INFO - Epoch 168: train_loss=1.4315
2025-02-01 17:47:37,617 - INFO - Epoch 168: val_loss=1.3220, val_acc=33.33%
2025-02-01 17:47:37,624 - INFO - ####################Training epoch 169####################
2025-02-01 17:47:38,044 - INFO - Epoch 169: train_loss=1.4198
2025-02-01 17:47:38,644 - INFO - Epoch 169: val_loss=1.3127, val_acc=33.33%
2025-02-01 17:47:38,648 - INFO - ####################Training epoch 170####################
2025-02-01 17:47:39,066 - INFO - Epoch 170: train_loss=1.4385
2025-02-01 17:47:39,665 - INFO - Epoch 170: val_loss=1.3345, val_acc=33.33%
2025-02-01 17:47:39,669 - INFO - ####################Training epoch 171####################
2025-02-01 17:47:40,082 - INFO - Epoch 171: train_loss=1.4457
2025-02-01 17:47:40,682 - INFO - Epoch 171: val_loss=1.3256, val_acc=33.33%
2025-02-01 17:47:40,686 - INFO - ####################Training epoch 172####################
2025-02-01 17:47:41,105 - INFO - Epoch 172: train_loss=1.4241
2025-02-01 17:47:41,707 - INFO - Epoch 172: val_loss=1.3387, val_acc=33.33%
2025-02-01 17:47:41,711 - INFO - ####################Training epoch 173####################
2025-02-01 17:47:42,122 - INFO - Epoch 173: train_loss=1.4390
2025-02-01 17:47:42,721 - INFO - Epoch 173: val_loss=1.2849, val_acc=33.33%
2025-02-01 17:47:42,725 - INFO - ####################Training epoch 174####################
2025-02-01 17:47:43,141 - INFO - Epoch 174: train_loss=1.4397
2025-02-01 17:47:43,741 - INFO - Epoch 174: val_loss=1.3253, val_acc=33.33%
2025-02-01 17:47:43,744 - INFO - ####################Training epoch 175####################
2025-02-01 17:47:44,161 - INFO - Epoch 175: train_loss=1.4540
2025-02-01 17:47:44,764 - INFO - Epoch 175: val_loss=1.3112, val_acc=33.33%
2025-02-01 17:47:44,767 - INFO - ####################Training epoch 176####################
2025-02-01 17:47:45,183 - INFO - Epoch 176: train_loss=1.4324
2025-02-01 17:47:45,776 - INFO - Epoch 176: val_loss=1.3037, val_acc=33.33%
2025-02-01 17:47:45,780 - INFO - ####################Training epoch 177####################
2025-02-01 17:47:46,191 - INFO - Epoch 177: train_loss=1.4400
2025-02-01 17:47:46,790 - INFO - Epoch 177: val_loss=1.3320, val_acc=33.33%
2025-02-01 17:47:46,794 - INFO - ####################Training epoch 178####################
2025-02-01 17:47:47,208 - INFO - Epoch 178: train_loss=1.4404
2025-02-01 17:47:47,809 - INFO - Epoch 178: val_loss=1.3301, val_acc=33.33%
2025-02-01 17:47:47,812 - INFO - ####################Training epoch 179####################
2025-02-01 17:47:48,225 - INFO - Epoch 179: train_loss=1.4207
2025-02-01 17:47:48,824 - INFO - Epoch 179: val_loss=1.3143, val_acc=33.33%
2025-02-01 17:47:48,827 - INFO - ####################Training epoch 180####################
2025-02-01 17:47:49,247 - INFO - Epoch 180: train_loss=1.4253
2025-02-01 17:47:49,845 - INFO - Epoch 180: val_loss=1.3220, val_acc=33.33%
2025-02-01 17:47:49,849 - INFO - ####################Training epoch 181####################
2025-02-01 17:47:50,267 - INFO - Epoch 181: train_loss=1.4441
2025-02-01 17:47:50,870 - INFO - Epoch 181: val_loss=1.3365, val_acc=33.33%
2025-02-01 17:47:50,874 - INFO - ####################Training epoch 182####################
2025-02-01 17:47:51,290 - INFO - Epoch 182: train_loss=1.4249
2025-02-01 17:47:51,891 - INFO - Epoch 182: val_loss=1.3151, val_acc=33.33%
2025-02-01 17:47:51,895 - INFO - ####################Training epoch 183####################
2025-02-01 17:47:52,315 - INFO - Epoch 183: train_loss=1.4368
2025-02-01 17:47:52,915 - INFO - Epoch 183: val_loss=1.3239, val_acc=33.33%
2025-02-01 17:47:52,918 - INFO - ####################Training epoch 184####################
2025-02-01 17:47:53,330 - INFO - Epoch 184: train_loss=1.4339
2025-02-01 17:47:53,928 - INFO - Epoch 184: val_loss=1.3079, val_acc=33.33%
2025-02-01 17:47:53,932 - INFO - ####################Training epoch 185####################
2025-02-01 17:47:54,344 - INFO - Epoch 185: train_loss=1.4287
2025-02-01 17:47:54,941 - INFO - Epoch 185: val_loss=1.3228, val_acc=33.33%
2025-02-01 17:47:54,945 - INFO - ####################Training epoch 186####################
2025-02-01 17:47:55,359 - INFO - Epoch 186: train_loss=1.4388
2025-02-01 17:47:55,955 - INFO - Epoch 186: val_loss=1.3249, val_acc=33.33%
2025-02-01 17:47:55,959 - INFO - ####################Training epoch 187####################
2025-02-01 17:47:56,373 - INFO - Epoch 187: train_loss=1.4295
2025-02-01 17:47:56,972 - INFO - Epoch 187: val_loss=1.3150, val_acc=33.33%
2025-02-01 17:47:56,976 - INFO - ####################Training epoch 188####################
2025-02-01 17:47:57,390 - INFO - Epoch 188: train_loss=1.4519
2025-02-01 17:47:57,984 - INFO - Epoch 188: val_loss=1.3306, val_acc=33.33%
2025-02-01 17:47:57,988 - INFO - ####################Training epoch 189####################
2025-02-01 17:47:58,405 - INFO - Epoch 189: train_loss=1.4426
2025-02-01 17:47:59,002 - INFO - Epoch 189: val_loss=1.3305, val_acc=33.33%
2025-02-01 17:47:59,006 - INFO - ####################Training epoch 190####################
2025-02-01 17:47:59,423 - INFO - Epoch 190: train_loss=1.4338
2025-02-01 17:48:00,022 - INFO - Epoch 190: val_loss=1.3277, val_acc=33.33%
2025-02-01 17:48:00,026 - INFO - ####################Training epoch 191####################
2025-02-01 17:48:00,437 - INFO - Epoch 191: train_loss=1.4448
2025-02-01 17:48:01,035 - INFO - Epoch 191: val_loss=1.3254, val_acc=33.33%
2025-02-01 17:48:01,038 - INFO - ####################Training epoch 192####################
2025-02-01 17:48:01,453 - INFO - Epoch 192: train_loss=1.4436
2025-02-01 17:48:02,050 - INFO - Epoch 192: val_loss=1.2977, val_acc=33.33%
2025-02-01 17:48:02,053 - INFO - ####################Training epoch 193####################
2025-02-01 17:48:02,468 - INFO - Epoch 193: train_loss=1.4325
2025-02-01 17:48:03,068 - INFO - Epoch 193: val_loss=1.3344, val_acc=33.33%
2025-02-01 17:48:03,072 - INFO - ####################Training epoch 194####################
2025-02-01 17:48:03,488 - INFO - Epoch 194: train_loss=1.4353
2025-02-01 17:48:04,084 - INFO - Epoch 194: val_loss=1.3275, val_acc=33.33%
2025-02-01 17:48:04,087 - INFO - ####################Training epoch 195####################
2025-02-01 17:48:04,500 - INFO - Epoch 195: train_loss=1.4347
2025-02-01 17:48:05,098 - INFO - Epoch 195: val_loss=1.3380, val_acc=33.33%
2025-02-01 17:48:05,102 - INFO - ####################Training epoch 196####################
2025-02-01 17:48:05,519 - INFO - Epoch 196: train_loss=1.4398
2025-02-01 17:48:06,118 - INFO - Epoch 196: val_loss=1.3267, val_acc=33.33%
2025-02-01 17:48:06,122 - INFO - ####################Training epoch 197####################
2025-02-01 17:48:06,537 - INFO - Epoch 197: train_loss=1.4351
2025-02-01 17:48:07,140 - INFO - Epoch 197: val_loss=1.2976, val_acc=33.33%
2025-02-01 17:48:07,144 - INFO - ####################Training epoch 198####################
2025-02-01 17:48:07,563 - INFO - Epoch 198: train_loss=1.4208
2025-02-01 17:48:08,158 - INFO - Epoch 198: val_loss=1.3426, val_acc=33.33%
2025-02-01 17:48:08,161 - INFO - ####################Training epoch 199####################
2025-02-01 17:48:08,576 - INFO - Epoch 199: train_loss=1.4495
2025-02-01 17:48:09,175 - INFO - Epoch 199: val_loss=1.3158, val_acc=33.33%
2025-02-01 17:48:09,178 - INFO - ####################Training epoch 200####################
2025-02-01 17:48:09,592 - INFO - Epoch 200: train_loss=1.4346
2025-02-01 17:48:10,192 - INFO - Epoch 200: val_loss=1.3314, val_acc=33.33%
2025-02-01 17:48:10,195 - INFO - ####################Training epoch 201####################
2025-02-01 17:48:10,613 - INFO - Epoch 201: train_loss=1.4172
2025-02-01 17:48:11,210 - INFO - Epoch 201: val_loss=1.3262, val_acc=33.33%
2025-02-01 17:48:11,214 - INFO - ####################Training epoch 202####################
2025-02-01 17:48:11,628 - INFO - Epoch 202: train_loss=1.4367
2025-02-01 17:48:12,226 - INFO - Epoch 202: val_loss=1.3173, val_acc=33.33%
2025-02-01 17:48:12,230 - INFO - ####################Training epoch 203####################
2025-02-01 17:48:12,647 - INFO - Epoch 203: train_loss=1.4359
2025-02-01 17:48:13,247 - INFO - Epoch 203: val_loss=1.3206, val_acc=33.33%
2025-02-01 17:48:13,254 - INFO - ####################Training epoch 204####################
2025-02-01 17:48:13,672 - INFO - Epoch 204: train_loss=1.4357
2025-02-01 17:48:14,269 - INFO - Epoch 204: val_loss=1.3254, val_acc=33.33%
2025-02-01 17:48:14,273 - INFO - ####################Training epoch 205####################
2025-02-01 17:48:14,689 - INFO - Epoch 205: train_loss=1.4302
2025-02-01 17:48:15,287 - INFO - Epoch 205: val_loss=1.3251, val_acc=33.33%
2025-02-01 17:48:15,290 - INFO - ####################Training epoch 206####################
2025-02-01 17:48:15,704 - INFO - Epoch 206: train_loss=1.4218
2025-02-01 17:48:16,302 - INFO - Epoch 206: val_loss=1.2817, val_acc=33.33%
2025-02-01 17:48:16,306 - INFO - ####################Training epoch 207####################
2025-02-01 17:48:16,722 - INFO - Epoch 207: train_loss=1.4389
2025-02-01 17:48:17,318 - INFO - Epoch 207: val_loss=1.2998, val_acc=33.33%
2025-02-01 17:48:17,322 - INFO - ####################Training epoch 208####################
2025-02-01 17:48:17,737 - INFO - Epoch 208: train_loss=1.4305
2025-02-01 17:48:18,334 - INFO - Epoch 208: val_loss=1.3297, val_acc=33.33%
2025-02-01 17:48:18,338 - INFO - ####################Training epoch 209####################
2025-02-01 17:48:18,755 - INFO - Epoch 209: train_loss=1.4319
2025-02-01 17:48:19,353 - INFO - Epoch 209: val_loss=1.3272, val_acc=33.33%
2025-02-01 17:48:19,357 - INFO - ####################Training epoch 210####################
2025-02-01 17:48:19,774 - INFO - Epoch 210: train_loss=1.4267
2025-02-01 17:48:20,375 - INFO - Epoch 210: val_loss=1.3180, val_acc=33.33%
2025-02-01 17:48:20,378 - INFO - ####################Training epoch 211####################
2025-02-01 17:48:20,795 - INFO - Epoch 211: train_loss=1.4409
2025-02-01 17:48:21,394 - INFO - Epoch 211: val_loss=1.3339, val_acc=33.33%
2025-02-01 17:48:21,398 - INFO - ####################Training epoch 212####################
2025-02-01 17:48:21,813 - INFO - Epoch 212: train_loss=1.4403
2025-02-01 17:48:22,413 - INFO - Epoch 212: val_loss=1.3199, val_acc=33.33%
2025-02-01 17:48:22,417 - INFO - ####################Training epoch 213####################
2025-02-01 17:48:22,832 - INFO - Epoch 213: train_loss=1.4280
2025-02-01 17:48:23,428 - INFO - Epoch 213: val_loss=1.3302, val_acc=33.33%
2025-02-01 17:48:23,431 - INFO - ####################Training epoch 214####################
2025-02-01 17:48:23,845 - INFO - Epoch 214: train_loss=1.4398
2025-02-01 17:48:24,443 - INFO - Epoch 214: val_loss=1.3045, val_acc=33.33%
2025-02-01 17:48:24,447 - INFO - ####################Training epoch 215####################
2025-02-01 17:48:24,863 - INFO - Epoch 215: train_loss=1.4448
2025-02-01 17:48:25,464 - INFO - Epoch 215: val_loss=1.3267, val_acc=33.33%
2025-02-01 17:48:25,468 - INFO - ####################Training epoch 216####################
2025-02-01 17:48:25,889 - INFO - Epoch 216: train_loss=1.4325
2025-02-01 17:48:26,488 - INFO - Epoch 216: val_loss=1.2882, val_acc=33.33%
2025-02-01 17:48:26,491 - INFO - ####################Training epoch 217####################
2025-02-01 17:48:26,910 - INFO - Epoch 217: train_loss=1.4473
2025-02-01 17:48:27,507 - INFO - Epoch 217: val_loss=1.3169, val_acc=33.33%
2025-02-01 17:48:27,511 - INFO - ####################Training epoch 218####################
2025-02-01 17:48:27,926 - INFO - Epoch 218: train_loss=1.4388
2025-02-01 17:48:28,525 - INFO - Epoch 218: val_loss=1.3225, val_acc=33.33%
2025-02-01 17:48:28,529 - INFO - ####################Training epoch 219####################
2025-02-01 17:48:28,947 - INFO - Epoch 219: train_loss=1.4444
2025-02-01 17:48:29,543 - INFO - Epoch 219: val_loss=1.3229, val_acc=33.33%
2025-02-01 17:48:29,546 - INFO - ####################Training epoch 220####################
2025-02-01 17:48:29,961 - INFO - Epoch 220: train_loss=1.4365
2025-02-01 17:48:30,561 - INFO - Epoch 220: val_loss=1.3153, val_acc=33.33%
2025-02-01 17:48:30,565 - INFO - ####################Training epoch 221####################
2025-02-01 17:48:30,982 - INFO - Epoch 221: train_loss=1.4338
2025-02-01 17:48:31,580 - INFO - Epoch 221: val_loss=1.3142, val_acc=33.33%
2025-02-01 17:48:31,584 - INFO - ####################Training epoch 222####################
2025-02-01 17:48:32,002 - INFO - Epoch 222: train_loss=1.4298
2025-02-01 17:48:32,599 - INFO - Epoch 222: val_loss=1.3174, val_acc=33.33%
2025-02-01 17:48:32,603 - INFO - ####################Training epoch 223####################
2025-02-01 17:48:33,018 - INFO - Epoch 223: train_loss=1.4533
2025-02-01 17:48:33,613 - INFO - Epoch 223: val_loss=1.3336, val_acc=33.33%
2025-02-01 17:48:33,617 - INFO - ####################Training epoch 224####################
2025-02-01 17:48:34,031 - INFO - Epoch 224: train_loss=1.4370
2025-02-01 17:48:34,629 - INFO - Epoch 224: val_loss=1.3286, val_acc=33.33%
2025-02-01 17:48:34,632 - INFO - ####################Training epoch 225####################
2025-02-01 17:48:35,048 - INFO - Epoch 225: train_loss=1.4456
2025-02-01 17:48:35,646 - INFO - Epoch 225: val_loss=1.3162, val_acc=33.33%
2025-02-01 17:48:35,649 - INFO - ####################Training epoch 226####################
2025-02-01 17:48:36,066 - INFO - Epoch 226: train_loss=1.4297
2025-02-01 17:48:36,666 - INFO - Epoch 226: val_loss=1.3226, val_acc=33.33%
2025-02-01 17:48:36,669 - INFO - ####################Training epoch 227####################
2025-02-01 17:48:37,085 - INFO - Epoch 227: train_loss=1.4430
2025-02-01 17:48:37,683 - INFO - Epoch 227: val_loss=1.3157, val_acc=33.33%
2025-02-01 17:48:37,687 - INFO - ####################Training epoch 228####################
2025-02-01 17:48:38,103 - INFO - Epoch 228: train_loss=1.4362
2025-02-01 17:48:38,693 - INFO - Epoch 228: val_loss=1.2968, val_acc=33.33%
2025-02-01 17:48:38,697 - INFO - ####################Training epoch 229####################
2025-02-01 17:48:39,110 - INFO - Epoch 229: train_loss=1.4347
2025-02-01 17:48:39,705 - INFO - Epoch 229: val_loss=1.3263, val_acc=33.33%
2025-02-01 17:48:39,709 - INFO - ####################Training epoch 230####################
2025-02-01 17:48:40,124 - INFO - Epoch 230: train_loss=1.4336
2025-02-01 17:48:40,721 - INFO - Epoch 230: val_loss=1.3219, val_acc=33.33%
2025-02-01 17:48:40,725 - INFO - ####################Training epoch 231####################
2025-02-01 17:48:41,143 - INFO - Epoch 231: train_loss=1.4439
2025-02-01 17:48:41,740 - INFO - Epoch 231: val_loss=1.3300, val_acc=33.33%
2025-02-01 17:48:41,744 - INFO - ####################Training epoch 232####################
2025-02-01 17:48:42,159 - INFO - Epoch 232: train_loss=1.4446
2025-02-01 17:48:42,755 - INFO - Epoch 232: val_loss=1.3331, val_acc=33.33%
2025-02-01 17:48:42,759 - INFO - ####################Training epoch 233####################
2025-02-01 17:48:43,176 - INFO - Epoch 233: train_loss=1.4348
2025-02-01 17:48:43,774 - INFO - Epoch 233: val_loss=1.3286, val_acc=33.33%
2025-02-01 17:48:43,778 - INFO - ####################Training epoch 234####################
2025-02-01 17:48:44,196 - INFO - Epoch 234: train_loss=1.4418
2025-02-01 17:48:44,795 - INFO - Epoch 234: val_loss=1.3211, val_acc=33.33%
2025-02-01 17:48:44,799 - INFO - ####################Training epoch 235####################
2025-02-01 17:48:45,216 - INFO - Epoch 235: train_loss=1.4416
2025-02-01 17:48:45,816 - INFO - Epoch 235: val_loss=1.3409, val_acc=33.33%
2025-02-01 17:48:45,819 - INFO - ####################Training epoch 236####################
2025-02-01 17:48:46,236 - INFO - Epoch 236: train_loss=1.4327
2025-02-01 17:48:46,834 - INFO - Epoch 236: val_loss=1.3333, val_acc=33.33%
2025-02-01 17:48:46,837 - INFO - ####################Training epoch 237####################
2025-02-01 17:48:47,252 - INFO - Epoch 237: train_loss=1.4431
2025-02-01 17:48:47,849 - INFO - Epoch 237: val_loss=1.3218, val_acc=33.33%
2025-02-01 17:48:47,853 - INFO - ####################Training epoch 238####################
2025-02-01 17:48:48,268 - INFO - Epoch 238: train_loss=1.4333
2025-02-01 17:48:48,869 - INFO - Epoch 238: val_loss=1.3312, val_acc=33.33%
2025-02-01 17:48:48,872 - INFO - ####################Training epoch 239####################
2025-02-01 17:48:49,294 - INFO - Epoch 239: train_loss=1.4405
2025-02-01 17:48:49,889 - INFO - Epoch 239: val_loss=1.3395, val_acc=33.33%
2025-02-01 17:48:49,893 - INFO - ####################Training epoch 240####################
2025-02-01 17:48:50,312 - INFO - Epoch 240: train_loss=1.4339
2025-02-01 17:48:50,911 - INFO - Epoch 240: val_loss=1.3086, val_acc=33.33%
2025-02-01 17:48:50,915 - INFO - ####################Training epoch 241####################
2025-02-01 17:48:51,329 - INFO - Epoch 241: train_loss=1.4362
2025-02-01 17:48:51,929 - INFO - Epoch 241: val_loss=1.3228, val_acc=33.33%
2025-02-01 17:48:51,932 - INFO - ####################Training epoch 242####################
2025-02-01 17:48:52,349 - INFO - Epoch 242: train_loss=1.4367
2025-02-01 17:48:52,953 - INFO - Epoch 242: val_loss=1.3221, val_acc=33.33%
2025-02-01 17:48:52,957 - INFO - ####################Training epoch 243####################
2025-02-01 17:48:53,372 - INFO - Epoch 243: train_loss=1.4395
2025-02-01 17:48:53,971 - INFO - Epoch 243: val_loss=1.3045, val_acc=33.33%
2025-02-01 17:48:53,975 - INFO - ####################Training epoch 244####################
2025-02-01 17:48:54,394 - INFO - Epoch 244: train_loss=1.4362
2025-02-01 17:48:54,991 - INFO - Epoch 244: val_loss=1.3062, val_acc=33.33%
2025-02-01 17:48:54,995 - INFO - ####################Training epoch 245####################
2025-02-01 17:48:55,409 - INFO - Epoch 245: train_loss=1.4510
2025-02-01 17:48:56,011 - INFO - Epoch 245: val_loss=1.3253, val_acc=33.33%
2025-02-01 17:48:56,015 - INFO - ####################Training epoch 246####################
2025-02-01 17:48:56,433 - INFO - Epoch 246: train_loss=1.4369
2025-02-01 17:48:57,026 - INFO - Epoch 246: val_loss=1.3107, val_acc=33.33%
2025-02-01 17:48:57,029 - INFO - ####################Training epoch 247####################
2025-02-01 17:48:57,444 - INFO - Epoch 247: train_loss=1.4434
2025-02-01 17:48:58,041 - INFO - Epoch 247: val_loss=1.3333, val_acc=33.33%
2025-02-01 17:48:58,045 - INFO - ####################Training epoch 248####################
2025-02-01 17:48:58,462 - INFO - Epoch 248: train_loss=1.4375
2025-02-01 17:48:59,065 - INFO - Epoch 248: val_loss=1.2973, val_acc=33.33%
2025-02-01 17:48:59,069 - INFO - ####################Training epoch 249####################
2025-02-01 17:48:59,485 - INFO - Epoch 249: train_loss=1.4452
2025-02-01 17:49:00,082 - INFO - Epoch 249: val_loss=1.3191, val_acc=33.33%
2025-02-01 17:49:00,086 - INFO - ####################Training epoch 250####################
2025-02-01 17:49:00,499 - INFO - Epoch 250: train_loss=1.4375
2025-02-01 17:49:01,098 - INFO - Epoch 250: val_loss=1.3306, val_acc=33.33%
2025-02-01 17:49:01,102 - INFO - ####################Training epoch 251####################
2025-02-01 17:49:01,520 - INFO - Epoch 251: train_loss=1.4288
2025-02-01 17:49:02,115 - INFO - Epoch 251: val_loss=1.3251, val_acc=33.33%
2025-02-01 17:49:02,119 - INFO - ####################Training epoch 252####################
2025-02-01 17:49:02,536 - INFO - Epoch 252: train_loss=1.4270
2025-02-01 17:49:03,136 - INFO - Epoch 252: val_loss=1.3048, val_acc=33.33%
2025-02-01 17:49:03,140 - INFO - ####################Training epoch 253####################
2025-02-01 17:49:03,555 - INFO - Epoch 253: train_loss=1.4356
2025-02-01 17:49:04,150 - INFO - Epoch 253: val_loss=1.3304, val_acc=33.33%
2025-02-01 17:49:04,154 - INFO - ####################Training epoch 254####################
2025-02-01 17:49:04,568 - INFO - Epoch 254: train_loss=1.4406
2025-02-01 17:49:05,163 - INFO - Epoch 254: val_loss=1.3099, val_acc=33.33%
2025-02-01 17:49:05,167 - INFO - ####################Training epoch 255####################
2025-02-01 17:49:05,584 - INFO - Epoch 255: train_loss=1.4338
2025-02-01 17:49:06,181 - INFO - Epoch 255: val_loss=1.3260, val_acc=33.33%
2025-02-01 17:49:06,185 - INFO - ####################Training epoch 256####################
2025-02-01 17:49:06,599 - INFO - Epoch 256: train_loss=1.4416
2025-02-01 17:49:07,195 - INFO - Epoch 256: val_loss=1.3310, val_acc=33.33%
2025-02-01 17:49:07,199 - INFO - ####################Training epoch 257####################
2025-02-01 17:49:07,616 - INFO - Epoch 257: train_loss=1.4391
2025-02-01 17:49:08,215 - INFO - Epoch 257: val_loss=1.3099, val_acc=33.33%
2025-02-01 17:49:08,219 - INFO - ####################Training epoch 258####################
2025-02-01 17:49:08,636 - INFO - Epoch 258: train_loss=1.4428
2025-02-01 17:49:09,231 - INFO - Epoch 258: val_loss=1.3285, val_acc=33.33%
2025-02-01 17:49:09,235 - INFO - ####################Training epoch 259####################
2025-02-01 17:49:09,649 - INFO - Epoch 259: train_loss=1.4247
2025-02-01 17:49:10,243 - INFO - Epoch 259: val_loss=1.3155, val_acc=33.33%
2025-02-01 17:49:10,247 - INFO - ####################Training epoch 260####################
2025-02-01 17:49:10,661 - INFO - Epoch 260: train_loss=1.4242
2025-02-01 17:49:11,261 - INFO - Epoch 260: val_loss=1.3238, val_acc=33.33%
2025-02-01 17:49:11,264 - INFO - ####################Training epoch 261####################
2025-02-01 17:49:11,682 - INFO - Epoch 261: train_loss=1.4193
2025-02-01 17:49:12,279 - INFO - Epoch 261: val_loss=1.3364, val_acc=33.33%
2025-02-01 17:49:12,283 - INFO - ####################Training epoch 262####################
2025-02-01 17:49:12,700 - INFO - Epoch 262: train_loss=1.4342
2025-02-01 17:49:13,298 - INFO - Epoch 262: val_loss=1.3184, val_acc=33.33%
2025-02-01 17:49:13,301 - INFO - ####################Training epoch 263####################
2025-02-01 17:49:13,715 - INFO - Epoch 263: train_loss=1.4347
2025-02-01 17:49:14,312 - INFO - Epoch 263: val_loss=1.3201, val_acc=33.33%
2025-02-01 17:49:14,316 - INFO - ####################Training epoch 264####################
2025-02-01 17:49:14,731 - INFO - Epoch 264: train_loss=1.4457
2025-02-01 17:49:15,331 - INFO - Epoch 264: val_loss=1.2882, val_acc=33.33%
2025-02-01 17:49:15,335 - INFO - ####################Training epoch 265####################
2025-02-01 17:49:15,754 - INFO - Epoch 265: train_loss=1.4336
2025-02-01 17:49:16,357 - INFO - Epoch 265: val_loss=1.3164, val_acc=33.33%
2025-02-01 17:49:16,360 - INFO - ####################Training epoch 266####################
2025-02-01 17:49:16,776 - INFO - Epoch 266: train_loss=1.4525
2025-02-01 17:49:17,380 - INFO - Epoch 266: val_loss=1.3427, val_acc=33.33%
2025-02-01 17:49:17,383 - INFO - ####################Training epoch 267####################
2025-02-01 17:49:17,802 - INFO - Epoch 267: train_loss=1.4286
2025-02-01 17:49:18,400 - INFO - Epoch 267: val_loss=1.3273, val_acc=33.33%
2025-02-01 17:49:18,404 - INFO - ####################Training epoch 268####################
2025-02-01 17:49:18,820 - INFO - Epoch 268: train_loss=1.4415
2025-02-01 17:49:19,418 - INFO - Epoch 268: val_loss=1.3264, val_acc=33.33%
2025-02-01 17:49:19,422 - INFO - ####################Training epoch 269####################
2025-02-01 17:49:19,838 - INFO - Epoch 269: train_loss=1.4320
2025-02-01 17:49:20,439 - INFO - Epoch 269: val_loss=1.3195, val_acc=33.33%
2025-02-01 17:49:20,443 - INFO - ####################Training epoch 270####################
2025-02-01 17:49:20,859 - INFO - Epoch 270: train_loss=1.4427
2025-02-01 17:49:21,459 - INFO - Epoch 270: val_loss=1.3518, val_acc=33.33%
2025-02-01 17:49:21,463 - INFO - ####################Training epoch 271####################
2025-02-01 17:49:21,882 - INFO - Epoch 271: train_loss=1.4362
2025-02-01 17:49:22,481 - INFO - Epoch 271: val_loss=1.2974, val_acc=33.33%
2025-02-01 17:49:22,485 - INFO - ####################Training epoch 272####################
2025-02-01 17:49:22,899 - INFO - Epoch 272: train_loss=1.4306
2025-02-01 17:49:23,501 - INFO - Epoch 272: val_loss=1.3103, val_acc=33.33%
2025-02-01 17:49:23,504 - INFO - ####################Training epoch 273####################
2025-02-01 17:49:23,933 - INFO - Epoch 273: train_loss=1.4296
2025-02-01 17:49:24,535 - INFO - Epoch 273: val_loss=1.3148, val_acc=33.33%
2025-02-01 17:49:24,539 - INFO - ####################Training epoch 274####################
2025-02-01 17:49:24,956 - INFO - Epoch 274: train_loss=1.4383
2025-02-01 17:49:25,557 - INFO - Epoch 274: val_loss=1.2983, val_acc=33.33%
2025-02-01 17:49:25,560 - INFO - ####################Training epoch 275####################
2025-02-01 17:49:25,975 - INFO - Epoch 275: train_loss=1.4300
2025-02-01 17:49:26,575 - INFO - Epoch 275: val_loss=1.3318, val_acc=33.33%
2025-02-01 17:49:26,579 - INFO - ####################Training epoch 276####################
2025-02-01 17:49:26,999 - INFO - Epoch 276: train_loss=1.4476
2025-02-01 17:49:27,598 - INFO - Epoch 276: val_loss=1.3329, val_acc=33.33%
2025-02-01 17:49:27,602 - INFO - ####################Training epoch 277####################
2025-02-01 17:49:28,023 - INFO - Epoch 277: train_loss=1.4368
2025-02-01 17:49:28,624 - INFO - Epoch 277: val_loss=1.3369, val_acc=33.33%
2025-02-01 17:49:28,627 - INFO - ####################Training epoch 278####################
2025-02-01 17:49:29,043 - INFO - Epoch 278: train_loss=1.4405
2025-02-01 17:49:29,649 - INFO - Epoch 278: val_loss=1.3333, val_acc=33.33%
2025-02-01 17:49:29,653 - INFO - ####################Training epoch 279####################
2025-02-01 17:49:30,074 - INFO - Epoch 279: train_loss=1.4432
2025-02-01 17:49:30,675 - INFO - Epoch 279: val_loss=1.3242, val_acc=33.33%
2025-02-01 17:49:30,679 - INFO - ####################Training epoch 280####################
2025-02-01 17:49:31,097 - INFO - Epoch 280: train_loss=1.4407
2025-02-01 17:49:31,699 - INFO - Epoch 280: val_loss=1.3190, val_acc=33.33%
2025-02-01 17:49:31,703 - INFO - ####################Training epoch 281####################
2025-02-01 17:49:32,116 - INFO - Epoch 281: train_loss=1.4251
2025-02-01 17:49:32,717 - INFO - Epoch 281: val_loss=1.3341, val_acc=33.33%
2025-02-01 17:49:32,721 - INFO - ####################Training epoch 282####################
2025-02-01 17:49:33,136 - INFO - Epoch 282: train_loss=1.4376
2025-02-01 17:49:33,737 - INFO - Epoch 282: val_loss=1.3217, val_acc=33.33%
2025-02-01 17:49:33,741 - INFO - ####################Training epoch 283####################
2025-02-01 17:49:34,160 - INFO - Epoch 283: train_loss=1.4294
2025-02-01 17:49:34,760 - INFO - Epoch 283: val_loss=1.3218, val_acc=33.33%
2025-02-01 17:49:34,764 - INFO - ####################Training epoch 284####################
2025-02-01 17:49:35,179 - INFO - Epoch 284: train_loss=1.4284
2025-02-01 17:49:35,780 - INFO - Epoch 284: val_loss=1.3254, val_acc=33.33%
2025-02-01 17:49:35,784 - INFO - ####################Training epoch 285####################
2025-02-01 17:49:36,200 - INFO - Epoch 285: train_loss=1.4488
2025-02-01 17:49:36,798 - INFO - Epoch 285: val_loss=1.3251, val_acc=33.33%
2025-02-01 17:49:36,802 - INFO - ####################Training epoch 286####################
2025-02-01 17:49:37,226 - INFO - Epoch 286: train_loss=1.4453
2025-02-01 17:49:37,824 - INFO - Epoch 286: val_loss=1.3291, val_acc=33.33%
2025-02-01 17:49:37,828 - INFO - ####################Training epoch 287####################
2025-02-01 17:49:38,247 - INFO - Epoch 287: train_loss=1.4456
2025-02-01 17:49:38,851 - INFO - Epoch 287: val_loss=1.3308, val_acc=33.33%
2025-02-01 17:49:38,855 - INFO - ####################Training epoch 288####################
2025-02-01 17:49:39,275 - INFO - Epoch 288: train_loss=1.4471
2025-02-01 17:49:39,872 - INFO - Epoch 288: val_loss=1.3257, val_acc=33.33%
2025-02-01 17:49:39,875 - INFO - ####################Training epoch 289####################
2025-02-01 17:49:40,295 - INFO - Epoch 289: train_loss=1.4476
2025-02-01 17:49:40,897 - INFO - Epoch 289: val_loss=1.3306, val_acc=33.33%
2025-02-01 17:49:40,900 - INFO - ####################Training epoch 290####################
2025-02-01 17:49:41,320 - INFO - Epoch 290: train_loss=1.4445
2025-02-01 17:49:41,920 - INFO - Epoch 290: val_loss=1.3287, val_acc=33.33%
2025-02-01 17:49:41,924 - INFO - ####################Training epoch 291####################
2025-02-01 17:49:42,340 - INFO - Epoch 291: train_loss=1.4428
2025-02-01 17:49:42,940 - INFO - Epoch 291: val_loss=1.2793, val_acc=33.33%
2025-02-01 17:49:42,944 - INFO - ####################Training epoch 292####################
2025-02-01 17:49:43,364 - INFO - Epoch 292: train_loss=1.4438
2025-02-01 17:49:43,962 - INFO - Epoch 292: val_loss=1.3238, val_acc=33.33%
2025-02-01 17:49:43,966 - INFO - ####################Training epoch 293####################
2025-02-01 17:49:44,381 - INFO - Epoch 293: train_loss=1.4499
2025-02-01 17:49:44,984 - INFO - Epoch 293: val_loss=1.3243, val_acc=33.33%
2025-02-01 17:49:44,988 - INFO - ####################Training epoch 294####################
2025-02-01 17:49:45,407 - INFO - Epoch 294: train_loss=1.4363
2025-02-01 17:49:46,006 - INFO - Epoch 294: val_loss=1.3243, val_acc=33.33%
2025-02-01 17:49:46,010 - INFO - ####################Training epoch 295####################
2025-02-01 17:49:46,432 - INFO - Epoch 295: train_loss=1.4375
2025-02-01 17:49:47,031 - INFO - Epoch 295: val_loss=1.3386, val_acc=33.33%
2025-02-01 17:49:47,035 - INFO - ####################Training epoch 296####################
2025-02-01 17:49:47,456 - INFO - Epoch 296: train_loss=1.4362
2025-02-01 17:49:48,057 - INFO - Epoch 296: val_loss=1.3231, val_acc=33.33%
2025-02-01 17:49:48,061 - INFO - ####################Training epoch 297####################
2025-02-01 17:49:48,480 - INFO - Epoch 297: train_loss=1.4453
2025-02-01 17:49:49,078 - INFO - Epoch 297: val_loss=1.3264, val_acc=33.33%
2025-02-01 17:49:49,082 - INFO - ####################Training epoch 298####################
2025-02-01 17:49:49,501 - INFO - Epoch 298: train_loss=1.4240
2025-02-01 17:49:50,098 - INFO - Epoch 298: val_loss=1.2962, val_acc=33.33%
2025-02-01 17:49:50,102 - INFO - ####################Training epoch 299####################
2025-02-01 17:49:50,522 - INFO - Epoch 299: train_loss=1.4302
2025-02-01 17:49:51,119 - INFO - Epoch 299: val_loss=1.3127, val_acc=33.33%
2025-02-01 17:49:51,293 - INFO - Model saved.
