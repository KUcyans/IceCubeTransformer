2025-02-01 15:51:16,882 - INFO - Starting training with the following parameters:
2025-02-01 15:51:16,882 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product |
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.001          |
| epochs          | 100            |

2025-02-01 15:51:17,465 - INFO - Epoch 0: val_loss=0.9795, val_acc=66.67%
2025-02-01 15:51:17,596 - INFO - ####################Training epoch 0####################
2025-02-01 15:51:17,740 - INFO - Epoch 0: train_loss=1.1282
2025-02-01 15:51:18,266 - INFO - Epoch 0: val_loss=2.8002, val_acc=0.00%
2025-02-01 15:51:18,294 - INFO - ####################Training epoch 1####################
2025-02-01 15:51:18,575 - INFO - Epoch 1: train_loss=1.8106
2025-02-01 15:51:19,045 - INFO - Epoch 1: val_loss=1.9032, val_acc=33.33%
2025-02-01 15:51:19,072 - INFO - ####################Training epoch 2####################
2025-02-01 15:51:19,355 - INFO - Epoch 2: train_loss=1.1109
2025-02-01 15:51:19,825 - INFO - Epoch 2: val_loss=1.6861, val_acc=33.33%
2025-02-01 15:51:19,852 - INFO - ####################Training epoch 3####################
2025-02-01 15:51:20,134 - INFO - Epoch 3: train_loss=1.1095
2025-02-01 15:51:20,605 - INFO - Epoch 3: val_loss=1.7984, val_acc=33.33%
2025-02-01 15:51:20,609 - INFO - ####################Training epoch 4####################
2025-02-01 15:51:20,893 - INFO - Epoch 4: train_loss=1.2737
2025-02-01 15:51:21,365 - INFO - Epoch 4: val_loss=1.8492, val_acc=33.33%
2025-02-01 15:51:21,368 - INFO - ####################Training epoch 5####################
2025-02-01 15:51:21,654 - INFO - Epoch 5: train_loss=1.1490
2025-02-01 15:51:22,123 - INFO - Epoch 5: val_loss=1.9796, val_acc=33.33%
2025-02-01 15:51:22,127 - INFO - ####################Training epoch 6####################
2025-02-01 15:51:22,413 - INFO - Epoch 6: train_loss=0.9873
2025-02-01 15:51:22,883 - INFO - Epoch 6: val_loss=2.2420, val_acc=33.33%
2025-02-01 15:51:22,886 - INFO - ####################Training epoch 7####################
2025-02-01 15:51:23,170 - INFO - Epoch 7: train_loss=0.9179
2025-02-01 15:51:23,639 - INFO - Epoch 7: val_loss=2.5072, val_acc=0.00%
2025-02-01 15:51:23,706 - INFO - ####################Training epoch 8####################
2025-02-01 15:51:23,992 - INFO - Epoch 8: train_loss=0.9522
2025-02-01 15:51:24,460 - INFO - Epoch 8: val_loss=2.6165, val_acc=33.33%
2025-02-01 15:51:24,464 - INFO - ####################Training epoch 9####################
2025-02-01 15:51:24,750 - INFO - Epoch 9: train_loss=0.9030
2025-02-01 15:51:25,221 - INFO - Epoch 9: val_loss=2.6498, val_acc=33.33%
2025-02-01 15:51:25,225 - INFO - ####################Training epoch 10####################
2025-02-01 15:51:25,513 - INFO - Epoch 10: train_loss=0.8629
2025-02-01 15:51:25,985 - INFO - Epoch 10: val_loss=2.6931, val_acc=33.33%
2025-02-01 15:51:25,989 - INFO - ####################Training epoch 11####################
2025-02-01 15:51:26,277 - INFO - Epoch 11: train_loss=0.8285
2025-02-01 15:51:26,749 - INFO - Epoch 11: val_loss=2.6988, val_acc=33.33%
2025-02-01 15:51:26,753 - INFO - ####################Training epoch 12####################
2025-02-01 15:51:27,042 - INFO - Epoch 12: train_loss=0.7920
2025-02-01 15:51:27,515 - INFO - Epoch 12: val_loss=2.7396, val_acc=33.33%
2025-02-01 15:51:27,519 - INFO - ####################Training epoch 13####################
2025-02-01 15:51:27,806 - INFO - Epoch 13: train_loss=0.7638
2025-02-01 15:51:28,277 - INFO - Epoch 13: val_loss=2.8042, val_acc=33.33%
2025-02-01 15:51:28,281 - INFO - ####################Training epoch 14####################
2025-02-01 15:51:28,568 - INFO - Epoch 14: train_loss=0.7286
2025-02-01 15:51:29,038 - INFO - Epoch 14: val_loss=2.9901, val_acc=33.33%
2025-02-01 15:51:29,042 - INFO - ####################Training epoch 15####################
2025-02-01 15:51:29,329 - INFO - Epoch 15: train_loss=0.7173
2025-02-01 15:51:29,798 - INFO - Epoch 15: val_loss=3.0691, val_acc=33.33%
2025-02-01 15:51:29,801 - INFO - ####################Training epoch 16####################
2025-02-01 15:51:30,087 - INFO - Epoch 16: train_loss=0.7069
2025-02-01 15:51:30,557 - INFO - Epoch 16: val_loss=3.0869, val_acc=33.33%
2025-02-01 15:51:30,560 - INFO - ####################Training epoch 17####################
2025-02-01 15:51:30,847 - INFO - Epoch 17: train_loss=0.6900
2025-02-01 15:51:31,316 - INFO - Epoch 17: val_loss=3.1167, val_acc=33.33%
2025-02-01 15:51:31,320 - INFO - ####################Training epoch 18####################
2025-02-01 15:51:31,606 - INFO - Epoch 18: train_loss=0.6854
2025-02-01 15:51:32,078 - INFO - Epoch 18: val_loss=3.2191, val_acc=33.33%
2025-02-01 15:51:32,082 - INFO - ####################Training epoch 19####################
2025-02-01 15:51:32,367 - INFO - Epoch 19: train_loss=0.6754
2025-02-01 15:51:32,837 - INFO - Epoch 19: val_loss=3.3247, val_acc=33.33%
2025-02-01 15:51:32,841 - INFO - ####################Training epoch 20####################
2025-02-01 15:51:33,129 - INFO - Epoch 20: train_loss=0.6705
2025-02-01 15:51:33,595 - INFO - Epoch 20: val_loss=3.4585, val_acc=33.33%
2025-02-01 15:51:33,598 - INFO - ####################Training epoch 21####################
2025-02-01 15:51:33,886 - INFO - Epoch 21: train_loss=0.6682
2025-02-01 15:51:34,357 - INFO - Epoch 21: val_loss=3.4912, val_acc=33.33%
2025-02-01 15:51:34,360 - INFO - ####################Training epoch 22####################
2025-02-01 15:51:34,646 - INFO - Epoch 22: train_loss=0.6685
2025-02-01 15:51:35,116 - INFO - Epoch 22: val_loss=3.4823, val_acc=33.33%
2025-02-01 15:51:35,119 - INFO - ####################Training epoch 23####################
2025-02-01 15:51:35,406 - INFO - Epoch 23: train_loss=0.6665
2025-02-01 15:51:35,878 - INFO - Epoch 23: val_loss=3.4995, val_acc=33.33%
2025-02-01 15:51:35,882 - INFO - ####################Training epoch 24####################
2025-02-01 15:51:36,168 - INFO - Epoch 24: train_loss=0.6567
2025-02-01 15:51:36,637 - INFO - Epoch 24: val_loss=3.5016, val_acc=33.33%
2025-02-01 15:51:36,641 - INFO - ####################Training epoch 25####################
2025-02-01 15:51:36,923 - INFO - Epoch 25: train_loss=0.6591
2025-02-01 15:51:37,392 - INFO - Epoch 25: val_loss=3.4896, val_acc=33.33%
2025-02-01 15:51:37,396 - INFO - ####################Training epoch 26####################
2025-02-01 15:51:37,680 - INFO - Epoch 26: train_loss=0.6569
2025-02-01 15:51:38,145 - INFO - Epoch 26: val_loss=3.5095, val_acc=33.33%
2025-02-01 15:51:38,149 - INFO - ####################Training epoch 27####################
2025-02-01 15:51:38,432 - INFO - Epoch 27: train_loss=0.6522
2025-02-01 15:51:38,902 - INFO - Epoch 27: val_loss=3.5301, val_acc=33.33%
2025-02-01 15:51:38,906 - INFO - ####################Training epoch 28####################
2025-02-01 15:51:39,193 - INFO - Epoch 28: train_loss=0.6490
2025-02-01 15:51:39,663 - INFO - Epoch 28: val_loss=3.5525, val_acc=33.33%
2025-02-01 15:51:39,667 - INFO - ####################Training epoch 29####################
2025-02-01 15:51:39,951 - INFO - Epoch 29: train_loss=0.6433
2025-02-01 15:51:40,421 - INFO - Epoch 29: val_loss=3.5655, val_acc=33.33%
2025-02-01 15:51:40,425 - INFO - ####################Training epoch 30####################
2025-02-01 15:51:40,710 - INFO - Epoch 30: train_loss=0.6429
2025-02-01 15:51:41,179 - INFO - Epoch 30: val_loss=3.6137, val_acc=33.33%
2025-02-01 15:51:41,183 - INFO - ####################Training epoch 31####################
2025-02-01 15:51:41,469 - INFO - Epoch 31: train_loss=0.6418
2025-02-01 15:51:41,939 - INFO - Epoch 31: val_loss=3.6201, val_acc=33.33%
2025-02-01 15:51:41,943 - INFO - ####################Training epoch 32####################
2025-02-01 15:51:42,227 - INFO - Epoch 32: train_loss=0.6386
2025-02-01 15:51:42,696 - INFO - Epoch 32: val_loss=3.5977, val_acc=33.33%
2025-02-01 15:51:42,702 - INFO - ####################Training epoch 33####################
2025-02-01 15:51:42,987 - INFO - Epoch 33: train_loss=0.6374
2025-02-01 15:51:43,456 - INFO - Epoch 33: val_loss=3.6075, val_acc=33.33%
2025-02-01 15:51:43,460 - INFO - ####################Training epoch 34####################
2025-02-01 15:51:43,746 - INFO - Epoch 34: train_loss=0.6372
2025-02-01 15:51:44,212 - INFO - Epoch 34: val_loss=3.5904, val_acc=33.33%
2025-02-01 15:51:44,216 - INFO - ####################Training epoch 35####################
2025-02-01 15:51:44,500 - INFO - Epoch 35: train_loss=0.6327
2025-02-01 15:51:44,969 - INFO - Epoch 35: val_loss=3.5723, val_acc=33.33%
2025-02-01 15:51:44,973 - INFO - ####################Training epoch 36####################
2025-02-01 15:51:45,258 - INFO - Epoch 36: train_loss=0.6336
2025-02-01 15:51:45,726 - INFO - Epoch 36: val_loss=3.5570, val_acc=33.33%
2025-02-01 15:51:45,730 - INFO - ####################Training epoch 37####################
2025-02-01 15:51:46,013 - INFO - Epoch 37: train_loss=0.6325
2025-02-01 15:51:46,480 - INFO - Epoch 37: val_loss=3.5527, val_acc=33.33%
2025-02-01 15:51:46,484 - INFO - ####################Training epoch 38####################
2025-02-01 15:51:46,769 - INFO - Epoch 38: train_loss=0.6339
2025-02-01 15:51:47,238 - INFO - Epoch 38: val_loss=3.5533, val_acc=33.33%
2025-02-01 15:51:47,242 - INFO - ####################Training epoch 39####################
2025-02-01 15:51:47,527 - INFO - Epoch 39: train_loss=0.6308
2025-02-01 15:51:47,992 - INFO - Epoch 39: val_loss=3.5663, val_acc=33.33%
2025-02-01 15:51:47,995 - INFO - ####################Training epoch 40####################
2025-02-01 15:51:48,281 - INFO - Epoch 40: train_loss=0.6299
2025-02-01 15:51:48,750 - INFO - Epoch 40: val_loss=3.5809, val_acc=33.33%
2025-02-01 15:51:48,754 - INFO - ####################Training epoch 41####################
2025-02-01 15:51:49,037 - INFO - Epoch 41: train_loss=0.6294
2025-02-01 15:51:49,510 - INFO - Epoch 41: val_loss=3.5706, val_acc=33.33%
2025-02-01 15:51:49,513 - INFO - ####################Training epoch 42####################
2025-02-01 15:51:49,799 - INFO - Epoch 42: train_loss=0.6279
2025-02-01 15:51:50,268 - INFO - Epoch 42: val_loss=3.5590, val_acc=33.33%
2025-02-01 15:51:50,272 - INFO - ####################Training epoch 43####################
2025-02-01 15:51:50,556 - INFO - Epoch 43: train_loss=0.6270
2025-02-01 15:51:51,140 - INFO - Epoch 43: val_loss=3.5792, val_acc=33.33%
2025-02-01 15:51:51,143 - INFO - ####################Training epoch 44####################
2025-02-01 15:51:51,427 - INFO - Epoch 44: train_loss=0.6274
2025-02-01 15:51:51,900 - INFO - Epoch 44: val_loss=3.5809, val_acc=33.33%
2025-02-01 15:51:51,904 - INFO - ####################Training epoch 45####################
2025-02-01 15:51:52,189 - INFO - Epoch 45: train_loss=0.6231
2025-02-01 15:51:52,659 - INFO - Epoch 45: val_loss=3.5608, val_acc=33.33%
2025-02-01 15:51:52,663 - INFO - ####################Training epoch 46####################
2025-02-01 15:51:52,950 - INFO - Epoch 46: train_loss=0.6282
2025-02-01 15:51:53,414 - INFO - Epoch 46: val_loss=3.5793, val_acc=33.33%
2025-02-01 15:51:53,418 - INFO - ####################Training epoch 47####################
2025-02-01 15:51:53,702 - INFO - Epoch 47: train_loss=0.6257
2025-02-01 15:51:54,169 - INFO - Epoch 47: val_loss=3.6044, val_acc=33.33%
2025-02-01 15:51:54,173 - INFO - ####################Training epoch 48####################
2025-02-01 15:51:54,458 - INFO - Epoch 48: train_loss=0.6275
2025-02-01 15:51:54,923 - INFO - Epoch 48: val_loss=3.5863, val_acc=33.33%
2025-02-01 15:51:54,927 - INFO - ####################Training epoch 49####################
2025-02-01 15:51:55,214 - INFO - Epoch 49: train_loss=0.6265
2025-02-01 15:51:55,684 - INFO - Epoch 49: val_loss=3.5978, val_acc=33.33%
2025-02-01 15:51:55,688 - INFO - ####################Training epoch 50####################
2025-02-01 15:51:55,972 - INFO - Epoch 50: train_loss=0.6253
2025-02-01 15:51:56,444 - INFO - Epoch 50: val_loss=3.6002, val_acc=33.33%
2025-02-01 15:51:56,447 - INFO - ####################Training epoch 51####################
2025-02-01 15:51:56,733 - INFO - Epoch 51: train_loss=0.6257
2025-02-01 15:51:57,204 - INFO - Epoch 51: val_loss=3.5881, val_acc=33.33%
2025-02-01 15:51:57,208 - INFO - ####################Training epoch 52####################
2025-02-01 15:51:57,494 - INFO - Epoch 52: train_loss=0.6252
2025-02-01 15:51:57,962 - INFO - Epoch 52: val_loss=3.6082, val_acc=33.33%
2025-02-01 15:51:57,965 - INFO - ####################Training epoch 53####################
2025-02-01 15:51:58,250 - INFO - Epoch 53: train_loss=0.6215
2025-02-01 15:51:58,718 - INFO - Epoch 53: val_loss=3.5840, val_acc=33.33%
2025-02-01 15:51:58,721 - INFO - ####################Training epoch 54####################
2025-02-01 15:51:59,006 - INFO - Epoch 54: train_loss=0.6218
2025-02-01 15:51:59,474 - INFO - Epoch 54: val_loss=3.5939, val_acc=33.33%
2025-02-01 15:51:59,478 - INFO - ####################Training epoch 55####################
2025-02-01 15:51:59,765 - INFO - Epoch 55: train_loss=0.6212
2025-02-01 15:52:00,231 - INFO - Epoch 55: val_loss=3.6072, val_acc=33.33%
2025-02-01 15:52:00,235 - INFO - ####################Training epoch 56####################
2025-02-01 15:52:00,521 - INFO - Epoch 56: train_loss=0.6253
2025-02-01 15:52:00,987 - INFO - Epoch 56: val_loss=3.5970, val_acc=33.33%
2025-02-01 15:52:00,991 - INFO - ####################Training epoch 57####################
2025-02-01 15:52:01,274 - INFO - Epoch 57: train_loss=0.6230
2025-02-01 15:52:01,744 - INFO - Epoch 57: val_loss=3.5963, val_acc=33.33%
2025-02-01 15:52:01,748 - INFO - ####################Training epoch 58####################
2025-02-01 15:52:02,028 - INFO - Epoch 58: train_loss=0.6229
2025-02-01 15:52:02,500 - INFO - Epoch 58: val_loss=3.6163, val_acc=33.33%
2025-02-01 15:52:02,504 - INFO - ####################Training epoch 59####################
2025-02-01 15:52:02,789 - INFO - Epoch 59: train_loss=0.6245
2025-02-01 15:52:03,258 - INFO - Epoch 59: val_loss=3.5865, val_acc=33.33%
2025-02-01 15:52:03,261 - INFO - ####################Training epoch 60####################
2025-02-01 15:52:03,545 - INFO - Epoch 60: train_loss=0.6234
2025-02-01 15:52:04,012 - INFO - Epoch 60: val_loss=3.5845, val_acc=33.33%
2025-02-01 15:52:04,016 - INFO - ####################Training epoch 61####################
2025-02-01 15:52:04,300 - INFO - Epoch 61: train_loss=0.6228
2025-02-01 15:52:04,769 - INFO - Epoch 61: val_loss=3.6013, val_acc=33.33%
2025-02-01 15:52:04,773 - INFO - ####################Training epoch 62####################
2025-02-01 15:52:05,057 - INFO - Epoch 62: train_loss=0.6218
2025-02-01 15:52:05,524 - INFO - Epoch 62: val_loss=3.6209, val_acc=33.33%
2025-02-01 15:52:05,528 - INFO - ####################Training epoch 63####################
2025-02-01 15:52:05,812 - INFO - Epoch 63: train_loss=0.6226
2025-02-01 15:52:06,283 - INFO - Epoch 63: val_loss=3.6094, val_acc=33.33%
2025-02-01 15:52:06,286 - INFO - ####################Training epoch 64####################
2025-02-01 15:52:06,570 - INFO - Epoch 64: train_loss=0.6235
2025-02-01 15:52:07,045 - INFO - Epoch 64: val_loss=3.5953, val_acc=33.33%
2025-02-01 15:52:07,048 - INFO - ####################Training epoch 65####################
2025-02-01 15:52:07,332 - INFO - Epoch 65: train_loss=0.6246
2025-02-01 15:52:07,802 - INFO - Epoch 65: val_loss=3.6112, val_acc=33.33%
2025-02-01 15:52:07,805 - INFO - ####################Training epoch 66####################
2025-02-01 15:52:08,090 - INFO - Epoch 66: train_loss=0.6248
2025-02-01 15:52:08,560 - INFO - Epoch 66: val_loss=3.5997, val_acc=33.33%
2025-02-01 15:52:08,564 - INFO - ####################Training epoch 67####################
2025-02-01 15:52:08,848 - INFO - Epoch 67: train_loss=0.6229
2025-02-01 15:52:09,317 - INFO - Epoch 67: val_loss=3.6028, val_acc=33.33%
2025-02-01 15:52:09,321 - INFO - ####################Training epoch 68####################
2025-02-01 15:52:09,604 - INFO - Epoch 68: train_loss=0.6204
2025-02-01 15:52:10,074 - INFO - Epoch 68: val_loss=3.6066, val_acc=33.33%
2025-02-01 15:52:10,077 - INFO - ####################Training epoch 69####################
2025-02-01 15:52:10,364 - INFO - Epoch 69: train_loss=0.6251
2025-02-01 15:52:10,833 - INFO - Epoch 69: val_loss=3.5920, val_acc=33.33%
2025-02-01 15:52:10,837 - INFO - ####################Training epoch 70####################
2025-02-01 15:52:11,123 - INFO - Epoch 70: train_loss=0.6237
2025-02-01 15:52:11,589 - INFO - Epoch 70: val_loss=3.6009, val_acc=33.33%
2025-02-01 15:52:11,593 - INFO - ####################Training epoch 71####################
2025-02-01 15:52:11,878 - INFO - Epoch 71: train_loss=0.6233
2025-02-01 15:52:12,345 - INFO - Epoch 71: val_loss=3.5968, val_acc=33.33%
2025-02-01 15:52:12,348 - INFO - ####################Training epoch 72####################
2025-02-01 15:52:12,634 - INFO - Epoch 72: train_loss=0.6231
2025-02-01 15:52:13,104 - INFO - Epoch 72: val_loss=3.6033, val_acc=33.33%
2025-02-01 15:52:13,108 - INFO - ####################Training epoch 73####################
2025-02-01 15:52:13,393 - INFO - Epoch 73: train_loss=0.6216
2025-02-01 15:52:13,863 - INFO - Epoch 73: val_loss=3.6015, val_acc=33.33%
2025-02-01 15:52:13,867 - INFO - ####################Training epoch 74####################
2025-02-01 15:52:14,151 - INFO - Epoch 74: train_loss=0.6249
2025-02-01 15:52:14,620 - INFO - Epoch 74: val_loss=3.5951, val_acc=33.33%
2025-02-01 15:52:14,623 - INFO - ####################Training epoch 75####################
2025-02-01 15:52:14,908 - INFO - Epoch 75: train_loss=0.6204
2025-02-01 15:52:15,377 - INFO - Epoch 75: val_loss=3.6090, val_acc=33.33%
2025-02-01 15:52:15,381 - INFO - ####################Training epoch 76####################
2025-02-01 15:52:15,668 - INFO - Epoch 76: train_loss=0.6230
2025-02-01 15:52:16,141 - INFO - Epoch 76: val_loss=3.6136, val_acc=33.33%
2025-02-01 15:52:16,145 - INFO - ####################Training epoch 77####################
2025-02-01 15:52:16,430 - INFO - Epoch 77: train_loss=0.6252
2025-02-01 15:52:16,898 - INFO - Epoch 77: val_loss=3.6164, val_acc=33.33%
2025-02-01 15:52:16,902 - INFO - ####################Training epoch 78####################
2025-02-01 15:52:17,190 - INFO - Epoch 78: train_loss=0.6223
2025-02-01 15:52:17,657 - INFO - Epoch 78: val_loss=3.6088, val_acc=33.33%
2025-02-01 15:52:17,661 - INFO - ####################Training epoch 79####################
2025-02-01 15:52:17,947 - INFO - Epoch 79: train_loss=0.6214
2025-02-01 15:52:18,419 - INFO - Epoch 79: val_loss=3.6087, val_acc=33.33%
2025-02-01 15:52:18,422 - INFO - ####################Training epoch 80####################
2025-02-01 15:52:18,710 - INFO - Epoch 80: train_loss=0.6228
2025-02-01 15:52:19,179 - INFO - Epoch 80: val_loss=3.6129, val_acc=33.33%
2025-02-01 15:52:19,183 - INFO - ####################Training epoch 81####################
2025-02-01 15:52:19,470 - INFO - Epoch 81: train_loss=0.6256
2025-02-01 15:52:19,938 - INFO - Epoch 81: val_loss=3.6033, val_acc=33.33%
2025-02-01 15:52:19,942 - INFO - ####################Training epoch 82####################
2025-02-01 15:52:20,229 - INFO - Epoch 82: train_loss=0.6240
2025-02-01 15:52:20,696 - INFO - Epoch 82: val_loss=3.6024, val_acc=33.33%
2025-02-01 15:52:20,700 - INFO - ####################Training epoch 83####################
2025-02-01 15:52:20,985 - INFO - Epoch 83: train_loss=0.6204
2025-02-01 15:52:21,451 - INFO - Epoch 83: val_loss=3.6124, val_acc=33.33%
2025-02-01 15:52:21,454 - INFO - ####################Training epoch 84####################
2025-02-01 15:52:21,740 - INFO - Epoch 84: train_loss=0.6215
2025-02-01 15:52:22,211 - INFO - Epoch 84: val_loss=3.6035, val_acc=33.33%
2025-02-01 15:52:22,214 - INFO - ####################Training epoch 85####################
2025-02-01 15:52:22,500 - INFO - Epoch 85: train_loss=0.6218
2025-02-01 15:52:22,966 - INFO - Epoch 85: val_loss=3.6050, val_acc=33.33%
2025-02-01 15:52:22,970 - INFO - ####################Training epoch 86####################
2025-02-01 15:52:23,256 - INFO - Epoch 86: train_loss=0.6223
2025-02-01 15:52:23,725 - INFO - Epoch 86: val_loss=3.6016, val_acc=33.33%
2025-02-01 15:52:23,729 - INFO - ####################Training epoch 87####################
2025-02-01 15:52:24,014 - INFO - Epoch 87: train_loss=0.6207
2025-02-01 15:52:24,477 - INFO - Epoch 87: val_loss=3.6051, val_acc=33.33%
2025-02-01 15:52:24,481 - INFO - ####################Training epoch 88####################
2025-02-01 15:52:24,759 - INFO - Epoch 88: train_loss=0.6206
2025-02-01 15:52:25,227 - INFO - Epoch 88: val_loss=3.5960, val_acc=33.33%
2025-02-01 15:52:25,230 - INFO - ####################Training epoch 89####################
2025-02-01 15:52:25,517 - INFO - Epoch 89: train_loss=0.6210
2025-02-01 15:52:25,985 - INFO - Epoch 89: val_loss=3.6035, val_acc=33.33%
2025-02-01 15:52:25,989 - INFO - ####################Training epoch 90####################
2025-02-01 15:52:26,276 - INFO - Epoch 90: train_loss=0.6254
2025-02-01 15:52:26,742 - INFO - Epoch 90: val_loss=3.6135, val_acc=33.33%
2025-02-01 15:52:26,746 - INFO - ####################Training epoch 91####################
2025-02-01 15:52:27,032 - INFO - Epoch 91: train_loss=0.6230
2025-02-01 15:52:27,503 - INFO - Epoch 91: val_loss=3.5932, val_acc=33.33%
2025-02-01 15:52:27,507 - INFO - ####################Training epoch 92####################
2025-02-01 15:52:27,793 - INFO - Epoch 92: train_loss=0.6216
2025-02-01 15:52:28,262 - INFO - Epoch 92: val_loss=3.5813, val_acc=33.33%
2025-02-01 15:52:28,266 - INFO - ####################Training epoch 93####################
2025-02-01 15:52:28,550 - INFO - Epoch 93: train_loss=0.6218
2025-02-01 15:52:29,018 - INFO - Epoch 93: val_loss=3.6003, val_acc=33.33%
2025-02-01 15:52:29,022 - INFO - ####################Training epoch 94####################
2025-02-01 15:52:29,309 - INFO - Epoch 94: train_loss=0.6222
2025-02-01 15:52:29,778 - INFO - Epoch 94: val_loss=3.6159, val_acc=33.33%
2025-02-01 15:52:29,782 - INFO - ####################Training epoch 95####################
2025-02-01 15:52:30,068 - INFO - Epoch 95: train_loss=0.6224
2025-02-01 15:52:30,541 - INFO - Epoch 95: val_loss=3.6072, val_acc=33.33%
2025-02-01 15:52:30,545 - INFO - ####################Training epoch 96####################
2025-02-01 15:52:30,828 - INFO - Epoch 96: train_loss=0.6231
2025-02-01 15:52:31,298 - INFO - Epoch 96: val_loss=3.6055, val_acc=33.33%
2025-02-01 15:52:31,302 - INFO - ####################Training epoch 97####################
2025-02-01 15:52:31,586 - INFO - Epoch 97: train_loss=0.6267
2025-02-01 15:52:32,058 - INFO - Epoch 97: val_loss=3.6043, val_acc=33.33%
2025-02-01 15:52:32,061 - INFO - ####################Training epoch 98####################
2025-02-01 15:52:32,347 - INFO - Epoch 98: train_loss=0.6234
2025-02-01 15:52:32,817 - INFO - Epoch 98: val_loss=3.6081, val_acc=33.33%
2025-02-01 15:52:32,821 - INFO - ####################Training epoch 99####################
2025-02-01 15:52:33,106 - INFO - Epoch 99: train_loss=0.6230
2025-02-01 15:52:33,576 - INFO - Epoch 99: val_loss=3.5957, val_acc=33.33%
2025-02-01 15:52:33,707 - INFO - Model saved.
