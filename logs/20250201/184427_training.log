2025-02-01 18:44:31,562 - INFO - Starting training with the following parameters:
2025-02-01 18:44:31,563 - INFO - | Parameter       | Value               |
|-----------------|---------------------|
| attention       | Scaled Dot-Product |
| d_model         | 128            |
| n_heads         | 8              |
| d_f             | 128            |
| num_layers      | 3              |
| d_input         | 32             |
| num_classes     | 3              |
| dropout         | 0.1            |
| learning_rate   | 0.005          |
| epochs          | 1000           |

2025-02-01 18:44:32,744 - INFO - Epoch 0: val_loss=1.1026, val_acc=33.33%
2025-02-01 18:44:33,422 - INFO - ####################Training epoch 0####################
2025-02-01 18:44:33,499 - INFO - Epoch 0: train_loss=1.0875
2025-02-01 18:44:33,766 - INFO - Epoch 0: train_loss=5.0043
2025-02-01 18:44:33,899 - INFO - Epoch 0: train_loss=1.3274
2025-02-01 18:44:34,823 - INFO - Epoch 0: val_loss=3.7491, val_acc=33.33%
2025-02-01 18:44:34,854 - INFO - ####################Training epoch 1####################
2025-02-01 18:44:35,835 - INFO - Epoch 1: train_loss=2.5588
2025-02-01 18:44:36,011 - INFO - Epoch 1: train_loss=2.0943
2025-02-01 18:44:36,145 - INFO - Epoch 1: train_loss=0.8112
2025-02-01 18:44:37,153 - INFO - Epoch 1: val_loss=3.0270, val_acc=0.00%
2025-02-01 18:44:37,179 - INFO - ####################Training epoch 2####################
2025-02-01 18:44:38,166 - INFO - Epoch 2: train_loss=1.5746
2025-02-01 18:44:38,329 - INFO - Epoch 2: train_loss=1.0183
2025-02-01 18:44:38,463 - INFO - Epoch 2: train_loss=1.3773
2025-02-01 18:44:39,449 - INFO - Epoch 2: val_loss=2.0072, val_acc=33.33%
2025-02-01 18:44:39,476 - INFO - ####################Training epoch 3####################
2025-02-01 18:44:40,452 - INFO - Epoch 3: train_loss=1.1688
2025-02-01 18:44:40,627 - INFO - Epoch 3: train_loss=1.0453
2025-02-01 18:44:40,761 - INFO - Epoch 3: train_loss=1.1916
2025-02-01 18:44:41,739 - INFO - Epoch 3: val_loss=2.1612, val_acc=0.00%
2025-02-01 18:44:41,767 - INFO - ####################Training epoch 4####################
2025-02-01 18:44:42,738 - INFO - Epoch 4: train_loss=1.1008
2025-02-01 18:44:42,904 - INFO - Epoch 4: train_loss=0.9982
2025-02-01 18:44:43,037 - INFO - Epoch 4: train_loss=1.0877
2025-02-01 18:44:44,028 - INFO - Epoch 4: val_loss=2.6095, val_acc=0.00%
2025-02-01 18:44:44,056 - INFO - ####################Training epoch 5####################
2025-02-01 18:44:45,045 - INFO - Epoch 5: train_loss=1.0097
2025-02-01 18:44:45,220 - INFO - Epoch 5: train_loss=1.1937
2025-02-01 18:44:45,354 - INFO - Epoch 5: train_loss=1.9824
2025-02-01 18:44:46,361 - INFO - Epoch 5: val_loss=2.9233, val_acc=33.33%
2025-02-01 18:44:46,365 - INFO - ####################Training epoch 6####################
2025-02-01 18:44:47,362 - INFO - Epoch 6: train_loss=2.4271
2025-02-01 18:44:47,524 - INFO - Epoch 6: train_loss=1.3518
2025-02-01 18:44:47,659 - INFO - Epoch 6: train_loss=1.5516
2025-02-01 18:44:48,648 - INFO - Epoch 6: val_loss=2.8512, val_acc=33.33%
2025-02-01 18:44:48,652 - INFO - ####################Training epoch 7####################
2025-02-01 18:44:49,634 - INFO - Epoch 7: train_loss=1.0456
2025-02-01 18:44:49,811 - INFO - Epoch 7: train_loss=2.9551
2025-02-01 18:44:49,945 - INFO - Epoch 7: train_loss=0.6757
2025-02-01 18:44:50,937 - INFO - Epoch 7: val_loss=2.8152, val_acc=33.33%
2025-02-01 18:44:50,941 - INFO - ####################Training epoch 8####################
2025-02-01 18:44:51,926 - INFO - Epoch 8: train_loss=1.6580
2025-02-01 18:44:52,092 - INFO - Epoch 8: train_loss=1.6326
2025-02-01 18:44:52,226 - INFO - Epoch 8: train_loss=2.2957
2025-02-01 18:44:53,211 - INFO - Epoch 8: val_loss=2.7924, val_acc=33.33%
2025-02-01 18:44:53,215 - INFO - ####################Training epoch 9####################
2025-02-01 18:44:54,203 - INFO - Epoch 9: train_loss=1.9315
2025-02-01 18:44:54,378 - INFO - Epoch 9: train_loss=1.6568
2025-02-01 18:44:54,516 - INFO - Epoch 9: train_loss=1.4620
2025-02-01 18:44:55,506 - INFO - Epoch 9: val_loss=2.7852, val_acc=33.33%
2025-02-01 18:44:55,510 - INFO - ####################Training epoch 10####################
2025-02-01 18:44:56,502 - INFO - Epoch 10: train_loss=2.2204
2025-02-01 18:44:56,671 - INFO - Epoch 10: train_loss=1.0310
2025-02-01 18:44:56,805 - INFO - Epoch 10: train_loss=2.2631
2025-02-01 18:44:57,792 - INFO - Epoch 10: val_loss=2.7783, val_acc=33.33%
2025-02-01 18:44:57,795 - INFO - ####################Training epoch 11####################
2025-02-01 18:44:58,792 - INFO - Epoch 11: train_loss=1.6370
2025-02-01 18:44:58,968 - INFO - Epoch 11: train_loss=1.9125
2025-02-01 18:44:59,106 - INFO - Epoch 11: train_loss=1.4905
2025-02-01 18:45:00,097 - INFO - Epoch 11: val_loss=2.7733, val_acc=33.33%
2025-02-01 18:45:00,100 - INFO - ####################Training epoch 12####################
2025-02-01 18:45:01,077 - INFO - Epoch 12: train_loss=2.2323
2025-02-01 18:45:01,250 - INFO - Epoch 12: train_loss=1.0151
2025-02-01 18:45:01,386 - INFO - Epoch 12: train_loss=2.2275
2025-02-01 18:45:02,462 - INFO - Epoch 12: val_loss=2.7697, val_acc=33.33%
2025-02-01 18:45:02,466 - INFO - ####################Training epoch 13####################
2025-02-01 18:45:03,479 - INFO - Epoch 13: train_loss=1.6075
2025-02-01 18:45:03,650 - INFO - Epoch 13: train_loss=2.2136
2025-02-01 18:45:03,785 - INFO - Epoch 13: train_loss=0.7709
2025-02-01 18:45:04,779 - INFO - Epoch 13: val_loss=2.7664, val_acc=33.33%
2025-02-01 18:45:04,783 - INFO - ####################Training epoch 14####################
2025-02-01 18:45:05,762 - INFO - Epoch 14: train_loss=2.2150
2025-02-01 18:45:05,928 - INFO - Epoch 14: train_loss=1.6102
2025-02-01 18:45:06,065 - INFO - Epoch 14: train_loss=0.7447
2025-02-01 18:45:07,067 - INFO - Epoch 14: val_loss=2.7636, val_acc=33.33%
2025-02-01 18:45:07,071 - INFO - ####################Training epoch 15####################
2025-02-01 18:45:08,063 - INFO - Epoch 15: train_loss=2.5231
2025-02-01 18:45:08,236 - INFO - Epoch 15: train_loss=1.2961
2025-02-01 18:45:08,370 - INFO - Epoch 15: train_loss=0.7494
2025-02-01 18:45:09,365 - INFO - Epoch 15: val_loss=2.7626, val_acc=33.33%
2025-02-01 18:45:09,369 - INFO - ####################Training epoch 16####################
2025-02-01 18:45:10,358 - INFO - Epoch 16: train_loss=1.6105
2025-02-01 18:45:10,522 - INFO - Epoch 16: train_loss=1.9160
2025-02-01 18:45:10,656 - INFO - Epoch 16: train_loss=nan
2025-02-01 18:45:11,662 - INFO - Epoch 16: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:11,666 - INFO - ####################Training epoch 17####################
2025-02-01 18:45:12,657 - INFO - Epoch 17: train_loss=nan
2025-02-01 18:45:12,830 - INFO - Epoch 17: train_loss=nan
2025-02-01 18:45:12,964 - INFO - Epoch 17: train_loss=nan
2025-02-01 18:45:13,964 - INFO - Epoch 17: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:13,968 - INFO - ####################Training epoch 18####################
2025-02-01 18:45:14,937 - INFO - Epoch 18: train_loss=nan
2025-02-01 18:45:15,101 - INFO - Epoch 18: train_loss=nan
2025-02-01 18:45:15,234 - INFO - Epoch 18: train_loss=nan
2025-02-01 18:45:16,208 - INFO - Epoch 18: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:16,212 - INFO - ####################Training epoch 19####################
2025-02-01 18:45:17,204 - INFO - Epoch 19: train_loss=nan
2025-02-01 18:45:17,379 - INFO - Epoch 19: train_loss=nan
2025-02-01 18:45:17,515 - INFO - Epoch 19: train_loss=nan
2025-02-01 18:45:18,517 - INFO - Epoch 19: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:18,520 - INFO - ####################Training epoch 20####################
2025-02-01 18:45:19,509 - INFO - Epoch 20: train_loss=nan
2025-02-01 18:45:19,677 - INFO - Epoch 20: train_loss=nan
2025-02-01 18:45:19,810 - INFO - Epoch 20: train_loss=nan
2025-02-01 18:45:20,788 - INFO - Epoch 20: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:20,791 - INFO - ####################Training epoch 21####################
2025-02-01 18:45:21,755 - INFO - Epoch 21: train_loss=nan
2025-02-01 18:45:21,920 - INFO - Epoch 21: train_loss=nan
2025-02-01 18:45:22,055 - INFO - Epoch 21: train_loss=nan
2025-02-01 18:45:23,047 - INFO - Epoch 21: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:23,051 - INFO - ####################Training epoch 22####################
2025-02-01 18:45:24,050 - INFO - Epoch 22: train_loss=nan
2025-02-01 18:45:24,359 - INFO - Epoch 22: train_loss=nan
2025-02-01 18:45:24,493 - INFO - Epoch 22: train_loss=nan
2025-02-01 18:45:25,033 - INFO - Epoch 22: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:25,037 - INFO - ####################Training epoch 23####################
2025-02-01 18:45:25,834 - INFO - Epoch 23: train_loss=nan
2025-02-01 18:45:25,991 - INFO - Epoch 23: train_loss=nan
2025-02-01 18:45:26,125 - INFO - Epoch 23: train_loss=nan
2025-02-01 18:45:26,518 - INFO - Epoch 23: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:26,522 - INFO - ####################Training epoch 24####################
2025-02-01 18:45:26,891 - INFO - Epoch 24: train_loss=nan
2025-02-01 18:45:27,048 - INFO - Epoch 24: train_loss=nan
2025-02-01 18:45:27,182 - INFO - Epoch 24: train_loss=nan
2025-02-01 18:45:27,569 - INFO - Epoch 24: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:27,573 - INFO - ####################Training epoch 25####################
2025-02-01 18:45:27,946 - INFO - Epoch 25: train_loss=nan
2025-02-01 18:45:28,104 - INFO - Epoch 25: train_loss=nan
2025-02-01 18:45:28,238 - INFO - Epoch 25: train_loss=nan
2025-02-01 18:45:28,625 - INFO - Epoch 25: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:28,629 - INFO - ####################Training epoch 26####################
2025-02-01 18:45:28,994 - INFO - Epoch 26: train_loss=nan
2025-02-01 18:45:29,152 - INFO - Epoch 26: train_loss=nan
2025-02-01 18:45:29,285 - INFO - Epoch 26: train_loss=nan
2025-02-01 18:45:29,676 - INFO - Epoch 26: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:29,680 - INFO - ####################Training epoch 27####################
2025-02-01 18:45:30,048 - INFO - Epoch 27: train_loss=nan
2025-02-01 18:45:30,206 - INFO - Epoch 27: train_loss=nan
2025-02-01 18:45:30,339 - INFO - Epoch 27: train_loss=nan
2025-02-01 18:45:30,728 - INFO - Epoch 27: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:30,732 - INFO - ####################Training epoch 28####################
2025-02-01 18:45:31,105 - INFO - Epoch 28: train_loss=nan
2025-02-01 18:45:31,263 - INFO - Epoch 28: train_loss=nan
2025-02-01 18:45:31,397 - INFO - Epoch 28: train_loss=nan
2025-02-01 18:45:31,784 - INFO - Epoch 28: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:31,787 - INFO - ####################Training epoch 29####################
2025-02-01 18:45:32,160 - INFO - Epoch 29: train_loss=nan
2025-02-01 18:45:32,317 - INFO - Epoch 29: train_loss=nan
2025-02-01 18:45:32,451 - INFO - Epoch 29: train_loss=nan
2025-02-01 18:45:32,845 - INFO - Epoch 29: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:32,849 - INFO - ####################Training epoch 30####################
2025-02-01 18:45:33,218 - INFO - Epoch 30: train_loss=nan
2025-02-01 18:45:33,376 - INFO - Epoch 30: train_loss=nan
2025-02-01 18:45:33,510 - INFO - Epoch 30: train_loss=nan
2025-02-01 18:45:33,896 - INFO - Epoch 30: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:33,900 - INFO - ####################Training epoch 31####################
2025-02-01 18:45:34,269 - INFO - Epoch 31: train_loss=nan
2025-02-01 18:45:34,427 - INFO - Epoch 31: train_loss=nan
2025-02-01 18:45:34,561 - INFO - Epoch 31: train_loss=nan
2025-02-01 18:45:34,953 - INFO - Epoch 31: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:34,957 - INFO - ####################Training epoch 32####################
2025-02-01 18:45:35,325 - INFO - Epoch 32: train_loss=nan
2025-02-01 18:45:35,483 - INFO - Epoch 32: train_loss=nan
2025-02-01 18:45:35,617 - INFO - Epoch 32: train_loss=nan
2025-02-01 18:45:36,008 - INFO - Epoch 32: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:36,012 - INFO - ####################Training epoch 33####################
2025-02-01 18:45:36,382 - INFO - Epoch 33: train_loss=nan
2025-02-01 18:45:36,539 - INFO - Epoch 33: train_loss=nan
2025-02-01 18:45:36,673 - INFO - Epoch 33: train_loss=nan
2025-02-01 18:45:37,058 - INFO - Epoch 33: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:37,062 - INFO - ####################Training epoch 34####################
2025-02-01 18:45:37,436 - INFO - Epoch 34: train_loss=nan
2025-02-01 18:45:37,594 - INFO - Epoch 34: train_loss=nan
2025-02-01 18:45:37,728 - INFO - Epoch 34: train_loss=nan
2025-02-01 18:45:38,116 - INFO - Epoch 34: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:38,120 - INFO - ####################Training epoch 35####################
2025-02-01 18:45:38,491 - INFO - Epoch 35: train_loss=nan
2025-02-01 18:45:38,648 - INFO - Epoch 35: train_loss=nan
2025-02-01 18:45:38,782 - INFO - Epoch 35: train_loss=nan
2025-02-01 18:45:39,171 - INFO - Epoch 35: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:39,175 - INFO - ####################Training epoch 36####################
2025-02-01 18:45:39,542 - INFO - Epoch 36: train_loss=nan
2025-02-01 18:45:39,700 - INFO - Epoch 36: train_loss=nan
2025-02-01 18:45:39,834 - INFO - Epoch 36: train_loss=nan
2025-02-01 18:45:40,222 - INFO - Epoch 36: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:40,226 - INFO - ####################Training epoch 37####################
2025-02-01 18:45:40,599 - INFO - Epoch 37: train_loss=nan
2025-02-01 18:45:40,757 - INFO - Epoch 37: train_loss=nan
2025-02-01 18:45:40,891 - INFO - Epoch 37: train_loss=nan
2025-02-01 18:45:41,279 - INFO - Epoch 37: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:41,283 - INFO - ####################Training epoch 38####################
2025-02-01 18:45:41,655 - INFO - Epoch 38: train_loss=nan
2025-02-01 18:45:41,813 - INFO - Epoch 38: train_loss=nan
2025-02-01 18:45:41,947 - INFO - Epoch 38: train_loss=nan
2025-02-01 18:45:42,340 - INFO - Epoch 38: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:42,344 - INFO - ####################Training epoch 39####################
2025-02-01 18:45:42,714 - INFO - Epoch 39: train_loss=nan
2025-02-01 18:45:42,871 - INFO - Epoch 39: train_loss=nan
2025-02-01 18:45:43,005 - INFO - Epoch 39: train_loss=nan
2025-02-01 18:45:43,394 - INFO - Epoch 39: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:43,398 - INFO - ####################Training epoch 40####################
2025-02-01 18:45:43,771 - INFO - Epoch 40: train_loss=nan
2025-02-01 18:45:43,928 - INFO - Epoch 40: train_loss=nan
2025-02-01 18:45:44,062 - INFO - Epoch 40: train_loss=nan
2025-02-01 18:45:44,450 - INFO - Epoch 40: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:44,453 - INFO - ####################Training epoch 41####################
2025-02-01 18:45:44,824 - INFO - Epoch 41: train_loss=nan
2025-02-01 18:45:44,981 - INFO - Epoch 41: train_loss=nan
2025-02-01 18:45:45,115 - INFO - Epoch 41: train_loss=nan
2025-02-01 18:45:45,508 - INFO - Epoch 41: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:45,512 - INFO - ####################Training epoch 42####################
2025-02-01 18:45:45,882 - INFO - Epoch 42: train_loss=nan
2025-02-01 18:45:46,039 - INFO - Epoch 42: train_loss=nan
2025-02-01 18:45:46,173 - INFO - Epoch 42: train_loss=nan
2025-02-01 18:45:46,561 - INFO - Epoch 42: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:46,565 - INFO - ####################Training epoch 43####################
2025-02-01 18:45:46,938 - INFO - Epoch 43: train_loss=nan
2025-02-01 18:45:47,096 - INFO - Epoch 43: train_loss=nan
2025-02-01 18:45:47,230 - INFO - Epoch 43: train_loss=nan
2025-02-01 18:45:47,616 - INFO - Epoch 43: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:47,620 - INFO - ####################Training epoch 44####################
2025-02-01 18:45:47,990 - INFO - Epoch 44: train_loss=nan
2025-02-01 18:45:48,147 - INFO - Epoch 44: train_loss=nan
2025-02-01 18:45:48,281 - INFO - Epoch 44: train_loss=nan
2025-02-01 18:45:48,766 - INFO - Epoch 44: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:48,769 - INFO - ####################Training epoch 45####################
2025-02-01 18:45:49,141 - INFO - Epoch 45: train_loss=nan
2025-02-01 18:45:49,298 - INFO - Epoch 45: train_loss=nan
2025-02-01 18:45:49,433 - INFO - Epoch 45: train_loss=nan
2025-02-01 18:45:49,827 - INFO - Epoch 45: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:49,830 - INFO - ####################Training epoch 46####################
2025-02-01 18:45:50,202 - INFO - Epoch 46: train_loss=nan
2025-02-01 18:45:50,359 - INFO - Epoch 46: train_loss=nan
2025-02-01 18:45:50,493 - INFO - Epoch 46: train_loss=nan
2025-02-01 18:45:50,884 - INFO - Epoch 46: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:50,887 - INFO - ####################Training epoch 47####################
2025-02-01 18:45:51,255 - INFO - Epoch 47: train_loss=nan
2025-02-01 18:45:51,415 - INFO - Epoch 47: train_loss=nan
2025-02-01 18:45:51,549 - INFO - Epoch 47: train_loss=nan
2025-02-01 18:45:51,945 - INFO - Epoch 47: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:51,948 - INFO - ####################Training epoch 48####################
2025-02-01 18:45:52,320 - INFO - Epoch 48: train_loss=nan
2025-02-01 18:45:52,477 - INFO - Epoch 48: train_loss=nan
2025-02-01 18:45:52,611 - INFO - Epoch 48: train_loss=nan
2025-02-01 18:45:53,006 - INFO - Epoch 48: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:53,010 - INFO - ####################Training epoch 49####################
2025-02-01 18:45:53,381 - INFO - Epoch 49: train_loss=nan
2025-02-01 18:45:53,537 - INFO - Epoch 49: train_loss=nan
2025-02-01 18:45:53,670 - INFO - Epoch 49: train_loss=nan
2025-02-01 18:45:54,059 - INFO - Epoch 49: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:54,063 - INFO - ####################Training epoch 50####################
2025-02-01 18:45:54,430 - INFO - Epoch 50: train_loss=nan
2025-02-01 18:45:54,588 - INFO - Epoch 50: train_loss=nan
2025-02-01 18:45:54,721 - INFO - Epoch 50: train_loss=nan
2025-02-01 18:45:55,107 - INFO - Epoch 50: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:55,111 - INFO - ####################Training epoch 51####################
2025-02-01 18:45:55,483 - INFO - Epoch 51: train_loss=nan
2025-02-01 18:45:55,639 - INFO - Epoch 51: train_loss=nan
2025-02-01 18:45:55,773 - INFO - Epoch 51: train_loss=nan
2025-02-01 18:45:56,163 - INFO - Epoch 51: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:56,167 - INFO - ####################Training epoch 52####################
2025-02-01 18:45:56,541 - INFO - Epoch 52: train_loss=nan
2025-02-01 18:45:56,698 - INFO - Epoch 52: train_loss=nan
2025-02-01 18:45:56,831 - INFO - Epoch 52: train_loss=nan
2025-02-01 18:45:57,220 - INFO - Epoch 52: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:57,224 - INFO - ####################Training epoch 53####################
2025-02-01 18:45:57,593 - INFO - Epoch 53: train_loss=nan
2025-02-01 18:45:57,750 - INFO - Epoch 53: train_loss=nan
2025-02-01 18:45:57,884 - INFO - Epoch 53: train_loss=nan
2025-02-01 18:45:58,276 - INFO - Epoch 53: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:58,280 - INFO - ####################Training epoch 54####################
2025-02-01 18:45:58,654 - INFO - Epoch 54: train_loss=nan
2025-02-01 18:45:58,811 - INFO - Epoch 54: train_loss=nan
2025-02-01 18:45:58,945 - INFO - Epoch 54: train_loss=nan
2025-02-01 18:45:59,334 - INFO - Epoch 54: val_loss=nan, val_acc=66.67%
2025-02-01 18:45:59,338 - INFO - ####################Training epoch 55####################
2025-02-01 18:45:59,710 - INFO - Epoch 55: train_loss=nan
2025-02-01 18:45:59,867 - INFO - Epoch 55: train_loss=nan
2025-02-01 18:46:00,000 - INFO - Epoch 55: train_loss=nan
2025-02-01 18:46:00,389 - INFO - Epoch 55: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:00,393 - INFO - ####################Training epoch 56####################
2025-02-01 18:46:00,762 - INFO - Epoch 56: train_loss=nan
2025-02-01 18:46:00,919 - INFO - Epoch 56: train_loss=nan
2025-02-01 18:46:01,053 - INFO - Epoch 56: train_loss=nan
2025-02-01 18:46:01,445 - INFO - Epoch 56: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:01,449 - INFO - ####################Training epoch 57####################
2025-02-01 18:46:01,819 - INFO - Epoch 57: train_loss=nan
2025-02-01 18:46:01,976 - INFO - Epoch 57: train_loss=nan
2025-02-01 18:46:02,109 - INFO - Epoch 57: train_loss=nan
2025-02-01 18:46:02,499 - INFO - Epoch 57: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:02,503 - INFO - ####################Training epoch 58####################
2025-02-01 18:46:02,874 - INFO - Epoch 58: train_loss=nan
2025-02-01 18:46:03,030 - INFO - Epoch 58: train_loss=nan
2025-02-01 18:46:03,164 - INFO - Epoch 58: train_loss=nan
2025-02-01 18:46:03,551 - INFO - Epoch 58: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:03,555 - INFO - ####################Training epoch 59####################
2025-02-01 18:46:03,923 - INFO - Epoch 59: train_loss=nan
2025-02-01 18:46:04,079 - INFO - Epoch 59: train_loss=nan
2025-02-01 18:46:04,213 - INFO - Epoch 59: train_loss=nan
2025-02-01 18:46:04,603 - INFO - Epoch 59: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:04,607 - INFO - ####################Training epoch 60####################
2025-02-01 18:46:04,976 - INFO - Epoch 60: train_loss=nan
2025-02-01 18:46:05,132 - INFO - Epoch 60: train_loss=nan
2025-02-01 18:46:05,266 - INFO - Epoch 60: train_loss=nan
2025-02-01 18:46:05,652 - INFO - Epoch 60: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:05,656 - INFO - ####################Training epoch 61####################
2025-02-01 18:46:06,033 - INFO - Epoch 61: train_loss=nan
2025-02-01 18:46:06,190 - INFO - Epoch 61: train_loss=nan
2025-02-01 18:46:06,323 - INFO - Epoch 61: train_loss=nan
2025-02-01 18:46:06,707 - INFO - Epoch 61: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:06,711 - INFO - ####################Training epoch 62####################
2025-02-01 18:46:07,082 - INFO - Epoch 62: train_loss=nan
2025-02-01 18:46:07,239 - INFO - Epoch 62: train_loss=nan
2025-02-01 18:46:07,372 - INFO - Epoch 62: train_loss=nan
2025-02-01 18:46:07,765 - INFO - Epoch 62: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:07,769 - INFO - ####################Training epoch 63####################
2025-02-01 18:46:08,159 - INFO - Epoch 63: train_loss=nan
2025-02-01 18:46:08,316 - INFO - Epoch 63: train_loss=nan
2025-02-01 18:46:08,448 - INFO - Epoch 63: train_loss=nan
2025-02-01 18:46:08,842 - INFO - Epoch 63: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:08,846 - INFO - ####################Training epoch 64####################
2025-02-01 18:46:09,220 - INFO - Epoch 64: train_loss=nan
2025-02-01 18:46:09,376 - INFO - Epoch 64: train_loss=nan
2025-02-01 18:46:09,508 - INFO - Epoch 64: train_loss=nan
2025-02-01 18:46:09,904 - INFO - Epoch 64: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:09,907 - INFO - ####################Training epoch 65####################
2025-02-01 18:46:10,279 - INFO - Epoch 65: train_loss=nan
2025-02-01 18:46:10,436 - INFO - Epoch 65: train_loss=nan
2025-02-01 18:46:10,568 - INFO - Epoch 65: train_loss=nan
2025-02-01 18:46:10,962 - INFO - Epoch 65: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:10,966 - INFO - ####################Training epoch 66####################
2025-02-01 18:46:11,342 - INFO - Epoch 66: train_loss=nan
2025-02-01 18:46:11,498 - INFO - Epoch 66: train_loss=nan
2025-02-01 18:46:11,631 - INFO - Epoch 66: train_loss=nan
2025-02-01 18:46:12,030 - INFO - Epoch 66: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:12,034 - INFO - ####################Training epoch 67####################
2025-02-01 18:46:12,410 - INFO - Epoch 67: train_loss=nan
2025-02-01 18:46:12,567 - INFO - Epoch 67: train_loss=nan
2025-02-01 18:46:12,700 - INFO - Epoch 67: train_loss=nan
2025-02-01 18:46:13,093 - INFO - Epoch 67: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:13,096 - INFO - ####################Training epoch 68####################
2025-02-01 18:46:13,466 - INFO - Epoch 68: train_loss=nan
2025-02-01 18:46:13,623 - INFO - Epoch 68: train_loss=nan
2025-02-01 18:46:13,757 - INFO - Epoch 68: train_loss=nan
2025-02-01 18:46:14,151 - INFO - Epoch 68: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:14,154 - INFO - ####################Training epoch 69####################
2025-02-01 18:46:14,527 - INFO - Epoch 69: train_loss=nan
2025-02-01 18:46:14,684 - INFO - Epoch 69: train_loss=nan
2025-02-01 18:46:14,818 - INFO - Epoch 69: train_loss=nan
2025-02-01 18:46:15,211 - INFO - Epoch 69: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:15,214 - INFO - ####################Training epoch 70####################
2025-02-01 18:46:15,590 - INFO - Epoch 70: train_loss=nan
2025-02-01 18:46:15,746 - INFO - Epoch 70: train_loss=nan
2025-02-01 18:46:15,880 - INFO - Epoch 70: train_loss=nan
2025-02-01 18:46:16,276 - INFO - Epoch 70: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:16,279 - INFO - ####################Training epoch 71####################
2025-02-01 18:46:16,652 - INFO - Epoch 71: train_loss=nan
2025-02-01 18:46:16,809 - INFO - Epoch 71: train_loss=nan
2025-02-01 18:46:16,942 - INFO - Epoch 71: train_loss=nan
2025-02-01 18:46:17,340 - INFO - Epoch 71: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:17,343 - INFO - ####################Training epoch 72####################
2025-02-01 18:46:17,719 - INFO - Epoch 72: train_loss=nan
2025-02-01 18:46:17,875 - INFO - Epoch 72: train_loss=nan
2025-02-01 18:46:18,009 - INFO - Epoch 72: train_loss=nan
2025-02-01 18:46:18,402 - INFO - Epoch 72: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:18,405 - INFO - ####################Training epoch 73####################
2025-02-01 18:46:18,781 - INFO - Epoch 73: train_loss=nan
2025-02-01 18:46:18,938 - INFO - Epoch 73: train_loss=nan
2025-02-01 18:46:19,071 - INFO - Epoch 73: train_loss=nan
2025-02-01 18:46:19,471 - INFO - Epoch 73: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:19,474 - INFO - ####################Training epoch 74####################
2025-02-01 18:46:19,845 - INFO - Epoch 74: train_loss=nan
2025-02-01 18:46:20,001 - INFO - Epoch 74: train_loss=nan
2025-02-01 18:46:20,135 - INFO - Epoch 74: train_loss=nan
2025-02-01 18:46:20,530 - INFO - Epoch 74: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:20,534 - INFO - ####################Training epoch 75####################
2025-02-01 18:46:20,908 - INFO - Epoch 75: train_loss=nan
2025-02-01 18:46:21,064 - INFO - Epoch 75: train_loss=nan
2025-02-01 18:46:21,197 - INFO - Epoch 75: train_loss=nan
2025-02-01 18:46:21,588 - INFO - Epoch 75: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:21,592 - INFO - ####################Training epoch 76####################
2025-02-01 18:46:21,966 - INFO - Epoch 76: train_loss=nan
2025-02-01 18:46:22,123 - INFO - Epoch 76: train_loss=nan
2025-02-01 18:46:22,256 - INFO - Epoch 76: train_loss=nan
2025-02-01 18:46:22,651 - INFO - Epoch 76: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:22,655 - INFO - ####################Training epoch 77####################
2025-02-01 18:46:23,026 - INFO - Epoch 77: train_loss=nan
2025-02-01 18:46:23,184 - INFO - Epoch 77: train_loss=nan
2025-02-01 18:46:23,317 - INFO - Epoch 77: train_loss=nan
2025-02-01 18:46:23,710 - INFO - Epoch 77: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:23,714 - INFO - ####################Training epoch 78####################
2025-02-01 18:46:24,088 - INFO - Epoch 78: train_loss=nan
2025-02-01 18:46:24,244 - INFO - Epoch 78: train_loss=nan
2025-02-01 18:46:24,378 - INFO - Epoch 78: train_loss=nan
2025-02-01 18:46:24,772 - INFO - Epoch 78: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:24,776 - INFO - ####################Training epoch 79####################
2025-02-01 18:46:25,152 - INFO - Epoch 79: train_loss=nan
2025-02-01 18:46:25,309 - INFO - Epoch 79: train_loss=nan
2025-02-01 18:46:25,442 - INFO - Epoch 79: train_loss=nan
2025-02-01 18:46:25,837 - INFO - Epoch 79: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:25,841 - INFO - ####################Training epoch 80####################
2025-02-01 18:46:26,210 - INFO - Epoch 80: train_loss=nan
2025-02-01 18:46:26,366 - INFO - Epoch 80: train_loss=nan
2025-02-01 18:46:26,500 - INFO - Epoch 80: train_loss=nan
2025-02-01 18:46:26,894 - INFO - Epoch 80: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:26,897 - INFO - ####################Training epoch 81####################
2025-02-01 18:46:27,274 - INFO - Epoch 81: train_loss=nan
2025-02-01 18:46:27,430 - INFO - Epoch 81: train_loss=nan
2025-02-01 18:46:27,562 - INFO - Epoch 81: train_loss=nan
2025-02-01 18:46:27,955 - INFO - Epoch 81: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:27,959 - INFO - ####################Training epoch 82####################
2025-02-01 18:46:28,335 - INFO - Epoch 82: train_loss=nan
2025-02-01 18:46:28,491 - INFO - Epoch 82: train_loss=nan
2025-02-01 18:46:28,624 - INFO - Epoch 82: train_loss=nan
2025-02-01 18:46:29,019 - INFO - Epoch 82: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:29,023 - INFO - ####################Training epoch 83####################
2025-02-01 18:46:29,396 - INFO - Epoch 83: train_loss=nan
2025-02-01 18:46:29,553 - INFO - Epoch 83: train_loss=nan
2025-02-01 18:46:29,685 - INFO - Epoch 83: train_loss=nan
2025-02-01 18:46:30,083 - INFO - Epoch 83: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:30,087 - INFO - ####################Training epoch 84####################
2025-02-01 18:46:30,464 - INFO - Epoch 84: train_loss=nan
2025-02-01 18:46:30,621 - INFO - Epoch 84: train_loss=nan
2025-02-01 18:46:30,754 - INFO - Epoch 84: train_loss=nan
2025-02-01 18:46:31,146 - INFO - Epoch 84: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:31,150 - INFO - ####################Training epoch 85####################
2025-02-01 18:46:31,526 - INFO - Epoch 85: train_loss=nan
2025-02-01 18:46:31,683 - INFO - Epoch 85: train_loss=nan
2025-02-01 18:46:31,816 - INFO - Epoch 85: train_loss=nan
2025-02-01 18:46:32,212 - INFO - Epoch 85: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:32,215 - INFO - ####################Training epoch 86####################
2025-02-01 18:46:32,587 - INFO - Epoch 86: train_loss=nan
2025-02-01 18:46:32,743 - INFO - Epoch 86: train_loss=nan
2025-02-01 18:46:32,876 - INFO - Epoch 86: train_loss=nan
2025-02-01 18:46:33,269 - INFO - Epoch 86: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:33,273 - INFO - ####################Training epoch 87####################
2025-02-01 18:46:33,648 - INFO - Epoch 87: train_loss=nan
2025-02-01 18:46:33,804 - INFO - Epoch 87: train_loss=nan
2025-02-01 18:46:33,938 - INFO - Epoch 87: train_loss=nan
2025-02-01 18:46:34,332 - INFO - Epoch 87: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:34,335 - INFO - ####################Training epoch 88####################
2025-02-01 18:46:34,713 - INFO - Epoch 88: train_loss=nan
2025-02-01 18:46:34,869 - INFO - Epoch 88: train_loss=nan
2025-02-01 18:46:35,002 - INFO - Epoch 88: train_loss=nan
2025-02-01 18:46:35,397 - INFO - Epoch 88: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:35,401 - INFO - ####################Training epoch 89####################
2025-02-01 18:46:35,773 - INFO - Epoch 89: train_loss=nan
2025-02-01 18:46:35,929 - INFO - Epoch 89: train_loss=nan
2025-02-01 18:46:36,062 - INFO - Epoch 89: train_loss=nan
2025-02-01 18:46:36,458 - INFO - Epoch 89: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:36,462 - INFO - ####################Training epoch 90####################
2025-02-01 18:46:36,834 - INFO - Epoch 90: train_loss=nan
2025-02-01 18:46:36,990 - INFO - Epoch 90: train_loss=nan
2025-02-01 18:46:37,123 - INFO - Epoch 90: train_loss=nan
2025-02-01 18:46:37,518 - INFO - Epoch 90: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:37,521 - INFO - ####################Training epoch 91####################
2025-02-01 18:46:37,896 - INFO - Epoch 91: train_loss=nan
2025-02-01 18:46:38,053 - INFO - Epoch 91: train_loss=nan
2025-02-01 18:46:38,186 - INFO - Epoch 91: train_loss=nan
2025-02-01 18:46:38,581 - INFO - Epoch 91: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:38,585 - INFO - ####################Training epoch 92####################
2025-02-01 18:46:38,958 - INFO - Epoch 92: train_loss=nan
2025-02-01 18:46:39,115 - INFO - Epoch 92: train_loss=nan
2025-02-01 18:46:39,248 - INFO - Epoch 92: train_loss=nan
2025-02-01 18:46:39,644 - INFO - Epoch 92: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:39,648 - INFO - ####################Training epoch 93####################
2025-02-01 18:46:40,023 - INFO - Epoch 93: train_loss=nan
2025-02-01 18:46:40,180 - INFO - Epoch 93: train_loss=nan
2025-02-01 18:46:40,313 - INFO - Epoch 93: train_loss=nan
2025-02-01 18:46:40,708 - INFO - Epoch 93: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:40,711 - INFO - ####################Training epoch 94####################
2025-02-01 18:46:41,085 - INFO - Epoch 94: train_loss=nan
2025-02-01 18:46:41,241 - INFO - Epoch 94: train_loss=nan
2025-02-01 18:46:41,375 - INFO - Epoch 94: train_loss=nan
2025-02-01 18:46:41,772 - INFO - Epoch 94: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:41,776 - INFO - ####################Training epoch 95####################
2025-02-01 18:46:42,149 - INFO - Epoch 95: train_loss=nan
2025-02-01 18:46:42,305 - INFO - Epoch 95: train_loss=nan
2025-02-01 18:46:42,438 - INFO - Epoch 95: train_loss=nan
2025-02-01 18:46:42,833 - INFO - Epoch 95: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:42,837 - INFO - ####################Training epoch 96####################
2025-02-01 18:46:43,213 - INFO - Epoch 96: train_loss=nan
2025-02-01 18:46:43,369 - INFO - Epoch 96: train_loss=nan
2025-02-01 18:46:43,503 - INFO - Epoch 96: train_loss=nan
2025-02-01 18:46:43,895 - INFO - Epoch 96: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:43,899 - INFO - ####################Training epoch 97####################
2025-02-01 18:46:44,270 - INFO - Epoch 97: train_loss=nan
2025-02-01 18:46:44,426 - INFO - Epoch 97: train_loss=nan
2025-02-01 18:46:44,562 - INFO - Epoch 97: train_loss=nan
2025-02-01 18:46:44,956 - INFO - Epoch 97: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:44,960 - INFO - ####################Training epoch 98####################
2025-02-01 18:46:45,329 - INFO - Epoch 98: train_loss=nan
2025-02-01 18:46:45,486 - INFO - Epoch 98: train_loss=nan
2025-02-01 18:46:45,619 - INFO - Epoch 98: train_loss=nan
2025-02-01 18:46:46,013 - INFO - Epoch 98: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:46,017 - INFO - ####################Training epoch 99####################
2025-02-01 18:46:46,390 - INFO - Epoch 99: train_loss=nan
2025-02-01 18:46:46,547 - INFO - Epoch 99: train_loss=nan
2025-02-01 18:46:46,680 - INFO - Epoch 99: train_loss=nan
2025-02-01 18:46:47,073 - INFO - Epoch 99: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:47,077 - INFO - ####################Training epoch 100####################
2025-02-01 18:46:47,452 - INFO - Epoch 100: train_loss=nan
2025-02-01 18:46:47,608 - INFO - Epoch 100: train_loss=nan
2025-02-01 18:46:47,741 - INFO - Epoch 100: train_loss=nan
2025-02-01 18:46:48,136 - INFO - Epoch 100: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:48,139 - INFO - ####################Training epoch 101####################
2025-02-01 18:46:48,508 - INFO - Epoch 101: train_loss=nan
2025-02-01 18:46:48,664 - INFO - Epoch 101: train_loss=nan
2025-02-01 18:46:48,798 - INFO - Epoch 101: train_loss=nan
2025-02-01 18:46:49,192 - INFO - Epoch 101: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:49,196 - INFO - ####################Training epoch 102####################
2025-02-01 18:46:49,569 - INFO - Epoch 102: train_loss=nan
2025-02-01 18:46:49,726 - INFO - Epoch 102: train_loss=nan
2025-02-01 18:46:49,859 - INFO - Epoch 102: train_loss=nan
2025-02-01 18:46:50,250 - INFO - Epoch 102: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:50,254 - INFO - ####################Training epoch 103####################
2025-02-01 18:46:50,632 - INFO - Epoch 103: train_loss=nan
2025-02-01 18:46:50,788 - INFO - Epoch 103: train_loss=nan
2025-02-01 18:46:50,922 - INFO - Epoch 103: train_loss=nan
2025-02-01 18:46:51,317 - INFO - Epoch 103: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:51,321 - INFO - ####################Training epoch 104####################
2025-02-01 18:46:51,694 - INFO - Epoch 104: train_loss=nan
2025-02-01 18:46:51,851 - INFO - Epoch 104: train_loss=nan
2025-02-01 18:46:51,984 - INFO - Epoch 104: train_loss=nan
2025-02-01 18:46:52,383 - INFO - Epoch 104: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:52,386 - INFO - ####################Training epoch 105####################
2025-02-01 18:46:52,762 - INFO - Epoch 105: train_loss=nan
2025-02-01 18:46:52,918 - INFO - Epoch 105: train_loss=nan
2025-02-01 18:46:53,051 - INFO - Epoch 105: train_loss=nan
2025-02-01 18:46:53,442 - INFO - Epoch 105: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:53,445 - INFO - ####################Training epoch 106####################
2025-02-01 18:46:53,822 - INFO - Epoch 106: train_loss=nan
2025-02-01 18:46:53,978 - INFO - Epoch 106: train_loss=nan
2025-02-01 18:46:54,112 - INFO - Epoch 106: train_loss=nan
2025-02-01 18:46:54,508 - INFO - Epoch 106: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:54,512 - INFO - ####################Training epoch 107####################
2025-02-01 18:46:54,884 - INFO - Epoch 107: train_loss=nan
2025-02-01 18:46:55,040 - INFO - Epoch 107: train_loss=nan
2025-02-01 18:46:55,173 - INFO - Epoch 107: train_loss=nan
2025-02-01 18:46:55,569 - INFO - Epoch 107: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:55,573 - INFO - ####################Training epoch 108####################
2025-02-01 18:46:55,947 - INFO - Epoch 108: train_loss=nan
2025-02-01 18:46:56,103 - INFO - Epoch 108: train_loss=nan
2025-02-01 18:46:56,236 - INFO - Epoch 108: train_loss=nan
2025-02-01 18:46:56,627 - INFO - Epoch 108: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:56,630 - INFO - ####################Training epoch 109####################
2025-02-01 18:46:57,007 - INFO - Epoch 109: train_loss=nan
2025-02-01 18:46:57,164 - INFO - Epoch 109: train_loss=nan
2025-02-01 18:46:57,297 - INFO - Epoch 109: train_loss=nan
2025-02-01 18:46:57,690 - INFO - Epoch 109: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:57,693 - INFO - ####################Training epoch 110####################
2025-02-01 18:46:58,066 - INFO - Epoch 110: train_loss=nan
2025-02-01 18:46:58,223 - INFO - Epoch 110: train_loss=nan
2025-02-01 18:46:58,356 - INFO - Epoch 110: train_loss=nan
2025-02-01 18:46:58,752 - INFO - Epoch 110: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:58,756 - INFO - ####################Training epoch 111####################
2025-02-01 18:46:59,133 - INFO - Epoch 111: train_loss=nan
2025-02-01 18:46:59,290 - INFO - Epoch 111: train_loss=nan
2025-02-01 18:46:59,423 - INFO - Epoch 111: train_loss=nan
2025-02-01 18:46:59,814 - INFO - Epoch 111: val_loss=nan, val_acc=66.67%
2025-02-01 18:46:59,818 - INFO - ####################Training epoch 112####################
2025-02-01 18:47:00,193 - INFO - Epoch 112: train_loss=nan
2025-02-01 18:47:00,349 - INFO - Epoch 112: train_loss=nan
2025-02-01 18:47:00,483 - INFO - Epoch 112: train_loss=nan
2025-02-01 18:47:00,880 - INFO - Epoch 112: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:00,884 - INFO - ####################Training epoch 113####################
2025-02-01 18:47:01,257 - INFO - Epoch 113: train_loss=nan
2025-02-01 18:47:01,413 - INFO - Epoch 113: train_loss=nan
2025-02-01 18:47:01,546 - INFO - Epoch 113: train_loss=nan
2025-02-01 18:47:01,945 - INFO - Epoch 113: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:01,949 - INFO - ####################Training epoch 114####################
2025-02-01 18:47:02,325 - INFO - Epoch 114: train_loss=nan
2025-02-01 18:47:02,481 - INFO - Epoch 114: train_loss=nan
2025-02-01 18:47:02,614 - INFO - Epoch 114: train_loss=nan
2025-02-01 18:47:03,008 - INFO - Epoch 114: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:03,012 - INFO - ####################Training epoch 115####################
2025-02-01 18:47:03,391 - INFO - Epoch 115: train_loss=nan
2025-02-01 18:47:03,549 - INFO - Epoch 115: train_loss=nan
2025-02-01 18:47:03,682 - INFO - Epoch 115: train_loss=nan
2025-02-01 18:47:04,072 - INFO - Epoch 115: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:04,076 - INFO - ####################Training epoch 116####################
2025-02-01 18:47:04,449 - INFO - Epoch 116: train_loss=nan
2025-02-01 18:47:04,605 - INFO - Epoch 116: train_loss=nan
2025-02-01 18:47:04,739 - INFO - Epoch 116: train_loss=nan
2025-02-01 18:47:05,136 - INFO - Epoch 116: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:05,140 - INFO - ####################Training epoch 117####################
2025-02-01 18:47:05,515 - INFO - Epoch 117: train_loss=nan
2025-02-01 18:47:05,671 - INFO - Epoch 117: train_loss=nan
2025-02-01 18:47:05,805 - INFO - Epoch 117: train_loss=nan
2025-02-01 18:47:06,199 - INFO - Epoch 117: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:06,203 - INFO - ####################Training epoch 118####################
2025-02-01 18:47:06,577 - INFO - Epoch 118: train_loss=nan
2025-02-01 18:47:06,733 - INFO - Epoch 118: train_loss=nan
2025-02-01 18:47:06,867 - INFO - Epoch 118: train_loss=nan
2025-02-01 18:47:07,261 - INFO - Epoch 118: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:07,265 - INFO - ####################Training epoch 119####################
2025-02-01 18:47:07,640 - INFO - Epoch 119: train_loss=nan
2025-02-01 18:47:07,797 - INFO - Epoch 119: train_loss=nan
2025-02-01 18:47:07,930 - INFO - Epoch 119: train_loss=nan
2025-02-01 18:47:08,321 - INFO - Epoch 119: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:08,324 - INFO - ####################Training epoch 120####################
2025-02-01 18:47:08,700 - INFO - Epoch 120: train_loss=nan
2025-02-01 18:47:08,856 - INFO - Epoch 120: train_loss=nan
2025-02-01 18:47:08,989 - INFO - Epoch 120: train_loss=nan
2025-02-01 18:47:09,383 - INFO - Epoch 120: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:09,387 - INFO - ####################Training epoch 121####################
2025-02-01 18:47:09,764 - INFO - Epoch 121: train_loss=nan
2025-02-01 18:47:09,920 - INFO - Epoch 121: train_loss=nan
2025-02-01 18:47:10,053 - INFO - Epoch 121: train_loss=nan
2025-02-01 18:47:10,449 - INFO - Epoch 121: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:10,453 - INFO - ####################Training epoch 122####################
2025-02-01 18:47:10,826 - INFO - Epoch 122: train_loss=nan
2025-02-01 18:47:10,983 - INFO - Epoch 122: train_loss=nan
2025-02-01 18:47:11,116 - INFO - Epoch 122: train_loss=nan
2025-02-01 18:47:11,514 - INFO - Epoch 122: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:11,518 - INFO - ####################Training epoch 123####################
2025-02-01 18:47:11,893 - INFO - Epoch 123: train_loss=nan
2025-02-01 18:47:12,050 - INFO - Epoch 123: train_loss=nan
2025-02-01 18:47:12,183 - INFO - Epoch 123: train_loss=nan
2025-02-01 18:47:12,575 - INFO - Epoch 123: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:12,579 - INFO - ####################Training epoch 124####################
2025-02-01 18:47:12,954 - INFO - Epoch 124: train_loss=nan
2025-02-01 18:47:13,111 - INFO - Epoch 124: train_loss=nan
2025-02-01 18:47:13,244 - INFO - Epoch 124: train_loss=nan
2025-02-01 18:47:13,641 - INFO - Epoch 124: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:13,644 - INFO - ####################Training epoch 125####################
2025-02-01 18:47:14,017 - INFO - Epoch 125: train_loss=nan
2025-02-01 18:47:14,173 - INFO - Epoch 125: train_loss=nan
2025-02-01 18:47:14,306 - INFO - Epoch 125: train_loss=nan
2025-02-01 18:47:14,700 - INFO - Epoch 125: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:14,704 - INFO - ####################Training epoch 126####################
2025-02-01 18:47:15,081 - INFO - Epoch 126: train_loss=nan
2025-02-01 18:47:15,238 - INFO - Epoch 126: train_loss=nan
2025-02-01 18:47:15,371 - INFO - Epoch 126: train_loss=nan
2025-02-01 18:47:15,766 - INFO - Epoch 126: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:15,770 - INFO - ####################Training epoch 127####################
2025-02-01 18:47:16,146 - INFO - Epoch 127: train_loss=nan
2025-02-01 18:47:16,303 - INFO - Epoch 127: train_loss=nan
2025-02-01 18:47:16,437 - INFO - Epoch 127: train_loss=nan
2025-02-01 18:47:16,832 - INFO - Epoch 127: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:16,836 - INFO - ####################Training epoch 128####################
2025-02-01 18:47:17,208 - INFO - Epoch 128: train_loss=nan
2025-02-01 18:47:17,365 - INFO - Epoch 128: train_loss=nan
2025-02-01 18:47:17,498 - INFO - Epoch 128: train_loss=nan
2025-02-01 18:47:17,893 - INFO - Epoch 128: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:17,897 - INFO - ####################Training epoch 129####################
2025-02-01 18:47:18,270 - INFO - Epoch 129: train_loss=nan
2025-02-01 18:47:18,427 - INFO - Epoch 129: train_loss=nan
2025-02-01 18:47:18,560 - INFO - Epoch 129: train_loss=nan
2025-02-01 18:47:18,954 - INFO - Epoch 129: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:18,957 - INFO - ####################Training epoch 130####################
2025-02-01 18:47:19,335 - INFO - Epoch 130: train_loss=nan
2025-02-01 18:47:19,491 - INFO - Epoch 130: train_loss=nan
2025-02-01 18:47:19,625 - INFO - Epoch 130: train_loss=nan
2025-02-01 18:47:20,020 - INFO - Epoch 130: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:20,024 - INFO - ####################Training epoch 131####################
2025-02-01 18:47:20,401 - INFO - Epoch 131: train_loss=nan
2025-02-01 18:47:20,558 - INFO - Epoch 131: train_loss=nan
2025-02-01 18:47:20,691 - INFO - Epoch 131: train_loss=nan
2025-02-01 18:47:21,090 - INFO - Epoch 131: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:21,093 - INFO - ####################Training epoch 132####################
2025-02-01 18:47:21,470 - INFO - Epoch 132: train_loss=nan
2025-02-01 18:47:21,627 - INFO - Epoch 132: train_loss=nan
2025-02-01 18:47:21,760 - INFO - Epoch 132: train_loss=nan
2025-02-01 18:47:22,158 - INFO - Epoch 132: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:22,161 - INFO - ####################Training epoch 133####################
2025-02-01 18:47:22,538 - INFO - Epoch 133: train_loss=nan
2025-02-01 18:47:22,695 - INFO - Epoch 133: train_loss=nan
2025-02-01 18:47:22,827 - INFO - Epoch 133: train_loss=nan
2025-02-01 18:47:23,221 - INFO - Epoch 133: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:23,224 - INFO - ####################Training epoch 134####################
2025-02-01 18:47:23,600 - INFO - Epoch 134: train_loss=nan
2025-02-01 18:47:23,757 - INFO - Epoch 134: train_loss=nan
2025-02-01 18:47:23,890 - INFO - Epoch 134: train_loss=nan
2025-02-01 18:47:24,286 - INFO - Epoch 134: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:24,290 - INFO - ####################Training epoch 135####################
2025-02-01 18:47:24,668 - INFO - Epoch 135: train_loss=nan
2025-02-01 18:47:24,825 - INFO - Epoch 135: train_loss=nan
2025-02-01 18:47:24,958 - INFO - Epoch 135: train_loss=nan
2025-02-01 18:47:25,352 - INFO - Epoch 135: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:25,356 - INFO - ####################Training epoch 136####################
2025-02-01 18:47:25,731 - INFO - Epoch 136: train_loss=nan
2025-02-01 18:47:25,887 - INFO - Epoch 136: train_loss=nan
2025-02-01 18:47:26,021 - INFO - Epoch 136: train_loss=nan
2025-02-01 18:47:26,417 - INFO - Epoch 136: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:26,421 - INFO - ####################Training epoch 137####################
2025-02-01 18:47:26,792 - INFO - Epoch 137: train_loss=nan
2025-02-01 18:47:26,948 - INFO - Epoch 137: train_loss=nan
2025-02-01 18:47:27,082 - INFO - Epoch 137: train_loss=nan
2025-02-01 18:47:27,478 - INFO - Epoch 137: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:27,483 - INFO - ####################Training epoch 138####################
2025-02-01 18:47:27,859 - INFO - Epoch 138: train_loss=nan
2025-02-01 18:47:28,016 - INFO - Epoch 138: train_loss=nan
2025-02-01 18:47:28,149 - INFO - Epoch 138: train_loss=nan
2025-02-01 18:47:28,541 - INFO - Epoch 138: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:28,544 - INFO - ####################Training epoch 139####################
2025-02-01 18:47:28,920 - INFO - Epoch 139: train_loss=nan
2025-02-01 18:47:29,077 - INFO - Epoch 139: train_loss=nan
2025-02-01 18:47:29,210 - INFO - Epoch 139: train_loss=nan
2025-02-01 18:47:29,606 - INFO - Epoch 139: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:29,610 - INFO - ####################Training epoch 140####################
2025-02-01 18:47:29,982 - INFO - Epoch 140: train_loss=nan
2025-02-01 18:47:30,139 - INFO - Epoch 140: train_loss=nan
2025-02-01 18:47:30,272 - INFO - Epoch 140: train_loss=nan
2025-02-01 18:47:30,671 - INFO - Epoch 140: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:30,675 - INFO - ####################Training epoch 141####################
2025-02-01 18:47:31,052 - INFO - Epoch 141: train_loss=nan
2025-02-01 18:47:31,209 - INFO - Epoch 141: train_loss=nan
2025-02-01 18:47:31,342 - INFO - Epoch 141: train_loss=nan
2025-02-01 18:47:31,734 - INFO - Epoch 141: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:31,738 - INFO - ####################Training epoch 142####################
2025-02-01 18:47:32,113 - INFO - Epoch 142: train_loss=nan
2025-02-01 18:47:32,270 - INFO - Epoch 142: train_loss=nan
2025-02-01 18:47:32,403 - INFO - Epoch 142: train_loss=nan
2025-02-01 18:47:32,798 - INFO - Epoch 142: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:32,802 - INFO - ####################Training epoch 143####################
2025-02-01 18:47:33,173 - INFO - Epoch 143: train_loss=nan
2025-02-01 18:47:33,329 - INFO - Epoch 143: train_loss=nan
2025-02-01 18:47:33,462 - INFO - Epoch 143: train_loss=nan
2025-02-01 18:47:33,857 - INFO - Epoch 143: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:33,861 - INFO - ####################Training epoch 144####################
2025-02-01 18:47:34,237 - INFO - Epoch 144: train_loss=nan
2025-02-01 18:47:34,394 - INFO - Epoch 144: train_loss=nan
2025-02-01 18:47:34,527 - INFO - Epoch 144: train_loss=nan
2025-02-01 18:47:34,921 - INFO - Epoch 144: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:34,925 - INFO - ####################Training epoch 145####################
2025-02-01 18:47:35,302 - INFO - Epoch 145: train_loss=nan
2025-02-01 18:47:35,459 - INFO - Epoch 145: train_loss=nan
2025-02-01 18:47:35,593 - INFO - Epoch 145: train_loss=nan
2025-02-01 18:47:35,991 - INFO - Epoch 145: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:35,994 - INFO - ####################Training epoch 146####################
2025-02-01 18:47:36,369 - INFO - Epoch 146: train_loss=nan
2025-02-01 18:47:36,525 - INFO - Epoch 146: train_loss=nan
2025-02-01 18:47:36,658 - INFO - Epoch 146: train_loss=nan
2025-02-01 18:47:37,056 - INFO - Epoch 146: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:37,060 - INFO - ####################Training epoch 147####################
2025-02-01 18:47:37,438 - INFO - Epoch 147: train_loss=nan
2025-02-01 18:47:37,595 - INFO - Epoch 147: train_loss=nan
2025-02-01 18:47:37,728 - INFO - Epoch 147: train_loss=nan
2025-02-01 18:47:38,124 - INFO - Epoch 147: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:38,127 - INFO - ####################Training epoch 148####################
2025-02-01 18:47:38,504 - INFO - Epoch 148: train_loss=nan
2025-02-01 18:47:38,661 - INFO - Epoch 148: train_loss=nan
2025-02-01 18:47:38,795 - INFO - Epoch 148: train_loss=nan
2025-02-01 18:47:39,190 - INFO - Epoch 148: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:39,194 - INFO - ####################Training epoch 149####################
2025-02-01 18:47:39,568 - INFO - Epoch 149: train_loss=nan
2025-02-01 18:47:39,724 - INFO - Epoch 149: train_loss=nan
2025-02-01 18:47:39,857 - INFO - Epoch 149: train_loss=nan
2025-02-01 18:47:40,257 - INFO - Epoch 149: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:40,261 - INFO - ####################Training epoch 150####################
2025-02-01 18:47:40,638 - INFO - Epoch 150: train_loss=nan
2025-02-01 18:47:40,794 - INFO - Epoch 150: train_loss=nan
2025-02-01 18:47:40,928 - INFO - Epoch 150: train_loss=nan
2025-02-01 18:47:41,325 - INFO - Epoch 150: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:41,328 - INFO - ####################Training epoch 151####################
2025-02-01 18:47:41,707 - INFO - Epoch 151: train_loss=nan
2025-02-01 18:47:41,864 - INFO - Epoch 151: train_loss=nan
2025-02-01 18:47:41,997 - INFO - Epoch 151: train_loss=nan
2025-02-01 18:47:42,397 - INFO - Epoch 151: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:42,401 - INFO - ####################Training epoch 152####################
2025-02-01 18:47:42,775 - INFO - Epoch 152: train_loss=nan
2025-02-01 18:47:42,931 - INFO - Epoch 152: train_loss=nan
2025-02-01 18:47:43,065 - INFO - Epoch 152: train_loss=nan
2025-02-01 18:47:43,467 - INFO - Epoch 152: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:43,470 - INFO - ####################Training epoch 153####################
2025-02-01 18:47:43,846 - INFO - Epoch 153: train_loss=nan
2025-02-01 18:47:44,002 - INFO - Epoch 153: train_loss=nan
2025-02-01 18:47:44,135 - INFO - Epoch 153: train_loss=nan
2025-02-01 18:47:44,528 - INFO - Epoch 153: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:44,532 - INFO - ####################Training epoch 154####################
2025-02-01 18:47:44,910 - INFO - Epoch 154: train_loss=nan
2025-02-01 18:47:45,066 - INFO - Epoch 154: train_loss=nan
2025-02-01 18:47:45,199 - INFO - Epoch 154: train_loss=nan
2025-02-01 18:47:45,599 - INFO - Epoch 154: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:45,603 - INFO - ####################Training epoch 155####################
2025-02-01 18:47:45,976 - INFO - Epoch 155: train_loss=nan
2025-02-01 18:47:46,133 - INFO - Epoch 155: train_loss=nan
2025-02-01 18:47:46,266 - INFO - Epoch 155: train_loss=nan
2025-02-01 18:47:46,659 - INFO - Epoch 155: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:46,662 - INFO - ####################Training epoch 156####################
2025-02-01 18:47:47,037 - INFO - Epoch 156: train_loss=nan
2025-02-01 18:47:47,195 - INFO - Epoch 156: train_loss=nan
2025-02-01 18:47:47,328 - INFO - Epoch 156: train_loss=nan
2025-02-01 18:47:47,722 - INFO - Epoch 156: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:47,725 - INFO - ####################Training epoch 157####################
2025-02-01 18:47:48,103 - INFO - Epoch 157: train_loss=nan
2025-02-01 18:47:48,260 - INFO - Epoch 157: train_loss=nan
2025-02-01 18:47:48,394 - INFO - Epoch 157: train_loss=nan
2025-02-01 18:47:48,791 - INFO - Epoch 157: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:48,795 - INFO - ####################Training epoch 158####################
2025-02-01 18:47:49,169 - INFO - Epoch 158: train_loss=nan
2025-02-01 18:47:49,325 - INFO - Epoch 158: train_loss=nan
2025-02-01 18:47:49,458 - INFO - Epoch 158: train_loss=nan
2025-02-01 18:47:49,856 - INFO - Epoch 158: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:49,860 - INFO - ####################Training epoch 159####################
2025-02-01 18:47:50,238 - INFO - Epoch 159: train_loss=nan
2025-02-01 18:47:50,395 - INFO - Epoch 159: train_loss=nan
2025-02-01 18:47:50,528 - INFO - Epoch 159: train_loss=nan
2025-02-01 18:47:50,926 - INFO - Epoch 159: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:50,929 - INFO - ####################Training epoch 160####################
2025-02-01 18:47:51,307 - INFO - Epoch 160: train_loss=nan
2025-02-01 18:47:51,463 - INFO - Epoch 160: train_loss=nan
2025-02-01 18:47:51,596 - INFO - Epoch 160: train_loss=nan
2025-02-01 18:47:51,992 - INFO - Epoch 160: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:51,996 - INFO - ####################Training epoch 161####################
2025-02-01 18:47:52,370 - INFO - Epoch 161: train_loss=nan
2025-02-01 18:47:52,526 - INFO - Epoch 161: train_loss=nan
2025-02-01 18:47:52,659 - INFO - Epoch 161: train_loss=nan
2025-02-01 18:47:53,055 - INFO - Epoch 161: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:53,059 - INFO - ####################Training epoch 162####################
2025-02-01 18:47:53,435 - INFO - Epoch 162: train_loss=nan
2025-02-01 18:47:53,592 - INFO - Epoch 162: train_loss=nan
2025-02-01 18:47:53,725 - INFO - Epoch 162: train_loss=nan
2025-02-01 18:47:54,121 - INFO - Epoch 162: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:54,125 - INFO - ####################Training epoch 163####################
2025-02-01 18:47:54,500 - INFO - Epoch 163: train_loss=nan
2025-02-01 18:47:54,656 - INFO - Epoch 163: train_loss=nan
2025-02-01 18:47:54,789 - INFO - Epoch 163: train_loss=nan
2025-02-01 18:47:55,188 - INFO - Epoch 163: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:55,192 - INFO - ####################Training epoch 164####################
2025-02-01 18:47:55,565 - INFO - Epoch 164: train_loss=nan
2025-02-01 18:47:55,721 - INFO - Epoch 164: train_loss=nan
2025-02-01 18:47:55,854 - INFO - Epoch 164: train_loss=nan
2025-02-01 18:47:56,248 - INFO - Epoch 164: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:56,252 - INFO - ####################Training epoch 165####################
2025-02-01 18:47:56,626 - INFO - Epoch 165: train_loss=nan
2025-02-01 18:47:56,782 - INFO - Epoch 165: train_loss=nan
2025-02-01 18:47:56,915 - INFO - Epoch 165: train_loss=nan
2025-02-01 18:47:57,307 - INFO - Epoch 165: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:57,311 - INFO - ####################Training epoch 166####################
2025-02-01 18:47:57,687 - INFO - Epoch 166: train_loss=nan
2025-02-01 18:47:57,843 - INFO - Epoch 166: train_loss=nan
2025-02-01 18:47:57,976 - INFO - Epoch 166: train_loss=nan
2025-02-01 18:47:58,376 - INFO - Epoch 166: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:58,379 - INFO - ####################Training epoch 167####################
2025-02-01 18:47:58,753 - INFO - Epoch 167: train_loss=nan
2025-02-01 18:47:58,909 - INFO - Epoch 167: train_loss=nan
2025-02-01 18:47:59,043 - INFO - Epoch 167: train_loss=nan
2025-02-01 18:47:59,441 - INFO - Epoch 167: val_loss=nan, val_acc=66.67%
2025-02-01 18:47:59,445 - INFO - ####################Training epoch 168####################
2025-02-01 18:47:59,818 - INFO - Epoch 168: train_loss=nan
2025-02-01 18:47:59,975 - INFO - Epoch 168: train_loss=nan
2025-02-01 18:48:00,108 - INFO - Epoch 168: train_loss=nan
2025-02-01 18:48:00,506 - INFO - Epoch 168: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:00,509 - INFO - ####################Training epoch 169####################
2025-02-01 18:48:00,885 - INFO - Epoch 169: train_loss=nan
2025-02-01 18:48:01,041 - INFO - Epoch 169: train_loss=nan
2025-02-01 18:48:01,175 - INFO - Epoch 169: train_loss=nan
2025-02-01 18:48:01,571 - INFO - Epoch 169: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:01,575 - INFO - ####################Training epoch 170####################
2025-02-01 18:48:01,946 - INFO - Epoch 170: train_loss=nan
2025-02-01 18:48:02,103 - INFO - Epoch 170: train_loss=nan
2025-02-01 18:48:02,235 - INFO - Epoch 170: train_loss=nan
2025-02-01 18:48:02,634 - INFO - Epoch 170: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:02,637 - INFO - ####################Training epoch 171####################
2025-02-01 18:48:03,013 - INFO - Epoch 171: train_loss=nan
2025-02-01 18:48:03,170 - INFO - Epoch 171: train_loss=nan
2025-02-01 18:48:03,303 - INFO - Epoch 171: train_loss=nan
2025-02-01 18:48:03,697 - INFO - Epoch 171: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:03,701 - INFO - ####################Training epoch 172####################
2025-02-01 18:48:04,074 - INFO - Epoch 172: train_loss=nan
2025-02-01 18:48:04,231 - INFO - Epoch 172: train_loss=nan
2025-02-01 18:48:04,365 - INFO - Epoch 172: train_loss=nan
2025-02-01 18:48:04,763 - INFO - Epoch 172: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:04,767 - INFO - ####################Training epoch 173####################
2025-02-01 18:48:05,137 - INFO - Epoch 173: train_loss=nan
2025-02-01 18:48:05,293 - INFO - Epoch 173: train_loss=nan
2025-02-01 18:48:05,427 - INFO - Epoch 173: train_loss=nan
2025-02-01 18:48:05,822 - INFO - Epoch 173: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:05,826 - INFO - ####################Training epoch 174####################
2025-02-01 18:48:06,199 - INFO - Epoch 174: train_loss=nan
2025-02-01 18:48:06,355 - INFO - Epoch 174: train_loss=nan
2025-02-01 18:48:06,489 - INFO - Epoch 174: train_loss=nan
2025-02-01 18:48:06,883 - INFO - Epoch 174: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:06,886 - INFO - ####################Training epoch 175####################
2025-02-01 18:48:07,265 - INFO - Epoch 175: train_loss=nan
2025-02-01 18:48:07,421 - INFO - Epoch 175: train_loss=nan
2025-02-01 18:48:07,554 - INFO - Epoch 175: train_loss=nan
2025-02-01 18:48:07,948 - INFO - Epoch 175: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:07,952 - INFO - ####################Training epoch 176####################
2025-02-01 18:48:08,324 - INFO - Epoch 176: train_loss=nan
2025-02-01 18:48:08,480 - INFO - Epoch 176: train_loss=nan
2025-02-01 18:48:08,613 - INFO - Epoch 176: train_loss=nan
2025-02-01 18:48:09,010 - INFO - Epoch 176: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:09,014 - INFO - ####################Training epoch 177####################
2025-02-01 18:48:09,391 - INFO - Epoch 177: train_loss=nan
2025-02-01 18:48:09,548 - INFO - Epoch 177: train_loss=nan
2025-02-01 18:48:09,682 - INFO - Epoch 177: train_loss=nan
2025-02-01 18:48:10,075 - INFO - Epoch 177: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:10,079 - INFO - ####################Training epoch 178####################
2025-02-01 18:48:10,453 - INFO - Epoch 178: train_loss=nan
2025-02-01 18:48:10,610 - INFO - Epoch 178: train_loss=nan
2025-02-01 18:48:10,743 - INFO - Epoch 178: train_loss=nan
2025-02-01 18:48:11,139 - INFO - Epoch 178: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:11,143 - INFO - ####################Training epoch 179####################
2025-02-01 18:48:11,517 - INFO - Epoch 179: train_loss=nan
2025-02-01 18:48:11,673 - INFO - Epoch 179: train_loss=nan
2025-02-01 18:48:11,807 - INFO - Epoch 179: train_loss=nan
2025-02-01 18:48:12,204 - INFO - Epoch 179: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:12,208 - INFO - ####################Training epoch 180####################
2025-02-01 18:48:12,584 - INFO - Epoch 180: train_loss=nan
2025-02-01 18:48:12,741 - INFO - Epoch 180: train_loss=nan
2025-02-01 18:48:12,874 - INFO - Epoch 180: train_loss=nan
2025-02-01 18:48:13,271 - INFO - Epoch 180: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:13,275 - INFO - ####################Training epoch 181####################
2025-02-01 18:48:13,653 - INFO - Epoch 181: train_loss=nan
2025-02-01 18:48:13,810 - INFO - Epoch 181: train_loss=nan
2025-02-01 18:48:13,943 - INFO - Epoch 181: train_loss=nan
2025-02-01 18:48:14,340 - INFO - Epoch 181: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:14,344 - INFO - ####################Training epoch 182####################
2025-02-01 18:48:14,717 - INFO - Epoch 182: train_loss=nan
2025-02-01 18:48:14,873 - INFO - Epoch 182: train_loss=nan
2025-02-01 18:48:15,006 - INFO - Epoch 182: train_loss=nan
2025-02-01 18:48:15,404 - INFO - Epoch 182: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:15,407 - INFO - ####################Training epoch 183####################
2025-02-01 18:48:15,785 - INFO - Epoch 183: train_loss=nan
2025-02-01 18:48:15,942 - INFO - Epoch 183: train_loss=nan
2025-02-01 18:48:16,076 - INFO - Epoch 183: train_loss=nan
2025-02-01 18:48:16,477 - INFO - Epoch 183: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:16,480 - INFO - ####################Training epoch 184####################
2025-02-01 18:48:16,858 - INFO - Epoch 184: train_loss=nan
2025-02-01 18:48:17,015 - INFO - Epoch 184: train_loss=nan
2025-02-01 18:48:17,148 - INFO - Epoch 184: train_loss=nan
2025-02-01 18:48:17,544 - INFO - Epoch 184: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:17,548 - INFO - ####################Training epoch 185####################
2025-02-01 18:48:17,921 - INFO - Epoch 185: train_loss=nan
2025-02-01 18:48:18,077 - INFO - Epoch 185: train_loss=nan
2025-02-01 18:48:18,210 - INFO - Epoch 185: train_loss=nan
2025-02-01 18:48:18,606 - INFO - Epoch 185: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:18,610 - INFO - ####################Training epoch 186####################
2025-02-01 18:48:18,986 - INFO - Epoch 186: train_loss=nan
2025-02-01 18:48:19,142 - INFO - Epoch 186: train_loss=nan
2025-02-01 18:48:19,276 - INFO - Epoch 186: train_loss=nan
2025-02-01 18:48:19,669 - INFO - Epoch 186: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:19,673 - INFO - ####################Training epoch 187####################
2025-02-01 18:48:20,050 - INFO - Epoch 187: train_loss=nan
2025-02-01 18:48:20,207 - INFO - Epoch 187: train_loss=nan
2025-02-01 18:48:20,340 - INFO - Epoch 187: train_loss=nan
2025-02-01 18:48:20,740 - INFO - Epoch 187: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:20,744 - INFO - ####################Training epoch 188####################
2025-02-01 18:48:21,115 - INFO - Epoch 188: train_loss=nan
2025-02-01 18:48:21,271 - INFO - Epoch 188: train_loss=nan
2025-02-01 18:48:21,405 - INFO - Epoch 188: train_loss=nan
2025-02-01 18:48:21,803 - INFO - Epoch 188: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:21,806 - INFO - ####################Training epoch 189####################
2025-02-01 18:48:22,184 - INFO - Epoch 189: train_loss=nan
2025-02-01 18:48:22,341 - INFO - Epoch 189: train_loss=nan
2025-02-01 18:48:22,474 - INFO - Epoch 189: train_loss=nan
2025-02-01 18:48:22,870 - INFO - Epoch 189: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:22,874 - INFO - ####################Training epoch 190####################
2025-02-01 18:48:23,250 - INFO - Epoch 190: train_loss=nan
2025-02-01 18:48:23,406 - INFO - Epoch 190: train_loss=nan
2025-02-01 18:48:23,541 - INFO - Epoch 190: train_loss=nan
2025-02-01 18:48:23,938 - INFO - Epoch 190: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:23,942 - INFO - ####################Training epoch 191####################
2025-02-01 18:48:24,315 - INFO - Epoch 191: train_loss=nan
2025-02-01 18:48:24,471 - INFO - Epoch 191: train_loss=nan
2025-02-01 18:48:24,605 - INFO - Epoch 191: train_loss=nan
2025-02-01 18:48:24,999 - INFO - Epoch 191: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:25,002 - INFO - ####################Training epoch 192####################
2025-02-01 18:48:25,379 - INFO - Epoch 192: train_loss=nan
2025-02-01 18:48:25,536 - INFO - Epoch 192: train_loss=nan
2025-02-01 18:48:25,669 - INFO - Epoch 192: train_loss=nan
2025-02-01 18:48:26,065 - INFO - Epoch 192: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:26,068 - INFO - ####################Training epoch 193####################
2025-02-01 18:48:26,442 - INFO - Epoch 193: train_loss=nan
2025-02-01 18:48:26,599 - INFO - Epoch 193: train_loss=nan
2025-02-01 18:48:26,733 - INFO - Epoch 193: train_loss=nan
2025-02-01 18:48:27,129 - INFO - Epoch 193: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:27,132 - INFO - ####################Training epoch 194####################
2025-02-01 18:48:27,505 - INFO - Epoch 194: train_loss=nan
2025-02-01 18:48:27,662 - INFO - Epoch 194: train_loss=nan
2025-02-01 18:48:27,796 - INFO - Epoch 194: train_loss=nan
2025-02-01 18:48:28,192 - INFO - Epoch 194: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:28,195 - INFO - ####################Training epoch 195####################
2025-02-01 18:48:28,569 - INFO - Epoch 195: train_loss=nan
2025-02-01 18:48:28,726 - INFO - Epoch 195: train_loss=nan
2025-02-01 18:48:28,859 - INFO - Epoch 195: train_loss=nan
2025-02-01 18:48:29,252 - INFO - Epoch 195: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:29,256 - INFO - ####################Training epoch 196####################
2025-02-01 18:48:29,632 - INFO - Epoch 196: train_loss=nan
2025-02-01 18:48:29,789 - INFO - Epoch 196: train_loss=nan
2025-02-01 18:48:29,922 - INFO - Epoch 196: train_loss=nan
2025-02-01 18:48:30,319 - INFO - Epoch 196: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:30,322 - INFO - ####################Training epoch 197####################
2025-02-01 18:48:30,696 - INFO - Epoch 197: train_loss=nan
2025-02-01 18:48:30,853 - INFO - Epoch 197: train_loss=nan
2025-02-01 18:48:30,986 - INFO - Epoch 197: train_loss=nan
2025-02-01 18:48:31,384 - INFO - Epoch 197: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:31,391 - INFO - ####################Training epoch 198####################
2025-02-01 18:48:31,767 - INFO - Epoch 198: train_loss=nan
2025-02-01 18:48:31,924 - INFO - Epoch 198: train_loss=nan
2025-02-01 18:48:32,058 - INFO - Epoch 198: train_loss=nan
2025-02-01 18:48:32,452 - INFO - Epoch 198: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:32,456 - INFO - ####################Training epoch 199####################
2025-02-01 18:48:32,832 - INFO - Epoch 199: train_loss=nan
2025-02-01 18:48:32,988 - INFO - Epoch 199: train_loss=nan
2025-02-01 18:48:33,122 - INFO - Epoch 199: train_loss=nan
2025-02-01 18:48:33,518 - INFO - Epoch 199: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:33,522 - INFO - ####################Training epoch 200####################
2025-02-01 18:48:33,899 - INFO - Epoch 200: train_loss=nan
2025-02-01 18:48:34,056 - INFO - Epoch 200: train_loss=nan
2025-02-01 18:48:34,189 - INFO - Epoch 200: train_loss=nan
2025-02-01 18:48:34,589 - INFO - Epoch 200: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:34,592 - INFO - ####################Training epoch 201####################
2025-02-01 18:48:34,966 - INFO - Epoch 201: train_loss=nan
2025-02-01 18:48:35,123 - INFO - Epoch 201: train_loss=nan
2025-02-01 18:48:35,256 - INFO - Epoch 201: train_loss=nan
2025-02-01 18:48:35,651 - INFO - Epoch 201: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:35,655 - INFO - ####################Training epoch 202####################
2025-02-01 18:48:36,030 - INFO - Epoch 202: train_loss=nan
2025-02-01 18:48:36,186 - INFO - Epoch 202: train_loss=nan
2025-02-01 18:48:36,320 - INFO - Epoch 202: train_loss=nan
2025-02-01 18:48:36,717 - INFO - Epoch 202: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:36,721 - INFO - ####################Training epoch 203####################
2025-02-01 18:48:37,093 - INFO - Epoch 203: train_loss=nan
2025-02-01 18:48:37,249 - INFO - Epoch 203: train_loss=nan
2025-02-01 18:48:37,382 - INFO - Epoch 203: train_loss=nan
2025-02-01 18:48:37,784 - INFO - Epoch 203: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:37,787 - INFO - ####################Training epoch 204####################
2025-02-01 18:48:38,161 - INFO - Epoch 204: train_loss=nan
2025-02-01 18:48:38,318 - INFO - Epoch 204: train_loss=nan
2025-02-01 18:48:38,451 - INFO - Epoch 204: train_loss=nan
2025-02-01 18:48:38,846 - INFO - Epoch 204: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:38,849 - INFO - ####################Training epoch 205####################
2025-02-01 18:48:39,222 - INFO - Epoch 205: train_loss=nan
2025-02-01 18:48:39,379 - INFO - Epoch 205: train_loss=nan
2025-02-01 18:48:39,513 - INFO - Epoch 205: train_loss=nan
2025-02-01 18:48:39,913 - INFO - Epoch 205: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:39,916 - INFO - ####################Training epoch 206####################
2025-02-01 18:48:40,291 - INFO - Epoch 206: train_loss=nan
2025-02-01 18:48:40,447 - INFO - Epoch 206: train_loss=nan
2025-02-01 18:48:40,580 - INFO - Epoch 206: train_loss=nan
2025-02-01 18:48:40,980 - INFO - Epoch 206: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:40,983 - INFO - ####################Training epoch 207####################
2025-02-01 18:48:41,358 - INFO - Epoch 207: train_loss=nan
2025-02-01 18:48:41,515 - INFO - Epoch 207: train_loss=nan
2025-02-01 18:48:41,648 - INFO - Epoch 207: train_loss=nan
2025-02-01 18:48:42,042 - INFO - Epoch 207: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:42,046 - INFO - ####################Training epoch 208####################
2025-02-01 18:48:42,420 - INFO - Epoch 208: train_loss=nan
2025-02-01 18:48:42,577 - INFO - Epoch 208: train_loss=nan
2025-02-01 18:48:42,710 - INFO - Epoch 208: train_loss=nan
2025-02-01 18:48:43,106 - INFO - Epoch 208: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:43,110 - INFO - ####################Training epoch 209####################
2025-02-01 18:48:43,487 - INFO - Epoch 209: train_loss=nan
2025-02-01 18:48:43,644 - INFO - Epoch 209: train_loss=nan
2025-02-01 18:48:43,777 - INFO - Epoch 209: train_loss=nan
2025-02-01 18:48:44,173 - INFO - Epoch 209: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:44,177 - INFO - ####################Training epoch 210####################
2025-02-01 18:48:44,555 - INFO - Epoch 210: train_loss=nan
2025-02-01 18:48:44,712 - INFO - Epoch 210: train_loss=nan
2025-02-01 18:48:44,845 - INFO - Epoch 210: train_loss=nan
2025-02-01 18:48:45,239 - INFO - Epoch 210: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:45,243 - INFO - ####################Training epoch 211####################
2025-02-01 18:48:45,621 - INFO - Epoch 211: train_loss=nan
2025-02-01 18:48:45,778 - INFO - Epoch 211: train_loss=nan
2025-02-01 18:48:45,912 - INFO - Epoch 211: train_loss=nan
2025-02-01 18:48:46,310 - INFO - Epoch 211: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:46,313 - INFO - ####################Training epoch 212####################
2025-02-01 18:48:46,687 - INFO - Epoch 212: train_loss=nan
2025-02-01 18:48:46,843 - INFO - Epoch 212: train_loss=nan
2025-02-01 18:48:46,977 - INFO - Epoch 212: train_loss=nan
2025-02-01 18:48:47,373 - INFO - Epoch 212: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:47,377 - INFO - ####################Training epoch 213####################
2025-02-01 18:48:47,752 - INFO - Epoch 213: train_loss=nan
2025-02-01 18:48:47,908 - INFO - Epoch 213: train_loss=nan
2025-02-01 18:48:48,041 - INFO - Epoch 213: train_loss=nan
2025-02-01 18:48:48,434 - INFO - Epoch 213: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:48,438 - INFO - ####################Training epoch 214####################
2025-02-01 18:48:48,818 - INFO - Epoch 214: train_loss=nan
2025-02-01 18:48:48,975 - INFO - Epoch 214: train_loss=nan
2025-02-01 18:48:49,109 - INFO - Epoch 214: train_loss=nan
2025-02-01 18:48:49,505 - INFO - Epoch 214: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:49,508 - INFO - ####################Training epoch 215####################
2025-02-01 18:48:49,884 - INFO - Epoch 215: train_loss=nan
2025-02-01 18:48:50,040 - INFO - Epoch 215: train_loss=nan
2025-02-01 18:48:50,174 - INFO - Epoch 215: train_loss=nan
2025-02-01 18:48:50,572 - INFO - Epoch 215: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:50,576 - INFO - ####################Training epoch 216####################
2025-02-01 18:48:50,950 - INFO - Epoch 216: train_loss=nan
2025-02-01 18:48:51,106 - INFO - Epoch 216: train_loss=nan
2025-02-01 18:48:51,239 - INFO - Epoch 216: train_loss=nan
2025-02-01 18:48:51,634 - INFO - Epoch 216: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:51,638 - INFO - ####################Training epoch 217####################
2025-02-01 18:48:52,018 - INFO - Epoch 217: train_loss=nan
2025-02-01 18:48:52,175 - INFO - Epoch 217: train_loss=nan
2025-02-01 18:48:52,308 - INFO - Epoch 217: train_loss=nan
2025-02-01 18:48:52,704 - INFO - Epoch 217: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:52,708 - INFO - ####################Training epoch 218####################
2025-02-01 18:48:53,079 - INFO - Epoch 218: train_loss=nan
2025-02-01 18:48:53,236 - INFO - Epoch 218: train_loss=nan
2025-02-01 18:48:53,370 - INFO - Epoch 218: train_loss=nan
2025-02-01 18:48:53,767 - INFO - Epoch 218: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:53,771 - INFO - ####################Training epoch 219####################
2025-02-01 18:48:54,151 - INFO - Epoch 219: train_loss=nan
2025-02-01 18:48:54,307 - INFO - Epoch 219: train_loss=nan
2025-02-01 18:48:54,440 - INFO - Epoch 219: train_loss=nan
2025-02-01 18:48:54,835 - INFO - Epoch 219: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:54,839 - INFO - ####################Training epoch 220####################
2025-02-01 18:48:55,218 - INFO - Epoch 220: train_loss=nan
2025-02-01 18:48:55,375 - INFO - Epoch 220: train_loss=nan
2025-02-01 18:48:55,509 - INFO - Epoch 220: train_loss=nan
2025-02-01 18:48:55,905 - INFO - Epoch 220: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:55,909 - INFO - ####################Training epoch 221####################
2025-02-01 18:48:56,280 - INFO - Epoch 221: train_loss=nan
2025-02-01 18:48:56,437 - INFO - Epoch 221: train_loss=nan
2025-02-01 18:48:56,570 - INFO - Epoch 221: train_loss=nan
2025-02-01 18:48:56,965 - INFO - Epoch 221: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:56,968 - INFO - ####################Training epoch 222####################
2025-02-01 18:48:57,347 - INFO - Epoch 222: train_loss=nan
2025-02-01 18:48:57,504 - INFO - Epoch 222: train_loss=nan
2025-02-01 18:48:57,637 - INFO - Epoch 222: train_loss=nan
2025-02-01 18:48:58,033 - INFO - Epoch 222: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:58,040 - INFO - ####################Training epoch 223####################
2025-02-01 18:48:58,420 - INFO - Epoch 223: train_loss=nan
2025-02-01 18:48:58,577 - INFO - Epoch 223: train_loss=nan
2025-02-01 18:48:58,711 - INFO - Epoch 223: train_loss=nan
2025-02-01 18:48:59,109 - INFO - Epoch 223: val_loss=nan, val_acc=66.67%
2025-02-01 18:48:59,112 - INFO - ####################Training epoch 224####################
2025-02-01 18:48:59,485 - INFO - Epoch 224: train_loss=nan
2025-02-01 18:48:59,641 - INFO - Epoch 224: train_loss=nan
2025-02-01 18:48:59,775 - INFO - Epoch 224: train_loss=nan
2025-02-01 18:49:00,171 - INFO - Epoch 224: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:00,175 - INFO - ####################Training epoch 225####################
2025-02-01 18:49:00,554 - INFO - Epoch 225: train_loss=nan
2025-02-01 18:49:00,711 - INFO - Epoch 225: train_loss=nan
2025-02-01 18:49:00,844 - INFO - Epoch 225: train_loss=nan
2025-02-01 18:49:01,238 - INFO - Epoch 225: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:01,242 - INFO - ####################Training epoch 226####################
2025-02-01 18:49:01,618 - INFO - Epoch 226: train_loss=nan
2025-02-01 18:49:01,775 - INFO - Epoch 226: train_loss=nan
2025-02-01 18:49:01,908 - INFO - Epoch 226: train_loss=nan
2025-02-01 18:49:02,304 - INFO - Epoch 226: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:02,308 - INFO - ####################Training epoch 227####################
2025-02-01 18:49:02,681 - INFO - Epoch 227: train_loss=nan
2025-02-01 18:49:02,838 - INFO - Epoch 227: train_loss=nan
2025-02-01 18:49:02,971 - INFO - Epoch 227: train_loss=nan
2025-02-01 18:49:03,368 - INFO - Epoch 227: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:03,372 - INFO - ####################Training epoch 228####################
2025-02-01 18:49:03,748 - INFO - Epoch 228: train_loss=nan
2025-02-01 18:49:03,904 - INFO - Epoch 228: train_loss=nan
2025-02-01 18:49:04,037 - INFO - Epoch 228: train_loss=nan
2025-02-01 18:49:04,430 - INFO - Epoch 228: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:04,434 - INFO - ####################Training epoch 229####################
2025-02-01 18:49:04,806 - INFO - Epoch 229: train_loss=nan
2025-02-01 18:49:04,962 - INFO - Epoch 229: train_loss=nan
2025-02-01 18:49:05,095 - INFO - Epoch 229: train_loss=nan
2025-02-01 18:49:05,493 - INFO - Epoch 229: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:05,497 - INFO - ####################Training epoch 230####################
2025-02-01 18:49:05,870 - INFO - Epoch 230: train_loss=nan
2025-02-01 18:49:06,026 - INFO - Epoch 230: train_loss=nan
2025-02-01 18:49:06,159 - INFO - Epoch 230: train_loss=nan
2025-02-01 18:49:06,555 - INFO - Epoch 230: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:06,559 - INFO - ####################Training epoch 231####################
2025-02-01 18:49:06,936 - INFO - Epoch 231: train_loss=nan
2025-02-01 18:49:07,093 - INFO - Epoch 231: train_loss=nan
2025-02-01 18:49:07,226 - INFO - Epoch 231: train_loss=nan
2025-02-01 18:49:07,621 - INFO - Epoch 231: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:07,625 - INFO - ####################Training epoch 232####################
2025-02-01 18:49:08,002 - INFO - Epoch 232: train_loss=nan
2025-02-01 18:49:08,158 - INFO - Epoch 232: train_loss=nan
2025-02-01 18:49:08,291 - INFO - Epoch 232: train_loss=nan
2025-02-01 18:49:08,685 - INFO - Epoch 232: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:08,689 - INFO - ####################Training epoch 233####################
2025-02-01 18:49:09,066 - INFO - Epoch 233: train_loss=nan
2025-02-01 18:49:09,223 - INFO - Epoch 233: train_loss=nan
2025-02-01 18:49:09,356 - INFO - Epoch 233: train_loss=nan
2025-02-01 18:49:09,753 - INFO - Epoch 233: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:09,757 - INFO - ####################Training epoch 234####################
2025-02-01 18:49:10,134 - INFO - Epoch 234: train_loss=nan
2025-02-01 18:49:10,291 - INFO - Epoch 234: train_loss=nan
2025-02-01 18:49:10,424 - INFO - Epoch 234: train_loss=nan
2025-02-01 18:49:10,818 - INFO - Epoch 234: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:10,822 - INFO - ####################Training epoch 235####################
2025-02-01 18:49:11,197 - INFO - Epoch 235: train_loss=nan
2025-02-01 18:49:11,354 - INFO - Epoch 235: train_loss=nan
2025-02-01 18:49:11,487 - INFO - Epoch 235: train_loss=nan
2025-02-01 18:49:11,885 - INFO - Epoch 235: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:11,888 - INFO - ####################Training epoch 236####################
2025-02-01 18:49:12,265 - INFO - Epoch 236: train_loss=nan
2025-02-01 18:49:12,421 - INFO - Epoch 236: train_loss=nan
2025-02-01 18:49:12,554 - INFO - Epoch 236: train_loss=nan
2025-02-01 18:49:12,949 - INFO - Epoch 236: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:12,953 - INFO - ####################Training epoch 237####################
2025-02-01 18:49:13,329 - INFO - Epoch 237: train_loss=nan
2025-02-01 18:49:13,485 - INFO - Epoch 237: train_loss=nan
2025-02-01 18:49:13,619 - INFO - Epoch 237: train_loss=nan
2025-02-01 18:49:14,013 - INFO - Epoch 237: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:14,017 - INFO - ####################Training epoch 238####################
2025-02-01 18:49:14,392 - INFO - Epoch 238: train_loss=nan
2025-02-01 18:49:14,549 - INFO - Epoch 238: train_loss=nan
2025-02-01 18:49:14,683 - INFO - Epoch 238: train_loss=nan
2025-02-01 18:49:15,081 - INFO - Epoch 238: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:15,085 - INFO - ####################Training epoch 239####################
2025-02-01 18:49:15,459 - INFO - Epoch 239: train_loss=nan
2025-02-01 18:49:15,615 - INFO - Epoch 239: train_loss=nan
2025-02-01 18:49:15,748 - INFO - Epoch 239: train_loss=nan
2025-02-01 18:49:16,147 - INFO - Epoch 239: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:16,151 - INFO - ####################Training epoch 240####################
2025-02-01 18:49:16,526 - INFO - Epoch 240: train_loss=nan
2025-02-01 18:49:16,683 - INFO - Epoch 240: train_loss=nan
2025-02-01 18:49:16,816 - INFO - Epoch 240: train_loss=nan
2025-02-01 18:49:17,212 - INFO - Epoch 240: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:17,216 - INFO - ####################Training epoch 241####################
2025-02-01 18:49:17,591 - INFO - Epoch 241: train_loss=nan
2025-02-01 18:49:17,748 - INFO - Epoch 241: train_loss=nan
2025-02-01 18:49:17,881 - INFO - Epoch 241: train_loss=nan
2025-02-01 18:49:18,274 - INFO - Epoch 241: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:18,278 - INFO - ####################Training epoch 242####################
2025-02-01 18:49:18,656 - INFO - Epoch 242: train_loss=nan
2025-02-01 18:49:18,812 - INFO - Epoch 242: train_loss=nan
2025-02-01 18:49:18,945 - INFO - Epoch 242: train_loss=nan
2025-02-01 18:49:19,345 - INFO - Epoch 242: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:19,348 - INFO - ####################Training epoch 243####################
2025-02-01 18:49:19,725 - INFO - Epoch 243: train_loss=nan
2025-02-01 18:49:19,882 - INFO - Epoch 243: train_loss=nan
2025-02-01 18:49:20,016 - INFO - Epoch 243: train_loss=nan
2025-02-01 18:49:20,410 - INFO - Epoch 243: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:20,414 - INFO - ####################Training epoch 244####################
2025-02-01 18:49:20,789 - INFO - Epoch 244: train_loss=nan
2025-02-01 18:49:20,946 - INFO - Epoch 244: train_loss=nan
2025-02-01 18:49:21,080 - INFO - Epoch 244: train_loss=nan
2025-02-01 18:49:21,476 - INFO - Epoch 244: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:21,480 - INFO - ####################Training epoch 245####################
2025-02-01 18:49:21,854 - INFO - Epoch 245: train_loss=nan
2025-02-01 18:49:22,010 - INFO - Epoch 245: train_loss=nan
2025-02-01 18:49:22,143 - INFO - Epoch 245: train_loss=nan
2025-02-01 18:49:22,539 - INFO - Epoch 245: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:22,542 - INFO - ####################Training epoch 246####################
2025-02-01 18:49:22,922 - INFO - Epoch 246: train_loss=nan
2025-02-01 18:49:23,079 - INFO - Epoch 246: train_loss=nan
2025-02-01 18:49:23,212 - INFO - Epoch 246: train_loss=nan
2025-02-01 18:49:23,604 - INFO - Epoch 246: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:23,607 - INFO - ####################Training epoch 247####################
2025-02-01 18:49:23,980 - INFO - Epoch 247: train_loss=nan
2025-02-01 18:49:24,137 - INFO - Epoch 247: train_loss=nan
2025-02-01 18:49:24,269 - INFO - Epoch 247: train_loss=nan
2025-02-01 18:49:24,667 - INFO - Epoch 247: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:24,674 - INFO - ####################Training epoch 248####################
2025-02-01 18:49:25,049 - INFO - Epoch 248: train_loss=nan
2025-02-01 18:49:25,206 - INFO - Epoch 248: train_loss=nan
2025-02-01 18:49:25,340 - INFO - Epoch 248: train_loss=nan
2025-02-01 18:49:25,736 - INFO - Epoch 248: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:25,740 - INFO - ####################Training epoch 249####################
2025-02-01 18:49:26,119 - INFO - Epoch 249: train_loss=nan
2025-02-01 18:49:26,275 - INFO - Epoch 249: train_loss=nan
2025-02-01 18:49:26,408 - INFO - Epoch 249: train_loss=nan
2025-02-01 18:49:26,802 - INFO - Epoch 249: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:26,806 - INFO - ####################Training epoch 250####################
2025-02-01 18:49:27,185 - INFO - Epoch 250: train_loss=nan
2025-02-01 18:49:27,341 - INFO - Epoch 250: train_loss=nan
2025-02-01 18:49:27,475 - INFO - Epoch 250: train_loss=nan
2025-02-01 18:49:27,877 - INFO - Epoch 250: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:27,881 - INFO - ####################Training epoch 251####################
2025-02-01 18:49:28,255 - INFO - Epoch 251: train_loss=nan
2025-02-01 18:49:28,411 - INFO - Epoch 251: train_loss=nan
2025-02-01 18:49:28,545 - INFO - Epoch 251: train_loss=nan
2025-02-01 18:49:28,943 - INFO - Epoch 251: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:28,946 - INFO - ####################Training epoch 252####################
2025-02-01 18:49:29,324 - INFO - Epoch 252: train_loss=nan
2025-02-01 18:49:29,481 - INFO - Epoch 252: train_loss=nan
2025-02-01 18:49:29,614 - INFO - Epoch 252: train_loss=nan
2025-02-01 18:49:30,012 - INFO - Epoch 252: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:30,015 - INFO - ####################Training epoch 253####################
2025-02-01 18:49:30,392 - INFO - Epoch 253: train_loss=nan
2025-02-01 18:49:30,548 - INFO - Epoch 253: train_loss=nan
2025-02-01 18:49:30,682 - INFO - Epoch 253: train_loss=nan
2025-02-01 18:49:31,079 - INFO - Epoch 253: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:31,082 - INFO - ####################Training epoch 254####################
2025-02-01 18:49:31,456 - INFO - Epoch 254: train_loss=nan
2025-02-01 18:49:31,613 - INFO - Epoch 254: train_loss=nan
2025-02-01 18:49:31,746 - INFO - Epoch 254: train_loss=nan
2025-02-01 18:49:32,147 - INFO - Epoch 254: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:32,151 - INFO - ####################Training epoch 255####################
2025-02-01 18:49:32,526 - INFO - Epoch 255: train_loss=nan
2025-02-01 18:49:32,682 - INFO - Epoch 255: train_loss=nan
2025-02-01 18:49:32,816 - INFO - Epoch 255: train_loss=nan
2025-02-01 18:49:33,212 - INFO - Epoch 255: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:33,215 - INFO - ####################Training epoch 256####################
2025-02-01 18:49:33,590 - INFO - Epoch 256: train_loss=nan
2025-02-01 18:49:33,747 - INFO - Epoch 256: train_loss=nan
2025-02-01 18:49:33,880 - INFO - Epoch 256: train_loss=nan
2025-02-01 18:49:34,274 - INFO - Epoch 256: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:34,277 - INFO - ####################Training epoch 257####################
2025-02-01 18:49:34,652 - INFO - Epoch 257: train_loss=nan
2025-02-01 18:49:34,808 - INFO - Epoch 257: train_loss=nan
2025-02-01 18:49:34,942 - INFO - Epoch 257: train_loss=nan
2025-02-01 18:49:35,339 - INFO - Epoch 257: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:35,343 - INFO - ####################Training epoch 258####################
2025-02-01 18:49:35,716 - INFO - Epoch 258: train_loss=nan
2025-02-01 18:49:35,872 - INFO - Epoch 258: train_loss=nan
2025-02-01 18:49:36,005 - INFO - Epoch 258: train_loss=nan
2025-02-01 18:49:36,403 - INFO - Epoch 258: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:36,407 - INFO - ####################Training epoch 259####################
2025-02-01 18:49:36,782 - INFO - Epoch 259: train_loss=nan
2025-02-01 18:49:36,938 - INFO - Epoch 259: train_loss=nan
2025-02-01 18:49:37,071 - INFO - Epoch 259: train_loss=nan
2025-02-01 18:49:37,465 - INFO - Epoch 259: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:37,469 - INFO - ####################Training epoch 260####################
2025-02-01 18:49:37,843 - INFO - Epoch 260: train_loss=nan
2025-02-01 18:49:38,000 - INFO - Epoch 260: train_loss=nan
2025-02-01 18:49:38,133 - INFO - Epoch 260: train_loss=nan
2025-02-01 18:49:38,532 - INFO - Epoch 260: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:38,535 - INFO - ####################Training epoch 261####################
2025-02-01 18:49:38,908 - INFO - Epoch 261: train_loss=nan
2025-02-01 18:49:39,065 - INFO - Epoch 261: train_loss=nan
2025-02-01 18:49:39,198 - INFO - Epoch 261: train_loss=nan
2025-02-01 18:49:39,591 - INFO - Epoch 261: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:39,595 - INFO - ####################Training epoch 262####################
2025-02-01 18:49:39,971 - INFO - Epoch 262: train_loss=nan
2025-02-01 18:49:40,127 - INFO - Epoch 262: train_loss=nan
2025-02-01 18:49:40,260 - INFO - Epoch 262: train_loss=nan
2025-02-01 18:49:40,657 - INFO - Epoch 262: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:40,660 - INFO - ####################Training epoch 263####################
2025-02-01 18:49:41,033 - INFO - Epoch 263: train_loss=nan
2025-02-01 18:49:41,190 - INFO - Epoch 263: train_loss=nan
2025-02-01 18:49:41,322 - INFO - Epoch 263: train_loss=nan
2025-02-01 18:49:41,717 - INFO - Epoch 263: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:41,720 - INFO - ####################Training epoch 264####################
2025-02-01 18:49:42,095 - INFO - Epoch 264: train_loss=nan
2025-02-01 18:49:42,252 - INFO - Epoch 264: train_loss=nan
2025-02-01 18:49:42,385 - INFO - Epoch 264: train_loss=nan
2025-02-01 18:49:42,782 - INFO - Epoch 264: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:42,786 - INFO - ####################Training epoch 265####################
2025-02-01 18:49:43,159 - INFO - Epoch 265: train_loss=nan
2025-02-01 18:49:43,315 - INFO - Epoch 265: train_loss=nan
2025-02-01 18:49:43,449 - INFO - Epoch 265: train_loss=nan
2025-02-01 18:49:43,842 - INFO - Epoch 265: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:43,846 - INFO - ####################Training epoch 266####################
2025-02-01 18:49:44,219 - INFO - Epoch 266: train_loss=nan
2025-02-01 18:49:44,376 - INFO - Epoch 266: train_loss=nan
2025-02-01 18:49:44,510 - INFO - Epoch 266: train_loss=nan
2025-02-01 18:49:44,906 - INFO - Epoch 266: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:44,910 - INFO - ####################Training epoch 267####################
2025-02-01 18:49:45,287 - INFO - Epoch 267: train_loss=nan
2025-02-01 18:49:45,443 - INFO - Epoch 267: train_loss=nan
2025-02-01 18:49:45,577 - INFO - Epoch 267: train_loss=nan
2025-02-01 18:49:45,971 - INFO - Epoch 267: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:45,975 - INFO - ####################Training epoch 268####################
2025-02-01 18:49:46,356 - INFO - Epoch 268: train_loss=nan
2025-02-01 18:49:46,512 - INFO - Epoch 268: train_loss=nan
2025-02-01 18:49:46,646 - INFO - Epoch 268: train_loss=nan
2025-02-01 18:49:47,042 - INFO - Epoch 268: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:47,046 - INFO - ####################Training epoch 269####################
2025-02-01 18:49:47,421 - INFO - Epoch 269: train_loss=nan
2025-02-01 18:49:47,578 - INFO - Epoch 269: train_loss=nan
2025-02-01 18:49:47,712 - INFO - Epoch 269: train_loss=nan
2025-02-01 18:49:48,107 - INFO - Epoch 269: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:48,111 - INFO - ####################Training epoch 270####################
2025-02-01 18:49:48,485 - INFO - Epoch 270: train_loss=nan
2025-02-01 18:49:48,642 - INFO - Epoch 270: train_loss=nan
2025-02-01 18:49:48,775 - INFO - Epoch 270: train_loss=nan
2025-02-01 18:49:49,170 - INFO - Epoch 270: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:49,173 - INFO - ####################Training epoch 271####################
2025-02-01 18:49:49,547 - INFO - Epoch 271: train_loss=nan
2025-02-01 18:49:49,704 - INFO - Epoch 271: train_loss=nan
2025-02-01 18:49:49,837 - INFO - Epoch 271: train_loss=nan
2025-02-01 18:49:50,235 - INFO - Epoch 271: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:50,239 - INFO - ####################Training epoch 272####################
2025-02-01 18:49:50,612 - INFO - Epoch 272: train_loss=nan
2025-02-01 18:49:50,768 - INFO - Epoch 272: train_loss=nan
2025-02-01 18:49:50,901 - INFO - Epoch 272: train_loss=nan
2025-02-01 18:49:51,297 - INFO - Epoch 272: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:51,304 - INFO - ####################Training epoch 273####################
2025-02-01 18:49:51,679 - INFO - Epoch 273: train_loss=nan
2025-02-01 18:49:51,836 - INFO - Epoch 273: train_loss=nan
2025-02-01 18:49:51,969 - INFO - Epoch 273: train_loss=nan
2025-02-01 18:49:52,372 - INFO - Epoch 273: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:52,376 - INFO - ####################Training epoch 274####################
2025-02-01 18:49:52,753 - INFO - Epoch 274: train_loss=nan
2025-02-01 18:49:52,910 - INFO - Epoch 274: train_loss=nan
2025-02-01 18:49:53,043 - INFO - Epoch 274: train_loss=nan
2025-02-01 18:49:53,440 - INFO - Epoch 274: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:53,444 - INFO - ####################Training epoch 275####################
2025-02-01 18:49:53,817 - INFO - Epoch 275: train_loss=nan
2025-02-01 18:49:53,974 - INFO - Epoch 275: train_loss=nan
2025-02-01 18:49:54,107 - INFO - Epoch 275: train_loss=nan
2025-02-01 18:49:54,506 - INFO - Epoch 275: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:54,509 - INFO - ####################Training epoch 276####################
2025-02-01 18:49:54,884 - INFO - Epoch 276: train_loss=nan
2025-02-01 18:49:55,041 - INFO - Epoch 276: train_loss=nan
2025-02-01 18:49:55,174 - INFO - Epoch 276: train_loss=nan
2025-02-01 18:49:55,572 - INFO - Epoch 276: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:55,576 - INFO - ####################Training epoch 277####################
2025-02-01 18:49:55,951 - INFO - Epoch 277: train_loss=nan
2025-02-01 18:49:56,107 - INFO - Epoch 277: train_loss=nan
2025-02-01 18:49:56,240 - INFO - Epoch 277: train_loss=nan
2025-02-01 18:49:56,635 - INFO - Epoch 277: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:56,639 - INFO - ####################Training epoch 278####################
2025-02-01 18:49:57,014 - INFO - Epoch 278: train_loss=nan
2025-02-01 18:49:57,170 - INFO - Epoch 278: train_loss=nan
2025-02-01 18:49:57,304 - INFO - Epoch 278: train_loss=nan
2025-02-01 18:49:57,696 - INFO - Epoch 278: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:57,700 - INFO - ####################Training epoch 279####################
2025-02-01 18:49:58,072 - INFO - Epoch 279: train_loss=nan
2025-02-01 18:49:58,228 - INFO - Epoch 279: train_loss=nan
2025-02-01 18:49:58,361 - INFO - Epoch 279: train_loss=nan
2025-02-01 18:49:58,754 - INFO - Epoch 279: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:58,758 - INFO - ####################Training epoch 280####################
2025-02-01 18:49:59,135 - INFO - Epoch 280: train_loss=nan
2025-02-01 18:49:59,292 - INFO - Epoch 280: train_loss=nan
2025-02-01 18:49:59,426 - INFO - Epoch 280: train_loss=nan
2025-02-01 18:49:59,825 - INFO - Epoch 280: val_loss=nan, val_acc=66.67%
2025-02-01 18:49:59,828 - INFO - ####################Training epoch 281####################
2025-02-01 18:50:00,199 - INFO - Epoch 281: train_loss=nan
2025-02-01 18:50:00,357 - INFO - Epoch 281: train_loss=nan
2025-02-01 18:50:00,490 - INFO - Epoch 281: train_loss=nan
2025-02-01 18:50:00,890 - INFO - Epoch 281: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:00,894 - INFO - ####################Training epoch 282####################
2025-02-01 18:50:01,268 - INFO - Epoch 282: train_loss=nan
2025-02-01 18:50:01,424 - INFO - Epoch 282: train_loss=nan
2025-02-01 18:50:01,557 - INFO - Epoch 282: train_loss=nan
2025-02-01 18:50:01,951 - INFO - Epoch 282: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:01,955 - INFO - ####################Training epoch 283####################
2025-02-01 18:50:02,330 - INFO - Epoch 283: train_loss=nan
2025-02-01 18:50:02,486 - INFO - Epoch 283: train_loss=nan
2025-02-01 18:50:02,619 - INFO - Epoch 283: train_loss=nan
2025-02-01 18:50:03,014 - INFO - Epoch 283: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:03,018 - INFO - ####################Training epoch 284####################
2025-02-01 18:50:03,393 - INFO - Epoch 284: train_loss=nan
2025-02-01 18:50:03,550 - INFO - Epoch 284: train_loss=nan
2025-02-01 18:50:03,683 - INFO - Epoch 284: train_loss=nan
2025-02-01 18:50:04,079 - INFO - Epoch 284: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:04,083 - INFO - ####################Training epoch 285####################
2025-02-01 18:50:04,459 - INFO - Epoch 285: train_loss=nan
2025-02-01 18:50:04,616 - INFO - Epoch 285: train_loss=nan
2025-02-01 18:50:04,749 - INFO - Epoch 285: train_loss=nan
2025-02-01 18:50:05,143 - INFO - Epoch 285: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:05,147 - INFO - ####################Training epoch 286####################
2025-02-01 18:50:05,522 - INFO - Epoch 286: train_loss=nan
2025-02-01 18:50:05,678 - INFO - Epoch 286: train_loss=nan
2025-02-01 18:50:05,811 - INFO - Epoch 286: train_loss=nan
2025-02-01 18:50:06,208 - INFO - Epoch 286: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:06,211 - INFO - ####################Training epoch 287####################
2025-02-01 18:50:06,588 - INFO - Epoch 287: train_loss=nan
2025-02-01 18:50:06,745 - INFO - Epoch 287: train_loss=nan
2025-02-01 18:50:06,878 - INFO - Epoch 287: train_loss=nan
2025-02-01 18:50:07,277 - INFO - Epoch 287: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:07,281 - INFO - ####################Training epoch 288####################
2025-02-01 18:50:07,658 - INFO - Epoch 288: train_loss=nan
2025-02-01 18:50:07,815 - INFO - Epoch 288: train_loss=nan
2025-02-01 18:50:07,948 - INFO - Epoch 288: train_loss=nan
2025-02-01 18:50:08,342 - INFO - Epoch 288: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:08,346 - INFO - ####################Training epoch 289####################
2025-02-01 18:50:08,721 - INFO - Epoch 289: train_loss=nan
2025-02-01 18:50:08,878 - INFO - Epoch 289: train_loss=nan
2025-02-01 18:50:09,011 - INFO - Epoch 289: train_loss=nan
2025-02-01 18:50:09,408 - INFO - Epoch 289: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:09,412 - INFO - ####################Training epoch 290####################
2025-02-01 18:50:09,788 - INFO - Epoch 290: train_loss=nan
2025-02-01 18:50:09,944 - INFO - Epoch 290: train_loss=nan
2025-02-01 18:50:10,077 - INFO - Epoch 290: train_loss=nan
2025-02-01 18:50:10,473 - INFO - Epoch 290: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:10,477 - INFO - ####################Training epoch 291####################
2025-02-01 18:50:10,853 - INFO - Epoch 291: train_loss=nan
2025-02-01 18:50:11,009 - INFO - Epoch 291: train_loss=nan
2025-02-01 18:50:11,142 - INFO - Epoch 291: train_loss=nan
2025-02-01 18:50:11,540 - INFO - Epoch 291: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:11,543 - INFO - ####################Training epoch 292####################
2025-02-01 18:50:11,918 - INFO - Epoch 292: train_loss=nan
2025-02-01 18:50:12,075 - INFO - Epoch 292: train_loss=nan
2025-02-01 18:50:12,208 - INFO - Epoch 292: train_loss=nan
2025-02-01 18:50:12,605 - INFO - Epoch 292: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:12,609 - INFO - ####################Training epoch 293####################
2025-02-01 18:50:12,980 - INFO - Epoch 293: train_loss=nan
2025-02-01 18:50:13,136 - INFO - Epoch 293: train_loss=nan
2025-02-01 18:50:13,270 - INFO - Epoch 293: train_loss=nan
2025-02-01 18:50:13,665 - INFO - Epoch 293: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:13,668 - INFO - ####################Training epoch 294####################
2025-02-01 18:50:14,045 - INFO - Epoch 294: train_loss=nan
2025-02-01 18:50:14,202 - INFO - Epoch 294: train_loss=nan
2025-02-01 18:50:14,335 - INFO - Epoch 294: train_loss=nan
2025-02-01 18:50:14,730 - INFO - Epoch 294: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:14,734 - INFO - ####################Training epoch 295####################
2025-02-01 18:50:15,108 - INFO - Epoch 295: train_loss=nan
2025-02-01 18:50:15,265 - INFO - Epoch 295: train_loss=nan
2025-02-01 18:50:15,398 - INFO - Epoch 295: train_loss=nan
2025-02-01 18:50:15,797 - INFO - Epoch 295: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:15,800 - INFO - ####################Training epoch 296####################
2025-02-01 18:50:16,175 - INFO - Epoch 296: train_loss=nan
2025-02-01 18:50:16,332 - INFO - Epoch 296: train_loss=nan
2025-02-01 18:50:16,465 - INFO - Epoch 296: train_loss=nan
2025-02-01 18:50:16,861 - INFO - Epoch 296: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:16,865 - INFO - ####################Training epoch 297####################
2025-02-01 18:50:17,242 - INFO - Epoch 297: train_loss=nan
2025-02-01 18:50:17,398 - INFO - Epoch 297: train_loss=nan
2025-02-01 18:50:17,531 - INFO - Epoch 297: train_loss=nan
2025-02-01 18:50:17,925 - INFO - Epoch 297: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:17,932 - INFO - ####################Training epoch 298####################
2025-02-01 18:50:18,306 - INFO - Epoch 298: train_loss=nan
2025-02-01 18:50:18,463 - INFO - Epoch 298: train_loss=nan
2025-02-01 18:50:18,596 - INFO - Epoch 298: train_loss=nan
2025-02-01 18:50:18,989 - INFO - Epoch 298: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:18,993 - INFO - ####################Training epoch 299####################
2025-02-01 18:50:19,372 - INFO - Epoch 299: train_loss=nan
2025-02-01 18:50:19,529 - INFO - Epoch 299: train_loss=nan
2025-02-01 18:50:19,662 - INFO - Epoch 299: train_loss=nan
2025-02-01 18:50:20,056 - INFO - Epoch 299: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:20,060 - INFO - ####################Training epoch 300####################
2025-02-01 18:50:20,432 - INFO - Epoch 300: train_loss=nan
2025-02-01 18:50:20,589 - INFO - Epoch 300: train_loss=nan
2025-02-01 18:50:20,722 - INFO - Epoch 300: train_loss=nan
2025-02-01 18:50:21,115 - INFO - Epoch 300: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:21,119 - INFO - ####################Training epoch 301####################
2025-02-01 18:50:21,493 - INFO - Epoch 301: train_loss=nan
2025-02-01 18:50:21,649 - INFO - Epoch 301: train_loss=nan
2025-02-01 18:50:21,783 - INFO - Epoch 301: train_loss=nan
2025-02-01 18:50:22,180 - INFO - Epoch 301: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:22,184 - INFO - ####################Training epoch 302####################
2025-02-01 18:50:22,558 - INFO - Epoch 302: train_loss=nan
2025-02-01 18:50:22,714 - INFO - Epoch 302: train_loss=nan
2025-02-01 18:50:22,847 - INFO - Epoch 302: train_loss=nan
2025-02-01 18:50:23,244 - INFO - Epoch 302: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:23,248 - INFO - ####################Training epoch 303####################
2025-02-01 18:50:23,624 - INFO - Epoch 303: train_loss=nan
2025-02-01 18:50:23,780 - INFO - Epoch 303: train_loss=nan
2025-02-01 18:50:23,913 - INFO - Epoch 303: train_loss=nan
2025-02-01 18:50:24,308 - INFO - Epoch 303: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:24,311 - INFO - ####################Training epoch 304####################
2025-02-01 18:50:24,687 - INFO - Epoch 304: train_loss=nan
2025-02-01 18:50:24,843 - INFO - Epoch 304: train_loss=nan
2025-02-01 18:50:24,977 - INFO - Epoch 304: train_loss=nan
2025-02-01 18:50:25,376 - INFO - Epoch 304: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:25,379 - INFO - ####################Training epoch 305####################
2025-02-01 18:50:25,754 - INFO - Epoch 305: train_loss=nan
2025-02-01 18:50:25,911 - INFO - Epoch 305: train_loss=nan
2025-02-01 18:50:26,044 - INFO - Epoch 305: train_loss=nan
2025-02-01 18:50:26,441 - INFO - Epoch 305: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:26,445 - INFO - ####################Training epoch 306####################
2025-02-01 18:50:26,820 - INFO - Epoch 306: train_loss=nan
2025-02-01 18:50:26,976 - INFO - Epoch 306: train_loss=nan
2025-02-01 18:50:27,109 - INFO - Epoch 306: train_loss=nan
2025-02-01 18:50:27,507 - INFO - Epoch 306: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:27,510 - INFO - ####################Training epoch 307####################
2025-02-01 18:50:27,890 - INFO - Epoch 307: train_loss=nan
2025-02-01 18:50:28,047 - INFO - Epoch 307: train_loss=nan
2025-02-01 18:50:28,180 - INFO - Epoch 307: train_loss=nan
2025-02-01 18:50:28,573 - INFO - Epoch 307: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:28,576 - INFO - ####################Training epoch 308####################
2025-02-01 18:50:28,948 - INFO - Epoch 308: train_loss=nan
2025-02-01 18:50:29,106 - INFO - Epoch 308: train_loss=nan
2025-02-01 18:50:29,239 - INFO - Epoch 308: train_loss=nan
2025-02-01 18:50:29,635 - INFO - Epoch 308: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:29,638 - INFO - ####################Training epoch 309####################
2025-02-01 18:50:30,013 - INFO - Epoch 309: train_loss=nan
2025-02-01 18:50:30,169 - INFO - Epoch 309: train_loss=nan
2025-02-01 18:50:30,303 - INFO - Epoch 309: train_loss=nan
2025-02-01 18:50:30,700 - INFO - Epoch 309: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:30,704 - INFO - ####################Training epoch 310####################
2025-02-01 18:50:31,079 - INFO - Epoch 310: train_loss=nan
2025-02-01 18:50:31,235 - INFO - Epoch 310: train_loss=nan
2025-02-01 18:50:31,368 - INFO - Epoch 310: train_loss=nan
2025-02-01 18:50:31,764 - INFO - Epoch 310: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:31,768 - INFO - ####################Training epoch 311####################
2025-02-01 18:50:32,142 - INFO - Epoch 311: train_loss=nan
2025-02-01 18:50:32,298 - INFO - Epoch 311: train_loss=nan
2025-02-01 18:50:32,431 - INFO - Epoch 311: train_loss=nan
2025-02-01 18:50:32,825 - INFO - Epoch 311: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:32,828 - INFO - ####################Training epoch 312####################
2025-02-01 18:50:33,206 - INFO - Epoch 312: train_loss=nan
2025-02-01 18:50:33,363 - INFO - Epoch 312: train_loss=nan
2025-02-01 18:50:33,497 - INFO - Epoch 312: train_loss=nan
2025-02-01 18:50:33,892 - INFO - Epoch 312: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:33,895 - INFO - ####################Training epoch 313####################
2025-02-01 18:50:34,272 - INFO - Epoch 313: train_loss=nan
2025-02-01 18:50:34,429 - INFO - Epoch 313: train_loss=nan
2025-02-01 18:50:34,562 - INFO - Epoch 313: train_loss=nan
2025-02-01 18:50:34,960 - INFO - Epoch 313: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:34,964 - INFO - ####################Training epoch 314####################
2025-02-01 18:50:35,338 - INFO - Epoch 314: train_loss=nan
2025-02-01 18:50:35,494 - INFO - Epoch 314: train_loss=nan
2025-02-01 18:50:35,627 - INFO - Epoch 314: train_loss=nan
2025-02-01 18:50:36,022 - INFO - Epoch 314: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:36,026 - INFO - ####################Training epoch 315####################
2025-02-01 18:50:36,400 - INFO - Epoch 315: train_loss=nan
2025-02-01 18:50:36,557 - INFO - Epoch 315: train_loss=nan
2025-02-01 18:50:36,690 - INFO - Epoch 315: train_loss=nan
2025-02-01 18:50:37,082 - INFO - Epoch 315: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:37,086 - INFO - ####################Training epoch 316####################
2025-02-01 18:50:37,464 - INFO - Epoch 316: train_loss=nan
2025-02-01 18:50:37,621 - INFO - Epoch 316: train_loss=nan
2025-02-01 18:50:37,755 - INFO - Epoch 316: train_loss=nan
2025-02-01 18:50:38,149 - INFO - Epoch 316: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:38,153 - INFO - ####################Training epoch 317####################
2025-02-01 18:50:38,528 - INFO - Epoch 317: train_loss=nan
2025-02-01 18:50:38,684 - INFO - Epoch 317: train_loss=nan
2025-02-01 18:50:38,818 - INFO - Epoch 317: train_loss=nan
2025-02-01 18:50:39,217 - INFO - Epoch 317: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:39,221 - INFO - ####################Training epoch 318####################
2025-02-01 18:50:39,600 - INFO - Epoch 318: train_loss=nan
2025-02-01 18:50:39,757 - INFO - Epoch 318: train_loss=nan
2025-02-01 18:50:39,890 - INFO - Epoch 318: train_loss=nan
2025-02-01 18:50:40,288 - INFO - Epoch 318: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:40,292 - INFO - ####################Training epoch 319####################
2025-02-01 18:50:40,671 - INFO - Epoch 319: train_loss=nan
2025-02-01 18:50:40,827 - INFO - Epoch 319: train_loss=nan
2025-02-01 18:50:40,960 - INFO - Epoch 319: train_loss=nan
2025-02-01 18:50:41,357 - INFO - Epoch 319: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:41,360 - INFO - ####################Training epoch 320####################
2025-02-01 18:50:41,738 - INFO - Epoch 320: train_loss=nan
2025-02-01 18:50:41,895 - INFO - Epoch 320: train_loss=nan
2025-02-01 18:50:42,028 - INFO - Epoch 320: train_loss=nan
2025-02-01 18:50:42,425 - INFO - Epoch 320: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:42,429 - INFO - ####################Training epoch 321####################
2025-02-01 18:50:42,804 - INFO - Epoch 321: train_loss=nan
2025-02-01 18:50:42,960 - INFO - Epoch 321: train_loss=nan
2025-02-01 18:50:43,094 - INFO - Epoch 321: train_loss=nan
2025-02-01 18:50:43,495 - INFO - Epoch 321: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:43,498 - INFO - ####################Training epoch 322####################
2025-02-01 18:50:43,876 - INFO - Epoch 322: train_loss=nan
2025-02-01 18:50:44,033 - INFO - Epoch 322: train_loss=nan
2025-02-01 18:50:44,166 - INFO - Epoch 322: train_loss=nan
2025-02-01 18:50:44,563 - INFO - Epoch 322: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:44,567 - INFO - ####################Training epoch 323####################
2025-02-01 18:50:44,944 - INFO - Epoch 323: train_loss=nan
2025-02-01 18:50:45,101 - INFO - Epoch 323: train_loss=nan
2025-02-01 18:50:45,234 - INFO - Epoch 323: train_loss=nan
2025-02-01 18:50:45,629 - INFO - Epoch 323: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:45,633 - INFO - ####################Training epoch 324####################
2025-02-01 18:50:46,012 - INFO - Epoch 324: train_loss=nan
2025-02-01 18:50:46,169 - INFO - Epoch 324: train_loss=nan
2025-02-01 18:50:46,302 - INFO - Epoch 324: train_loss=nan
2025-02-01 18:50:46,697 - INFO - Epoch 324: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:46,701 - INFO - ####################Training epoch 325####################
2025-02-01 18:50:47,078 - INFO - Epoch 325: train_loss=nan
2025-02-01 18:50:47,235 - INFO - Epoch 325: train_loss=nan
2025-02-01 18:50:47,368 - INFO - Epoch 325: train_loss=nan
2025-02-01 18:50:47,764 - INFO - Epoch 325: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:47,767 - INFO - ####################Training epoch 326####################
2025-02-01 18:50:48,145 - INFO - Epoch 326: train_loss=nan
2025-02-01 18:50:48,302 - INFO - Epoch 326: train_loss=nan
2025-02-01 18:50:48,435 - INFO - Epoch 326: train_loss=nan
2025-02-01 18:50:48,832 - INFO - Epoch 326: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:48,836 - INFO - ####################Training epoch 327####################
2025-02-01 18:50:49,211 - INFO - Epoch 327: train_loss=nan
2025-02-01 18:50:49,368 - INFO - Epoch 327: train_loss=nan
2025-02-01 18:50:49,501 - INFO - Epoch 327: train_loss=nan
2025-02-01 18:50:49,903 - INFO - Epoch 327: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:49,907 - INFO - ####################Training epoch 328####################
2025-02-01 18:50:50,287 - INFO - Epoch 328: train_loss=nan
2025-02-01 18:50:50,443 - INFO - Epoch 328: train_loss=nan
2025-02-01 18:50:50,577 - INFO - Epoch 328: train_loss=nan
2025-02-01 18:50:50,974 - INFO - Epoch 328: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:50,977 - INFO - ####################Training epoch 329####################
2025-02-01 18:50:51,350 - INFO - Epoch 329: train_loss=nan
2025-02-01 18:50:51,507 - INFO - Epoch 329: train_loss=nan
2025-02-01 18:50:51,640 - INFO - Epoch 329: train_loss=nan
2025-02-01 18:50:52,039 - INFO - Epoch 329: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:52,043 - INFO - ####################Training epoch 330####################
2025-02-01 18:50:52,419 - INFO - Epoch 330: train_loss=nan
2025-02-01 18:50:52,576 - INFO - Epoch 330: train_loss=nan
2025-02-01 18:50:52,709 - INFO - Epoch 330: train_loss=nan
2025-02-01 18:50:53,101 - INFO - Epoch 330: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:53,105 - INFO - ####################Training epoch 331####################
2025-02-01 18:50:53,480 - INFO - Epoch 331: train_loss=nan
2025-02-01 18:50:53,637 - INFO - Epoch 331: train_loss=nan
2025-02-01 18:50:53,771 - INFO - Epoch 331: train_loss=nan
2025-02-01 18:50:54,166 - INFO - Epoch 331: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:54,169 - INFO - ####################Training epoch 332####################
2025-02-01 18:50:54,544 - INFO - Epoch 332: train_loss=nan
2025-02-01 18:50:54,701 - INFO - Epoch 332: train_loss=nan
2025-02-01 18:50:54,834 - INFO - Epoch 332: train_loss=nan
2025-02-01 18:50:55,231 - INFO - Epoch 332: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:55,234 - INFO - ####################Training epoch 333####################
2025-02-01 18:50:55,608 - INFO - Epoch 333: train_loss=nan
2025-02-01 18:50:55,764 - INFO - Epoch 333: train_loss=nan
2025-02-01 18:50:55,897 - INFO - Epoch 333: train_loss=nan
2025-02-01 18:50:56,292 - INFO - Epoch 333: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:56,296 - INFO - ####################Training epoch 334####################
2025-02-01 18:50:56,671 - INFO - Epoch 334: train_loss=nan
2025-02-01 18:50:56,828 - INFO - Epoch 334: train_loss=nan
2025-02-01 18:50:56,961 - INFO - Epoch 334: train_loss=nan
2025-02-01 18:50:57,358 - INFO - Epoch 334: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:57,362 - INFO - ####################Training epoch 335####################
2025-02-01 18:50:57,734 - INFO - Epoch 335: train_loss=nan
2025-02-01 18:50:57,891 - INFO - Epoch 335: train_loss=nan
2025-02-01 18:50:58,023 - INFO - Epoch 335: train_loss=nan
2025-02-01 18:50:58,422 - INFO - Epoch 335: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:58,426 - INFO - ####################Training epoch 336####################
2025-02-01 18:50:58,802 - INFO - Epoch 336: train_loss=nan
2025-02-01 18:50:58,959 - INFO - Epoch 336: train_loss=nan
2025-02-01 18:50:59,093 - INFO - Epoch 336: train_loss=nan
2025-02-01 18:50:59,487 - INFO - Epoch 336: val_loss=nan, val_acc=66.67%
2025-02-01 18:50:59,491 - INFO - ####################Training epoch 337####################
2025-02-01 18:50:59,869 - INFO - Epoch 337: train_loss=nan
2025-02-01 18:51:00,025 - INFO - Epoch 337: train_loss=nan
2025-02-01 18:51:00,158 - INFO - Epoch 337: train_loss=nan
2025-02-01 18:51:00,555 - INFO - Epoch 337: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:00,559 - INFO - ####################Training epoch 338####################
2025-02-01 18:51:00,937 - INFO - Epoch 338: train_loss=nan
2025-02-01 18:51:01,094 - INFO - Epoch 338: train_loss=nan
2025-02-01 18:51:01,228 - INFO - Epoch 338: train_loss=nan
2025-02-01 18:51:01,715 - INFO - Epoch 338: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:01,718 - INFO - ####################Training epoch 339####################
2025-02-01 18:51:02,097 - INFO - Epoch 339: train_loss=nan
2025-02-01 18:51:02,254 - INFO - Epoch 339: train_loss=nan
2025-02-01 18:51:02,388 - INFO - Epoch 339: train_loss=nan
2025-02-01 18:51:02,784 - INFO - Epoch 339: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:02,788 - INFO - ####################Training epoch 340####################
2025-02-01 18:51:03,161 - INFO - Epoch 340: train_loss=nan
2025-02-01 18:51:03,318 - INFO - Epoch 340: train_loss=nan
2025-02-01 18:51:03,452 - INFO - Epoch 340: train_loss=nan
2025-02-01 18:51:03,850 - INFO - Epoch 340: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:03,854 - INFO - ####################Training epoch 341####################
2025-02-01 18:51:04,231 - INFO - Epoch 341: train_loss=nan
2025-02-01 18:51:04,388 - INFO - Epoch 341: train_loss=nan
2025-02-01 18:51:04,521 - INFO - Epoch 341: train_loss=nan
2025-02-01 18:51:04,921 - INFO - Epoch 341: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:04,925 - INFO - ####################Training epoch 342####################
2025-02-01 18:51:05,307 - INFO - Epoch 342: train_loss=nan
2025-02-01 18:51:05,463 - INFO - Epoch 342: train_loss=nan
2025-02-01 18:51:05,596 - INFO - Epoch 342: train_loss=nan
2025-02-01 18:51:05,993 - INFO - Epoch 342: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:05,997 - INFO - ####################Training epoch 343####################
2025-02-01 18:51:06,374 - INFO - Epoch 343: train_loss=nan
2025-02-01 18:51:06,531 - INFO - Epoch 343: train_loss=nan
2025-02-01 18:51:06,664 - INFO - Epoch 343: train_loss=nan
2025-02-01 18:51:07,062 - INFO - Epoch 343: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:07,066 - INFO - ####################Training epoch 344####################
2025-02-01 18:51:07,446 - INFO - Epoch 344: train_loss=nan
2025-02-01 18:51:07,602 - INFO - Epoch 344: train_loss=nan
2025-02-01 18:51:07,735 - INFO - Epoch 344: train_loss=nan
2025-02-01 18:51:08,135 - INFO - Epoch 344: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:08,138 - INFO - ####################Training epoch 345####################
2025-02-01 18:51:08,514 - INFO - Epoch 345: train_loss=nan
2025-02-01 18:51:08,670 - INFO - Epoch 345: train_loss=nan
2025-02-01 18:51:08,804 - INFO - Epoch 345: train_loss=nan
2025-02-01 18:51:09,200 - INFO - Epoch 345: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:09,203 - INFO - ####################Training epoch 346####################
2025-02-01 18:51:09,581 - INFO - Epoch 346: train_loss=nan
2025-02-01 18:51:09,738 - INFO - Epoch 346: train_loss=nan
2025-02-01 18:51:09,871 - INFO - Epoch 346: train_loss=nan
2025-02-01 18:51:10,269 - INFO - Epoch 346: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:10,272 - INFO - ####################Training epoch 347####################
2025-02-01 18:51:10,650 - INFO - Epoch 347: train_loss=nan
2025-02-01 18:51:10,806 - INFO - Epoch 347: train_loss=nan
2025-02-01 18:51:10,939 - INFO - Epoch 347: train_loss=nan
2025-02-01 18:51:11,337 - INFO - Epoch 347: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:11,341 - INFO - ####################Training epoch 348####################
2025-02-01 18:51:11,718 - INFO - Epoch 348: train_loss=nan
2025-02-01 18:51:11,875 - INFO - Epoch 348: train_loss=nan
2025-02-01 18:51:12,008 - INFO - Epoch 348: train_loss=nan
2025-02-01 18:51:12,407 - INFO - Epoch 348: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:12,410 - INFO - ####################Training epoch 349####################
2025-02-01 18:51:12,788 - INFO - Epoch 349: train_loss=nan
2025-02-01 18:51:12,944 - INFO - Epoch 349: train_loss=nan
2025-02-01 18:51:13,077 - INFO - Epoch 349: train_loss=nan
2025-02-01 18:51:13,479 - INFO - Epoch 349: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:13,483 - INFO - ####################Training epoch 350####################
2025-02-01 18:51:13,858 - INFO - Epoch 350: train_loss=nan
2025-02-01 18:51:14,015 - INFO - Epoch 350: train_loss=nan
2025-02-01 18:51:14,148 - INFO - Epoch 350: train_loss=nan
2025-02-01 18:51:14,545 - INFO - Epoch 350: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:14,549 - INFO - ####################Training epoch 351####################
2025-02-01 18:51:14,934 - INFO - Epoch 351: train_loss=nan
2025-02-01 18:51:15,091 - INFO - Epoch 351: train_loss=nan
2025-02-01 18:51:15,224 - INFO - Epoch 351: train_loss=nan
2025-02-01 18:51:15,619 - INFO - Epoch 351: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:15,623 - INFO - ####################Training epoch 352####################
2025-02-01 18:51:16,000 - INFO - Epoch 352: train_loss=nan
2025-02-01 18:51:16,157 - INFO - Epoch 352: train_loss=nan
2025-02-01 18:51:16,290 - INFO - Epoch 352: train_loss=nan
2025-02-01 18:51:16,688 - INFO - Epoch 352: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:16,692 - INFO - ####################Training epoch 353####################
2025-02-01 18:51:17,070 - INFO - Epoch 353: train_loss=nan
2025-02-01 18:51:17,226 - INFO - Epoch 353: train_loss=nan
2025-02-01 18:51:17,359 - INFO - Epoch 353: train_loss=nan
2025-02-01 18:51:17,752 - INFO - Epoch 353: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:17,756 - INFO - ####################Training epoch 354####################
2025-02-01 18:51:18,133 - INFO - Epoch 354: train_loss=nan
2025-02-01 18:51:18,290 - INFO - Epoch 354: train_loss=nan
2025-02-01 18:51:18,423 - INFO - Epoch 354: train_loss=nan
2025-02-01 18:51:18,816 - INFO - Epoch 354: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:18,820 - INFO - ####################Training epoch 355####################
2025-02-01 18:51:19,199 - INFO - Epoch 355: train_loss=nan
2025-02-01 18:51:19,355 - INFO - Epoch 355: train_loss=nan
2025-02-01 18:51:19,489 - INFO - Epoch 355: train_loss=nan
2025-02-01 18:51:19,883 - INFO - Epoch 355: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:19,886 - INFO - ####################Training epoch 356####################
2025-02-01 18:51:20,261 - INFO - Epoch 356: train_loss=nan
2025-02-01 18:51:20,417 - INFO - Epoch 356: train_loss=nan
2025-02-01 18:51:20,550 - INFO - Epoch 356: train_loss=nan
2025-02-01 18:51:20,951 - INFO - Epoch 356: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:20,954 - INFO - ####################Training epoch 357####################
2025-02-01 18:51:21,329 - INFO - Epoch 357: train_loss=nan
2025-02-01 18:51:21,486 - INFO - Epoch 357: train_loss=nan
2025-02-01 18:51:21,619 - INFO - Epoch 357: train_loss=nan
2025-02-01 18:51:22,020 - INFO - Epoch 357: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:22,024 - INFO - ####################Training epoch 358####################
2025-02-01 18:51:22,400 - INFO - Epoch 358: train_loss=nan
2025-02-01 18:51:22,556 - INFO - Epoch 358: train_loss=nan
2025-02-01 18:51:22,690 - INFO - Epoch 358: train_loss=nan
2025-02-01 18:51:23,087 - INFO - Epoch 358: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:23,091 - INFO - ####################Training epoch 359####################
2025-02-01 18:51:23,467 - INFO - Epoch 359: train_loss=nan
2025-02-01 18:51:23,624 - INFO - Epoch 359: train_loss=nan
2025-02-01 18:51:23,758 - INFO - Epoch 359: train_loss=nan
2025-02-01 18:51:24,157 - INFO - Epoch 359: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:24,161 - INFO - ####################Training epoch 360####################
2025-02-01 18:51:24,535 - INFO - Epoch 360: train_loss=nan
2025-02-01 18:51:24,692 - INFO - Epoch 360: train_loss=nan
2025-02-01 18:51:24,825 - INFO - Epoch 360: train_loss=nan
2025-02-01 18:51:25,226 - INFO - Epoch 360: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:25,229 - INFO - ####################Training epoch 361####################
2025-02-01 18:51:25,608 - INFO - Epoch 361: train_loss=nan
2025-02-01 18:51:25,764 - INFO - Epoch 361: train_loss=nan
2025-02-01 18:51:25,898 - INFO - Epoch 361: train_loss=nan
2025-02-01 18:51:26,296 - INFO - Epoch 361: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:26,300 - INFO - ####################Training epoch 362####################
2025-02-01 18:51:26,677 - INFO - Epoch 362: train_loss=nan
2025-02-01 18:51:26,833 - INFO - Epoch 362: train_loss=nan
2025-02-01 18:51:26,967 - INFO - Epoch 362: train_loss=nan
2025-02-01 18:51:27,366 - INFO - Epoch 362: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:27,370 - INFO - ####################Training epoch 363####################
2025-02-01 18:51:27,746 - INFO - Epoch 363: train_loss=nan
2025-02-01 18:51:27,902 - INFO - Epoch 363: train_loss=nan
2025-02-01 18:51:28,035 - INFO - Epoch 363: train_loss=nan
2025-02-01 18:51:28,433 - INFO - Epoch 363: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:28,436 - INFO - ####################Training epoch 364####################
2025-02-01 18:51:28,814 - INFO - Epoch 364: train_loss=nan
2025-02-01 18:51:28,971 - INFO - Epoch 364: train_loss=nan
2025-02-01 18:51:29,105 - INFO - Epoch 364: train_loss=nan
2025-02-01 18:51:29,497 - INFO - Epoch 364: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:29,501 - INFO - ####################Training epoch 365####################
2025-02-01 18:51:29,876 - INFO - Epoch 365: train_loss=nan
2025-02-01 18:51:30,033 - INFO - Epoch 365: train_loss=nan
2025-02-01 18:51:30,166 - INFO - Epoch 365: train_loss=nan
2025-02-01 18:51:30,561 - INFO - Epoch 365: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:30,565 - INFO - ####################Training epoch 366####################
2025-02-01 18:51:30,943 - INFO - Epoch 366: train_loss=nan
2025-02-01 18:51:31,099 - INFO - Epoch 366: train_loss=nan
2025-02-01 18:51:31,232 - INFO - Epoch 366: train_loss=nan
2025-02-01 18:51:31,633 - INFO - Epoch 366: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:31,637 - INFO - ####################Training epoch 367####################
2025-02-01 18:51:32,015 - INFO - Epoch 367: train_loss=nan
2025-02-01 18:51:32,171 - INFO - Epoch 367: train_loss=nan
2025-02-01 18:51:32,304 - INFO - Epoch 367: train_loss=nan
2025-02-01 18:51:32,701 - INFO - Epoch 367: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:32,705 - INFO - ####################Training epoch 368####################
2025-02-01 18:51:33,081 - INFO - Epoch 368: train_loss=nan
2025-02-01 18:51:33,237 - INFO - Epoch 368: train_loss=nan
2025-02-01 18:51:33,370 - INFO - Epoch 368: train_loss=nan
2025-02-01 18:51:33,765 - INFO - Epoch 368: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:33,769 - INFO - ####################Training epoch 369####################
2025-02-01 18:51:34,146 - INFO - Epoch 369: train_loss=nan
2025-02-01 18:51:34,302 - INFO - Epoch 369: train_loss=nan
2025-02-01 18:51:34,436 - INFO - Epoch 369: train_loss=nan
2025-02-01 18:51:34,830 - INFO - Epoch 369: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:34,834 - INFO - ####################Training epoch 370####################
2025-02-01 18:51:35,213 - INFO - Epoch 370: train_loss=nan
2025-02-01 18:51:35,369 - INFO - Epoch 370: train_loss=nan
2025-02-01 18:51:35,503 - INFO - Epoch 370: train_loss=nan
2025-02-01 18:51:35,899 - INFO - Epoch 370: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:35,902 - INFO - ####################Training epoch 371####################
2025-02-01 18:51:36,277 - INFO - Epoch 371: train_loss=nan
2025-02-01 18:51:36,434 - INFO - Epoch 371: train_loss=nan
2025-02-01 18:51:36,567 - INFO - Epoch 371: train_loss=nan
2025-02-01 18:51:36,964 - INFO - Epoch 371: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:36,967 - INFO - ####################Training epoch 372####################
2025-02-01 18:51:37,345 - INFO - Epoch 372: train_loss=nan
2025-02-01 18:51:37,502 - INFO - Epoch 372: train_loss=nan
2025-02-01 18:51:37,635 - INFO - Epoch 372: train_loss=nan
2025-02-01 18:51:38,029 - INFO - Epoch 372: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:38,033 - INFO - ####################Training epoch 373####################
2025-02-01 18:51:38,410 - INFO - Epoch 373: train_loss=nan
2025-02-01 18:51:38,570 - INFO - Epoch 373: train_loss=nan
2025-02-01 18:51:38,704 - INFO - Epoch 373: train_loss=nan
2025-02-01 18:51:39,102 - INFO - Epoch 373: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:39,106 - INFO - ####################Training epoch 374####################
2025-02-01 18:51:39,481 - INFO - Epoch 374: train_loss=nan
2025-02-01 18:51:39,637 - INFO - Epoch 374: train_loss=nan
2025-02-01 18:51:39,770 - INFO - Epoch 374: train_loss=nan
2025-02-01 18:51:40,168 - INFO - Epoch 374: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:40,172 - INFO - ####################Training epoch 375####################
2025-02-01 18:51:40,549 - INFO - Epoch 375: train_loss=nan
2025-02-01 18:51:40,706 - INFO - Epoch 375: train_loss=nan
2025-02-01 18:51:40,839 - INFO - Epoch 375: train_loss=nan
2025-02-01 18:51:41,238 - INFO - Epoch 375: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:41,241 - INFO - ####################Training epoch 376####################
2025-02-01 18:51:41,618 - INFO - Epoch 376: train_loss=nan
2025-02-01 18:51:41,774 - INFO - Epoch 376: train_loss=nan
2025-02-01 18:51:41,907 - INFO - Epoch 376: train_loss=nan
2025-02-01 18:51:42,305 - INFO - Epoch 376: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:42,308 - INFO - ####################Training epoch 377####################
2025-02-01 18:51:42,685 - INFO - Epoch 377: train_loss=nan
2025-02-01 18:51:42,843 - INFO - Epoch 377: train_loss=nan
2025-02-01 18:51:42,976 - INFO - Epoch 377: train_loss=nan
2025-02-01 18:51:43,374 - INFO - Epoch 377: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:43,377 - INFO - ####################Training epoch 378####################
2025-02-01 18:51:43,758 - INFO - Epoch 378: train_loss=nan
2025-02-01 18:51:43,914 - INFO - Epoch 378: train_loss=nan
2025-02-01 18:51:44,047 - INFO - Epoch 378: train_loss=nan
2025-02-01 18:51:44,443 - INFO - Epoch 378: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:44,446 - INFO - ####################Training epoch 379####################
2025-02-01 18:51:44,823 - INFO - Epoch 379: train_loss=nan
2025-02-01 18:51:44,980 - INFO - Epoch 379: train_loss=nan
2025-02-01 18:51:45,113 - INFO - Epoch 379: train_loss=nan
2025-02-01 18:51:45,510 - INFO - Epoch 379: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:45,514 - INFO - ####################Training epoch 380####################
2025-02-01 18:51:45,889 - INFO - Epoch 380: train_loss=nan
2025-02-01 18:51:46,045 - INFO - Epoch 380: train_loss=nan
2025-02-01 18:51:46,179 - INFO - Epoch 380: train_loss=nan
2025-02-01 18:51:46,578 - INFO - Epoch 380: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:46,582 - INFO - ####################Training epoch 381####################
2025-02-01 18:51:46,959 - INFO - Epoch 381: train_loss=nan
2025-02-01 18:51:47,116 - INFO - Epoch 381: train_loss=nan
2025-02-01 18:51:47,249 - INFO - Epoch 381: train_loss=nan
2025-02-01 18:51:47,647 - INFO - Epoch 381: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:47,651 - INFO - ####################Training epoch 382####################
2025-02-01 18:51:48,028 - INFO - Epoch 382: train_loss=nan
2025-02-01 18:51:48,185 - INFO - Epoch 382: train_loss=nan
2025-02-01 18:51:48,318 - INFO - Epoch 382: train_loss=nan
2025-02-01 18:51:48,713 - INFO - Epoch 382: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:48,717 - INFO - ####################Training epoch 383####################
2025-02-01 18:51:49,091 - INFO - Epoch 383: train_loss=nan
2025-02-01 18:51:49,247 - INFO - Epoch 383: train_loss=nan
2025-02-01 18:51:49,380 - INFO - Epoch 383: train_loss=nan
2025-02-01 18:51:49,776 - INFO - Epoch 383: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:49,780 - INFO - ####################Training epoch 384####################
2025-02-01 18:51:50,156 - INFO - Epoch 384: train_loss=nan
2025-02-01 18:51:50,312 - INFO - Epoch 384: train_loss=nan
2025-02-01 18:51:50,445 - INFO - Epoch 384: train_loss=nan
2025-02-01 18:51:50,842 - INFO - Epoch 384: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:50,846 - INFO - ####################Training epoch 385####################
2025-02-01 18:51:51,224 - INFO - Epoch 385: train_loss=nan
2025-02-01 18:51:51,381 - INFO - Epoch 385: train_loss=nan
2025-02-01 18:51:51,514 - INFO - Epoch 385: train_loss=nan
2025-02-01 18:51:51,913 - INFO - Epoch 385: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:51,917 - INFO - ####################Training epoch 386####################
2025-02-01 18:51:52,298 - INFO - Epoch 386: train_loss=nan
2025-02-01 18:51:52,454 - INFO - Epoch 386: train_loss=nan
2025-02-01 18:51:52,588 - INFO - Epoch 386: train_loss=nan
2025-02-01 18:51:52,985 - INFO - Epoch 386: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:52,989 - INFO - ####################Training epoch 387####################
2025-02-01 18:51:53,365 - INFO - Epoch 387: train_loss=nan
2025-02-01 18:51:53,522 - INFO - Epoch 387: train_loss=nan
2025-02-01 18:51:53,655 - INFO - Epoch 387: train_loss=nan
2025-02-01 18:51:54,050 - INFO - Epoch 387: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:54,054 - INFO - ####################Training epoch 388####################
2025-02-01 18:51:54,432 - INFO - Epoch 388: train_loss=nan
2025-02-01 18:51:54,588 - INFO - Epoch 388: train_loss=nan
2025-02-01 18:51:54,721 - INFO - Epoch 388: train_loss=nan
2025-02-01 18:51:55,124 - INFO - Epoch 388: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:55,128 - INFO - ####################Training epoch 389####################
2025-02-01 18:51:55,507 - INFO - Epoch 389: train_loss=nan
2025-02-01 18:51:55,663 - INFO - Epoch 389: train_loss=nan
2025-02-01 18:51:55,797 - INFO - Epoch 389: train_loss=nan
2025-02-01 18:51:56,193 - INFO - Epoch 389: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:56,197 - INFO - ####################Training epoch 390####################
2025-02-01 18:51:56,575 - INFO - Epoch 390: train_loss=nan
2025-02-01 18:51:56,732 - INFO - Epoch 390: train_loss=nan
2025-02-01 18:51:56,865 - INFO - Epoch 390: train_loss=nan
2025-02-01 18:51:57,264 - INFO - Epoch 390: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:57,268 - INFO - ####################Training epoch 391####################
2025-02-01 18:51:57,644 - INFO - Epoch 391: train_loss=nan
2025-02-01 18:51:57,801 - INFO - Epoch 391: train_loss=nan
2025-02-01 18:51:57,935 - INFO - Epoch 391: train_loss=nan
2025-02-01 18:51:58,335 - INFO - Epoch 391: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:58,338 - INFO - ####################Training epoch 392####################
2025-02-01 18:51:58,713 - INFO - Epoch 392: train_loss=nan
2025-02-01 18:51:58,869 - INFO - Epoch 392: train_loss=nan
2025-02-01 18:51:59,002 - INFO - Epoch 392: train_loss=nan
2025-02-01 18:51:59,400 - INFO - Epoch 392: val_loss=nan, val_acc=66.67%
2025-02-01 18:51:59,404 - INFO - ####################Training epoch 393####################
2025-02-01 18:51:59,782 - INFO - Epoch 393: train_loss=nan
2025-02-01 18:51:59,939 - INFO - Epoch 393: train_loss=nan
2025-02-01 18:52:00,072 - INFO - Epoch 393: train_loss=nan
2025-02-01 18:52:00,469 - INFO - Epoch 393: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:00,472 - INFO - ####################Training epoch 394####################
2025-02-01 18:52:00,847 - INFO - Epoch 394: train_loss=nan
2025-02-01 18:52:01,003 - INFO - Epoch 394: train_loss=nan
2025-02-01 18:52:01,137 - INFO - Epoch 394: train_loss=nan
2025-02-01 18:52:01,538 - INFO - Epoch 394: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:01,542 - INFO - ####################Training epoch 395####################
2025-02-01 18:52:01,918 - INFO - Epoch 395: train_loss=nan
2025-02-01 18:52:02,075 - INFO - Epoch 395: train_loss=nan
2025-02-01 18:52:02,208 - INFO - Epoch 395: train_loss=nan
2025-02-01 18:52:02,605 - INFO - Epoch 395: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:02,609 - INFO - ####################Training epoch 396####################
2025-02-01 18:52:02,985 - INFO - Epoch 396: train_loss=nan
2025-02-01 18:52:03,141 - INFO - Epoch 396: train_loss=nan
2025-02-01 18:52:03,275 - INFO - Epoch 396: train_loss=nan
2025-02-01 18:52:03,676 - INFO - Epoch 396: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:03,680 - INFO - ####################Training epoch 397####################
2025-02-01 18:52:04,057 - INFO - Epoch 397: train_loss=nan
2025-02-01 18:52:04,214 - INFO - Epoch 397: train_loss=nan
2025-02-01 18:52:04,347 - INFO - Epoch 397: train_loss=nan
2025-02-01 18:52:04,742 - INFO - Epoch 397: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:04,746 - INFO - ####################Training epoch 398####################
2025-02-01 18:52:05,123 - INFO - Epoch 398: train_loss=nan
2025-02-01 18:52:05,279 - INFO - Epoch 398: train_loss=nan
2025-02-01 18:52:05,413 - INFO - Epoch 398: train_loss=nan
2025-02-01 18:52:05,808 - INFO - Epoch 398: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:05,811 - INFO - ####################Training epoch 399####################
2025-02-01 18:52:06,188 - INFO - Epoch 399: train_loss=nan
2025-02-01 18:52:06,344 - INFO - Epoch 399: train_loss=nan
2025-02-01 18:52:06,477 - INFO - Epoch 399: train_loss=nan
2025-02-01 18:52:06,876 - INFO - Epoch 399: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:06,880 - INFO - ####################Training epoch 400####################
2025-02-01 18:52:07,256 - INFO - Epoch 400: train_loss=nan
2025-02-01 18:52:07,412 - INFO - Epoch 400: train_loss=nan
2025-02-01 18:52:07,545 - INFO - Epoch 400: train_loss=nan
2025-02-01 18:52:07,940 - INFO - Epoch 400: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:07,943 - INFO - ####################Training epoch 401####################
2025-02-01 18:52:08,320 - INFO - Epoch 401: train_loss=nan
2025-02-01 18:52:08,477 - INFO - Epoch 401: train_loss=nan
2025-02-01 18:52:08,610 - INFO - Epoch 401: train_loss=nan
2025-02-01 18:52:09,007 - INFO - Epoch 401: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:09,011 - INFO - ####################Training epoch 402####################
2025-02-01 18:52:09,392 - INFO - Epoch 402: train_loss=nan
2025-02-01 18:52:09,548 - INFO - Epoch 402: train_loss=nan
2025-02-01 18:52:09,681 - INFO - Epoch 402: train_loss=nan
2025-02-01 18:52:10,075 - INFO - Epoch 402: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:10,079 - INFO - ####################Training epoch 403####################
2025-02-01 18:52:10,459 - INFO - Epoch 403: train_loss=nan
2025-02-01 18:52:10,615 - INFO - Epoch 403: train_loss=nan
2025-02-01 18:52:10,749 - INFO - Epoch 403: train_loss=nan
2025-02-01 18:52:11,146 - INFO - Epoch 403: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:11,150 - INFO - ####################Training epoch 404####################
2025-02-01 18:52:11,528 - INFO - Epoch 404: train_loss=nan
2025-02-01 18:52:11,685 - INFO - Epoch 404: train_loss=nan
2025-02-01 18:52:11,818 - INFO - Epoch 404: train_loss=nan
2025-02-01 18:52:12,217 - INFO - Epoch 404: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:12,221 - INFO - ####################Training epoch 405####################
2025-02-01 18:52:12,602 - INFO - Epoch 405: train_loss=nan
2025-02-01 18:52:12,758 - INFO - Epoch 405: train_loss=nan
2025-02-01 18:52:12,891 - INFO - Epoch 405: train_loss=nan
2025-02-01 18:52:13,287 - INFO - Epoch 405: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:13,291 - INFO - ####################Training epoch 406####################
2025-02-01 18:52:13,667 - INFO - Epoch 406: train_loss=nan
2025-02-01 18:52:13,824 - INFO - Epoch 406: train_loss=nan
2025-02-01 18:52:13,956 - INFO - Epoch 406: train_loss=nan
2025-02-01 18:52:14,351 - INFO - Epoch 406: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:14,355 - INFO - ####################Training epoch 407####################
2025-02-01 18:52:14,735 - INFO - Epoch 407: train_loss=nan
2025-02-01 18:52:14,893 - INFO - Epoch 407: train_loss=nan
2025-02-01 18:52:15,026 - INFO - Epoch 407: train_loss=nan
2025-02-01 18:52:15,424 - INFO - Epoch 407: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:15,428 - INFO - ####################Training epoch 408####################
2025-02-01 18:52:15,805 - INFO - Epoch 408: train_loss=nan
2025-02-01 18:52:15,961 - INFO - Epoch 408: train_loss=nan
2025-02-01 18:52:16,094 - INFO - Epoch 408: train_loss=nan
2025-02-01 18:52:16,494 - INFO - Epoch 408: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:16,497 - INFO - ####################Training epoch 409####################
2025-02-01 18:52:16,876 - INFO - Epoch 409: train_loss=nan
2025-02-01 18:52:17,033 - INFO - Epoch 409: train_loss=nan
2025-02-01 18:52:17,166 - INFO - Epoch 409: train_loss=nan
2025-02-01 18:52:17,567 - INFO - Epoch 409: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:17,571 - INFO - ####################Training epoch 410####################
2025-02-01 18:52:17,948 - INFO - Epoch 410: train_loss=nan
2025-02-01 18:52:18,104 - INFO - Epoch 410: train_loss=nan
2025-02-01 18:52:18,237 - INFO - Epoch 410: train_loss=nan
2025-02-01 18:52:18,636 - INFO - Epoch 410: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:18,640 - INFO - ####################Training epoch 411####################
2025-02-01 18:52:19,014 - INFO - Epoch 411: train_loss=nan
2025-02-01 18:52:19,171 - INFO - Epoch 411: train_loss=nan
2025-02-01 18:52:19,304 - INFO - Epoch 411: train_loss=nan
2025-02-01 18:52:19,696 - INFO - Epoch 411: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:19,700 - INFO - ####################Training epoch 412####################
2025-02-01 18:52:20,076 - INFO - Epoch 412: train_loss=nan
2025-02-01 18:52:20,233 - INFO - Epoch 412: train_loss=nan
2025-02-01 18:52:20,367 - INFO - Epoch 412: train_loss=nan
2025-02-01 18:52:20,766 - INFO - Epoch 412: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:20,769 - INFO - ####################Training epoch 413####################
2025-02-01 18:52:21,144 - INFO - Epoch 413: train_loss=nan
2025-02-01 18:52:21,300 - INFO - Epoch 413: train_loss=nan
2025-02-01 18:52:21,433 - INFO - Epoch 413: train_loss=nan
2025-02-01 18:52:21,827 - INFO - Epoch 413: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:21,831 - INFO - ####################Training epoch 414####################
2025-02-01 18:52:22,207 - INFO - Epoch 414: train_loss=nan
2025-02-01 18:52:22,364 - INFO - Epoch 414: train_loss=nan
2025-02-01 18:52:22,497 - INFO - Epoch 414: train_loss=nan
2025-02-01 18:52:22,891 - INFO - Epoch 414: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:22,894 - INFO - ####################Training epoch 415####################
2025-02-01 18:52:23,272 - INFO - Epoch 415: train_loss=nan
2025-02-01 18:52:23,429 - INFO - Epoch 415: train_loss=nan
2025-02-01 18:52:23,562 - INFO - Epoch 415: train_loss=nan
2025-02-01 18:52:23,963 - INFO - Epoch 415: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:23,967 - INFO - ####################Training epoch 416####################
2025-02-01 18:52:24,342 - INFO - Epoch 416: train_loss=nan
2025-02-01 18:52:24,498 - INFO - Epoch 416: train_loss=nan
2025-02-01 18:52:24,631 - INFO - Epoch 416: train_loss=nan
2025-02-01 18:52:25,024 - INFO - Epoch 416: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:25,028 - INFO - ####################Training epoch 417####################
2025-02-01 18:52:25,407 - INFO - Epoch 417: train_loss=nan
2025-02-01 18:52:25,564 - INFO - Epoch 417: train_loss=nan
2025-02-01 18:52:25,697 - INFO - Epoch 417: train_loss=nan
2025-02-01 18:52:26,093 - INFO - Epoch 417: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:26,096 - INFO - ####################Training epoch 418####################
2025-02-01 18:52:26,474 - INFO - Epoch 418: train_loss=nan
2025-02-01 18:52:26,632 - INFO - Epoch 418: train_loss=nan
2025-02-01 18:52:26,765 - INFO - Epoch 418: train_loss=nan
2025-02-01 18:52:27,159 - INFO - Epoch 418: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:27,163 - INFO - ####################Training epoch 419####################
2025-02-01 18:52:27,542 - INFO - Epoch 419: train_loss=nan
2025-02-01 18:52:27,699 - INFO - Epoch 419: train_loss=nan
2025-02-01 18:52:27,832 - INFO - Epoch 419: train_loss=nan
2025-02-01 18:52:28,227 - INFO - Epoch 419: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:28,230 - INFO - ####################Training epoch 420####################
2025-02-01 18:52:28,606 - INFO - Epoch 420: train_loss=nan
2025-02-01 18:52:28,762 - INFO - Epoch 420: train_loss=nan
2025-02-01 18:52:28,895 - INFO - Epoch 420: train_loss=nan
2025-02-01 18:52:29,290 - INFO - Epoch 420: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:29,293 - INFO - ####################Training epoch 421####################
2025-02-01 18:52:29,667 - INFO - Epoch 421: train_loss=nan
2025-02-01 18:52:29,823 - INFO - Epoch 421: train_loss=nan
2025-02-01 18:52:29,957 - INFO - Epoch 421: train_loss=nan
2025-02-01 18:52:30,353 - INFO - Epoch 421: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:30,356 - INFO - ####################Training epoch 422####################
2025-02-01 18:52:30,731 - INFO - Epoch 422: train_loss=nan
2025-02-01 18:52:30,888 - INFO - Epoch 422: train_loss=nan
2025-02-01 18:52:31,021 - INFO - Epoch 422: train_loss=nan
2025-02-01 18:52:31,420 - INFO - Epoch 422: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:31,423 - INFO - ####################Training epoch 423####################
2025-02-01 18:52:31,798 - INFO - Epoch 423: train_loss=nan
2025-02-01 18:52:31,954 - INFO - Epoch 423: train_loss=nan
2025-02-01 18:52:32,090 - INFO - Epoch 423: train_loss=nan
2025-02-01 18:52:32,487 - INFO - Epoch 423: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:32,491 - INFO - ####################Training epoch 424####################
2025-02-01 18:52:32,865 - INFO - Epoch 424: train_loss=nan
2025-02-01 18:52:33,022 - INFO - Epoch 424: train_loss=nan
2025-02-01 18:52:33,155 - INFO - Epoch 424: train_loss=nan
2025-02-01 18:52:33,554 - INFO - Epoch 424: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:33,558 - INFO - ####################Training epoch 425####################
2025-02-01 18:52:33,931 - INFO - Epoch 425: train_loss=nan
2025-02-01 18:52:34,088 - INFO - Epoch 425: train_loss=nan
2025-02-01 18:52:34,221 - INFO - Epoch 425: train_loss=nan
2025-02-01 18:52:34,620 - INFO - Epoch 425: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:34,624 - INFO - ####################Training epoch 426####################
2025-02-01 18:52:35,003 - INFO - Epoch 426: train_loss=nan
2025-02-01 18:52:35,159 - INFO - Epoch 426: train_loss=nan
2025-02-01 18:52:35,292 - INFO - Epoch 426: train_loss=nan
2025-02-01 18:52:35,688 - INFO - Epoch 426: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:35,691 - INFO - ####################Training epoch 427####################
2025-02-01 18:52:36,065 - INFO - Epoch 427: train_loss=nan
2025-02-01 18:52:36,222 - INFO - Epoch 427: train_loss=nan
2025-02-01 18:52:36,355 - INFO - Epoch 427: train_loss=nan
2025-02-01 18:52:36,752 - INFO - Epoch 427: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:36,755 - INFO - ####################Training epoch 428####################
2025-02-01 18:52:37,132 - INFO - Epoch 428: train_loss=nan
2025-02-01 18:52:37,289 - INFO - Epoch 428: train_loss=nan
2025-02-01 18:52:37,422 - INFO - Epoch 428: train_loss=nan
2025-02-01 18:52:37,822 - INFO - Epoch 428: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:37,826 - INFO - ####################Training epoch 429####################
2025-02-01 18:52:38,200 - INFO - Epoch 429: train_loss=nan
2025-02-01 18:52:38,356 - INFO - Epoch 429: train_loss=nan
2025-02-01 18:52:38,489 - INFO - Epoch 429: train_loss=nan
2025-02-01 18:52:38,886 - INFO - Epoch 429: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:38,890 - INFO - ####################Training epoch 430####################
2025-02-01 18:52:39,269 - INFO - Epoch 430: train_loss=nan
2025-02-01 18:52:39,426 - INFO - Epoch 430: train_loss=nan
2025-02-01 18:52:39,559 - INFO - Epoch 430: train_loss=nan
2025-02-01 18:52:39,958 - INFO - Epoch 430: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:39,962 - INFO - ####################Training epoch 431####################
2025-02-01 18:52:40,337 - INFO - Epoch 431: train_loss=nan
2025-02-01 18:52:40,493 - INFO - Epoch 431: train_loss=nan
2025-02-01 18:52:40,626 - INFO - Epoch 431: train_loss=nan
2025-02-01 18:52:41,024 - INFO - Epoch 431: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:41,028 - INFO - ####################Training epoch 432####################
2025-02-01 18:52:41,404 - INFO - Epoch 432: train_loss=nan
2025-02-01 18:52:41,561 - INFO - Epoch 432: train_loss=nan
2025-02-01 18:52:41,695 - INFO - Epoch 432: train_loss=nan
2025-02-01 18:52:42,090 - INFO - Epoch 432: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:42,094 - INFO - ####################Training epoch 433####################
2025-02-01 18:52:42,473 - INFO - Epoch 433: train_loss=nan
2025-02-01 18:52:42,630 - INFO - Epoch 433: train_loss=nan
2025-02-01 18:52:42,763 - INFO - Epoch 433: train_loss=nan
2025-02-01 18:52:43,161 - INFO - Epoch 433: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:43,165 - INFO - ####################Training epoch 434####################
2025-02-01 18:52:43,543 - INFO - Epoch 434: train_loss=nan
2025-02-01 18:52:43,699 - INFO - Epoch 434: train_loss=nan
2025-02-01 18:52:43,832 - INFO - Epoch 434: train_loss=nan
2025-02-01 18:52:44,228 - INFO - Epoch 434: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:44,232 - INFO - ####################Training epoch 435####################
2025-02-01 18:52:44,608 - INFO - Epoch 435: train_loss=nan
2025-02-01 18:52:44,765 - INFO - Epoch 435: train_loss=nan
2025-02-01 18:52:44,899 - INFO - Epoch 435: train_loss=nan
2025-02-01 18:52:45,297 - INFO - Epoch 435: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:45,300 - INFO - ####################Training epoch 436####################
2025-02-01 18:52:45,681 - INFO - Epoch 436: train_loss=nan
2025-02-01 18:52:45,838 - INFO - Epoch 436: train_loss=nan
2025-02-01 18:52:45,971 - INFO - Epoch 436: train_loss=nan
2025-02-01 18:52:46,367 - INFO - Epoch 436: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:46,371 - INFO - ####################Training epoch 437####################
2025-02-01 18:52:46,745 - INFO - Epoch 437: train_loss=nan
2025-02-01 18:52:46,902 - INFO - Epoch 437: train_loss=nan
2025-02-01 18:52:47,035 - INFO - Epoch 437: train_loss=nan
2025-02-01 18:52:47,432 - INFO - Epoch 437: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:47,435 - INFO - ####################Training epoch 438####################
2025-02-01 18:52:47,811 - INFO - Epoch 438: train_loss=nan
2025-02-01 18:52:47,967 - INFO - Epoch 438: train_loss=nan
2025-02-01 18:52:48,100 - INFO - Epoch 438: train_loss=nan
2025-02-01 18:52:48,498 - INFO - Epoch 438: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:48,501 - INFO - ####################Training epoch 439####################
2025-02-01 18:52:48,879 - INFO - Epoch 439: train_loss=nan
2025-02-01 18:52:49,035 - INFO - Epoch 439: train_loss=nan
2025-02-01 18:52:49,168 - INFO - Epoch 439: train_loss=nan
2025-02-01 18:52:49,566 - INFO - Epoch 439: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:49,569 - INFO - ####################Training epoch 440####################
2025-02-01 18:52:49,943 - INFO - Epoch 440: train_loss=nan
2025-02-01 18:52:50,100 - INFO - Epoch 440: train_loss=nan
2025-02-01 18:52:50,234 - INFO - Epoch 440: train_loss=nan
2025-02-01 18:52:50,629 - INFO - Epoch 440: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:50,633 - INFO - ####################Training epoch 441####################
2025-02-01 18:52:51,009 - INFO - Epoch 441: train_loss=nan
2025-02-01 18:52:51,166 - INFO - Epoch 441: train_loss=nan
2025-02-01 18:52:51,299 - INFO - Epoch 441: train_loss=nan
2025-02-01 18:52:51,696 - INFO - Epoch 441: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:51,700 - INFO - ####################Training epoch 442####################
2025-02-01 18:52:52,075 - INFO - Epoch 442: train_loss=nan
2025-02-01 18:52:52,231 - INFO - Epoch 442: train_loss=nan
2025-02-01 18:52:52,364 - INFO - Epoch 442: train_loss=nan
2025-02-01 18:52:52,762 - INFO - Epoch 442: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:52,766 - INFO - ####################Training epoch 443####################
2025-02-01 18:52:53,138 - INFO - Epoch 443: train_loss=nan
2025-02-01 18:52:53,294 - INFO - Epoch 443: train_loss=nan
2025-02-01 18:52:53,427 - INFO - Epoch 443: train_loss=nan
2025-02-01 18:52:53,826 - INFO - Epoch 443: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:53,830 - INFO - ####################Training epoch 444####################
2025-02-01 18:52:54,206 - INFO - Epoch 444: train_loss=nan
2025-02-01 18:52:54,363 - INFO - Epoch 444: train_loss=nan
2025-02-01 18:52:54,496 - INFO - Epoch 444: train_loss=nan
2025-02-01 18:52:54,896 - INFO - Epoch 444: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:54,899 - INFO - ####################Training epoch 445####################
2025-02-01 18:52:55,275 - INFO - Epoch 445: train_loss=nan
2025-02-01 18:52:55,431 - INFO - Epoch 445: train_loss=nan
2025-02-01 18:52:55,564 - INFO - Epoch 445: train_loss=nan
2025-02-01 18:52:55,959 - INFO - Epoch 445: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:55,962 - INFO - ####################Training epoch 446####################
2025-02-01 18:52:56,337 - INFO - Epoch 446: train_loss=nan
2025-02-01 18:52:56,493 - INFO - Epoch 446: train_loss=nan
2025-02-01 18:52:56,626 - INFO - Epoch 446: train_loss=nan
2025-02-01 18:52:57,025 - INFO - Epoch 446: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:57,029 - INFO - ####################Training epoch 447####################
2025-02-01 18:52:57,405 - INFO - Epoch 447: train_loss=nan
2025-02-01 18:52:57,562 - INFO - Epoch 447: train_loss=nan
2025-02-01 18:52:57,696 - INFO - Epoch 447: train_loss=nan
2025-02-01 18:52:58,092 - INFO - Epoch 447: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:58,096 - INFO - ####################Training epoch 448####################
2025-02-01 18:52:58,472 - INFO - Epoch 448: train_loss=nan
2025-02-01 18:52:58,628 - INFO - Epoch 448: train_loss=nan
2025-02-01 18:52:58,762 - INFO - Epoch 448: train_loss=nan
2025-02-01 18:52:59,158 - INFO - Epoch 448: val_loss=nan, val_acc=66.67%
2025-02-01 18:52:59,162 - INFO - ####################Training epoch 449####################
2025-02-01 18:52:59,537 - INFO - Epoch 449: train_loss=nan
2025-02-01 18:52:59,694 - INFO - Epoch 449: train_loss=nan
2025-02-01 18:52:59,827 - INFO - Epoch 449: train_loss=nan
2025-02-01 18:53:00,226 - INFO - Epoch 449: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:00,230 - INFO - ####################Training epoch 450####################
2025-02-01 18:53:00,608 - INFO - Epoch 450: train_loss=nan
2025-02-01 18:53:00,764 - INFO - Epoch 450: train_loss=nan
2025-02-01 18:53:00,898 - INFO - Epoch 450: train_loss=nan
2025-02-01 18:53:01,295 - INFO - Epoch 450: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:01,299 - INFO - ####################Training epoch 451####################
2025-02-01 18:53:01,677 - INFO - Epoch 451: train_loss=nan
2025-02-01 18:53:01,833 - INFO - Epoch 451: train_loss=nan
2025-02-01 18:53:01,967 - INFO - Epoch 451: train_loss=nan
2025-02-01 18:53:02,368 - INFO - Epoch 451: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:02,372 - INFO - ####################Training epoch 452####################
2025-02-01 18:53:02,748 - INFO - Epoch 452: train_loss=nan
2025-02-01 18:53:02,904 - INFO - Epoch 452: train_loss=nan
2025-02-01 18:53:03,037 - INFO - Epoch 452: train_loss=nan
2025-02-01 18:53:03,434 - INFO - Epoch 452: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:03,438 - INFO - ####################Training epoch 453####################
2025-02-01 18:53:03,815 - INFO - Epoch 453: train_loss=nan
2025-02-01 18:53:03,971 - INFO - Epoch 453: train_loss=nan
2025-02-01 18:53:04,105 - INFO - Epoch 453: train_loss=nan
2025-02-01 18:53:04,506 - INFO - Epoch 453: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:04,509 - INFO - ####################Training epoch 454####################
2025-02-01 18:53:04,883 - INFO - Epoch 454: train_loss=nan
2025-02-01 18:53:05,040 - INFO - Epoch 454: train_loss=nan
2025-02-01 18:53:05,173 - INFO - Epoch 454: train_loss=nan
2025-02-01 18:53:05,570 - INFO - Epoch 454: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:05,573 - INFO - ####################Training epoch 455####################
2025-02-01 18:53:05,947 - INFO - Epoch 455: train_loss=nan
2025-02-01 18:53:06,104 - INFO - Epoch 455: train_loss=nan
2025-02-01 18:53:06,237 - INFO - Epoch 455: train_loss=nan
2025-02-01 18:53:06,635 - INFO - Epoch 455: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:06,639 - INFO - ####################Training epoch 456####################
2025-02-01 18:53:07,016 - INFO - Epoch 456: train_loss=nan
2025-02-01 18:53:07,172 - INFO - Epoch 456: train_loss=nan
2025-02-01 18:53:07,306 - INFO - Epoch 456: train_loss=nan
2025-02-01 18:53:07,701 - INFO - Epoch 456: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:07,705 - INFO - ####################Training epoch 457####################
2025-02-01 18:53:08,081 - INFO - Epoch 457: train_loss=nan
2025-02-01 18:53:08,238 - INFO - Epoch 457: train_loss=nan
2025-02-01 18:53:08,372 - INFO - Epoch 457: train_loss=nan
2025-02-01 18:53:08,765 - INFO - Epoch 457: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:08,769 - INFO - ####################Training epoch 458####################
2025-02-01 18:53:09,143 - INFO - Epoch 458: train_loss=nan
2025-02-01 18:53:09,300 - INFO - Epoch 458: train_loss=nan
2025-02-01 18:53:09,433 - INFO - Epoch 458: train_loss=nan
2025-02-01 18:53:09,832 - INFO - Epoch 458: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:09,835 - INFO - ####################Training epoch 459####################
2025-02-01 18:53:10,212 - INFO - Epoch 459: train_loss=nan
2025-02-01 18:53:10,368 - INFO - Epoch 459: train_loss=nan
2025-02-01 18:53:10,501 - INFO - Epoch 459: train_loss=nan
2025-02-01 18:53:10,899 - INFO - Epoch 459: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:10,903 - INFO - ####################Training epoch 460####################
2025-02-01 18:53:11,280 - INFO - Epoch 460: train_loss=nan
2025-02-01 18:53:11,437 - INFO - Epoch 460: train_loss=nan
2025-02-01 18:53:11,570 - INFO - Epoch 460: train_loss=nan
2025-02-01 18:53:11,966 - INFO - Epoch 460: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:11,969 - INFO - ####################Training epoch 461####################
2025-02-01 18:53:12,347 - INFO - Epoch 461: train_loss=nan
2025-02-01 18:53:12,504 - INFO - Epoch 461: train_loss=nan
2025-02-01 18:53:12,637 - INFO - Epoch 461: train_loss=nan
2025-02-01 18:53:13,032 - INFO - Epoch 461: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:13,036 - INFO - ####################Training epoch 462####################
2025-02-01 18:53:13,413 - INFO - Epoch 462: train_loss=nan
2025-02-01 18:53:13,570 - INFO - Epoch 462: train_loss=nan
2025-02-01 18:53:13,703 - INFO - Epoch 462: train_loss=nan
2025-02-01 18:53:14,101 - INFO - Epoch 462: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:14,105 - INFO - ####################Training epoch 463####################
2025-02-01 18:53:14,480 - INFO - Epoch 463: train_loss=nan
2025-02-01 18:53:14,637 - INFO - Epoch 463: train_loss=nan
2025-02-01 18:53:14,771 - INFO - Epoch 463: train_loss=nan
2025-02-01 18:53:15,169 - INFO - Epoch 463: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:15,173 - INFO - ####################Training epoch 464####################
2025-02-01 18:53:15,549 - INFO - Epoch 464: train_loss=nan
2025-02-01 18:53:15,706 - INFO - Epoch 464: train_loss=nan
2025-02-01 18:53:15,839 - INFO - Epoch 464: train_loss=nan
2025-02-01 18:53:16,233 - INFO - Epoch 464: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:16,236 - INFO - ####################Training epoch 465####################
2025-02-01 18:53:16,612 - INFO - Epoch 465: train_loss=nan
2025-02-01 18:53:16,768 - INFO - Epoch 465: train_loss=nan
2025-02-01 18:53:16,901 - INFO - Epoch 465: train_loss=nan
2025-02-01 18:53:17,301 - INFO - Epoch 465: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:17,305 - INFO - ####################Training epoch 466####################
2025-02-01 18:53:17,684 - INFO - Epoch 466: train_loss=nan
2025-02-01 18:53:17,840 - INFO - Epoch 466: train_loss=nan
2025-02-01 18:53:17,973 - INFO - Epoch 466: train_loss=nan
2025-02-01 18:53:18,371 - INFO - Epoch 466: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:18,375 - INFO - ####################Training epoch 467####################
2025-02-01 18:53:18,751 - INFO - Epoch 467: train_loss=nan
2025-02-01 18:53:18,907 - INFO - Epoch 467: train_loss=nan
2025-02-01 18:53:19,040 - INFO - Epoch 467: train_loss=nan
2025-02-01 18:53:19,441 - INFO - Epoch 467: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:19,445 - INFO - ####################Training epoch 468####################
2025-02-01 18:53:19,820 - INFO - Epoch 468: train_loss=nan
2025-02-01 18:53:19,976 - INFO - Epoch 468: train_loss=nan
2025-02-01 18:53:20,110 - INFO - Epoch 468: train_loss=nan
2025-02-01 18:53:20,504 - INFO - Epoch 468: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:20,508 - INFO - ####################Training epoch 469####################
2025-02-01 18:53:20,885 - INFO - Epoch 469: train_loss=nan
2025-02-01 18:53:21,041 - INFO - Epoch 469: train_loss=nan
2025-02-01 18:53:21,174 - INFO - Epoch 469: train_loss=nan
2025-02-01 18:53:21,571 - INFO - Epoch 469: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:21,575 - INFO - ####################Training epoch 470####################
2025-02-01 18:53:21,951 - INFO - Epoch 470: train_loss=nan
2025-02-01 18:53:22,108 - INFO - Epoch 470: train_loss=nan
2025-02-01 18:53:22,241 - INFO - Epoch 470: train_loss=nan
2025-02-01 18:53:22,641 - INFO - Epoch 470: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:22,644 - INFO - ####################Training epoch 471####################
2025-02-01 18:53:23,022 - INFO - Epoch 471: train_loss=nan
2025-02-01 18:53:23,178 - INFO - Epoch 471: train_loss=nan
2025-02-01 18:53:23,312 - INFO - Epoch 471: train_loss=nan
2025-02-01 18:53:23,709 - INFO - Epoch 471: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:23,712 - INFO - ####################Training epoch 472####################
2025-02-01 18:53:24,087 - INFO - Epoch 472: train_loss=nan
2025-02-01 18:53:24,244 - INFO - Epoch 472: train_loss=nan
2025-02-01 18:53:24,377 - INFO - Epoch 472: train_loss=nan
2025-02-01 18:53:24,771 - INFO - Epoch 472: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:24,775 - INFO - ####################Training epoch 473####################
2025-02-01 18:53:25,151 - INFO - Epoch 473: train_loss=nan
2025-02-01 18:53:25,308 - INFO - Epoch 473: train_loss=nan
2025-02-01 18:53:25,441 - INFO - Epoch 473: train_loss=nan
2025-02-01 18:53:25,843 - INFO - Epoch 473: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:25,847 - INFO - ####################Training epoch 474####################
2025-02-01 18:53:26,223 - INFO - Epoch 474: train_loss=nan
2025-02-01 18:53:26,379 - INFO - Epoch 474: train_loss=nan
2025-02-01 18:53:26,513 - INFO - Epoch 474: train_loss=nan
2025-02-01 18:53:26,908 - INFO - Epoch 474: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:26,911 - INFO - ####################Training epoch 475####################
2025-02-01 18:53:27,288 - INFO - Epoch 475: train_loss=nan
2025-02-01 18:53:27,444 - INFO - Epoch 475: train_loss=nan
2025-02-01 18:53:27,578 - INFO - Epoch 475: train_loss=nan
2025-02-01 18:53:27,976 - INFO - Epoch 475: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:27,979 - INFO - ####################Training epoch 476####################
2025-02-01 18:53:28,356 - INFO - Epoch 476: train_loss=nan
2025-02-01 18:53:28,513 - INFO - Epoch 476: train_loss=nan
2025-02-01 18:53:28,646 - INFO - Epoch 476: train_loss=nan
2025-02-01 18:53:29,041 - INFO - Epoch 476: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:29,045 - INFO - ####################Training epoch 477####################
2025-02-01 18:53:29,419 - INFO - Epoch 477: train_loss=nan
2025-02-01 18:53:29,575 - INFO - Epoch 477: train_loss=nan
2025-02-01 18:53:29,708 - INFO - Epoch 477: train_loss=nan
2025-02-01 18:53:30,101 - INFO - Epoch 477: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:30,104 - INFO - ####################Training epoch 478####################
2025-02-01 18:53:30,479 - INFO - Epoch 478: train_loss=nan
2025-02-01 18:53:30,635 - INFO - Epoch 478: train_loss=nan
2025-02-01 18:53:30,768 - INFO - Epoch 478: train_loss=nan
2025-02-01 18:53:31,166 - INFO - Epoch 478: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:31,170 - INFO - ####################Training epoch 479####################
2025-02-01 18:53:31,546 - INFO - Epoch 479: train_loss=nan
2025-02-01 18:53:31,703 - INFO - Epoch 479: train_loss=nan
2025-02-01 18:53:31,836 - INFO - Epoch 479: train_loss=nan
2025-02-01 18:53:32,231 - INFO - Epoch 479: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:32,235 - INFO - ####################Training epoch 480####################
2025-02-01 18:53:32,612 - INFO - Epoch 480: train_loss=nan
2025-02-01 18:53:32,769 - INFO - Epoch 480: train_loss=nan
2025-02-01 18:53:32,903 - INFO - Epoch 480: train_loss=nan
2025-02-01 18:53:33,299 - INFO - Epoch 480: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:33,303 - INFO - ####################Training epoch 481####################
2025-02-01 18:53:33,680 - INFO - Epoch 481: train_loss=nan
2025-02-01 18:53:33,836 - INFO - Epoch 481: train_loss=nan
2025-02-01 18:53:33,969 - INFO - Epoch 481: train_loss=nan
2025-02-01 18:53:34,366 - INFO - Epoch 481: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:34,370 - INFO - ####################Training epoch 482####################
2025-02-01 18:53:34,744 - INFO - Epoch 482: train_loss=nan
2025-02-01 18:53:34,900 - INFO - Epoch 482: train_loss=nan
2025-02-01 18:53:35,033 - INFO - Epoch 482: train_loss=nan
2025-02-01 18:53:35,430 - INFO - Epoch 482: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:35,434 - INFO - ####################Training epoch 483####################
2025-02-01 18:53:35,811 - INFO - Epoch 483: train_loss=nan
2025-02-01 18:53:35,968 - INFO - Epoch 483: train_loss=nan
2025-02-01 18:53:36,101 - INFO - Epoch 483: train_loss=nan
2025-02-01 18:53:36,503 - INFO - Epoch 483: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:36,507 - INFO - ####################Training epoch 484####################
2025-02-01 18:53:36,883 - INFO - Epoch 484: train_loss=nan
2025-02-01 18:53:37,039 - INFO - Epoch 484: train_loss=nan
2025-02-01 18:53:37,172 - INFO - Epoch 484: train_loss=nan
2025-02-01 18:53:37,566 - INFO - Epoch 484: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:37,570 - INFO - ####################Training epoch 485####################
2025-02-01 18:53:37,946 - INFO - Epoch 485: train_loss=nan
2025-02-01 18:53:38,103 - INFO - Epoch 485: train_loss=nan
2025-02-01 18:53:38,236 - INFO - Epoch 485: train_loss=nan
2025-02-01 18:53:38,632 - INFO - Epoch 485: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:38,636 - INFO - ####################Training epoch 486####################
2025-02-01 18:53:39,011 - INFO - Epoch 486: train_loss=nan
2025-02-01 18:53:39,168 - INFO - Epoch 486: train_loss=nan
2025-02-01 18:53:39,301 - INFO - Epoch 486: train_loss=nan
2025-02-01 18:53:39,696 - INFO - Epoch 486: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:39,700 - INFO - ####################Training epoch 487####################
2025-02-01 18:53:40,079 - INFO - Epoch 487: train_loss=nan
2025-02-01 18:53:40,235 - INFO - Epoch 487: train_loss=nan
2025-02-01 18:53:40,368 - INFO - Epoch 487: train_loss=nan
2025-02-01 18:53:40,765 - INFO - Epoch 487: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:40,769 - INFO - ####################Training epoch 488####################
2025-02-01 18:53:41,147 - INFO - Epoch 488: train_loss=nan
2025-02-01 18:53:41,303 - INFO - Epoch 488: train_loss=nan
2025-02-01 18:53:41,436 - INFO - Epoch 488: train_loss=nan
2025-02-01 18:53:41,836 - INFO - Epoch 488: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:41,839 - INFO - ####################Training epoch 489####################
2025-02-01 18:53:42,214 - INFO - Epoch 489: train_loss=nan
2025-02-01 18:53:42,371 - INFO - Epoch 489: train_loss=nan
2025-02-01 18:53:42,504 - INFO - Epoch 489: train_loss=nan
2025-02-01 18:53:42,905 - INFO - Epoch 489: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:42,908 - INFO - ####################Training epoch 490####################
2025-02-01 18:53:43,282 - INFO - Epoch 490: train_loss=nan
2025-02-01 18:53:43,439 - INFO - Epoch 490: train_loss=nan
2025-02-01 18:53:43,572 - INFO - Epoch 490: train_loss=nan
2025-02-01 18:53:43,974 - INFO - Epoch 490: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:43,978 - INFO - ####################Training epoch 491####################
2025-02-01 18:53:44,352 - INFO - Epoch 491: train_loss=nan
2025-02-01 18:53:44,508 - INFO - Epoch 491: train_loss=nan
2025-02-01 18:53:44,642 - INFO - Epoch 491: train_loss=nan
2025-02-01 18:53:45,040 - INFO - Epoch 491: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:45,043 - INFO - ####################Training epoch 492####################
2025-02-01 18:53:45,419 - INFO - Epoch 492: train_loss=nan
2025-02-01 18:53:45,575 - INFO - Epoch 492: train_loss=nan
2025-02-01 18:53:45,708 - INFO - Epoch 492: train_loss=nan
2025-02-01 18:53:46,107 - INFO - Epoch 492: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:46,110 - INFO - ####################Training epoch 493####################
2025-02-01 18:53:46,488 - INFO - Epoch 493: train_loss=nan
2025-02-01 18:53:46,645 - INFO - Epoch 493: train_loss=nan
2025-02-01 18:53:46,779 - INFO - Epoch 493: train_loss=nan
2025-02-01 18:53:47,175 - INFO - Epoch 493: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:47,178 - INFO - ####################Training epoch 494####################
2025-02-01 18:53:47,553 - INFO - Epoch 494: train_loss=nan
2025-02-01 18:53:47,710 - INFO - Epoch 494: train_loss=nan
2025-02-01 18:53:47,843 - INFO - Epoch 494: train_loss=nan
2025-02-01 18:53:48,241 - INFO - Epoch 494: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:48,245 - INFO - ####################Training epoch 495####################
2025-02-01 18:53:48,620 - INFO - Epoch 495: train_loss=nan
2025-02-01 18:53:48,776 - INFO - Epoch 495: train_loss=nan
2025-02-01 18:53:48,909 - INFO - Epoch 495: train_loss=nan
2025-02-01 18:53:49,306 - INFO - Epoch 495: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:49,310 - INFO - ####################Training epoch 496####################
2025-02-01 18:53:49,685 - INFO - Epoch 496: train_loss=nan
2025-02-01 18:53:49,842 - INFO - Epoch 496: train_loss=nan
2025-02-01 18:53:49,975 - INFO - Epoch 496: train_loss=nan
2025-02-01 18:53:50,372 - INFO - Epoch 496: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:50,376 - INFO - ####################Training epoch 497####################
2025-02-01 18:53:50,752 - INFO - Epoch 497: train_loss=nan
2025-02-01 18:53:50,908 - INFO - Epoch 497: train_loss=nan
2025-02-01 18:53:51,041 - INFO - Epoch 497: train_loss=nan
2025-02-01 18:53:51,437 - INFO - Epoch 497: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:51,441 - INFO - ####################Training epoch 498####################
2025-02-01 18:53:51,816 - INFO - Epoch 498: train_loss=nan
2025-02-01 18:53:51,972 - INFO - Epoch 498: train_loss=nan
2025-02-01 18:53:52,105 - INFO - Epoch 498: train_loss=nan
2025-02-01 18:53:52,510 - INFO - Epoch 498: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:52,513 - INFO - ####################Training epoch 499####################
2025-02-01 18:53:52,887 - INFO - Epoch 499: train_loss=nan
2025-02-01 18:53:53,043 - INFO - Epoch 499: train_loss=nan
2025-02-01 18:53:53,177 - INFO - Epoch 499: train_loss=nan
2025-02-01 18:53:53,572 - INFO - Epoch 499: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:53,576 - INFO - ####################Training epoch 500####################
2025-02-01 18:53:53,952 - INFO - Epoch 500: train_loss=nan
2025-02-01 18:53:54,108 - INFO - Epoch 500: train_loss=nan
2025-02-01 18:53:54,241 - INFO - Epoch 500: train_loss=nan
2025-02-01 18:53:54,635 - INFO - Epoch 500: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:54,639 - INFO - ####################Training epoch 501####################
2025-02-01 18:53:55,018 - INFO - Epoch 501: train_loss=nan
2025-02-01 18:53:55,174 - INFO - Epoch 501: train_loss=nan
2025-02-01 18:53:55,307 - INFO - Epoch 501: train_loss=nan
2025-02-01 18:53:55,706 - INFO - Epoch 501: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:55,710 - INFO - ####################Training epoch 502####################
2025-02-01 18:53:56,085 - INFO - Epoch 502: train_loss=nan
2025-02-01 18:53:56,243 - INFO - Epoch 502: train_loss=nan
2025-02-01 18:53:56,376 - INFO - Epoch 502: train_loss=nan
2025-02-01 18:53:56,773 - INFO - Epoch 502: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:56,777 - INFO - ####################Training epoch 503####################
2025-02-01 18:53:57,154 - INFO - Epoch 503: train_loss=nan
2025-02-01 18:53:57,310 - INFO - Epoch 503: train_loss=nan
2025-02-01 18:53:57,444 - INFO - Epoch 503: train_loss=nan
2025-02-01 18:53:57,840 - INFO - Epoch 503: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:57,844 - INFO - ####################Training epoch 504####################
2025-02-01 18:53:58,219 - INFO - Epoch 504: train_loss=nan
2025-02-01 18:53:58,375 - INFO - Epoch 504: train_loss=nan
2025-02-01 18:53:58,508 - INFO - Epoch 504: train_loss=nan
2025-02-01 18:53:58,905 - INFO - Epoch 504: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:58,909 - INFO - ####################Training epoch 505####################
2025-02-01 18:53:59,284 - INFO - Epoch 505: train_loss=nan
2025-02-01 18:53:59,441 - INFO - Epoch 505: train_loss=nan
2025-02-01 18:53:59,575 - INFO - Epoch 505: train_loss=nan
2025-02-01 18:53:59,974 - INFO - Epoch 505: val_loss=nan, val_acc=66.67%
2025-02-01 18:53:59,977 - INFO - ####################Training epoch 506####################
2025-02-01 18:54:00,353 - INFO - Epoch 506: train_loss=nan
2025-02-01 18:54:00,510 - INFO - Epoch 506: train_loss=nan
2025-02-01 18:54:00,642 - INFO - Epoch 506: train_loss=nan
2025-02-01 18:54:01,040 - INFO - Epoch 506: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:01,044 - INFO - ####################Training epoch 507####################
2025-02-01 18:54:01,419 - INFO - Epoch 507: train_loss=nan
2025-02-01 18:54:01,576 - INFO - Epoch 507: train_loss=nan
2025-02-01 18:54:01,710 - INFO - Epoch 507: train_loss=nan
2025-02-01 18:54:02,109 - INFO - Epoch 507: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:02,113 - INFO - ####################Training epoch 508####################
2025-02-01 18:54:02,491 - INFO - Epoch 508: train_loss=nan
2025-02-01 18:54:02,647 - INFO - Epoch 508: train_loss=nan
2025-02-01 18:54:02,780 - INFO - Epoch 508: train_loss=nan
2025-02-01 18:54:03,177 - INFO - Epoch 508: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:03,181 - INFO - ####################Training epoch 509####################
2025-02-01 18:54:03,559 - INFO - Epoch 509: train_loss=nan
2025-02-01 18:54:03,715 - INFO - Epoch 509: train_loss=nan
2025-02-01 18:54:03,849 - INFO - Epoch 509: train_loss=nan
2025-02-01 18:54:04,249 - INFO - Epoch 509: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:04,253 - INFO - ####################Training epoch 510####################
2025-02-01 18:54:04,630 - INFO - Epoch 510: train_loss=nan
2025-02-01 18:54:04,786 - INFO - Epoch 510: train_loss=nan
2025-02-01 18:54:04,919 - INFO - Epoch 510: train_loss=nan
2025-02-01 18:54:05,314 - INFO - Epoch 510: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:05,318 - INFO - ####################Training epoch 511####################
2025-02-01 18:54:05,695 - INFO - Epoch 511: train_loss=nan
2025-02-01 18:54:05,851 - INFO - Epoch 511: train_loss=nan
2025-02-01 18:54:05,984 - INFO - Epoch 511: train_loss=nan
2025-02-01 18:54:06,381 - INFO - Epoch 511: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:06,384 - INFO - ####################Training epoch 512####################
2025-02-01 18:54:06,758 - INFO - Epoch 512: train_loss=nan
2025-02-01 18:54:06,915 - INFO - Epoch 512: train_loss=nan
2025-02-01 18:54:07,048 - INFO - Epoch 512: train_loss=nan
2025-02-01 18:54:07,444 - INFO - Epoch 512: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:07,448 - INFO - ####################Training epoch 513####################
2025-02-01 18:54:07,825 - INFO - Epoch 513: train_loss=nan
2025-02-01 18:54:07,981 - INFO - Epoch 513: train_loss=nan
2025-02-01 18:54:08,115 - INFO - Epoch 513: train_loss=nan
2025-02-01 18:54:08,510 - INFO - Epoch 513: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:08,513 - INFO - ####################Training epoch 514####################
2025-02-01 18:54:08,893 - INFO - Epoch 514: train_loss=nan
2025-02-01 18:54:09,049 - INFO - Epoch 514: train_loss=nan
2025-02-01 18:54:09,182 - INFO - Epoch 514: train_loss=nan
2025-02-01 18:54:09,578 - INFO - Epoch 514: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:09,582 - INFO - ####################Training epoch 515####################
2025-02-01 18:54:09,960 - INFO - Epoch 515: train_loss=nan
2025-02-01 18:54:10,117 - INFO - Epoch 515: train_loss=nan
2025-02-01 18:54:10,251 - INFO - Epoch 515: train_loss=nan
2025-02-01 18:54:10,648 - INFO - Epoch 515: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:10,652 - INFO - ####################Training epoch 516####################
2025-02-01 18:54:11,026 - INFO - Epoch 516: train_loss=nan
2025-02-01 18:54:11,182 - INFO - Epoch 516: train_loss=nan
2025-02-01 18:54:11,315 - INFO - Epoch 516: train_loss=nan
2025-02-01 18:54:11,710 - INFO - Epoch 516: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:11,714 - INFO - ####################Training epoch 517####################
2025-02-01 18:54:12,093 - INFO - Epoch 517: train_loss=nan
2025-02-01 18:54:12,250 - INFO - Epoch 517: train_loss=nan
2025-02-01 18:54:12,383 - INFO - Epoch 517: train_loss=nan
2025-02-01 18:54:12,781 - INFO - Epoch 517: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:12,785 - INFO - ####################Training epoch 518####################
2025-02-01 18:54:13,163 - INFO - Epoch 518: train_loss=nan
2025-02-01 18:54:13,320 - INFO - Epoch 518: train_loss=nan
2025-02-01 18:54:13,453 - INFO - Epoch 518: train_loss=nan
2025-02-01 18:54:13,848 - INFO - Epoch 518: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:13,852 - INFO - ####################Training epoch 519####################
2025-02-01 18:54:14,228 - INFO - Epoch 519: train_loss=nan
2025-02-01 18:54:14,384 - INFO - Epoch 519: train_loss=nan
2025-02-01 18:54:14,517 - INFO - Epoch 519: train_loss=nan
2025-02-01 18:54:14,913 - INFO - Epoch 519: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:14,917 - INFO - ####################Training epoch 520####################
2025-02-01 18:54:15,293 - INFO - Epoch 520: train_loss=nan
2025-02-01 18:54:15,450 - INFO - Epoch 520: train_loss=nan
2025-02-01 18:54:15,583 - INFO - Epoch 520: train_loss=nan
2025-02-01 18:54:15,983 - INFO - Epoch 520: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:15,987 - INFO - ####################Training epoch 521####################
2025-02-01 18:54:16,361 - INFO - Epoch 521: train_loss=nan
2025-02-01 18:54:16,518 - INFO - Epoch 521: train_loss=nan
2025-02-01 18:54:16,652 - INFO - Epoch 521: train_loss=nan
2025-02-01 18:54:17,048 - INFO - Epoch 521: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:17,052 - INFO - ####################Training epoch 522####################
2025-02-01 18:54:17,428 - INFO - Epoch 522: train_loss=nan
2025-02-01 18:54:17,584 - INFO - Epoch 522: train_loss=nan
2025-02-01 18:54:17,717 - INFO - Epoch 522: train_loss=nan
2025-02-01 18:54:18,117 - INFO - Epoch 522: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:18,121 - INFO - ####################Training epoch 523####################
2025-02-01 18:54:18,497 - INFO - Epoch 523: train_loss=nan
2025-02-01 18:54:18,654 - INFO - Epoch 523: train_loss=nan
2025-02-01 18:54:18,787 - INFO - Epoch 523: train_loss=nan
2025-02-01 18:54:19,187 - INFO - Epoch 523: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:19,191 - INFO - ####################Training epoch 524####################
2025-02-01 18:54:19,569 - INFO - Epoch 524: train_loss=nan
2025-02-01 18:54:19,726 - INFO - Epoch 524: train_loss=nan
2025-02-01 18:54:19,859 - INFO - Epoch 524: train_loss=nan
2025-02-01 18:54:20,256 - INFO - Epoch 524: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:20,260 - INFO - ####################Training epoch 525####################
2025-02-01 18:54:20,636 - INFO - Epoch 525: train_loss=nan
2025-02-01 18:54:20,793 - INFO - Epoch 525: train_loss=nan
2025-02-01 18:54:20,925 - INFO - Epoch 525: train_loss=nan
2025-02-01 18:54:21,325 - INFO - Epoch 525: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:21,329 - INFO - ####################Training epoch 526####################
2025-02-01 18:54:21,705 - INFO - Epoch 526: train_loss=nan
2025-02-01 18:54:21,861 - INFO - Epoch 526: train_loss=nan
2025-02-01 18:54:21,994 - INFO - Epoch 526: train_loss=nan
2025-02-01 18:54:22,389 - INFO - Epoch 526: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:22,393 - INFO - ####################Training epoch 527####################
2025-02-01 18:54:22,771 - INFO - Epoch 527: train_loss=nan
2025-02-01 18:54:22,928 - INFO - Epoch 527: train_loss=nan
2025-02-01 18:54:23,061 - INFO - Epoch 527: train_loss=nan
2025-02-01 18:54:23,458 - INFO - Epoch 527: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:23,462 - INFO - ####################Training epoch 528####################
2025-02-01 18:54:23,843 - INFO - Epoch 528: train_loss=nan
2025-02-01 18:54:23,999 - INFO - Epoch 528: train_loss=nan
2025-02-01 18:54:24,132 - INFO - Epoch 528: train_loss=nan
2025-02-01 18:54:24,528 - INFO - Epoch 528: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:24,531 - INFO - ####################Training epoch 529####################
2025-02-01 18:54:24,909 - INFO - Epoch 529: train_loss=nan
2025-02-01 18:54:25,066 - INFO - Epoch 529: train_loss=nan
2025-02-01 18:54:25,199 - INFO - Epoch 529: train_loss=nan
2025-02-01 18:54:25,594 - INFO - Epoch 529: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:25,598 - INFO - ####################Training epoch 530####################
2025-02-01 18:54:25,973 - INFO - Epoch 530: train_loss=nan
2025-02-01 18:54:26,129 - INFO - Epoch 530: train_loss=nan
2025-02-01 18:54:26,263 - INFO - Epoch 530: train_loss=nan
2025-02-01 18:54:26,658 - INFO - Epoch 530: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:26,662 - INFO - ####################Training epoch 531####################
2025-02-01 18:54:27,041 - INFO - Epoch 531: train_loss=nan
2025-02-01 18:54:27,197 - INFO - Epoch 531: train_loss=nan
2025-02-01 18:54:27,331 - INFO - Epoch 531: train_loss=nan
2025-02-01 18:54:27,733 - INFO - Epoch 531: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:27,737 - INFO - ####################Training epoch 532####################
2025-02-01 18:54:28,112 - INFO - Epoch 532: train_loss=nan
2025-02-01 18:54:28,269 - INFO - Epoch 532: train_loss=nan
2025-02-01 18:54:28,402 - INFO - Epoch 532: train_loss=nan
2025-02-01 18:54:28,799 - INFO - Epoch 532: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:28,802 - INFO - ####################Training epoch 533####################
2025-02-01 18:54:29,179 - INFO - Epoch 533: train_loss=nan
2025-02-01 18:54:29,336 - INFO - Epoch 533: train_loss=nan
2025-02-01 18:54:29,469 - INFO - Epoch 533: train_loss=nan
2025-02-01 18:54:29,868 - INFO - Epoch 533: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:29,871 - INFO - ####################Training epoch 534####################
2025-02-01 18:54:30,250 - INFO - Epoch 534: train_loss=nan
2025-02-01 18:54:30,407 - INFO - Epoch 534: train_loss=nan
2025-02-01 18:54:30,540 - INFO - Epoch 534: train_loss=nan
2025-02-01 18:54:30,940 - INFO - Epoch 534: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:30,943 - INFO - ####################Training epoch 535####################
2025-02-01 18:54:31,322 - INFO - Epoch 535: train_loss=nan
2025-02-01 18:54:31,479 - INFO - Epoch 535: train_loss=nan
2025-02-01 18:54:31,612 - INFO - Epoch 535: train_loss=nan
2025-02-01 18:54:32,009 - INFO - Epoch 535: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:32,013 - INFO - ####################Training epoch 536####################
2025-02-01 18:54:32,392 - INFO - Epoch 536: train_loss=nan
2025-02-01 18:54:32,549 - INFO - Epoch 536: train_loss=nan
2025-02-01 18:54:32,682 - INFO - Epoch 536: train_loss=nan
2025-02-01 18:54:33,076 - INFO - Epoch 536: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:33,079 - INFO - ####################Training epoch 537####################
2025-02-01 18:54:33,455 - INFO - Epoch 537: train_loss=nan
2025-02-01 18:54:33,612 - INFO - Epoch 537: train_loss=nan
2025-02-01 18:54:33,746 - INFO - Epoch 537: train_loss=nan
2025-02-01 18:54:34,146 - INFO - Epoch 537: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:34,149 - INFO - ####################Training epoch 538####################
2025-02-01 18:54:34,526 - INFO - Epoch 538: train_loss=nan
2025-02-01 18:54:34,683 - INFO - Epoch 538: train_loss=nan
2025-02-01 18:54:34,815 - INFO - Epoch 538: train_loss=nan
2025-02-01 18:54:35,217 - INFO - Epoch 538: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:35,221 - INFO - ####################Training epoch 539####################
2025-02-01 18:54:35,600 - INFO - Epoch 539: train_loss=nan
2025-02-01 18:54:35,756 - INFO - Epoch 539: train_loss=nan
2025-02-01 18:54:35,889 - INFO - Epoch 539: train_loss=nan
2025-02-01 18:54:36,286 - INFO - Epoch 539: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:36,290 - INFO - ####################Training epoch 540####################
2025-02-01 18:54:36,666 - INFO - Epoch 540: train_loss=nan
2025-02-01 18:54:36,822 - INFO - Epoch 540: train_loss=nan
2025-02-01 18:54:36,955 - INFO - Epoch 540: train_loss=nan
2025-02-01 18:54:37,357 - INFO - Epoch 540: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:37,360 - INFO - ####################Training epoch 541####################
2025-02-01 18:54:37,739 - INFO - Epoch 541: train_loss=nan
2025-02-01 18:54:37,895 - INFO - Epoch 541: train_loss=nan
2025-02-01 18:54:38,028 - INFO - Epoch 541: train_loss=nan
2025-02-01 18:54:38,422 - INFO - Epoch 541: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:38,426 - INFO - ####################Training epoch 542####################
2025-02-01 18:54:38,803 - INFO - Epoch 542: train_loss=nan
2025-02-01 18:54:38,959 - INFO - Epoch 542: train_loss=nan
2025-02-01 18:54:39,092 - INFO - Epoch 542: train_loss=nan
2025-02-01 18:54:39,486 - INFO - Epoch 542: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:39,490 - INFO - ####################Training epoch 543####################
2025-02-01 18:54:39,870 - INFO - Epoch 543: train_loss=nan
2025-02-01 18:54:40,027 - INFO - Epoch 543: train_loss=nan
2025-02-01 18:54:40,161 - INFO - Epoch 543: train_loss=nan
2025-02-01 18:54:40,557 - INFO - Epoch 543: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:40,561 - INFO - ####################Training epoch 544####################
2025-02-01 18:54:40,936 - INFO - Epoch 544: train_loss=nan
2025-02-01 18:54:41,093 - INFO - Epoch 544: train_loss=nan
2025-02-01 18:54:41,226 - INFO - Epoch 544: train_loss=nan
2025-02-01 18:54:41,623 - INFO - Epoch 544: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:41,627 - INFO - ####################Training epoch 545####################
2025-02-01 18:54:42,005 - INFO - Epoch 545: train_loss=nan
2025-02-01 18:54:42,161 - INFO - Epoch 545: train_loss=nan
2025-02-01 18:54:42,294 - INFO - Epoch 545: train_loss=nan
2025-02-01 18:54:42,695 - INFO - Epoch 545: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:42,699 - INFO - ####################Training epoch 546####################
2025-02-01 18:54:43,077 - INFO - Epoch 546: train_loss=nan
2025-02-01 18:54:43,233 - INFO - Epoch 546: train_loss=nan
2025-02-01 18:54:43,367 - INFO - Epoch 546: train_loss=nan
2025-02-01 18:54:43,762 - INFO - Epoch 546: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:43,766 - INFO - ####################Training epoch 547####################
2025-02-01 18:54:44,140 - INFO - Epoch 547: train_loss=nan
2025-02-01 18:54:44,297 - INFO - Epoch 547: train_loss=nan
2025-02-01 18:54:44,430 - INFO - Epoch 547: train_loss=nan
2025-02-01 18:54:44,827 - INFO - Epoch 547: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:44,831 - INFO - ####################Training epoch 548####################
2025-02-01 18:54:45,206 - INFO - Epoch 548: train_loss=nan
2025-02-01 18:54:45,363 - INFO - Epoch 548: train_loss=nan
2025-02-01 18:54:45,496 - INFO - Epoch 548: train_loss=nan
2025-02-01 18:54:45,892 - INFO - Epoch 548: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:45,899 - INFO - ####################Training epoch 549####################
2025-02-01 18:54:46,276 - INFO - Epoch 549: train_loss=nan
2025-02-01 18:54:46,432 - INFO - Epoch 549: train_loss=nan
2025-02-01 18:54:46,566 - INFO - Epoch 549: train_loss=nan
2025-02-01 18:54:46,961 - INFO - Epoch 549: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:46,964 - INFO - ####################Training epoch 550####################
2025-02-01 18:54:47,342 - INFO - Epoch 550: train_loss=nan
2025-02-01 18:54:47,499 - INFO - Epoch 550: train_loss=nan
2025-02-01 18:54:47,632 - INFO - Epoch 550: train_loss=nan
2025-02-01 18:54:48,030 - INFO - Epoch 550: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:48,033 - INFO - ####################Training epoch 551####################
2025-02-01 18:54:48,412 - INFO - Epoch 551: train_loss=nan
2025-02-01 18:54:48,568 - INFO - Epoch 551: train_loss=nan
2025-02-01 18:54:48,702 - INFO - Epoch 551: train_loss=nan
2025-02-01 18:54:49,100 - INFO - Epoch 551: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:49,103 - INFO - ####################Training epoch 552####################
2025-02-01 18:54:49,479 - INFO - Epoch 552: train_loss=nan
2025-02-01 18:54:49,635 - INFO - Epoch 552: train_loss=nan
2025-02-01 18:54:49,768 - INFO - Epoch 552: train_loss=nan
2025-02-01 18:54:50,167 - INFO - Epoch 552: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:50,170 - INFO - ####################Training epoch 553####################
2025-02-01 18:54:50,546 - INFO - Epoch 553: train_loss=nan
2025-02-01 18:54:50,703 - INFO - Epoch 553: train_loss=nan
2025-02-01 18:54:50,837 - INFO - Epoch 553: train_loss=nan
2025-02-01 18:54:51,236 - INFO - Epoch 553: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:51,239 - INFO - ####################Training epoch 554####################
2025-02-01 18:54:51,615 - INFO - Epoch 554: train_loss=nan
2025-02-01 18:54:51,771 - INFO - Epoch 554: train_loss=nan
2025-02-01 18:54:51,904 - INFO - Epoch 554: train_loss=nan
2025-02-01 18:54:52,301 - INFO - Epoch 554: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:52,305 - INFO - ####################Training epoch 555####################
2025-02-01 18:54:52,682 - INFO - Epoch 555: train_loss=nan
2025-02-01 18:54:52,839 - INFO - Epoch 555: train_loss=nan
2025-02-01 18:54:52,971 - INFO - Epoch 555: train_loss=nan
2025-02-01 18:54:53,375 - INFO - Epoch 555: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:53,379 - INFO - ####################Training epoch 556####################
2025-02-01 18:54:53,754 - INFO - Epoch 556: train_loss=nan
2025-02-01 18:54:53,910 - INFO - Epoch 556: train_loss=nan
2025-02-01 18:54:54,043 - INFO - Epoch 556: train_loss=nan
2025-02-01 18:54:54,443 - INFO - Epoch 556: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:54,447 - INFO - ####################Training epoch 557####################
2025-02-01 18:54:54,823 - INFO - Epoch 557: train_loss=nan
2025-02-01 18:54:54,980 - INFO - Epoch 557: train_loss=nan
2025-02-01 18:54:55,114 - INFO - Epoch 557: train_loss=nan
2025-02-01 18:54:55,509 - INFO - Epoch 557: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:55,513 - INFO - ####################Training epoch 558####################
2025-02-01 18:54:55,892 - INFO - Epoch 558: train_loss=nan
2025-02-01 18:54:56,048 - INFO - Epoch 558: train_loss=nan
2025-02-01 18:54:56,182 - INFO - Epoch 558: train_loss=nan
2025-02-01 18:54:56,579 - INFO - Epoch 558: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:56,583 - INFO - ####################Training epoch 559####################
2025-02-01 18:54:56,960 - INFO - Epoch 559: train_loss=nan
2025-02-01 18:54:57,116 - INFO - Epoch 559: train_loss=nan
2025-02-01 18:54:57,249 - INFO - Epoch 559: train_loss=nan
2025-02-01 18:54:57,647 - INFO - Epoch 559: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:57,651 - INFO - ####################Training epoch 560####################
2025-02-01 18:54:58,027 - INFO - Epoch 560: train_loss=nan
2025-02-01 18:54:58,184 - INFO - Epoch 560: train_loss=nan
2025-02-01 18:54:58,317 - INFO - Epoch 560: train_loss=nan
2025-02-01 18:54:58,711 - INFO - Epoch 560: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:58,714 - INFO - ####################Training epoch 561####################
2025-02-01 18:54:59,089 - INFO - Epoch 561: train_loss=nan
2025-02-01 18:54:59,245 - INFO - Epoch 561: train_loss=nan
2025-02-01 18:54:59,379 - INFO - Epoch 561: train_loss=nan
2025-02-01 18:54:59,771 - INFO - Epoch 561: val_loss=nan, val_acc=66.67%
2025-02-01 18:54:59,774 - INFO - ####################Training epoch 562####################
2025-02-01 18:55:00,151 - INFO - Epoch 562: train_loss=nan
2025-02-01 18:55:00,307 - INFO - Epoch 562: train_loss=nan
2025-02-01 18:55:00,440 - INFO - Epoch 562: train_loss=nan
2025-02-01 18:55:00,839 - INFO - Epoch 562: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:00,843 - INFO - ####################Training epoch 563####################
2025-02-01 18:55:01,220 - INFO - Epoch 563: train_loss=nan
2025-02-01 18:55:01,376 - INFO - Epoch 563: train_loss=nan
2025-02-01 18:55:01,509 - INFO - Epoch 563: train_loss=nan
2025-02-01 18:55:01,908 - INFO - Epoch 563: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:01,912 - INFO - ####################Training epoch 564####################
2025-02-01 18:55:02,287 - INFO - Epoch 564: train_loss=nan
2025-02-01 18:55:02,444 - INFO - Epoch 564: train_loss=nan
2025-02-01 18:55:02,577 - INFO - Epoch 564: train_loss=nan
2025-02-01 18:55:02,973 - INFO - Epoch 564: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:02,977 - INFO - ####################Training epoch 565####################
2025-02-01 18:55:03,353 - INFO - Epoch 565: train_loss=nan
2025-02-01 18:55:03,509 - INFO - Epoch 565: train_loss=nan
2025-02-01 18:55:03,643 - INFO - Epoch 565: train_loss=nan
2025-02-01 18:55:04,037 - INFO - Epoch 565: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:04,041 - INFO - ####################Training epoch 566####################
2025-02-01 18:55:04,417 - INFO - Epoch 566: train_loss=nan
2025-02-01 18:55:04,573 - INFO - Epoch 566: train_loss=nan
2025-02-01 18:55:04,706 - INFO - Epoch 566: train_loss=nan
2025-02-01 18:55:05,101 - INFO - Epoch 566: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:05,105 - INFO - ####################Training epoch 567####################
2025-02-01 18:55:05,483 - INFO - Epoch 567: train_loss=nan
2025-02-01 18:55:05,639 - INFO - Epoch 567: train_loss=nan
2025-02-01 18:55:05,773 - INFO - Epoch 567: train_loss=nan
2025-02-01 18:55:06,168 - INFO - Epoch 567: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:06,172 - INFO - ####################Training epoch 568####################
2025-02-01 18:55:06,547 - INFO - Epoch 568: train_loss=nan
2025-02-01 18:55:06,704 - INFO - Epoch 568: train_loss=nan
2025-02-01 18:55:06,837 - INFO - Epoch 568: train_loss=nan
2025-02-01 18:55:07,233 - INFO - Epoch 568: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:07,237 - INFO - ####################Training epoch 569####################
2025-02-01 18:55:07,615 - INFO - Epoch 569: train_loss=nan
2025-02-01 18:55:07,771 - INFO - Epoch 569: train_loss=nan
2025-02-01 18:55:07,904 - INFO - Epoch 569: train_loss=nan
2025-02-01 18:55:08,301 - INFO - Epoch 569: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:08,304 - INFO - ####################Training epoch 570####################
2025-02-01 18:55:08,682 - INFO - Epoch 570: train_loss=nan
2025-02-01 18:55:08,839 - INFO - Epoch 570: train_loss=nan
2025-02-01 18:55:08,972 - INFO - Epoch 570: train_loss=nan
2025-02-01 18:55:09,368 - INFO - Epoch 570: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:09,371 - INFO - ####################Training epoch 571####################
2025-02-01 18:55:09,745 - INFO - Epoch 571: train_loss=nan
2025-02-01 18:55:09,902 - INFO - Epoch 571: train_loss=nan
2025-02-01 18:55:10,036 - INFO - Epoch 571: train_loss=nan
2025-02-01 18:55:10,433 - INFO - Epoch 571: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:10,436 - INFO - ####################Training epoch 572####################
2025-02-01 18:55:10,811 - INFO - Epoch 572: train_loss=nan
2025-02-01 18:55:10,968 - INFO - Epoch 572: train_loss=nan
2025-02-01 18:55:11,101 - INFO - Epoch 572: train_loss=nan
2025-02-01 18:55:11,501 - INFO - Epoch 572: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:11,504 - INFO - ####################Training epoch 573####################
2025-02-01 18:55:11,881 - INFO - Epoch 573: train_loss=nan
2025-02-01 18:55:12,038 - INFO - Epoch 573: train_loss=nan
2025-02-01 18:55:12,172 - INFO - Epoch 573: train_loss=nan
2025-02-01 18:55:12,568 - INFO - Epoch 573: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:12,576 - INFO - ####################Training epoch 574####################
2025-02-01 18:55:12,950 - INFO - Epoch 574: train_loss=nan
2025-02-01 18:55:13,106 - INFO - Epoch 574: train_loss=nan
2025-02-01 18:55:13,239 - INFO - Epoch 574: train_loss=nan
2025-02-01 18:55:13,639 - INFO - Epoch 574: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:13,642 - INFO - ####################Training epoch 575####################
2025-02-01 18:55:14,020 - INFO - Epoch 575: train_loss=nan
2025-02-01 18:55:14,177 - INFO - Epoch 575: train_loss=nan
2025-02-01 18:55:14,310 - INFO - Epoch 575: train_loss=nan
2025-02-01 18:55:14,704 - INFO - Epoch 575: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:14,708 - INFO - ####################Training epoch 576####################
2025-02-01 18:55:15,083 - INFO - Epoch 576: train_loss=nan
2025-02-01 18:55:15,240 - INFO - Epoch 576: train_loss=nan
2025-02-01 18:55:15,373 - INFO - Epoch 576: train_loss=nan
2025-02-01 18:55:15,769 - INFO - Epoch 576: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:15,773 - INFO - ####################Training epoch 577####################
2025-02-01 18:55:16,148 - INFO - Epoch 577: train_loss=nan
2025-02-01 18:55:16,304 - INFO - Epoch 577: train_loss=nan
2025-02-01 18:55:16,437 - INFO - Epoch 577: train_loss=nan
2025-02-01 18:55:16,836 - INFO - Epoch 577: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:16,840 - INFO - ####################Training epoch 578####################
2025-02-01 18:55:17,214 - INFO - Epoch 578: train_loss=nan
2025-02-01 18:55:17,371 - INFO - Epoch 578: train_loss=nan
2025-02-01 18:55:17,503 - INFO - Epoch 578: train_loss=nan
2025-02-01 18:55:17,899 - INFO - Epoch 578: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:17,902 - INFO - ####################Training epoch 579####################
2025-02-01 18:55:18,279 - INFO - Epoch 579: train_loss=nan
2025-02-01 18:55:18,436 - INFO - Epoch 579: train_loss=nan
2025-02-01 18:55:18,569 - INFO - Epoch 579: train_loss=nan
2025-02-01 18:55:18,965 - INFO - Epoch 579: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:18,969 - INFO - ####################Training epoch 580####################
2025-02-01 18:55:19,342 - INFO - Epoch 580: train_loss=nan
2025-02-01 18:55:19,499 - INFO - Epoch 580: train_loss=nan
2025-02-01 18:55:19,632 - INFO - Epoch 580: train_loss=nan
2025-02-01 18:55:20,027 - INFO - Epoch 580: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:20,030 - INFO - ####################Training epoch 581####################
2025-02-01 18:55:20,400 - INFO - Epoch 581: train_loss=nan
2025-02-01 18:55:20,557 - INFO - Epoch 581: train_loss=nan
2025-02-01 18:55:20,690 - INFO - Epoch 581: train_loss=nan
2025-02-01 18:55:21,085 - INFO - Epoch 581: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:21,089 - INFO - ####################Training epoch 582####################
2025-02-01 18:55:21,461 - INFO - Epoch 582: train_loss=nan
2025-02-01 18:55:21,617 - INFO - Epoch 582: train_loss=nan
2025-02-01 18:55:21,751 - INFO - Epoch 582: train_loss=nan
2025-02-01 18:55:22,148 - INFO - Epoch 582: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:22,152 - INFO - ####################Training epoch 583####################
2025-02-01 18:55:22,530 - INFO - Epoch 583: train_loss=nan
2025-02-01 18:55:22,687 - INFO - Epoch 583: train_loss=nan
2025-02-01 18:55:22,820 - INFO - Epoch 583: train_loss=nan
2025-02-01 18:55:23,217 - INFO - Epoch 583: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:23,221 - INFO - ####################Training epoch 584####################
2025-02-01 18:55:23,598 - INFO - Epoch 584: train_loss=nan
2025-02-01 18:55:23,755 - INFO - Epoch 584: train_loss=nan
2025-02-01 18:55:23,889 - INFO - Epoch 584: train_loss=nan
2025-02-01 18:55:24,285 - INFO - Epoch 584: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:24,288 - INFO - ####################Training epoch 585####################
2025-02-01 18:55:24,664 - INFO - Epoch 585: train_loss=nan
2025-02-01 18:55:24,821 - INFO - Epoch 585: train_loss=nan
2025-02-01 18:55:24,954 - INFO - Epoch 585: train_loss=nan
2025-02-01 18:55:25,349 - INFO - Epoch 585: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:25,352 - INFO - ####################Training epoch 586####################
2025-02-01 18:55:25,729 - INFO - Epoch 586: train_loss=nan
2025-02-01 18:55:25,885 - INFO - Epoch 586: train_loss=nan
2025-02-01 18:55:26,018 - INFO - Epoch 586: train_loss=nan
2025-02-01 18:55:26,415 - INFO - Epoch 586: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:26,419 - INFO - ####################Training epoch 587####################
2025-02-01 18:55:26,796 - INFO - Epoch 587: train_loss=nan
2025-02-01 18:55:26,953 - INFO - Epoch 587: train_loss=nan
2025-02-01 18:55:27,087 - INFO - Epoch 587: train_loss=nan
2025-02-01 18:55:27,486 - INFO - Epoch 587: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:27,490 - INFO - ####################Training epoch 588####################
2025-02-01 18:55:27,867 - INFO - Epoch 588: train_loss=nan
2025-02-01 18:55:28,023 - INFO - Epoch 588: train_loss=nan
2025-02-01 18:55:28,156 - INFO - Epoch 588: train_loss=nan
2025-02-01 18:55:28,554 - INFO - Epoch 588: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:28,557 - INFO - ####################Training epoch 589####################
2025-02-01 18:55:28,932 - INFO - Epoch 589: train_loss=nan
2025-02-01 18:55:29,088 - INFO - Epoch 589: train_loss=nan
2025-02-01 18:55:29,221 - INFO - Epoch 589: train_loss=nan
2025-02-01 18:55:29,620 - INFO - Epoch 589: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:29,624 - INFO - ####################Training epoch 590####################
2025-02-01 18:55:29,995 - INFO - Epoch 590: train_loss=nan
2025-02-01 18:55:30,152 - INFO - Epoch 590: train_loss=nan
2025-02-01 18:55:30,285 - INFO - Epoch 590: train_loss=nan
2025-02-01 18:55:30,685 - INFO - Epoch 590: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:30,689 - INFO - ####################Training epoch 591####################
2025-02-01 18:55:31,064 - INFO - Epoch 591: train_loss=nan
2025-02-01 18:55:31,220 - INFO - Epoch 591: train_loss=nan
2025-02-01 18:55:31,353 - INFO - Epoch 591: train_loss=nan
2025-02-01 18:55:31,750 - INFO - Epoch 591: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:31,754 - INFO - ####################Training epoch 592####################
2025-02-01 18:55:32,131 - INFO - Epoch 592: train_loss=nan
2025-02-01 18:55:32,287 - INFO - Epoch 592: train_loss=nan
2025-02-01 18:55:32,420 - INFO - Epoch 592: train_loss=nan
2025-02-01 18:55:32,818 - INFO - Epoch 592: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:32,822 - INFO - ####################Training epoch 593####################
2025-02-01 18:55:33,198 - INFO - Epoch 593: train_loss=nan
2025-02-01 18:55:33,354 - INFO - Epoch 593: train_loss=nan
2025-02-01 18:55:33,488 - INFO - Epoch 593: train_loss=nan
2025-02-01 18:55:33,888 - INFO - Epoch 593: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:33,892 - INFO - ####################Training epoch 594####################
2025-02-01 18:55:34,267 - INFO - Epoch 594: train_loss=nan
2025-02-01 18:55:34,423 - INFO - Epoch 594: train_loss=nan
2025-02-01 18:55:34,556 - INFO - Epoch 594: train_loss=nan
2025-02-01 18:55:34,953 - INFO - Epoch 594: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:34,957 - INFO - ####################Training epoch 595####################
2025-02-01 18:55:35,332 - INFO - Epoch 595: train_loss=nan
2025-02-01 18:55:35,489 - INFO - Epoch 595: train_loss=nan
2025-02-01 18:55:35,623 - INFO - Epoch 595: train_loss=nan
2025-02-01 18:55:36,021 - INFO - Epoch 595: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:36,024 - INFO - ####################Training epoch 596####################
2025-02-01 18:55:36,402 - INFO - Epoch 596: train_loss=nan
2025-02-01 18:55:36,558 - INFO - Epoch 596: train_loss=nan
2025-02-01 18:55:36,691 - INFO - Epoch 596: train_loss=nan
2025-02-01 18:55:37,089 - INFO - Epoch 596: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:37,092 - INFO - ####################Training epoch 597####################
2025-02-01 18:55:37,468 - INFO - Epoch 597: train_loss=nan
2025-02-01 18:55:37,624 - INFO - Epoch 597: train_loss=nan
2025-02-01 18:55:37,757 - INFO - Epoch 597: train_loss=nan
2025-02-01 18:55:38,152 - INFO - Epoch 597: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:38,156 - INFO - ####################Training epoch 598####################
2025-02-01 18:55:38,532 - INFO - Epoch 598: train_loss=nan
2025-02-01 18:55:38,689 - INFO - Epoch 598: train_loss=nan
2025-02-01 18:55:38,822 - INFO - Epoch 598: train_loss=nan
2025-02-01 18:55:39,219 - INFO - Epoch 598: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:39,226 - INFO - ####################Training epoch 599####################
2025-02-01 18:55:39,601 - INFO - Epoch 599: train_loss=nan
2025-02-01 18:55:39,757 - INFO - Epoch 599: train_loss=nan
2025-02-01 18:55:39,890 - INFO - Epoch 599: train_loss=nan
2025-02-01 18:55:40,285 - INFO - Epoch 599: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:40,288 - INFO - ####################Training epoch 600####################
2025-02-01 18:55:40,665 - INFO - Epoch 600: train_loss=nan
2025-02-01 18:55:40,821 - INFO - Epoch 600: train_loss=nan
2025-02-01 18:55:40,954 - INFO - Epoch 600: train_loss=nan
2025-02-01 18:55:41,349 - INFO - Epoch 600: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:41,353 - INFO - ####################Training epoch 601####################
2025-02-01 18:55:41,730 - INFO - Epoch 601: train_loss=nan
2025-02-01 18:55:41,886 - INFO - Epoch 601: train_loss=nan
2025-02-01 18:55:42,020 - INFO - Epoch 601: train_loss=nan
2025-02-01 18:55:42,417 - INFO - Epoch 601: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:42,421 - INFO - ####################Training epoch 602####################
2025-02-01 18:55:42,798 - INFO - Epoch 602: train_loss=nan
2025-02-01 18:55:42,955 - INFO - Epoch 602: train_loss=nan
2025-02-01 18:55:43,088 - INFO - Epoch 602: train_loss=nan
2025-02-01 18:55:43,486 - INFO - Epoch 602: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:43,489 - INFO - ####################Training epoch 603####################
2025-02-01 18:55:43,865 - INFO - Epoch 603: train_loss=nan
2025-02-01 18:55:44,021 - INFO - Epoch 603: train_loss=nan
2025-02-01 18:55:44,155 - INFO - Epoch 603: train_loss=nan
2025-02-01 18:55:44,548 - INFO - Epoch 603: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:44,552 - INFO - ####################Training epoch 604####################
2025-02-01 18:55:44,931 - INFO - Epoch 604: train_loss=nan
2025-02-01 18:55:45,089 - INFO - Epoch 604: train_loss=nan
2025-02-01 18:55:45,222 - INFO - Epoch 604: train_loss=nan
2025-02-01 18:55:45,622 - INFO - Epoch 604: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:45,625 - INFO - ####################Training epoch 605####################
2025-02-01 18:55:46,003 - INFO - Epoch 605: train_loss=nan
2025-02-01 18:55:46,159 - INFO - Epoch 605: train_loss=nan
2025-02-01 18:55:46,292 - INFO - Epoch 605: train_loss=nan
2025-02-01 18:55:46,690 - INFO - Epoch 605: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:46,694 - INFO - ####################Training epoch 606####################
2025-02-01 18:55:47,068 - INFO - Epoch 606: train_loss=nan
2025-02-01 18:55:47,225 - INFO - Epoch 606: train_loss=nan
2025-02-01 18:55:47,358 - INFO - Epoch 606: train_loss=nan
2025-02-01 18:55:47,760 - INFO - Epoch 606: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:47,763 - INFO - ####################Training epoch 607####################
2025-02-01 18:55:48,140 - INFO - Epoch 607: train_loss=nan
2025-02-01 18:55:48,296 - INFO - Epoch 607: train_loss=nan
2025-02-01 18:55:48,429 - INFO - Epoch 607: train_loss=nan
2025-02-01 18:55:48,826 - INFO - Epoch 607: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:48,830 - INFO - ####################Training epoch 608####################
2025-02-01 18:55:49,207 - INFO - Epoch 608: train_loss=nan
2025-02-01 18:55:49,363 - INFO - Epoch 608: train_loss=nan
2025-02-01 18:55:49,497 - INFO - Epoch 608: train_loss=nan
2025-02-01 18:55:49,892 - INFO - Epoch 608: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:49,895 - INFO - ####################Training epoch 609####################
2025-02-01 18:55:50,270 - INFO - Epoch 609: train_loss=nan
2025-02-01 18:55:50,427 - INFO - Epoch 609: train_loss=nan
2025-02-01 18:55:50,560 - INFO - Epoch 609: train_loss=nan
2025-02-01 18:55:50,955 - INFO - Epoch 609: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:50,959 - INFO - ####################Training epoch 610####################
2025-02-01 18:55:51,338 - INFO - Epoch 610: train_loss=nan
2025-02-01 18:55:51,494 - INFO - Epoch 610: train_loss=nan
2025-02-01 18:55:51,627 - INFO - Epoch 610: train_loss=nan
2025-02-01 18:55:52,023 - INFO - Epoch 610: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:52,027 - INFO - ####################Training epoch 611####################
2025-02-01 18:55:52,405 - INFO - Epoch 611: train_loss=nan
2025-02-01 18:55:52,562 - INFO - Epoch 611: train_loss=nan
2025-02-01 18:55:52,695 - INFO - Epoch 611: train_loss=nan
2025-02-01 18:55:53,090 - INFO - Epoch 611: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:53,094 - INFO - ####################Training epoch 612####################
2025-02-01 18:55:53,474 - INFO - Epoch 612: train_loss=nan
2025-02-01 18:55:53,630 - INFO - Epoch 612: train_loss=nan
2025-02-01 18:55:53,763 - INFO - Epoch 612: train_loss=nan
2025-02-01 18:55:54,161 - INFO - Epoch 612: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:54,164 - INFO - ####################Training epoch 613####################
2025-02-01 18:55:54,540 - INFO - Epoch 613: train_loss=nan
2025-02-01 18:55:54,697 - INFO - Epoch 613: train_loss=nan
2025-02-01 18:55:54,830 - INFO - Epoch 613: train_loss=nan
2025-02-01 18:55:55,226 - INFO - Epoch 613: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:55,229 - INFO - ####################Training epoch 614####################
2025-02-01 18:55:55,607 - INFO - Epoch 614: train_loss=nan
2025-02-01 18:55:55,764 - INFO - Epoch 614: train_loss=nan
2025-02-01 18:55:55,897 - INFO - Epoch 614: train_loss=nan
2025-02-01 18:55:56,293 - INFO - Epoch 614: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:56,297 - INFO - ####################Training epoch 615####################
2025-02-01 18:55:56,672 - INFO - Epoch 615: train_loss=nan
2025-02-01 18:55:56,829 - INFO - Epoch 615: train_loss=nan
2025-02-01 18:55:56,962 - INFO - Epoch 615: train_loss=nan
2025-02-01 18:55:57,360 - INFO - Epoch 615: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:57,363 - INFO - ####################Training epoch 616####################
2025-02-01 18:55:57,744 - INFO - Epoch 616: train_loss=nan
2025-02-01 18:55:57,901 - INFO - Epoch 616: train_loss=nan
2025-02-01 18:55:58,034 - INFO - Epoch 616: train_loss=nan
2025-02-01 18:55:58,429 - INFO - Epoch 616: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:58,432 - INFO - ####################Training epoch 617####################
2025-02-01 18:55:58,810 - INFO - Epoch 617: train_loss=nan
2025-02-01 18:55:58,966 - INFO - Epoch 617: train_loss=nan
2025-02-01 18:55:59,100 - INFO - Epoch 617: train_loss=nan
2025-02-01 18:55:59,495 - INFO - Epoch 617: val_loss=nan, val_acc=66.67%
2025-02-01 18:55:59,499 - INFO - ####################Training epoch 618####################
2025-02-01 18:55:59,878 - INFO - Epoch 618: train_loss=nan
2025-02-01 18:56:00,035 - INFO - Epoch 618: train_loss=nan
2025-02-01 18:56:00,168 - INFO - Epoch 618: train_loss=nan
2025-02-01 18:56:00,563 - INFO - Epoch 618: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:00,567 - INFO - ####################Training epoch 619####################
2025-02-01 18:56:00,939 - INFO - Epoch 619: train_loss=nan
2025-02-01 18:56:01,095 - INFO - Epoch 619: train_loss=nan
2025-02-01 18:56:01,228 - INFO - Epoch 619: train_loss=nan
2025-02-01 18:56:01,622 - INFO - Epoch 619: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:01,626 - INFO - ####################Training epoch 620####################
2025-02-01 18:56:02,006 - INFO - Epoch 620: train_loss=nan
2025-02-01 18:56:02,163 - INFO - Epoch 620: train_loss=nan
2025-02-01 18:56:02,296 - INFO - Epoch 620: train_loss=nan
2025-02-01 18:56:02,692 - INFO - Epoch 620: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:02,696 - INFO - ####################Training epoch 621####################
2025-02-01 18:56:03,071 - INFO - Epoch 621: train_loss=nan
2025-02-01 18:56:03,227 - INFO - Epoch 621: train_loss=nan
2025-02-01 18:56:03,360 - INFO - Epoch 621: train_loss=nan
2025-02-01 18:56:03,759 - INFO - Epoch 621: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:03,762 - INFO - ####################Training epoch 622####################
2025-02-01 18:56:04,140 - INFO - Epoch 622: train_loss=nan
2025-02-01 18:56:04,296 - INFO - Epoch 622: train_loss=nan
2025-02-01 18:56:04,429 - INFO - Epoch 622: train_loss=nan
2025-02-01 18:56:04,834 - INFO - Epoch 622: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:04,838 - INFO - ####################Training epoch 623####################
2025-02-01 18:56:05,214 - INFO - Epoch 623: train_loss=nan
2025-02-01 18:56:05,370 - INFO - Epoch 623: train_loss=nan
2025-02-01 18:56:05,503 - INFO - Epoch 623: train_loss=nan
2025-02-01 18:56:05,901 - INFO - Epoch 623: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:05,908 - INFO - ####################Training epoch 624####################
2025-02-01 18:56:06,286 - INFO - Epoch 624: train_loss=nan
2025-02-01 18:56:06,442 - INFO - Epoch 624: train_loss=nan
2025-02-01 18:56:06,576 - INFO - Epoch 624: train_loss=nan
2025-02-01 18:56:06,975 - INFO - Epoch 624: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:06,978 - INFO - ####################Training epoch 625####################
2025-02-01 18:56:07,354 - INFO - Epoch 625: train_loss=nan
2025-02-01 18:56:07,510 - INFO - Epoch 625: train_loss=nan
2025-02-01 18:56:07,643 - INFO - Epoch 625: train_loss=nan
2025-02-01 18:56:08,044 - INFO - Epoch 625: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:08,048 - INFO - ####################Training epoch 626####################
2025-02-01 18:56:08,424 - INFO - Epoch 626: train_loss=nan
2025-02-01 18:56:08,581 - INFO - Epoch 626: train_loss=nan
2025-02-01 18:56:08,715 - INFO - Epoch 626: train_loss=nan
2025-02-01 18:56:09,109 - INFO - Epoch 626: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:09,113 - INFO - ####################Training epoch 627####################
2025-02-01 18:56:09,491 - INFO - Epoch 627: train_loss=nan
2025-02-01 18:56:09,647 - INFO - Epoch 627: train_loss=nan
2025-02-01 18:56:09,780 - INFO - Epoch 627: train_loss=nan
2025-02-01 18:56:10,178 - INFO - Epoch 627: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:10,182 - INFO - ####################Training epoch 628####################
2025-02-01 18:56:10,558 - INFO - Epoch 628: train_loss=nan
2025-02-01 18:56:10,715 - INFO - Epoch 628: train_loss=nan
2025-02-01 18:56:10,848 - INFO - Epoch 628: train_loss=nan
2025-02-01 18:56:11,243 - INFO - Epoch 628: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:11,247 - INFO - ####################Training epoch 629####################
2025-02-01 18:56:11,624 - INFO - Epoch 629: train_loss=nan
2025-02-01 18:56:11,781 - INFO - Epoch 629: train_loss=nan
2025-02-01 18:56:11,914 - INFO - Epoch 629: train_loss=nan
2025-02-01 18:56:12,311 - INFO - Epoch 629: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:12,314 - INFO - ####################Training epoch 630####################
2025-02-01 18:56:12,692 - INFO - Epoch 630: train_loss=nan
2025-02-01 18:56:12,848 - INFO - Epoch 630: train_loss=nan
2025-02-01 18:56:12,981 - INFO - Epoch 630: train_loss=nan
2025-02-01 18:56:13,379 - INFO - Epoch 630: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:13,383 - INFO - ####################Training epoch 631####################
2025-02-01 18:56:13,759 - INFO - Epoch 631: train_loss=nan
2025-02-01 18:56:13,916 - INFO - Epoch 631: train_loss=nan
2025-02-01 18:56:14,049 - INFO - Epoch 631: train_loss=nan
2025-02-01 18:56:14,447 - INFO - Epoch 631: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:14,451 - INFO - ####################Training epoch 632####################
2025-02-01 18:56:14,825 - INFO - Epoch 632: train_loss=nan
2025-02-01 18:56:14,982 - INFO - Epoch 632: train_loss=nan
2025-02-01 18:56:15,115 - INFO - Epoch 632: train_loss=nan
2025-02-01 18:56:15,604 - INFO - Epoch 632: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:15,607 - INFO - ####################Training epoch 633####################
2025-02-01 18:56:15,985 - INFO - Epoch 633: train_loss=nan
2025-02-01 18:56:16,141 - INFO - Epoch 633: train_loss=nan
2025-02-01 18:56:16,275 - INFO - Epoch 633: train_loss=nan
2025-02-01 18:56:16,675 - INFO - Epoch 633: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:16,679 - INFO - ####################Training epoch 634####################
2025-02-01 18:56:17,056 - INFO - Epoch 634: train_loss=nan
2025-02-01 18:56:17,213 - INFO - Epoch 634: train_loss=nan
2025-02-01 18:56:17,347 - INFO - Epoch 634: train_loss=nan
2025-02-01 18:56:17,744 - INFO - Epoch 634: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:17,748 - INFO - ####################Training epoch 635####################
2025-02-01 18:56:18,126 - INFO - Epoch 635: train_loss=nan
2025-02-01 18:56:18,282 - INFO - Epoch 635: train_loss=nan
2025-02-01 18:56:18,415 - INFO - Epoch 635: train_loss=nan
2025-02-01 18:56:18,809 - INFO - Epoch 635: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:18,813 - INFO - ####################Training epoch 636####################
2025-02-01 18:56:19,190 - INFO - Epoch 636: train_loss=nan
2025-02-01 18:56:19,346 - INFO - Epoch 636: train_loss=nan
2025-02-01 18:56:19,479 - INFO - Epoch 636: train_loss=nan
2025-02-01 18:56:19,877 - INFO - Epoch 636: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:19,881 - INFO - ####################Training epoch 637####################
2025-02-01 18:56:20,261 - INFO - Epoch 637: train_loss=nan
2025-02-01 18:56:20,418 - INFO - Epoch 637: train_loss=nan
2025-02-01 18:56:20,552 - INFO - Epoch 637: train_loss=nan
2025-02-01 18:56:20,950 - INFO - Epoch 637: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:20,954 - INFO - ####################Training epoch 638####################
2025-02-01 18:56:21,329 - INFO - Epoch 638: train_loss=nan
2025-02-01 18:56:21,486 - INFO - Epoch 638: train_loss=nan
2025-02-01 18:56:21,619 - INFO - Epoch 638: train_loss=nan
2025-02-01 18:56:22,018 - INFO - Epoch 638: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:22,021 - INFO - ####################Training epoch 639####################
2025-02-01 18:56:22,399 - INFO - Epoch 639: train_loss=nan
2025-02-01 18:56:22,556 - INFO - Epoch 639: train_loss=nan
2025-02-01 18:56:22,690 - INFO - Epoch 639: train_loss=nan
2025-02-01 18:56:23,089 - INFO - Epoch 639: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:23,093 - INFO - ####################Training epoch 640####################
2025-02-01 18:56:23,471 - INFO - Epoch 640: train_loss=nan
2025-02-01 18:56:23,627 - INFO - Epoch 640: train_loss=nan
2025-02-01 18:56:23,760 - INFO - Epoch 640: train_loss=nan
2025-02-01 18:56:24,158 - INFO - Epoch 640: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:24,162 - INFO - ####################Training epoch 641####################
2025-02-01 18:56:24,540 - INFO - Epoch 641: train_loss=nan
2025-02-01 18:56:24,697 - INFO - Epoch 641: train_loss=nan
2025-02-01 18:56:24,830 - INFO - Epoch 641: train_loss=nan
2025-02-01 18:56:25,228 - INFO - Epoch 641: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:25,232 - INFO - ####################Training epoch 642####################
2025-02-01 18:56:25,609 - INFO - Epoch 642: train_loss=nan
2025-02-01 18:56:25,766 - INFO - Epoch 642: train_loss=nan
2025-02-01 18:56:25,899 - INFO - Epoch 642: train_loss=nan
2025-02-01 18:56:26,297 - INFO - Epoch 642: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:26,301 - INFO - ####################Training epoch 643####################
2025-02-01 18:56:26,676 - INFO - Epoch 643: train_loss=nan
2025-02-01 18:56:26,833 - INFO - Epoch 643: train_loss=nan
2025-02-01 18:56:26,966 - INFO - Epoch 643: train_loss=nan
2025-02-01 18:56:27,362 - INFO - Epoch 643: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:27,365 - INFO - ####################Training epoch 644####################
2025-02-01 18:56:27,742 - INFO - Epoch 644: train_loss=nan
2025-02-01 18:56:27,899 - INFO - Epoch 644: train_loss=nan
2025-02-01 18:56:28,032 - INFO - Epoch 644: train_loss=nan
2025-02-01 18:56:28,428 - INFO - Epoch 644: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:28,432 - INFO - ####################Training epoch 645####################
2025-02-01 18:56:28,807 - INFO - Epoch 645: train_loss=nan
2025-02-01 18:56:28,964 - INFO - Epoch 645: train_loss=nan
2025-02-01 18:56:29,098 - INFO - Epoch 645: train_loss=nan
2025-02-01 18:56:29,493 - INFO - Epoch 645: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:29,497 - INFO - ####################Training epoch 646####################
2025-02-01 18:56:29,871 - INFO - Epoch 646: train_loss=nan
2025-02-01 18:56:30,027 - INFO - Epoch 646: train_loss=nan
2025-02-01 18:56:30,161 - INFO - Epoch 646: train_loss=nan
2025-02-01 18:56:30,558 - INFO - Epoch 646: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:30,561 - INFO - ####################Training epoch 647####################
2025-02-01 18:56:30,937 - INFO - Epoch 647: train_loss=nan
2025-02-01 18:56:31,094 - INFO - Epoch 647: train_loss=nan
2025-02-01 18:56:31,228 - INFO - Epoch 647: train_loss=nan
2025-02-01 18:56:31,626 - INFO - Epoch 647: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:31,629 - INFO - ####################Training epoch 648####################
2025-02-01 18:56:32,004 - INFO - Epoch 648: train_loss=nan
2025-02-01 18:56:32,160 - INFO - Epoch 648: train_loss=nan
2025-02-01 18:56:32,294 - INFO - Epoch 648: train_loss=nan
2025-02-01 18:56:32,689 - INFO - Epoch 648: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:32,696 - INFO - ####################Training epoch 649####################
2025-02-01 18:56:33,075 - INFO - Epoch 649: train_loss=nan
2025-02-01 18:56:33,232 - INFO - Epoch 649: train_loss=nan
2025-02-01 18:56:33,366 - INFO - Epoch 649: train_loss=nan
2025-02-01 18:56:33,760 - INFO - Epoch 649: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:33,763 - INFO - ####################Training epoch 650####################
2025-02-01 18:56:34,141 - INFO - Epoch 650: train_loss=nan
2025-02-01 18:56:34,297 - INFO - Epoch 650: train_loss=nan
2025-02-01 18:56:34,431 - INFO - Epoch 650: train_loss=nan
2025-02-01 18:56:34,828 - INFO - Epoch 650: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:34,831 - INFO - ####################Training epoch 651####################
2025-02-01 18:56:35,209 - INFO - Epoch 651: train_loss=nan
2025-02-01 18:56:35,366 - INFO - Epoch 651: train_loss=nan
2025-02-01 18:56:35,499 - INFO - Epoch 651: train_loss=nan
2025-02-01 18:56:35,898 - INFO - Epoch 651: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:35,902 - INFO - ####################Training epoch 652####################
2025-02-01 18:56:36,279 - INFO - Epoch 652: train_loss=nan
2025-02-01 18:56:36,436 - INFO - Epoch 652: train_loss=nan
2025-02-01 18:56:36,570 - INFO - Epoch 652: train_loss=nan
2025-02-01 18:56:36,968 - INFO - Epoch 652: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:36,971 - INFO - ####################Training epoch 653####################
2025-02-01 18:56:37,346 - INFO - Epoch 653: train_loss=nan
2025-02-01 18:56:37,503 - INFO - Epoch 653: train_loss=nan
2025-02-01 18:56:37,636 - INFO - Epoch 653: train_loss=nan
2025-02-01 18:56:38,033 - INFO - Epoch 653: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:38,037 - INFO - ####################Training epoch 654####################
2025-02-01 18:56:38,413 - INFO - Epoch 654: train_loss=nan
2025-02-01 18:56:38,570 - INFO - Epoch 654: train_loss=nan
2025-02-01 18:56:38,703 - INFO - Epoch 654: train_loss=nan
2025-02-01 18:56:39,099 - INFO - Epoch 654: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:39,102 - INFO - ####################Training epoch 655####################
2025-02-01 18:56:39,478 - INFO - Epoch 655: train_loss=nan
2025-02-01 18:56:39,635 - INFO - Epoch 655: train_loss=nan
2025-02-01 18:56:39,768 - INFO - Epoch 655: train_loss=nan
2025-02-01 18:56:40,164 - INFO - Epoch 655: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:40,168 - INFO - ####################Training epoch 656####################
2025-02-01 18:56:40,542 - INFO - Epoch 656: train_loss=nan
2025-02-01 18:56:40,698 - INFO - Epoch 656: train_loss=nan
2025-02-01 18:56:40,832 - INFO - Epoch 656: train_loss=nan
2025-02-01 18:56:41,232 - INFO - Epoch 656: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:41,235 - INFO - ####################Training epoch 657####################
2025-02-01 18:56:41,612 - INFO - Epoch 657: train_loss=nan
2025-02-01 18:56:41,769 - INFO - Epoch 657: train_loss=nan
2025-02-01 18:56:41,902 - INFO - Epoch 657: train_loss=nan
2025-02-01 18:56:42,299 - INFO - Epoch 657: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:42,303 - INFO - ####################Training epoch 658####################
2025-02-01 18:56:42,679 - INFO - Epoch 658: train_loss=nan
2025-02-01 18:56:42,836 - INFO - Epoch 658: train_loss=nan
2025-02-01 18:56:42,969 - INFO - Epoch 658: train_loss=nan
2025-02-01 18:56:43,367 - INFO - Epoch 658: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:43,371 - INFO - ####################Training epoch 659####################
2025-02-01 18:56:43,745 - INFO - Epoch 659: train_loss=nan
2025-02-01 18:56:43,901 - INFO - Epoch 659: train_loss=nan
2025-02-01 18:56:44,034 - INFO - Epoch 659: train_loss=nan
2025-02-01 18:56:44,429 - INFO - Epoch 659: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:44,433 - INFO - ####################Training epoch 660####################
2025-02-01 18:56:44,809 - INFO - Epoch 660: train_loss=nan
2025-02-01 18:56:44,965 - INFO - Epoch 660: train_loss=nan
2025-02-01 18:56:45,099 - INFO - Epoch 660: train_loss=nan
2025-02-01 18:56:45,495 - INFO - Epoch 660: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:45,498 - INFO - ####################Training epoch 661####################
2025-02-01 18:56:45,875 - INFO - Epoch 661: train_loss=nan
2025-02-01 18:56:46,032 - INFO - Epoch 661: train_loss=nan
2025-02-01 18:56:46,165 - INFO - Epoch 661: train_loss=nan
2025-02-01 18:56:46,563 - INFO - Epoch 661: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:46,566 - INFO - ####################Training epoch 662####################
2025-02-01 18:56:46,941 - INFO - Epoch 662: train_loss=nan
2025-02-01 18:56:47,097 - INFO - Epoch 662: train_loss=nan
2025-02-01 18:56:47,230 - INFO - Epoch 662: train_loss=nan
2025-02-01 18:56:47,630 - INFO - Epoch 662: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:47,633 - INFO - ####################Training epoch 663####################
2025-02-01 18:56:48,010 - INFO - Epoch 663: train_loss=nan
2025-02-01 18:56:48,167 - INFO - Epoch 663: train_loss=nan
2025-02-01 18:56:48,300 - INFO - Epoch 663: train_loss=nan
2025-02-01 18:56:48,699 - INFO - Epoch 663: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:48,703 - INFO - ####################Training epoch 664####################
2025-02-01 18:56:49,078 - INFO - Epoch 664: train_loss=nan
2025-02-01 18:56:49,234 - INFO - Epoch 664: train_loss=nan
2025-02-01 18:56:49,367 - INFO - Epoch 664: train_loss=nan
2025-02-01 18:56:49,763 - INFO - Epoch 664: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:49,767 - INFO - ####################Training epoch 665####################
2025-02-01 18:56:50,145 - INFO - Epoch 665: train_loss=nan
2025-02-01 18:56:50,302 - INFO - Epoch 665: train_loss=nan
2025-02-01 18:56:50,435 - INFO - Epoch 665: train_loss=nan
2025-02-01 18:56:50,831 - INFO - Epoch 665: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:50,835 - INFO - ####################Training epoch 666####################
2025-02-01 18:56:51,210 - INFO - Epoch 666: train_loss=nan
2025-02-01 18:56:51,367 - INFO - Epoch 666: train_loss=nan
2025-02-01 18:56:51,501 - INFO - Epoch 666: train_loss=nan
2025-02-01 18:56:51,896 - INFO - Epoch 666: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:51,900 - INFO - ####################Training epoch 667####################
2025-02-01 18:56:52,278 - INFO - Epoch 667: train_loss=nan
2025-02-01 18:56:52,434 - INFO - Epoch 667: train_loss=nan
2025-02-01 18:56:52,567 - INFO - Epoch 667: train_loss=nan
2025-02-01 18:56:52,967 - INFO - Epoch 667: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:52,971 - INFO - ####################Training epoch 668####################
2025-02-01 18:56:53,346 - INFO - Epoch 668: train_loss=nan
2025-02-01 18:56:53,503 - INFO - Epoch 668: train_loss=nan
2025-02-01 18:56:53,636 - INFO - Epoch 668: train_loss=nan
2025-02-01 18:56:54,033 - INFO - Epoch 668: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:54,037 - INFO - ####################Training epoch 669####################
2025-02-01 18:56:54,413 - INFO - Epoch 669: train_loss=nan
2025-02-01 18:56:54,569 - INFO - Epoch 669: train_loss=nan
2025-02-01 18:56:54,703 - INFO - Epoch 669: train_loss=nan
2025-02-01 18:56:55,102 - INFO - Epoch 669: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:55,105 - INFO - ####################Training epoch 670####################
2025-02-01 18:56:55,480 - INFO - Epoch 670: train_loss=nan
2025-02-01 18:56:55,637 - INFO - Epoch 670: train_loss=nan
2025-02-01 18:56:55,769 - INFO - Epoch 670: train_loss=nan
2025-02-01 18:56:56,168 - INFO - Epoch 670: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:56,172 - INFO - ####################Training epoch 671####################
2025-02-01 18:56:56,548 - INFO - Epoch 671: train_loss=nan
2025-02-01 18:56:56,705 - INFO - Epoch 671: train_loss=nan
2025-02-01 18:56:56,838 - INFO - Epoch 671: train_loss=nan
2025-02-01 18:56:57,238 - INFO - Epoch 671: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:57,242 - INFO - ####################Training epoch 672####################
2025-02-01 18:56:57,618 - INFO - Epoch 672: train_loss=nan
2025-02-01 18:56:57,775 - INFO - Epoch 672: train_loss=nan
2025-02-01 18:56:57,907 - INFO - Epoch 672: train_loss=nan
2025-02-01 18:56:58,306 - INFO - Epoch 672: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:58,310 - INFO - ####################Training epoch 673####################
2025-02-01 18:56:58,687 - INFO - Epoch 673: train_loss=nan
2025-02-01 18:56:58,844 - INFO - Epoch 673: train_loss=nan
2025-02-01 18:56:58,978 - INFO - Epoch 673: train_loss=nan
2025-02-01 18:56:59,378 - INFO - Epoch 673: val_loss=nan, val_acc=66.67%
2025-02-01 18:56:59,382 - INFO - ####################Training epoch 674####################
2025-02-01 18:56:59,760 - INFO - Epoch 674: train_loss=nan
2025-02-01 18:56:59,916 - INFO - Epoch 674: train_loss=nan
2025-02-01 18:57:00,049 - INFO - Epoch 674: train_loss=nan
2025-02-01 18:57:00,446 - INFO - Epoch 674: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:00,450 - INFO - ####################Training epoch 675####################
2025-02-01 18:57:00,826 - INFO - Epoch 675: train_loss=nan
2025-02-01 18:57:00,983 - INFO - Epoch 675: train_loss=nan
2025-02-01 18:57:01,116 - INFO - Epoch 675: train_loss=nan
2025-02-01 18:57:01,513 - INFO - Epoch 675: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:01,516 - INFO - ####################Training epoch 676####################
2025-02-01 18:57:01,892 - INFO - Epoch 676: train_loss=nan
2025-02-01 18:57:02,048 - INFO - Epoch 676: train_loss=nan
2025-02-01 18:57:02,182 - INFO - Epoch 676: train_loss=nan
2025-02-01 18:57:02,577 - INFO - Epoch 676: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:02,581 - INFO - ####################Training epoch 677####################
2025-02-01 18:57:02,959 - INFO - Epoch 677: train_loss=nan
2025-02-01 18:57:03,116 - INFO - Epoch 677: train_loss=nan
2025-02-01 18:57:03,249 - INFO - Epoch 677: train_loss=nan
2025-02-01 18:57:03,647 - INFO - Epoch 677: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:03,651 - INFO - ####################Training epoch 678####################
2025-02-01 18:57:04,029 - INFO - Epoch 678: train_loss=nan
2025-02-01 18:57:04,186 - INFO - Epoch 678: train_loss=nan
2025-02-01 18:57:04,320 - INFO - Epoch 678: train_loss=nan
2025-02-01 18:57:04,716 - INFO - Epoch 678: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:04,719 - INFO - ####################Training epoch 679####################
2025-02-01 18:57:05,095 - INFO - Epoch 679: train_loss=nan
2025-02-01 18:57:05,251 - INFO - Epoch 679: train_loss=nan
2025-02-01 18:57:05,384 - INFO - Epoch 679: train_loss=nan
2025-02-01 18:57:05,780 - INFO - Epoch 679: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:05,784 - INFO - ####################Training epoch 680####################
2025-02-01 18:57:06,165 - INFO - Epoch 680: train_loss=nan
2025-02-01 18:57:06,322 - INFO - Epoch 680: train_loss=nan
2025-02-01 18:57:06,456 - INFO - Epoch 680: train_loss=nan
2025-02-01 18:57:06,850 - INFO - Epoch 680: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:06,854 - INFO - ####################Training epoch 681####################
2025-02-01 18:57:07,230 - INFO - Epoch 681: train_loss=nan
2025-02-01 18:57:07,387 - INFO - Epoch 681: train_loss=nan
2025-02-01 18:57:07,520 - INFO - Epoch 681: train_loss=nan
2025-02-01 18:57:07,917 - INFO - Epoch 681: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:07,920 - INFO - ####################Training epoch 682####################
2025-02-01 18:57:08,303 - INFO - Epoch 682: train_loss=nan
2025-02-01 18:57:08,460 - INFO - Epoch 682: train_loss=nan
2025-02-01 18:57:08,593 - INFO - Epoch 682: train_loss=nan
2025-02-01 18:57:08,988 - INFO - Epoch 682: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:08,992 - INFO - ####################Training epoch 683####################
2025-02-01 18:57:09,368 - INFO - Epoch 683: train_loss=nan
2025-02-01 18:57:09,525 - INFO - Epoch 683: train_loss=nan
2025-02-01 18:57:09,658 - INFO - Epoch 683: train_loss=nan
2025-02-01 18:57:10,054 - INFO - Epoch 683: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:10,058 - INFO - ####################Training epoch 684####################
2025-02-01 18:57:10,434 - INFO - Epoch 684: train_loss=nan
2025-02-01 18:57:10,590 - INFO - Epoch 684: train_loss=nan
2025-02-01 18:57:10,723 - INFO - Epoch 684: train_loss=nan
2025-02-01 18:57:11,119 - INFO - Epoch 684: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:11,123 - INFO - ####################Training epoch 685####################
2025-02-01 18:57:11,499 - INFO - Epoch 685: train_loss=nan
2025-02-01 18:57:11,655 - INFO - Epoch 685: train_loss=nan
2025-02-01 18:57:11,788 - INFO - Epoch 685: train_loss=nan
2025-02-01 18:57:12,187 - INFO - Epoch 685: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:12,191 - INFO - ####################Training epoch 686####################
2025-02-01 18:57:12,568 - INFO - Epoch 686: train_loss=nan
2025-02-01 18:57:12,724 - INFO - Epoch 686: train_loss=nan
2025-02-01 18:57:12,858 - INFO - Epoch 686: train_loss=nan
2025-02-01 18:57:13,255 - INFO - Epoch 686: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:13,259 - INFO - ####################Training epoch 687####################
2025-02-01 18:57:13,636 - INFO - Epoch 687: train_loss=nan
2025-02-01 18:57:13,792 - INFO - Epoch 687: train_loss=nan
2025-02-01 18:57:13,925 - INFO - Epoch 687: train_loss=nan
2025-02-01 18:57:14,326 - INFO - Epoch 687: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:14,330 - INFO - ####################Training epoch 688####################
2025-02-01 18:57:14,704 - INFO - Epoch 688: train_loss=nan
2025-02-01 18:57:14,861 - INFO - Epoch 688: train_loss=nan
2025-02-01 18:57:14,994 - INFO - Epoch 688: train_loss=nan
2025-02-01 18:57:15,394 - INFO - Epoch 688: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:15,397 - INFO - ####################Training epoch 689####################
2025-02-01 18:57:15,778 - INFO - Epoch 689: train_loss=nan
2025-02-01 18:57:15,934 - INFO - Epoch 689: train_loss=nan
2025-02-01 18:57:16,067 - INFO - Epoch 689: train_loss=nan
2025-02-01 18:57:16,462 - INFO - Epoch 689: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:16,466 - INFO - ####################Training epoch 690####################
2025-02-01 18:57:16,842 - INFO - Epoch 690: train_loss=nan
2025-02-01 18:57:16,999 - INFO - Epoch 690: train_loss=nan
2025-02-01 18:57:17,132 - INFO - Epoch 690: train_loss=nan
2025-02-01 18:57:17,530 - INFO - Epoch 690: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:17,533 - INFO - ####################Training epoch 691####################
2025-02-01 18:57:17,910 - INFO - Epoch 691: train_loss=nan
2025-02-01 18:57:18,066 - INFO - Epoch 691: train_loss=nan
2025-02-01 18:57:18,199 - INFO - Epoch 691: train_loss=nan
2025-02-01 18:57:18,597 - INFO - Epoch 691: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:18,601 - INFO - ####################Training epoch 692####################
2025-02-01 18:57:18,975 - INFO - Epoch 692: train_loss=nan
2025-02-01 18:57:19,132 - INFO - Epoch 692: train_loss=nan
2025-02-01 18:57:19,265 - INFO - Epoch 692: train_loss=nan
2025-02-01 18:57:19,659 - INFO - Epoch 692: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:19,663 - INFO - ####################Training epoch 693####################
2025-02-01 18:57:20,042 - INFO - Epoch 693: train_loss=nan
2025-02-01 18:57:20,199 - INFO - Epoch 693: train_loss=nan
2025-02-01 18:57:20,333 - INFO - Epoch 693: train_loss=nan
2025-02-01 18:57:20,729 - INFO - Epoch 693: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:20,733 - INFO - ####################Training epoch 694####################
2025-02-01 18:57:21,109 - INFO - Epoch 694: train_loss=nan
2025-02-01 18:57:21,265 - INFO - Epoch 694: train_loss=nan
2025-02-01 18:57:21,399 - INFO - Epoch 694: train_loss=nan
2025-02-01 18:57:21,793 - INFO - Epoch 694: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:21,797 - INFO - ####################Training epoch 695####################
2025-02-01 18:57:22,173 - INFO - Epoch 695: train_loss=nan
2025-02-01 18:57:22,330 - INFO - Epoch 695: train_loss=nan
2025-02-01 18:57:22,463 - INFO - Epoch 695: train_loss=nan
2025-02-01 18:57:22,861 - INFO - Epoch 695: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:22,864 - INFO - ####################Training epoch 696####################
2025-02-01 18:57:23,241 - INFO - Epoch 696: train_loss=nan
2025-02-01 18:57:23,398 - INFO - Epoch 696: train_loss=nan
2025-02-01 18:57:23,531 - INFO - Epoch 696: train_loss=nan
2025-02-01 18:57:23,926 - INFO - Epoch 696: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:23,930 - INFO - ####################Training epoch 697####################
2025-02-01 18:57:24,309 - INFO - Epoch 697: train_loss=nan
2025-02-01 18:57:24,465 - INFO - Epoch 697: train_loss=nan
2025-02-01 18:57:24,598 - INFO - Epoch 697: train_loss=nan
2025-02-01 18:57:24,995 - INFO - Epoch 697: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:24,999 - INFO - ####################Training epoch 698####################
2025-02-01 18:57:25,376 - INFO - Epoch 698: train_loss=nan
2025-02-01 18:57:25,533 - INFO - Epoch 698: train_loss=nan
2025-02-01 18:57:25,666 - INFO - Epoch 698: train_loss=nan
2025-02-01 18:57:26,063 - INFO - Epoch 698: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:26,067 - INFO - ####################Training epoch 699####################
2025-02-01 18:57:26,444 - INFO - Epoch 699: train_loss=nan
2025-02-01 18:57:26,601 - INFO - Epoch 699: train_loss=nan
2025-02-01 18:57:26,734 - INFO - Epoch 699: train_loss=nan
2025-02-01 18:57:27,132 - INFO - Epoch 699: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:27,135 - INFO - ####################Training epoch 700####################
2025-02-01 18:57:27,509 - INFO - Epoch 700: train_loss=nan
2025-02-01 18:57:27,666 - INFO - Epoch 700: train_loss=nan
2025-02-01 18:57:27,798 - INFO - Epoch 700: train_loss=nan
2025-02-01 18:57:28,194 - INFO - Epoch 700: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:28,197 - INFO - ####################Training epoch 701####################
2025-02-01 18:57:28,575 - INFO - Epoch 701: train_loss=nan
2025-02-01 18:57:28,732 - INFO - Epoch 701: train_loss=nan
2025-02-01 18:57:28,865 - INFO - Epoch 701: train_loss=nan
2025-02-01 18:57:29,259 - INFO - Epoch 701: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:29,262 - INFO - ####################Training epoch 702####################
2025-02-01 18:57:29,637 - INFO - Epoch 702: train_loss=nan
2025-02-01 18:57:29,794 - INFO - Epoch 702: train_loss=nan
2025-02-01 18:57:29,927 - INFO - Epoch 702: train_loss=nan
2025-02-01 18:57:30,326 - INFO - Epoch 702: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:30,329 - INFO - ####################Training epoch 703####################
2025-02-01 18:57:30,707 - INFO - Epoch 703: train_loss=nan
2025-02-01 18:57:30,862 - INFO - Epoch 703: train_loss=nan
2025-02-01 18:57:30,996 - INFO - Epoch 703: train_loss=nan
2025-02-01 18:57:31,395 - INFO - Epoch 703: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:31,399 - INFO - ####################Training epoch 704####################
2025-02-01 18:57:31,774 - INFO - Epoch 704: train_loss=nan
2025-02-01 18:57:31,930 - INFO - Epoch 704: train_loss=nan
2025-02-01 18:57:32,064 - INFO - Epoch 704: train_loss=nan
2025-02-01 18:57:32,459 - INFO - Epoch 704: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:32,462 - INFO - ####################Training epoch 705####################
2025-02-01 18:57:32,839 - INFO - Epoch 705: train_loss=nan
2025-02-01 18:57:32,996 - INFO - Epoch 705: train_loss=nan
2025-02-01 18:57:33,129 - INFO - Epoch 705: train_loss=nan
2025-02-01 18:57:33,526 - INFO - Epoch 705: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:33,530 - INFO - ####################Training epoch 706####################
2025-02-01 18:57:33,904 - INFO - Epoch 706: train_loss=nan
2025-02-01 18:57:34,060 - INFO - Epoch 706: train_loss=nan
2025-02-01 18:57:34,194 - INFO - Epoch 706: train_loss=nan
2025-02-01 18:57:34,591 - INFO - Epoch 706: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:34,595 - INFO - ####################Training epoch 707####################
2025-02-01 18:57:34,970 - INFO - Epoch 707: train_loss=nan
2025-02-01 18:57:35,126 - INFO - Epoch 707: train_loss=nan
2025-02-01 18:57:35,259 - INFO - Epoch 707: train_loss=nan
2025-02-01 18:57:35,656 - INFO - Epoch 707: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:35,660 - INFO - ####################Training epoch 708####################
2025-02-01 18:57:36,036 - INFO - Epoch 708: train_loss=nan
2025-02-01 18:57:36,193 - INFO - Epoch 708: train_loss=nan
2025-02-01 18:57:36,327 - INFO - Epoch 708: train_loss=nan
2025-02-01 18:57:36,721 - INFO - Epoch 708: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:36,725 - INFO - ####################Training epoch 709####################
2025-02-01 18:57:37,101 - INFO - Epoch 709: train_loss=nan
2025-02-01 18:57:37,257 - INFO - Epoch 709: train_loss=nan
2025-02-01 18:57:37,391 - INFO - Epoch 709: train_loss=nan
2025-02-01 18:57:37,791 - INFO - Epoch 709: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:37,795 - INFO - ####################Training epoch 710####################
2025-02-01 18:57:38,172 - INFO - Epoch 710: train_loss=nan
2025-02-01 18:57:38,328 - INFO - Epoch 710: train_loss=nan
2025-02-01 18:57:38,461 - INFO - Epoch 710: train_loss=nan
2025-02-01 18:57:38,856 - INFO - Epoch 710: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:38,859 - INFO - ####################Training epoch 711####################
2025-02-01 18:57:39,234 - INFO - Epoch 711: train_loss=nan
2025-02-01 18:57:39,391 - INFO - Epoch 711: train_loss=nan
2025-02-01 18:57:39,525 - INFO - Epoch 711: train_loss=nan
2025-02-01 18:57:39,922 - INFO - Epoch 711: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:39,926 - INFO - ####################Training epoch 712####################
2025-02-01 18:57:40,303 - INFO - Epoch 712: train_loss=nan
2025-02-01 18:57:40,459 - INFO - Epoch 712: train_loss=nan
2025-02-01 18:57:40,592 - INFO - Epoch 712: train_loss=nan
2025-02-01 18:57:40,987 - INFO - Epoch 712: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:40,991 - INFO - ####################Training epoch 713####################
2025-02-01 18:57:41,371 - INFO - Epoch 713: train_loss=nan
2025-02-01 18:57:41,528 - INFO - Epoch 713: train_loss=nan
2025-02-01 18:57:41,661 - INFO - Epoch 713: train_loss=nan
2025-02-01 18:57:42,055 - INFO - Epoch 713: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:42,059 - INFO - ####################Training epoch 714####################
2025-02-01 18:57:42,433 - INFO - Epoch 714: train_loss=nan
2025-02-01 18:57:42,590 - INFO - Epoch 714: train_loss=nan
2025-02-01 18:57:42,723 - INFO - Epoch 714: train_loss=nan
2025-02-01 18:57:43,117 - INFO - Epoch 714: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:43,121 - INFO - ####################Training epoch 715####################
2025-02-01 18:57:43,495 - INFO - Epoch 715: train_loss=nan
2025-02-01 18:57:43,652 - INFO - Epoch 715: train_loss=nan
2025-02-01 18:57:43,786 - INFO - Epoch 715: train_loss=nan
2025-02-01 18:57:44,181 - INFO - Epoch 715: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:44,184 - INFO - ####################Training epoch 716####################
2025-02-01 18:57:44,562 - INFO - Epoch 716: train_loss=nan
2025-02-01 18:57:44,718 - INFO - Epoch 716: train_loss=nan
2025-02-01 18:57:44,851 - INFO - Epoch 716: train_loss=nan
2025-02-01 18:57:45,249 - INFO - Epoch 716: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:45,252 - INFO - ####################Training epoch 717####################
2025-02-01 18:57:45,626 - INFO - Epoch 717: train_loss=nan
2025-02-01 18:57:45,783 - INFO - Epoch 717: train_loss=nan
2025-02-01 18:57:45,916 - INFO - Epoch 717: train_loss=nan
2025-02-01 18:57:46,312 - INFO - Epoch 717: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:46,315 - INFO - ####################Training epoch 718####################
2025-02-01 18:57:46,688 - INFO - Epoch 718: train_loss=nan
2025-02-01 18:57:46,844 - INFO - Epoch 718: train_loss=nan
2025-02-01 18:57:46,977 - INFO - Epoch 718: train_loss=nan
2025-02-01 18:57:47,374 - INFO - Epoch 718: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:47,378 - INFO - ####################Training epoch 719####################
2025-02-01 18:57:47,751 - INFO - Epoch 719: train_loss=nan
2025-02-01 18:57:47,908 - INFO - Epoch 719: train_loss=nan
2025-02-01 18:57:48,041 - INFO - Epoch 719: train_loss=nan
2025-02-01 18:57:48,443 - INFO - Epoch 719: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:48,447 - INFO - ####################Training epoch 720####################
2025-02-01 18:57:48,826 - INFO - Epoch 720: train_loss=nan
2025-02-01 18:57:48,983 - INFO - Epoch 720: train_loss=nan
2025-02-01 18:57:49,115 - INFO - Epoch 720: train_loss=nan
2025-02-01 18:57:49,512 - INFO - Epoch 720: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:49,515 - INFO - ####################Training epoch 721####################
2025-02-01 18:57:49,893 - INFO - Epoch 721: train_loss=nan
2025-02-01 18:57:50,050 - INFO - Epoch 721: train_loss=nan
2025-02-01 18:57:50,184 - INFO - Epoch 721: train_loss=nan
2025-02-01 18:57:50,581 - INFO - Epoch 721: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:50,585 - INFO - ####################Training epoch 722####################
2025-02-01 18:57:50,961 - INFO - Epoch 722: train_loss=nan
2025-02-01 18:57:51,117 - INFO - Epoch 722: train_loss=nan
2025-02-01 18:57:51,250 - INFO - Epoch 722: train_loss=nan
2025-02-01 18:57:51,646 - INFO - Epoch 722: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:51,650 - INFO - ####################Training epoch 723####################
2025-02-01 18:57:52,026 - INFO - Epoch 723: train_loss=nan
2025-02-01 18:57:52,182 - INFO - Epoch 723: train_loss=nan
2025-02-01 18:57:52,315 - INFO - Epoch 723: train_loss=nan
2025-02-01 18:57:52,713 - INFO - Epoch 723: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:52,716 - INFO - ####################Training epoch 724####################
2025-02-01 18:57:53,095 - INFO - Epoch 724: train_loss=nan
2025-02-01 18:57:53,255 - INFO - Epoch 724: train_loss=nan
2025-02-01 18:57:53,388 - INFO - Epoch 724: train_loss=nan
2025-02-01 18:57:53,784 - INFO - Epoch 724: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:53,788 - INFO - ####################Training epoch 725####################
2025-02-01 18:57:54,164 - INFO - Epoch 725: train_loss=nan
2025-02-01 18:57:54,320 - INFO - Epoch 725: train_loss=nan
2025-02-01 18:57:54,453 - INFO - Epoch 725: train_loss=nan
2025-02-01 18:57:54,849 - INFO - Epoch 725: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:54,853 - INFO - ####################Training epoch 726####################
2025-02-01 18:57:55,229 - INFO - Epoch 726: train_loss=nan
2025-02-01 18:57:55,386 - INFO - Epoch 726: train_loss=nan
2025-02-01 18:57:55,519 - INFO - Epoch 726: train_loss=nan
2025-02-01 18:57:55,915 - INFO - Epoch 726: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:55,919 - INFO - ####################Training epoch 727####################
2025-02-01 18:57:56,295 - INFO - Epoch 727: train_loss=nan
2025-02-01 18:57:56,452 - INFO - Epoch 727: train_loss=nan
2025-02-01 18:57:56,585 - INFO - Epoch 727: train_loss=nan
2025-02-01 18:57:56,979 - INFO - Epoch 727: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:56,982 - INFO - ####################Training epoch 728####################
2025-02-01 18:57:57,360 - INFO - Epoch 728: train_loss=nan
2025-02-01 18:57:57,516 - INFO - Epoch 728: train_loss=nan
2025-02-01 18:57:57,649 - INFO - Epoch 728: train_loss=nan
2025-02-01 18:57:58,044 - INFO - Epoch 728: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:58,048 - INFO - ####################Training epoch 729####################
2025-02-01 18:57:58,423 - INFO - Epoch 729: train_loss=nan
2025-02-01 18:57:58,580 - INFO - Epoch 729: train_loss=nan
2025-02-01 18:57:58,713 - INFO - Epoch 729: train_loss=nan
2025-02-01 18:57:59,107 - INFO - Epoch 729: val_loss=nan, val_acc=66.67%
2025-02-01 18:57:59,111 - INFO - ####################Training epoch 730####################
2025-02-01 18:57:59,489 - INFO - Epoch 730: train_loss=nan
2025-02-01 18:57:59,646 - INFO - Epoch 730: train_loss=nan
2025-02-01 18:57:59,779 - INFO - Epoch 730: train_loss=nan
2025-02-01 18:58:00,178 - INFO - Epoch 730: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:00,182 - INFO - ####################Training epoch 731####################
2025-02-01 18:58:00,559 - INFO - Epoch 731: train_loss=nan
2025-02-01 18:58:00,716 - INFO - Epoch 731: train_loss=nan
2025-02-01 18:58:00,849 - INFO - Epoch 731: train_loss=nan
2025-02-01 18:58:01,245 - INFO - Epoch 731: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:01,249 - INFO - ####################Training epoch 732####################
2025-02-01 18:58:01,624 - INFO - Epoch 732: train_loss=nan
2025-02-01 18:58:01,781 - INFO - Epoch 732: train_loss=nan
2025-02-01 18:58:01,914 - INFO - Epoch 732: train_loss=nan
2025-02-01 18:58:02,312 - INFO - Epoch 732: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:02,316 - INFO - ####################Training epoch 733####################
2025-02-01 18:58:02,693 - INFO - Epoch 733: train_loss=nan
2025-02-01 18:58:02,850 - INFO - Epoch 733: train_loss=nan
2025-02-01 18:58:02,983 - INFO - Epoch 733: train_loss=nan
2025-02-01 18:58:03,379 - INFO - Epoch 733: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:03,383 - INFO - ####################Training epoch 734####################
2025-02-01 18:58:03,762 - INFO - Epoch 734: train_loss=nan
2025-02-01 18:58:03,919 - INFO - Epoch 734: train_loss=nan
2025-02-01 18:58:04,052 - INFO - Epoch 734: train_loss=nan
2025-02-01 18:58:04,449 - INFO - Epoch 734: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:04,453 - INFO - ####################Training epoch 735####################
2025-02-01 18:58:04,827 - INFO - Epoch 735: train_loss=nan
2025-02-01 18:58:04,984 - INFO - Epoch 735: train_loss=nan
2025-02-01 18:58:05,117 - INFO - Epoch 735: train_loss=nan
2025-02-01 18:58:05,517 - INFO - Epoch 735: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:05,520 - INFO - ####################Training epoch 736####################
2025-02-01 18:58:05,896 - INFO - Epoch 736: train_loss=nan
2025-02-01 18:58:06,052 - INFO - Epoch 736: train_loss=nan
2025-02-01 18:58:06,186 - INFO - Epoch 736: train_loss=nan
2025-02-01 18:58:06,583 - INFO - Epoch 736: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:06,587 - INFO - ####################Training epoch 737####################
2025-02-01 18:58:06,966 - INFO - Epoch 737: train_loss=nan
2025-02-01 18:58:07,123 - INFO - Epoch 737: train_loss=nan
2025-02-01 18:58:07,256 - INFO - Epoch 737: train_loss=nan
2025-02-01 18:58:07,655 - INFO - Epoch 737: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:07,659 - INFO - ####################Training epoch 738####################
2025-02-01 18:58:08,035 - INFO - Epoch 738: train_loss=nan
2025-02-01 18:58:08,191 - INFO - Epoch 738: train_loss=nan
2025-02-01 18:58:08,325 - INFO - Epoch 738: train_loss=nan
2025-02-01 18:58:08,722 - INFO - Epoch 738: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:08,726 - INFO - ####################Training epoch 739####################
2025-02-01 18:58:09,104 - INFO - Epoch 739: train_loss=nan
2025-02-01 18:58:09,260 - INFO - Epoch 739: train_loss=nan
2025-02-01 18:58:09,394 - INFO - Epoch 739: train_loss=nan
2025-02-01 18:58:09,789 - INFO - Epoch 739: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:09,792 - INFO - ####################Training epoch 740####################
2025-02-01 18:58:10,169 - INFO - Epoch 740: train_loss=nan
2025-02-01 18:58:10,326 - INFO - Epoch 740: train_loss=nan
2025-02-01 18:58:10,459 - INFO - Epoch 740: train_loss=nan
2025-02-01 18:58:10,857 - INFO - Epoch 740: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:10,861 - INFO - ####################Training epoch 741####################
2025-02-01 18:58:11,237 - INFO - Epoch 741: train_loss=nan
2025-02-01 18:58:11,393 - INFO - Epoch 741: train_loss=nan
2025-02-01 18:58:11,526 - INFO - Epoch 741: train_loss=nan
2025-02-01 18:58:11,919 - INFO - Epoch 741: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:11,923 - INFO - ####################Training epoch 742####################
2025-02-01 18:58:12,298 - INFO - Epoch 742: train_loss=nan
2025-02-01 18:58:12,454 - INFO - Epoch 742: train_loss=nan
2025-02-01 18:58:12,586 - INFO - Epoch 742: train_loss=nan
2025-02-01 18:58:12,984 - INFO - Epoch 742: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:12,987 - INFO - ####################Training epoch 743####################
2025-02-01 18:58:13,364 - INFO - Epoch 743: train_loss=nan
2025-02-01 18:58:13,520 - INFO - Epoch 743: train_loss=nan
2025-02-01 18:58:13,654 - INFO - Epoch 743: train_loss=nan
2025-02-01 18:58:14,051 - INFO - Epoch 743: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:14,054 - INFO - ####################Training epoch 744####################
2025-02-01 18:58:14,430 - INFO - Epoch 744: train_loss=nan
2025-02-01 18:58:14,586 - INFO - Epoch 744: train_loss=nan
2025-02-01 18:58:14,720 - INFO - Epoch 744: train_loss=nan
2025-02-01 18:58:15,118 - INFO - Epoch 744: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:15,122 - INFO - ####################Training epoch 745####################
2025-02-01 18:58:15,497 - INFO - Epoch 745: train_loss=nan
2025-02-01 18:58:15,654 - INFO - Epoch 745: train_loss=nan
2025-02-01 18:58:15,786 - INFO - Epoch 745: train_loss=nan
2025-02-01 18:58:16,182 - INFO - Epoch 745: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:16,185 - INFO - ####################Training epoch 746####################
2025-02-01 18:58:16,563 - INFO - Epoch 746: train_loss=nan
2025-02-01 18:58:16,720 - INFO - Epoch 746: train_loss=nan
2025-02-01 18:58:16,853 - INFO - Epoch 746: train_loss=nan
2025-02-01 18:58:17,251 - INFO - Epoch 746: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:17,255 - INFO - ####################Training epoch 747####################
2025-02-01 18:58:17,630 - INFO - Epoch 747: train_loss=nan
2025-02-01 18:58:17,786 - INFO - Epoch 747: train_loss=nan
2025-02-01 18:58:17,920 - INFO - Epoch 747: train_loss=nan
2025-02-01 18:58:18,315 - INFO - Epoch 747: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:18,318 - INFO - ####################Training epoch 748####################
2025-02-01 18:58:18,696 - INFO - Epoch 748: train_loss=nan
2025-02-01 18:58:18,852 - INFO - Epoch 748: train_loss=nan
2025-02-01 18:58:18,985 - INFO - Epoch 748: train_loss=nan
2025-02-01 18:58:19,382 - INFO - Epoch 748: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:19,386 - INFO - ####################Training epoch 749####################
2025-02-01 18:58:19,764 - INFO - Epoch 749: train_loss=nan
2025-02-01 18:58:19,923 - INFO - Epoch 749: train_loss=nan
2025-02-01 18:58:20,057 - INFO - Epoch 749: train_loss=nan
2025-02-01 18:58:20,452 - INFO - Epoch 749: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:20,456 - INFO - ####################Training epoch 750####################
2025-02-01 18:58:20,831 - INFO - Epoch 750: train_loss=nan
2025-02-01 18:58:20,987 - INFO - Epoch 750: train_loss=nan
2025-02-01 18:58:21,120 - INFO - Epoch 750: train_loss=nan
2025-02-01 18:58:21,516 - INFO - Epoch 750: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:21,520 - INFO - ####################Training epoch 751####################
2025-02-01 18:58:21,899 - INFO - Epoch 751: train_loss=nan
2025-02-01 18:58:22,056 - INFO - Epoch 751: train_loss=nan
2025-02-01 18:58:22,189 - INFO - Epoch 751: train_loss=nan
2025-02-01 18:58:22,594 - INFO - Epoch 751: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:22,597 - INFO - ####################Training epoch 752####################
2025-02-01 18:58:22,973 - INFO - Epoch 752: train_loss=nan
2025-02-01 18:58:23,129 - INFO - Epoch 752: train_loss=nan
2025-02-01 18:58:23,262 - INFO - Epoch 752: train_loss=nan
2025-02-01 18:58:23,660 - INFO - Epoch 752: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:23,664 - INFO - ####################Training epoch 753####################
2025-02-01 18:58:24,040 - INFO - Epoch 753: train_loss=nan
2025-02-01 18:58:24,196 - INFO - Epoch 753: train_loss=nan
2025-02-01 18:58:24,329 - INFO - Epoch 753: train_loss=nan
2025-02-01 18:58:24,728 - INFO - Epoch 753: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:24,732 - INFO - ####################Training epoch 754####################
2025-02-01 18:58:25,109 - INFO - Epoch 754: train_loss=nan
2025-02-01 18:58:25,265 - INFO - Epoch 754: train_loss=nan
2025-02-01 18:58:25,398 - INFO - Epoch 754: train_loss=nan
2025-02-01 18:58:25,796 - INFO - Epoch 754: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:25,800 - INFO - ####################Training epoch 755####################
2025-02-01 18:58:26,176 - INFO - Epoch 755: train_loss=nan
2025-02-01 18:58:26,332 - INFO - Epoch 755: train_loss=nan
2025-02-01 18:58:26,465 - INFO - Epoch 755: train_loss=nan
2025-02-01 18:58:26,859 - INFO - Epoch 755: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:26,863 - INFO - ####################Training epoch 756####################
2025-02-01 18:58:27,239 - INFO - Epoch 756: train_loss=nan
2025-02-01 18:58:27,395 - INFO - Epoch 756: train_loss=nan
2025-02-01 18:58:27,528 - INFO - Epoch 756: train_loss=nan
2025-02-01 18:58:27,925 - INFO - Epoch 756: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:27,929 - INFO - ####################Training epoch 757####################
2025-02-01 18:58:28,306 - INFO - Epoch 757: train_loss=nan
2025-02-01 18:58:28,462 - INFO - Epoch 757: train_loss=nan
2025-02-01 18:58:28,595 - INFO - Epoch 757: train_loss=nan
2025-02-01 18:58:28,986 - INFO - Epoch 757: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:28,990 - INFO - ####################Training epoch 758####################
2025-02-01 18:58:29,365 - INFO - Epoch 758: train_loss=nan
2025-02-01 18:58:29,521 - INFO - Epoch 758: train_loss=nan
2025-02-01 18:58:29,654 - INFO - Epoch 758: train_loss=nan
2025-02-01 18:58:30,055 - INFO - Epoch 758: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:30,059 - INFO - ####################Training epoch 759####################
2025-02-01 18:58:30,432 - INFO - Epoch 759: train_loss=nan
2025-02-01 18:58:30,588 - INFO - Epoch 759: train_loss=nan
2025-02-01 18:58:30,720 - INFO - Epoch 759: train_loss=nan
2025-02-01 18:58:31,123 - INFO - Epoch 759: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:31,127 - INFO - ####################Training epoch 760####################
2025-02-01 18:58:31,503 - INFO - Epoch 760: train_loss=nan
2025-02-01 18:58:31,659 - INFO - Epoch 760: train_loss=nan
2025-02-01 18:58:31,792 - INFO - Epoch 760: train_loss=nan
2025-02-01 18:58:32,190 - INFO - Epoch 760: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:32,194 - INFO - ####################Training epoch 761####################
2025-02-01 18:58:32,570 - INFO - Epoch 761: train_loss=nan
2025-02-01 18:58:32,725 - INFO - Epoch 761: train_loss=nan
2025-02-01 18:58:32,858 - INFO - Epoch 761: train_loss=nan
2025-02-01 18:58:33,253 - INFO - Epoch 761: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:33,257 - INFO - ####################Training epoch 762####################
2025-02-01 18:58:33,633 - INFO - Epoch 762: train_loss=nan
2025-02-01 18:58:33,789 - INFO - Epoch 762: train_loss=nan
2025-02-01 18:58:33,922 - INFO - Epoch 762: train_loss=nan
2025-02-01 18:58:34,318 - INFO - Epoch 762: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:34,322 - INFO - ####################Training epoch 763####################
2025-02-01 18:58:34,702 - INFO - Epoch 763: train_loss=nan
2025-02-01 18:58:34,858 - INFO - Epoch 763: train_loss=nan
2025-02-01 18:58:34,991 - INFO - Epoch 763: train_loss=nan
2025-02-01 18:58:35,388 - INFO - Epoch 763: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:35,392 - INFO - ####################Training epoch 764####################
2025-02-01 18:58:35,771 - INFO - Epoch 764: train_loss=nan
2025-02-01 18:58:35,927 - INFO - Epoch 764: train_loss=nan
2025-02-01 18:58:36,060 - INFO - Epoch 764: train_loss=nan
2025-02-01 18:58:36,455 - INFO - Epoch 764: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:36,459 - INFO - ####################Training epoch 765####################
2025-02-01 18:58:36,836 - INFO - Epoch 765: train_loss=nan
2025-02-01 18:58:36,992 - INFO - Epoch 765: train_loss=nan
2025-02-01 18:58:37,125 - INFO - Epoch 765: train_loss=nan
2025-02-01 18:58:37,523 - INFO - Epoch 765: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:37,526 - INFO - ####################Training epoch 766####################
2025-02-01 18:58:37,901 - INFO - Epoch 766: train_loss=nan
2025-02-01 18:58:38,058 - INFO - Epoch 766: train_loss=nan
2025-02-01 18:58:38,191 - INFO - Epoch 766: train_loss=nan
2025-02-01 18:58:38,587 - INFO - Epoch 766: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:38,591 - INFO - ####################Training epoch 767####################
2025-02-01 18:58:38,969 - INFO - Epoch 767: train_loss=nan
2025-02-01 18:58:39,125 - INFO - Epoch 767: train_loss=nan
2025-02-01 18:58:39,258 - INFO - Epoch 767: train_loss=nan
2025-02-01 18:58:39,658 - INFO - Epoch 767: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:39,662 - INFO - ####################Training epoch 768####################
2025-02-01 18:58:40,038 - INFO - Epoch 768: train_loss=nan
2025-02-01 18:58:40,195 - INFO - Epoch 768: train_loss=nan
2025-02-01 18:58:40,329 - INFO - Epoch 768: train_loss=nan
2025-02-01 18:58:40,727 - INFO - Epoch 768: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:40,730 - INFO - ####################Training epoch 769####################
2025-02-01 18:58:41,110 - INFO - Epoch 769: train_loss=nan
2025-02-01 18:58:41,266 - INFO - Epoch 769: train_loss=nan
2025-02-01 18:58:41,399 - INFO - Epoch 769: train_loss=nan
2025-02-01 18:58:41,801 - INFO - Epoch 769: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:41,804 - INFO - ####################Training epoch 770####################
2025-02-01 18:58:42,177 - INFO - Epoch 770: train_loss=nan
2025-02-01 18:58:42,334 - INFO - Epoch 770: train_loss=nan
2025-02-01 18:58:42,467 - INFO - Epoch 770: train_loss=nan
2025-02-01 18:58:42,868 - INFO - Epoch 770: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:42,872 - INFO - ####################Training epoch 771####################
2025-02-01 18:58:43,248 - INFO - Epoch 771: train_loss=nan
2025-02-01 18:58:43,404 - INFO - Epoch 771: train_loss=nan
2025-02-01 18:58:43,536 - INFO - Epoch 771: train_loss=nan
2025-02-01 18:58:43,934 - INFO - Epoch 771: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:43,938 - INFO - ####################Training epoch 772####################
2025-02-01 18:58:44,313 - INFO - Epoch 772: train_loss=nan
2025-02-01 18:58:44,469 - INFO - Epoch 772: train_loss=nan
2025-02-01 18:58:44,602 - INFO - Epoch 772: train_loss=nan
2025-02-01 18:58:44,998 - INFO - Epoch 772: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:45,002 - INFO - ####################Training epoch 773####################
2025-02-01 18:58:45,379 - INFO - Epoch 773: train_loss=nan
2025-02-01 18:58:45,535 - INFO - Epoch 773: train_loss=nan
2025-02-01 18:58:45,669 - INFO - Epoch 773: train_loss=nan
2025-02-01 18:58:46,066 - INFO - Epoch 773: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:46,070 - INFO - ####################Training epoch 774####################
2025-02-01 18:58:46,449 - INFO - Epoch 774: train_loss=nan
2025-02-01 18:58:46,605 - INFO - Epoch 774: train_loss=nan
2025-02-01 18:58:46,741 - INFO - Epoch 774: train_loss=nan
2025-02-01 18:58:47,137 - INFO - Epoch 774: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:47,141 - INFO - ####################Training epoch 775####################
2025-02-01 18:58:47,516 - INFO - Epoch 775: train_loss=nan
2025-02-01 18:58:47,673 - INFO - Epoch 775: train_loss=nan
2025-02-01 18:58:47,807 - INFO - Epoch 775: train_loss=nan
2025-02-01 18:58:48,202 - INFO - Epoch 775: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:48,206 - INFO - ####################Training epoch 776####################
2025-02-01 18:58:48,585 - INFO - Epoch 776: train_loss=nan
2025-02-01 18:58:48,741 - INFO - Epoch 776: train_loss=nan
2025-02-01 18:58:48,874 - INFO - Epoch 776: train_loss=nan
2025-02-01 18:58:49,274 - INFO - Epoch 776: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:49,277 - INFO - ####################Training epoch 777####################
2025-02-01 18:58:49,652 - INFO - Epoch 777: train_loss=nan
2025-02-01 18:58:49,808 - INFO - Epoch 777: train_loss=nan
2025-02-01 18:58:49,941 - INFO - Epoch 777: train_loss=nan
2025-02-01 18:58:50,340 - INFO - Epoch 777: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:50,344 - INFO - ####################Training epoch 778####################
2025-02-01 18:58:50,725 - INFO - Epoch 778: train_loss=nan
2025-02-01 18:58:50,881 - INFO - Epoch 778: train_loss=nan
2025-02-01 18:58:51,013 - INFO - Epoch 778: train_loss=nan
2025-02-01 18:58:51,413 - INFO - Epoch 778: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:51,417 - INFO - ####################Training epoch 779####################
2025-02-01 18:58:51,794 - INFO - Epoch 779: train_loss=nan
2025-02-01 18:58:51,950 - INFO - Epoch 779: train_loss=nan
2025-02-01 18:58:52,084 - INFO - Epoch 779: train_loss=nan
2025-02-01 18:58:52,481 - INFO - Epoch 779: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:52,485 - INFO - ####################Training epoch 780####################
2025-02-01 18:58:52,861 - INFO - Epoch 780: train_loss=nan
2025-02-01 18:58:53,017 - INFO - Epoch 780: train_loss=nan
2025-02-01 18:58:53,151 - INFO - Epoch 780: train_loss=nan
2025-02-01 18:58:53,547 - INFO - Epoch 780: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:53,551 - INFO - ####################Training epoch 781####################
2025-02-01 18:58:53,932 - INFO - Epoch 781: train_loss=nan
2025-02-01 18:58:54,089 - INFO - Epoch 781: train_loss=nan
2025-02-01 18:58:54,223 - INFO - Epoch 781: train_loss=nan
2025-02-01 18:58:54,618 - INFO - Epoch 781: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:54,621 - INFO - ####################Training epoch 782####################
2025-02-01 18:58:54,997 - INFO - Epoch 782: train_loss=nan
2025-02-01 18:58:55,154 - INFO - Epoch 782: train_loss=nan
2025-02-01 18:58:55,287 - INFO - Epoch 782: train_loss=nan
2025-02-01 18:58:55,683 - INFO - Epoch 782: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:55,686 - INFO - ####################Training epoch 783####################
2025-02-01 18:58:56,063 - INFO - Epoch 783: train_loss=nan
2025-02-01 18:58:56,219 - INFO - Epoch 783: train_loss=nan
2025-02-01 18:58:56,352 - INFO - Epoch 783: train_loss=nan
2025-02-01 18:58:56,751 - INFO - Epoch 783: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:56,755 - INFO - ####################Training epoch 784####################
2025-02-01 18:58:57,130 - INFO - Epoch 784: train_loss=nan
2025-02-01 18:58:57,287 - INFO - Epoch 784: train_loss=nan
2025-02-01 18:58:57,420 - INFO - Epoch 784: train_loss=nan
2025-02-01 18:58:57,818 - INFO - Epoch 784: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:57,822 - INFO - ####################Training epoch 785####################
2025-02-01 18:58:58,198 - INFO - Epoch 785: train_loss=nan
2025-02-01 18:58:58,354 - INFO - Epoch 785: train_loss=nan
2025-02-01 18:58:58,487 - INFO - Epoch 785: train_loss=nan
2025-02-01 18:58:58,885 - INFO - Epoch 785: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:58,888 - INFO - ####################Training epoch 786####################
2025-02-01 18:58:59,263 - INFO - Epoch 786: train_loss=nan
2025-02-01 18:58:59,420 - INFO - Epoch 786: train_loss=nan
2025-02-01 18:58:59,553 - INFO - Epoch 786: train_loss=nan
2025-02-01 18:58:59,955 - INFO - Epoch 786: val_loss=nan, val_acc=66.67%
2025-02-01 18:58:59,958 - INFO - ####################Training epoch 787####################
2025-02-01 18:59:00,332 - INFO - Epoch 787: train_loss=nan
2025-02-01 18:59:00,489 - INFO - Epoch 787: train_loss=nan
2025-02-01 18:59:00,622 - INFO - Epoch 787: train_loss=nan
2025-02-01 18:59:01,019 - INFO - Epoch 787: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:01,022 - INFO - ####################Training epoch 788####################
2025-02-01 18:59:01,400 - INFO - Epoch 788: train_loss=nan
2025-02-01 18:59:01,557 - INFO - Epoch 788: train_loss=nan
2025-02-01 18:59:01,690 - INFO - Epoch 788: train_loss=nan
2025-02-01 18:59:02,089 - INFO - Epoch 788: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:02,093 - INFO - ####################Training epoch 789####################
2025-02-01 18:59:02,475 - INFO - Epoch 789: train_loss=nan
2025-02-01 18:59:02,631 - INFO - Epoch 789: train_loss=nan
2025-02-01 18:59:02,764 - INFO - Epoch 789: train_loss=nan
2025-02-01 18:59:03,165 - INFO - Epoch 789: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:03,169 - INFO - ####################Training epoch 790####################
2025-02-01 18:59:03,546 - INFO - Epoch 790: train_loss=nan
2025-02-01 18:59:03,702 - INFO - Epoch 790: train_loss=nan
2025-02-01 18:59:03,835 - INFO - Epoch 790: train_loss=nan
2025-02-01 18:59:04,230 - INFO - Epoch 790: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:04,234 - INFO - ####################Training epoch 791####################
2025-02-01 18:59:04,610 - INFO - Epoch 791: train_loss=nan
2025-02-01 18:59:04,767 - INFO - Epoch 791: train_loss=nan
2025-02-01 18:59:04,900 - INFO - Epoch 791: train_loss=nan
2025-02-01 18:59:05,295 - INFO - Epoch 791: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:05,299 - INFO - ####################Training epoch 792####################
2025-02-01 18:59:05,673 - INFO - Epoch 792: train_loss=nan
2025-02-01 18:59:05,830 - INFO - Epoch 792: train_loss=nan
2025-02-01 18:59:05,963 - INFO - Epoch 792: train_loss=nan
2025-02-01 18:59:06,358 - INFO - Epoch 792: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:06,362 - INFO - ####################Training epoch 793####################
2025-02-01 18:59:06,741 - INFO - Epoch 793: train_loss=nan
2025-02-01 18:59:06,897 - INFO - Epoch 793: train_loss=nan
2025-02-01 18:59:07,030 - INFO - Epoch 793: train_loss=nan
2025-02-01 18:59:07,427 - INFO - Epoch 793: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:07,430 - INFO - ####################Training epoch 794####################
2025-02-01 18:59:07,809 - INFO - Epoch 794: train_loss=nan
2025-02-01 18:59:07,966 - INFO - Epoch 794: train_loss=nan
2025-02-01 18:59:08,099 - INFO - Epoch 794: train_loss=nan
2025-02-01 18:59:08,497 - INFO - Epoch 794: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:08,501 - INFO - ####################Training epoch 795####################
2025-02-01 18:59:08,879 - INFO - Epoch 795: train_loss=nan
2025-02-01 18:59:09,035 - INFO - Epoch 795: train_loss=nan
2025-02-01 18:59:09,169 - INFO - Epoch 795: train_loss=nan
2025-02-01 18:59:09,572 - INFO - Epoch 795: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:09,576 - INFO - ####################Training epoch 796####################
2025-02-01 18:59:09,954 - INFO - Epoch 796: train_loss=nan
2025-02-01 18:59:10,111 - INFO - Epoch 796: train_loss=nan
2025-02-01 18:59:10,244 - INFO - Epoch 796: train_loss=nan
2025-02-01 18:59:10,648 - INFO - Epoch 796: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:10,652 - INFO - ####################Training epoch 797####################
2025-02-01 18:59:11,027 - INFO - Epoch 797: train_loss=nan
2025-02-01 18:59:11,184 - INFO - Epoch 797: train_loss=nan
2025-02-01 18:59:11,317 - INFO - Epoch 797: train_loss=nan
2025-02-01 18:59:11,716 - INFO - Epoch 797: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:11,720 - INFO - ####################Training epoch 798####################
2025-02-01 18:59:12,097 - INFO - Epoch 798: train_loss=nan
2025-02-01 18:59:12,253 - INFO - Epoch 798: train_loss=nan
2025-02-01 18:59:12,386 - INFO - Epoch 798: train_loss=nan
2025-02-01 18:59:12,785 - INFO - Epoch 798: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:12,789 - INFO - ####################Training epoch 799####################
2025-02-01 18:59:13,169 - INFO - Epoch 799: train_loss=nan
2025-02-01 18:59:13,326 - INFO - Epoch 799: train_loss=nan
2025-02-01 18:59:13,459 - INFO - Epoch 799: train_loss=nan
2025-02-01 18:59:13,858 - INFO - Epoch 799: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:13,862 - INFO - ####################Training epoch 800####################
2025-02-01 18:59:14,238 - INFO - Epoch 800: train_loss=nan
2025-02-01 18:59:14,395 - INFO - Epoch 800: train_loss=nan
2025-02-01 18:59:14,528 - INFO - Epoch 800: train_loss=nan
2025-02-01 18:59:14,932 - INFO - Epoch 800: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:14,935 - INFO - ####################Training epoch 801####################
2025-02-01 18:59:15,313 - INFO - Epoch 801: train_loss=nan
2025-02-01 18:59:15,469 - INFO - Epoch 801: train_loss=nan
2025-02-01 18:59:15,603 - INFO - Epoch 801: train_loss=nan
2025-02-01 18:59:16,001 - INFO - Epoch 801: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:16,005 - INFO - ####################Training epoch 802####################
2025-02-01 18:59:16,380 - INFO - Epoch 802: train_loss=nan
2025-02-01 18:59:16,537 - INFO - Epoch 802: train_loss=nan
2025-02-01 18:59:16,670 - INFO - Epoch 802: train_loss=nan
2025-02-01 18:59:17,067 - INFO - Epoch 802: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:17,071 - INFO - ####################Training epoch 803####################
2025-02-01 18:59:17,451 - INFO - Epoch 803: train_loss=nan
2025-02-01 18:59:17,607 - INFO - Epoch 803: train_loss=nan
2025-02-01 18:59:17,740 - INFO - Epoch 803: train_loss=nan
2025-02-01 18:59:18,138 - INFO - Epoch 803: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:18,142 - INFO - ####################Training epoch 804####################
2025-02-01 18:59:18,520 - INFO - Epoch 804: train_loss=nan
2025-02-01 18:59:18,677 - INFO - Epoch 804: train_loss=nan
2025-02-01 18:59:18,810 - INFO - Epoch 804: train_loss=nan
2025-02-01 18:59:19,210 - INFO - Epoch 804: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:19,213 - INFO - ####################Training epoch 805####################
2025-02-01 18:59:19,592 - INFO - Epoch 805: train_loss=nan
2025-02-01 18:59:19,748 - INFO - Epoch 805: train_loss=nan
2025-02-01 18:59:19,882 - INFO - Epoch 805: train_loss=nan
2025-02-01 18:59:20,279 - INFO - Epoch 805: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:20,283 - INFO - ####################Training epoch 806####################
2025-02-01 18:59:20,663 - INFO - Epoch 806: train_loss=nan
2025-02-01 18:59:20,819 - INFO - Epoch 806: train_loss=nan
2025-02-01 18:59:20,953 - INFO - Epoch 806: train_loss=nan
2025-02-01 18:59:21,351 - INFO - Epoch 806: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:21,355 - INFO - ####################Training epoch 807####################
2025-02-01 18:59:21,729 - INFO - Epoch 807: train_loss=nan
2025-02-01 18:59:21,885 - INFO - Epoch 807: train_loss=nan
2025-02-01 18:59:22,019 - INFO - Epoch 807: train_loss=nan
2025-02-01 18:59:22,418 - INFO - Epoch 807: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:22,422 - INFO - ####################Training epoch 808####################
2025-02-01 18:59:22,796 - INFO - Epoch 808: train_loss=nan
2025-02-01 18:59:22,953 - INFO - Epoch 808: train_loss=nan
2025-02-01 18:59:23,086 - INFO - Epoch 808: train_loss=nan
2025-02-01 18:59:23,485 - INFO - Epoch 808: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:23,488 - INFO - ####################Training epoch 809####################
2025-02-01 18:59:23,865 - INFO - Epoch 809: train_loss=nan
2025-02-01 18:59:24,022 - INFO - Epoch 809: train_loss=nan
2025-02-01 18:59:24,155 - INFO - Epoch 809: train_loss=nan
2025-02-01 18:59:24,552 - INFO - Epoch 809: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:24,556 - INFO - ####################Training epoch 810####################
2025-02-01 18:59:24,932 - INFO - Epoch 810: train_loss=nan
2025-02-01 18:59:25,088 - INFO - Epoch 810: train_loss=nan
2025-02-01 18:59:25,221 - INFO - Epoch 810: train_loss=nan
2025-02-01 18:59:25,620 - INFO - Epoch 810: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:25,623 - INFO - ####################Training epoch 811####################
2025-02-01 18:59:26,005 - INFO - Epoch 811: train_loss=nan
2025-02-01 18:59:26,162 - INFO - Epoch 811: train_loss=nan
2025-02-01 18:59:26,296 - INFO - Epoch 811: train_loss=nan
2025-02-01 18:59:26,694 - INFO - Epoch 811: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:26,698 - INFO - ####################Training epoch 812####################
2025-02-01 18:59:27,078 - INFO - Epoch 812: train_loss=nan
2025-02-01 18:59:27,235 - INFO - Epoch 812: train_loss=nan
2025-02-01 18:59:27,368 - INFO - Epoch 812: train_loss=nan
2025-02-01 18:59:27,769 - INFO - Epoch 812: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:27,773 - INFO - ####################Training epoch 813####################
2025-02-01 18:59:28,151 - INFO - Epoch 813: train_loss=nan
2025-02-01 18:59:28,308 - INFO - Epoch 813: train_loss=nan
2025-02-01 18:59:28,441 - INFO - Epoch 813: train_loss=nan
2025-02-01 18:59:28,840 - INFO - Epoch 813: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:28,844 - INFO - ####################Training epoch 814####################
2025-02-01 18:59:29,222 - INFO - Epoch 814: train_loss=nan
2025-02-01 18:59:29,378 - INFO - Epoch 814: train_loss=nan
2025-02-01 18:59:29,512 - INFO - Epoch 814: train_loss=nan
2025-02-01 18:59:29,909 - INFO - Epoch 814: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:29,913 - INFO - ####################Training epoch 815####################
2025-02-01 18:59:30,291 - INFO - Epoch 815: train_loss=nan
2025-02-01 18:59:30,447 - INFO - Epoch 815: train_loss=nan
2025-02-01 18:59:30,580 - INFO - Epoch 815: train_loss=nan
2025-02-01 18:59:30,980 - INFO - Epoch 815: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:30,983 - INFO - ####################Training epoch 816####################
2025-02-01 18:59:31,361 - INFO - Epoch 816: train_loss=nan
2025-02-01 18:59:31,519 - INFO - Epoch 816: train_loss=nan
2025-02-01 18:59:31,652 - INFO - Epoch 816: train_loss=nan
2025-02-01 18:59:32,051 - INFO - Epoch 816: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:32,055 - INFO - ####################Training epoch 817####################
2025-02-01 18:59:32,439 - INFO - Epoch 817: train_loss=nan
2025-02-01 18:59:32,596 - INFO - Epoch 817: train_loss=nan
2025-02-01 18:59:32,730 - INFO - Epoch 817: train_loss=nan
2025-02-01 18:59:33,129 - INFO - Epoch 817: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:33,133 - INFO - ####################Training epoch 818####################
2025-02-01 18:59:33,510 - INFO - Epoch 818: train_loss=nan
2025-02-01 18:59:33,666 - INFO - Epoch 818: train_loss=nan
2025-02-01 18:59:33,799 - INFO - Epoch 818: train_loss=nan
2025-02-01 18:59:34,198 - INFO - Epoch 818: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:34,201 - INFO - ####################Training epoch 819####################
2025-02-01 18:59:34,578 - INFO - Epoch 819: train_loss=nan
2025-02-01 18:59:34,736 - INFO - Epoch 819: train_loss=nan
2025-02-01 18:59:34,869 - INFO - Epoch 819: train_loss=nan
2025-02-01 18:59:35,267 - INFO - Epoch 819: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:35,270 - INFO - ####################Training epoch 820####################
2025-02-01 18:59:35,647 - INFO - Epoch 820: train_loss=nan
2025-02-01 18:59:35,804 - INFO - Epoch 820: train_loss=nan
2025-02-01 18:59:35,937 - INFO - Epoch 820: train_loss=nan
2025-02-01 18:59:36,333 - INFO - Epoch 820: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:36,337 - INFO - ####################Training epoch 821####################
2025-02-01 18:59:36,715 - INFO - Epoch 821: train_loss=nan
2025-02-01 18:59:36,872 - INFO - Epoch 821: train_loss=nan
2025-02-01 18:59:37,005 - INFO - Epoch 821: train_loss=nan
2025-02-01 18:59:37,405 - INFO - Epoch 821: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:37,409 - INFO - ####################Training epoch 822####################
2025-02-01 18:59:37,784 - INFO - Epoch 822: train_loss=nan
2025-02-01 18:59:37,940 - INFO - Epoch 822: train_loss=nan
2025-02-01 18:59:38,074 - INFO - Epoch 822: train_loss=nan
2025-02-01 18:59:38,473 - INFO - Epoch 822: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:38,476 - INFO - ####################Training epoch 823####################
2025-02-01 18:59:38,857 - INFO - Epoch 823: train_loss=nan
2025-02-01 18:59:39,014 - INFO - Epoch 823: train_loss=nan
2025-02-01 18:59:39,147 - INFO - Epoch 823: train_loss=nan
2025-02-01 18:59:39,543 - INFO - Epoch 823: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:39,547 - INFO - ####################Training epoch 824####################
2025-02-01 18:59:39,923 - INFO - Epoch 824: train_loss=nan
2025-02-01 18:59:40,080 - INFO - Epoch 824: train_loss=nan
2025-02-01 18:59:40,213 - INFO - Epoch 824: train_loss=nan
2025-02-01 18:59:40,615 - INFO - Epoch 824: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:40,619 - INFO - ####################Training epoch 825####################
2025-02-01 18:59:40,997 - INFO - Epoch 825: train_loss=nan
2025-02-01 18:59:41,154 - INFO - Epoch 825: train_loss=nan
2025-02-01 18:59:41,287 - INFO - Epoch 825: train_loss=nan
2025-02-01 18:59:41,686 - INFO - Epoch 825: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:41,690 - INFO - ####################Training epoch 826####################
2025-02-01 18:59:42,071 - INFO - Epoch 826: train_loss=nan
2025-02-01 18:59:42,227 - INFO - Epoch 826: train_loss=nan
2025-02-01 18:59:42,360 - INFO - Epoch 826: train_loss=nan
2025-02-01 18:59:42,757 - INFO - Epoch 826: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:42,761 - INFO - ####################Training epoch 827####################
2025-02-01 18:59:43,141 - INFO - Epoch 827: train_loss=nan
2025-02-01 18:59:43,298 - INFO - Epoch 827: train_loss=nan
2025-02-01 18:59:43,432 - INFO - Epoch 827: train_loss=nan
2025-02-01 18:59:43,828 - INFO - Epoch 827: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:43,832 - INFO - ####################Training epoch 828####################
2025-02-01 18:59:44,211 - INFO - Epoch 828: train_loss=nan
2025-02-01 18:59:44,367 - INFO - Epoch 828: train_loss=nan
2025-02-01 18:59:44,500 - INFO - Epoch 828: train_loss=nan
2025-02-01 18:59:44,898 - INFO - Epoch 828: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:44,902 - INFO - ####################Training epoch 829####################
2025-02-01 18:59:45,282 - INFO - Epoch 829: train_loss=nan
2025-02-01 18:59:45,438 - INFO - Epoch 829: train_loss=nan
2025-02-01 18:59:45,573 - INFO - Epoch 829: train_loss=nan
2025-02-01 18:59:45,970 - INFO - Epoch 829: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:45,974 - INFO - ####################Training epoch 830####################
2025-02-01 18:59:46,347 - INFO - Epoch 830: train_loss=nan
2025-02-01 18:59:46,503 - INFO - Epoch 830: train_loss=nan
2025-02-01 18:59:46,636 - INFO - Epoch 830: train_loss=nan
2025-02-01 18:59:47,033 - INFO - Epoch 830: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:47,037 - INFO - ####################Training epoch 831####################
2025-02-01 18:59:47,415 - INFO - Epoch 831: train_loss=nan
2025-02-01 18:59:47,572 - INFO - Epoch 831: train_loss=nan
2025-02-01 18:59:47,705 - INFO - Epoch 831: train_loss=nan
2025-02-01 18:59:48,105 - INFO - Epoch 831: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:48,109 - INFO - ####################Training epoch 832####################
2025-02-01 18:59:48,485 - INFO - Epoch 832: train_loss=nan
2025-02-01 18:59:48,641 - INFO - Epoch 832: train_loss=nan
2025-02-01 18:59:48,774 - INFO - Epoch 832: train_loss=nan
2025-02-01 18:59:49,170 - INFO - Epoch 832: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:49,173 - INFO - ####################Training epoch 833####################
2025-02-01 18:59:49,550 - INFO - Epoch 833: train_loss=nan
2025-02-01 18:59:49,706 - INFO - Epoch 833: train_loss=nan
2025-02-01 18:59:49,839 - INFO - Epoch 833: train_loss=nan
2025-02-01 18:59:50,236 - INFO - Epoch 833: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:50,239 - INFO - ####################Training epoch 834####################
2025-02-01 18:59:50,615 - INFO - Epoch 834: train_loss=nan
2025-02-01 18:59:50,771 - INFO - Epoch 834: train_loss=nan
2025-02-01 18:59:50,905 - INFO - Epoch 834: train_loss=nan
2025-02-01 18:59:51,303 - INFO - Epoch 834: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:51,307 - INFO - ####################Training epoch 835####################
2025-02-01 18:59:51,686 - INFO - Epoch 835: train_loss=nan
2025-02-01 18:59:51,843 - INFO - Epoch 835: train_loss=nan
2025-02-01 18:59:51,976 - INFO - Epoch 835: train_loss=nan
2025-02-01 18:59:52,372 - INFO - Epoch 835: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:52,375 - INFO - ####################Training epoch 836####################
2025-02-01 18:59:52,751 - INFO - Epoch 836: train_loss=nan
2025-02-01 18:59:52,907 - INFO - Epoch 836: train_loss=nan
2025-02-01 18:59:53,040 - INFO - Epoch 836: train_loss=nan
2025-02-01 18:59:53,434 - INFO - Epoch 836: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:53,438 - INFO - ####################Training epoch 837####################
2025-02-01 18:59:53,813 - INFO - Epoch 837: train_loss=nan
2025-02-01 18:59:53,970 - INFO - Epoch 837: train_loss=nan
2025-02-01 18:59:54,104 - INFO - Epoch 837: train_loss=nan
2025-02-01 18:59:54,504 - INFO - Epoch 837: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:54,507 - INFO - ####################Training epoch 838####################
2025-02-01 18:59:54,886 - INFO - Epoch 838: train_loss=nan
2025-02-01 18:59:55,042 - INFO - Epoch 838: train_loss=nan
2025-02-01 18:59:55,175 - INFO - Epoch 838: train_loss=nan
2025-02-01 18:59:55,571 - INFO - Epoch 838: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:55,575 - INFO - ####################Training epoch 839####################
2025-02-01 18:59:55,953 - INFO - Epoch 839: train_loss=nan
2025-02-01 18:59:56,110 - INFO - Epoch 839: train_loss=nan
2025-02-01 18:59:56,244 - INFO - Epoch 839: train_loss=nan
2025-02-01 18:59:56,644 - INFO - Epoch 839: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:56,648 - INFO - ####################Training epoch 840####################
2025-02-01 18:59:57,021 - INFO - Epoch 840: train_loss=nan
2025-02-01 18:59:57,178 - INFO - Epoch 840: train_loss=nan
2025-02-01 18:59:57,311 - INFO - Epoch 840: train_loss=nan
2025-02-01 18:59:57,710 - INFO - Epoch 840: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:57,714 - INFO - ####################Training epoch 841####################
2025-02-01 18:59:58,090 - INFO - Epoch 841: train_loss=nan
2025-02-01 18:59:58,247 - INFO - Epoch 841: train_loss=nan
2025-02-01 18:59:58,380 - INFO - Epoch 841: train_loss=nan
2025-02-01 18:59:58,777 - INFO - Epoch 841: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:58,780 - INFO - ####################Training epoch 842####################
2025-02-01 18:59:59,156 - INFO - Epoch 842: train_loss=nan
2025-02-01 18:59:59,313 - INFO - Epoch 842: train_loss=nan
2025-02-01 18:59:59,446 - INFO - Epoch 842: train_loss=nan
2025-02-01 18:59:59,845 - INFO - Epoch 842: val_loss=nan, val_acc=66.67%
2025-02-01 18:59:59,849 - INFO - ####################Training epoch 843####################
2025-02-01 19:00:00,226 - INFO - Epoch 843: train_loss=nan
2025-02-01 19:00:00,383 - INFO - Epoch 843: train_loss=nan
2025-02-01 19:00:00,516 - INFO - Epoch 843: train_loss=nan
2025-02-01 19:00:00,913 - INFO - Epoch 843: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:00,917 - INFO - ####################Training epoch 844####################
2025-02-01 19:00:01,295 - INFO - Epoch 844: train_loss=nan
2025-02-01 19:00:01,452 - INFO - Epoch 844: train_loss=nan
2025-02-01 19:00:01,585 - INFO - Epoch 844: train_loss=nan
2025-02-01 19:00:01,980 - INFO - Epoch 844: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:01,984 - INFO - ####################Training epoch 845####################
2025-02-01 19:00:02,362 - INFO - Epoch 845: train_loss=nan
2025-02-01 19:00:02,518 - INFO - Epoch 845: train_loss=nan
2025-02-01 19:00:02,651 - INFO - Epoch 845: train_loss=nan
2025-02-01 19:00:03,046 - INFO - Epoch 845: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:03,050 - INFO - ####################Training epoch 846####################
2025-02-01 19:00:03,426 - INFO - Epoch 846: train_loss=nan
2025-02-01 19:00:03,582 - INFO - Epoch 846: train_loss=nan
2025-02-01 19:00:03,715 - INFO - Epoch 846: train_loss=nan
2025-02-01 19:00:04,114 - INFO - Epoch 846: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:04,118 - INFO - ####################Training epoch 847####################
2025-02-01 19:00:04,492 - INFO - Epoch 847: train_loss=nan
2025-02-01 19:00:04,649 - INFO - Epoch 847: train_loss=nan
2025-02-01 19:00:04,782 - INFO - Epoch 847: train_loss=nan
2025-02-01 19:00:05,179 - INFO - Epoch 847: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:05,182 - INFO - ####################Training epoch 848####################
2025-02-01 19:00:05,562 - INFO - Epoch 848: train_loss=nan
2025-02-01 19:00:05,719 - INFO - Epoch 848: train_loss=nan
2025-02-01 19:00:05,852 - INFO - Epoch 848: train_loss=nan
2025-02-01 19:00:06,247 - INFO - Epoch 848: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:06,251 - INFO - ####################Training epoch 849####################
2025-02-01 19:00:06,625 - INFO - Epoch 849: train_loss=nan
2025-02-01 19:00:06,782 - INFO - Epoch 849: train_loss=nan
2025-02-01 19:00:06,915 - INFO - Epoch 849: train_loss=nan
2025-02-01 19:00:07,316 - INFO - Epoch 849: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:07,320 - INFO - ####################Training epoch 850####################
2025-02-01 19:00:07,695 - INFO - Epoch 850: train_loss=nan
2025-02-01 19:00:07,851 - INFO - Epoch 850: train_loss=nan
2025-02-01 19:00:07,984 - INFO - Epoch 850: train_loss=nan
2025-02-01 19:00:08,381 - INFO - Epoch 850: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:08,384 - INFO - ####################Training epoch 851####################
2025-02-01 19:00:08,762 - INFO - Epoch 851: train_loss=nan
2025-02-01 19:00:08,918 - INFO - Epoch 851: train_loss=nan
2025-02-01 19:00:09,051 - INFO - Epoch 851: train_loss=nan
2025-02-01 19:00:09,445 - INFO - Epoch 851: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:09,449 - INFO - ####################Training epoch 852####################
2025-02-01 19:00:09,826 - INFO - Epoch 852: train_loss=nan
2025-02-01 19:00:09,982 - INFO - Epoch 852: train_loss=nan
2025-02-01 19:00:10,115 - INFO - Epoch 852: train_loss=nan
2025-02-01 19:00:10,514 - INFO - Epoch 852: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:10,518 - INFO - ####################Training epoch 853####################
2025-02-01 19:00:10,893 - INFO - Epoch 853: train_loss=nan
2025-02-01 19:00:11,050 - INFO - Epoch 853: train_loss=nan
2025-02-01 19:00:11,183 - INFO - Epoch 853: train_loss=nan
2025-02-01 19:00:11,580 - INFO - Epoch 853: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:11,583 - INFO - ####################Training epoch 854####################
2025-02-01 19:00:11,960 - INFO - Epoch 854: train_loss=nan
2025-02-01 19:00:12,116 - INFO - Epoch 854: train_loss=nan
2025-02-01 19:00:12,249 - INFO - Epoch 854: train_loss=nan
2025-02-01 19:00:12,646 - INFO - Epoch 854: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:12,650 - INFO - ####################Training epoch 855####################
2025-02-01 19:00:13,028 - INFO - Epoch 855: train_loss=nan
2025-02-01 19:00:13,185 - INFO - Epoch 855: train_loss=nan
2025-02-01 19:00:13,319 - INFO - Epoch 855: train_loss=nan
2025-02-01 19:00:13,719 - INFO - Epoch 855: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:13,723 - INFO - ####################Training epoch 856####################
2025-02-01 19:00:14,098 - INFO - Epoch 856: train_loss=nan
2025-02-01 19:00:14,254 - INFO - Epoch 856: train_loss=nan
2025-02-01 19:00:14,387 - INFO - Epoch 856: train_loss=nan
2025-02-01 19:00:14,790 - INFO - Epoch 856: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:14,793 - INFO - ####################Training epoch 857####################
2025-02-01 19:00:15,171 - INFO - Epoch 857: train_loss=nan
2025-02-01 19:00:15,328 - INFO - Epoch 857: train_loss=nan
2025-02-01 19:00:15,461 - INFO - Epoch 857: train_loss=nan
2025-02-01 19:00:15,858 - INFO - Epoch 857: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:15,862 - INFO - ####################Training epoch 858####################
2025-02-01 19:00:16,238 - INFO - Epoch 858: train_loss=nan
2025-02-01 19:00:16,394 - INFO - Epoch 858: train_loss=nan
2025-02-01 19:00:16,527 - INFO - Epoch 858: train_loss=nan
2025-02-01 19:00:16,925 - INFO - Epoch 858: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:16,928 - INFO - ####################Training epoch 859####################
2025-02-01 19:00:17,304 - INFO - Epoch 859: train_loss=nan
2025-02-01 19:00:17,461 - INFO - Epoch 859: train_loss=nan
2025-02-01 19:00:17,594 - INFO - Epoch 859: train_loss=nan
2025-02-01 19:00:17,988 - INFO - Epoch 859: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:17,992 - INFO - ####################Training epoch 860####################
2025-02-01 19:00:18,370 - INFO - Epoch 860: train_loss=nan
2025-02-01 19:00:18,527 - INFO - Epoch 860: train_loss=nan
2025-02-01 19:00:18,660 - INFO - Epoch 860: train_loss=nan
2025-02-01 19:00:19,057 - INFO - Epoch 860: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:19,061 - INFO - ####################Training epoch 861####################
2025-02-01 19:00:19,438 - INFO - Epoch 861: train_loss=nan
2025-02-01 19:00:19,595 - INFO - Epoch 861: train_loss=nan
2025-02-01 19:00:19,727 - INFO - Epoch 861: train_loss=nan
2025-02-01 19:00:20,127 - INFO - Epoch 861: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:20,131 - INFO - ####################Training epoch 862####################
2025-02-01 19:00:20,506 - INFO - Epoch 862: train_loss=nan
2025-02-01 19:00:20,663 - INFO - Epoch 862: train_loss=nan
2025-02-01 19:00:20,797 - INFO - Epoch 862: train_loss=nan
2025-02-01 19:00:21,193 - INFO - Epoch 862: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:21,197 - INFO - ####################Training epoch 863####################
2025-02-01 19:00:21,575 - INFO - Epoch 863: train_loss=nan
2025-02-01 19:00:21,732 - INFO - Epoch 863: train_loss=nan
2025-02-01 19:00:21,865 - INFO - Epoch 863: train_loss=nan
2025-02-01 19:00:22,265 - INFO - Epoch 863: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:22,269 - INFO - ####################Training epoch 864####################
2025-02-01 19:00:22,646 - INFO - Epoch 864: train_loss=nan
2025-02-01 19:00:22,803 - INFO - Epoch 864: train_loss=nan
2025-02-01 19:00:22,936 - INFO - Epoch 864: train_loss=nan
2025-02-01 19:00:23,337 - INFO - Epoch 864: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:23,341 - INFO - ####################Training epoch 865####################
2025-02-01 19:00:23,722 - INFO - Epoch 865: train_loss=nan
2025-02-01 19:00:23,879 - INFO - Epoch 865: train_loss=nan
2025-02-01 19:00:24,012 - INFO - Epoch 865: train_loss=nan
2025-02-01 19:00:24,410 - INFO - Epoch 865: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:24,413 - INFO - ####################Training epoch 866####################
2025-02-01 19:00:24,797 - INFO - Epoch 866: train_loss=nan
2025-02-01 19:00:24,953 - INFO - Epoch 866: train_loss=nan
2025-02-01 19:00:25,086 - INFO - Epoch 866: train_loss=nan
2025-02-01 19:00:25,486 - INFO - Epoch 866: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:25,490 - INFO - ####################Training epoch 867####################
2025-02-01 19:00:25,871 - INFO - Epoch 867: train_loss=nan
2025-02-01 19:00:26,027 - INFO - Epoch 867: train_loss=nan
2025-02-01 19:00:26,160 - INFO - Epoch 867: train_loss=nan
2025-02-01 19:00:26,559 - INFO - Epoch 867: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:26,563 - INFO - ####################Training epoch 868####################
2025-02-01 19:00:26,943 - INFO - Epoch 868: train_loss=nan
2025-02-01 19:00:27,100 - INFO - Epoch 868: train_loss=nan
2025-02-01 19:00:27,233 - INFO - Epoch 868: train_loss=nan
2025-02-01 19:00:27,628 - INFO - Epoch 868: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:27,632 - INFO - ####################Training epoch 869####################
2025-02-01 19:00:28,007 - INFO - Epoch 869: train_loss=nan
2025-02-01 19:00:28,164 - INFO - Epoch 869: train_loss=nan
2025-02-01 19:00:28,298 - INFO - Epoch 869: train_loss=nan
2025-02-01 19:00:28,692 - INFO - Epoch 869: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:28,696 - INFO - ####################Training epoch 870####################
2025-02-01 19:00:29,074 - INFO - Epoch 870: train_loss=nan
2025-02-01 19:00:29,230 - INFO - Epoch 870: train_loss=nan
2025-02-01 19:00:29,363 - INFO - Epoch 870: train_loss=nan
2025-02-01 19:00:29,763 - INFO - Epoch 870: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:29,766 - INFO - ####################Training epoch 871####################
2025-02-01 19:00:30,144 - INFO - Epoch 871: train_loss=nan
2025-02-01 19:00:30,301 - INFO - Epoch 871: train_loss=nan
2025-02-01 19:00:30,434 - INFO - Epoch 871: train_loss=nan
2025-02-01 19:00:30,831 - INFO - Epoch 871: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:30,834 - INFO - ####################Training epoch 872####################
2025-02-01 19:00:31,212 - INFO - Epoch 872: train_loss=nan
2025-02-01 19:00:31,369 - INFO - Epoch 872: train_loss=nan
2025-02-01 19:00:31,502 - INFO - Epoch 872: train_loss=nan
2025-02-01 19:00:31,897 - INFO - Epoch 872: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:31,901 - INFO - ####################Training epoch 873####################
2025-02-01 19:00:32,281 - INFO - Epoch 873: train_loss=nan
2025-02-01 19:00:32,438 - INFO - Epoch 873: train_loss=nan
2025-02-01 19:00:32,571 - INFO - Epoch 873: train_loss=nan
2025-02-01 19:00:32,969 - INFO - Epoch 873: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:32,972 - INFO - ####################Training epoch 874####################
2025-02-01 19:00:33,353 - INFO - Epoch 874: train_loss=nan
2025-02-01 19:00:33,509 - INFO - Epoch 874: train_loss=nan
2025-02-01 19:00:33,642 - INFO - Epoch 874: train_loss=nan
2025-02-01 19:00:34,043 - INFO - Epoch 874: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:34,046 - INFO - ####################Training epoch 875####################
2025-02-01 19:00:34,422 - INFO - Epoch 875: train_loss=nan
2025-02-01 19:00:34,579 - INFO - Epoch 875: train_loss=nan
2025-02-01 19:00:34,712 - INFO - Epoch 875: train_loss=nan
2025-02-01 19:00:35,107 - INFO - Epoch 875: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:35,111 - INFO - ####################Training epoch 876####################
2025-02-01 19:00:35,490 - INFO - Epoch 876: train_loss=nan
2025-02-01 19:00:35,647 - INFO - Epoch 876: train_loss=nan
2025-02-01 19:00:35,780 - INFO - Epoch 876: train_loss=nan
2025-02-01 19:00:36,178 - INFO - Epoch 876: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:36,182 - INFO - ####################Training epoch 877####################
2025-02-01 19:00:36,561 - INFO - Epoch 877: train_loss=nan
2025-02-01 19:00:36,718 - INFO - Epoch 877: train_loss=nan
2025-02-01 19:00:36,851 - INFO - Epoch 877: train_loss=nan
2025-02-01 19:00:37,248 - INFO - Epoch 877: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:37,252 - INFO - ####################Training epoch 878####################
2025-02-01 19:00:37,632 - INFO - Epoch 878: train_loss=nan
2025-02-01 19:00:37,788 - INFO - Epoch 878: train_loss=nan
2025-02-01 19:00:37,921 - INFO - Epoch 878: train_loss=nan
2025-02-01 19:00:38,321 - INFO - Epoch 878: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:38,324 - INFO - ####################Training epoch 879####################
2025-02-01 19:00:38,701 - INFO - Epoch 879: train_loss=nan
2025-02-01 19:00:38,858 - INFO - Epoch 879: train_loss=nan
2025-02-01 19:00:38,991 - INFO - Epoch 879: train_loss=nan
2025-02-01 19:00:39,390 - INFO - Epoch 879: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:39,394 - INFO - ####################Training epoch 880####################
2025-02-01 19:00:39,773 - INFO - Epoch 880: train_loss=nan
2025-02-01 19:00:39,929 - INFO - Epoch 880: train_loss=nan
2025-02-01 19:00:40,062 - INFO - Epoch 880: train_loss=nan
2025-02-01 19:00:40,459 - INFO - Epoch 880: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:40,463 - INFO - ####################Training epoch 881####################
2025-02-01 19:00:40,839 - INFO - Epoch 881: train_loss=nan
2025-02-01 19:00:40,996 - INFO - Epoch 881: train_loss=nan
2025-02-01 19:00:41,130 - INFO - Epoch 881: train_loss=nan
2025-02-01 19:00:41,531 - INFO - Epoch 881: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:41,535 - INFO - ####################Training epoch 882####################
2025-02-01 19:00:41,912 - INFO - Epoch 882: train_loss=nan
2025-02-01 19:00:42,069 - INFO - Epoch 882: train_loss=nan
2025-02-01 19:00:42,202 - INFO - Epoch 882: train_loss=nan
2025-02-01 19:00:42,599 - INFO - Epoch 882: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:42,603 - INFO - ####################Training epoch 883####################
2025-02-01 19:00:42,980 - INFO - Epoch 883: train_loss=nan
2025-02-01 19:00:43,137 - INFO - Epoch 883: train_loss=nan
2025-02-01 19:00:43,270 - INFO - Epoch 883: train_loss=nan
2025-02-01 19:00:43,664 - INFO - Epoch 883: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:43,668 - INFO - ####################Training epoch 884####################
2025-02-01 19:00:44,047 - INFO - Epoch 884: train_loss=nan
2025-02-01 19:00:44,203 - INFO - Epoch 884: train_loss=nan
2025-02-01 19:00:44,336 - INFO - Epoch 884: train_loss=nan
2025-02-01 19:00:44,730 - INFO - Epoch 884: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:44,734 - INFO - ####################Training epoch 885####################
2025-02-01 19:00:45,112 - INFO - Epoch 885: train_loss=nan
2025-02-01 19:00:45,269 - INFO - Epoch 885: train_loss=nan
2025-02-01 19:00:45,402 - INFO - Epoch 885: train_loss=nan
2025-02-01 19:00:45,797 - INFO - Epoch 885: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:45,801 - INFO - ####################Training epoch 886####################
2025-02-01 19:00:46,175 - INFO - Epoch 886: train_loss=nan
2025-02-01 19:00:46,332 - INFO - Epoch 886: train_loss=nan
2025-02-01 19:00:46,465 - INFO - Epoch 886: train_loss=nan
2025-02-01 19:00:46,862 - INFO - Epoch 886: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:46,866 - INFO - ####################Training epoch 887####################
2025-02-01 19:00:47,244 - INFO - Epoch 887: train_loss=nan
2025-02-01 19:00:47,400 - INFO - Epoch 887: train_loss=nan
2025-02-01 19:00:47,534 - INFO - Epoch 887: train_loss=nan
2025-02-01 19:00:47,934 - INFO - Epoch 887: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:47,938 - INFO - ####################Training epoch 888####################
2025-02-01 19:00:48,317 - INFO - Epoch 888: train_loss=nan
2025-02-01 19:00:48,474 - INFO - Epoch 888: train_loss=nan
2025-02-01 19:00:48,608 - INFO - Epoch 888: train_loss=nan
2025-02-01 19:00:49,006 - INFO - Epoch 888: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:49,010 - INFO - ####################Training epoch 889####################
2025-02-01 19:00:49,385 - INFO - Epoch 889: train_loss=nan
2025-02-01 19:00:49,541 - INFO - Epoch 889: train_loss=nan
2025-02-01 19:00:49,674 - INFO - Epoch 889: train_loss=nan
2025-02-01 19:00:50,071 - INFO - Epoch 889: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:50,075 - INFO - ####################Training epoch 890####################
2025-02-01 19:00:50,454 - INFO - Epoch 890: train_loss=nan
2025-02-01 19:00:50,610 - INFO - Epoch 890: train_loss=nan
2025-02-01 19:00:50,743 - INFO - Epoch 890: train_loss=nan
2025-02-01 19:00:51,137 - INFO - Epoch 890: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:51,140 - INFO - ####################Training epoch 891####################
2025-02-01 19:00:51,513 - INFO - Epoch 891: train_loss=nan
2025-02-01 19:00:51,670 - INFO - Epoch 891: train_loss=nan
2025-02-01 19:00:51,803 - INFO - Epoch 891: train_loss=nan
2025-02-01 19:00:52,198 - INFO - Epoch 891: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:52,202 - INFO - ####################Training epoch 892####################
2025-02-01 19:00:52,577 - INFO - Epoch 892: train_loss=nan
2025-02-01 19:00:52,734 - INFO - Epoch 892: train_loss=nan
2025-02-01 19:00:52,867 - INFO - Epoch 892: train_loss=nan
2025-02-01 19:00:53,264 - INFO - Epoch 892: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:53,268 - INFO - ####################Training epoch 893####################
2025-02-01 19:00:53,645 - INFO - Epoch 893: train_loss=nan
2025-02-01 19:00:53,800 - INFO - Epoch 893: train_loss=nan
2025-02-01 19:00:53,933 - INFO - Epoch 893: train_loss=nan
2025-02-01 19:00:54,329 - INFO - Epoch 893: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:54,333 - INFO - ####################Training epoch 894####################
2025-02-01 19:00:54,707 - INFO - Epoch 894: train_loss=nan
2025-02-01 19:00:54,863 - INFO - Epoch 894: train_loss=nan
2025-02-01 19:00:54,996 - INFO - Epoch 894: train_loss=nan
2025-02-01 19:00:55,395 - INFO - Epoch 894: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:55,398 - INFO - ####################Training epoch 895####################
2025-02-01 19:00:55,772 - INFO - Epoch 895: train_loss=nan
2025-02-01 19:00:55,929 - INFO - Epoch 895: train_loss=nan
2025-02-01 19:00:56,062 - INFO - Epoch 895: train_loss=nan
2025-02-01 19:00:56,458 - INFO - Epoch 895: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:56,462 - INFO - ####################Training epoch 896####################
2025-02-01 19:00:56,838 - INFO - Epoch 896: train_loss=nan
2025-02-01 19:00:56,995 - INFO - Epoch 896: train_loss=nan
2025-02-01 19:00:57,128 - INFO - Epoch 896: train_loss=nan
2025-02-01 19:00:57,524 - INFO - Epoch 896: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:57,528 - INFO - ####################Training epoch 897####################
2025-02-01 19:00:57,902 - INFO - Epoch 897: train_loss=nan
2025-02-01 19:00:58,058 - INFO - Epoch 897: train_loss=nan
2025-02-01 19:00:58,191 - INFO - Epoch 897: train_loss=nan
2025-02-01 19:00:58,587 - INFO - Epoch 897: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:58,591 - INFO - ####################Training epoch 898####################
2025-02-01 19:00:58,967 - INFO - Epoch 898: train_loss=nan
2025-02-01 19:00:59,124 - INFO - Epoch 898: train_loss=nan
2025-02-01 19:00:59,256 - INFO - Epoch 898: train_loss=nan
2025-02-01 19:00:59,655 - INFO - Epoch 898: val_loss=nan, val_acc=66.67%
2025-02-01 19:00:59,658 - INFO - ####################Training epoch 899####################
2025-02-01 19:01:00,034 - INFO - Epoch 899: train_loss=nan
2025-02-01 19:01:00,191 - INFO - Epoch 899: train_loss=nan
2025-02-01 19:01:00,324 - INFO - Epoch 899: train_loss=nan
2025-02-01 19:01:00,723 - INFO - Epoch 899: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:00,727 - INFO - ####################Training epoch 900####################
2025-02-01 19:01:01,100 - INFO - Epoch 900: train_loss=nan
2025-02-01 19:01:01,257 - INFO - Epoch 900: train_loss=nan
2025-02-01 19:01:01,390 - INFO - Epoch 900: train_loss=nan
2025-02-01 19:01:01,783 - INFO - Epoch 900: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:01,787 - INFO - ####################Training epoch 901####################
2025-02-01 19:01:02,162 - INFO - Epoch 901: train_loss=nan
2025-02-01 19:01:02,318 - INFO - Epoch 901: train_loss=nan
2025-02-01 19:01:02,451 - INFO - Epoch 901: train_loss=nan
2025-02-01 19:01:02,849 - INFO - Epoch 901: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:02,853 - INFO - ####################Training epoch 902####################
2025-02-01 19:01:03,235 - INFO - Epoch 902: train_loss=nan
2025-02-01 19:01:03,392 - INFO - Epoch 902: train_loss=nan
2025-02-01 19:01:03,526 - INFO - Epoch 902: train_loss=nan
2025-02-01 19:01:03,925 - INFO - Epoch 902: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:03,928 - INFO - ####################Training epoch 903####################
2025-02-01 19:01:04,302 - INFO - Epoch 903: train_loss=nan
2025-02-01 19:01:04,458 - INFO - Epoch 903: train_loss=nan
2025-02-01 19:01:04,591 - INFO - Epoch 903: train_loss=nan
2025-02-01 19:01:04,989 - INFO - Epoch 903: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:04,993 - INFO - ####################Training epoch 904####################
2025-02-01 19:01:05,368 - INFO - Epoch 904: train_loss=nan
2025-02-01 19:01:05,524 - INFO - Epoch 904: train_loss=nan
2025-02-01 19:01:05,658 - INFO - Epoch 904: train_loss=nan
2025-02-01 19:01:06,053 - INFO - Epoch 904: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:06,057 - INFO - ####################Training epoch 905####################
2025-02-01 19:01:06,433 - INFO - Epoch 905: train_loss=nan
2025-02-01 19:01:06,590 - INFO - Epoch 905: train_loss=nan
2025-02-01 19:01:06,724 - INFO - Epoch 905: train_loss=nan
2025-02-01 19:01:07,122 - INFO - Epoch 905: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:07,126 - INFO - ####################Training epoch 906####################
2025-02-01 19:01:07,501 - INFO - Epoch 906: train_loss=nan
2025-02-01 19:01:07,657 - INFO - Epoch 906: train_loss=nan
2025-02-01 19:01:07,790 - INFO - Epoch 906: train_loss=nan
2025-02-01 19:01:08,190 - INFO - Epoch 906: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:08,194 - INFO - ####################Training epoch 907####################
2025-02-01 19:01:08,572 - INFO - Epoch 907: train_loss=nan
2025-02-01 19:01:08,729 - INFO - Epoch 907: train_loss=nan
2025-02-01 19:01:08,862 - INFO - Epoch 907: train_loss=nan
2025-02-01 19:01:09,258 - INFO - Epoch 907: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:09,262 - INFO - ####################Training epoch 908####################
2025-02-01 19:01:09,638 - INFO - Epoch 908: train_loss=nan
2025-02-01 19:01:09,795 - INFO - Epoch 908: train_loss=nan
2025-02-01 19:01:09,928 - INFO - Epoch 908: train_loss=nan
2025-02-01 19:01:10,323 - INFO - Epoch 908: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:10,327 - INFO - ####################Training epoch 909####################
2025-02-01 19:01:10,708 - INFO - Epoch 909: train_loss=nan
2025-02-01 19:01:10,865 - INFO - Epoch 909: train_loss=nan
2025-02-01 19:01:10,998 - INFO - Epoch 909: train_loss=nan
2025-02-01 19:01:11,395 - INFO - Epoch 909: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:11,399 - INFO - ####################Training epoch 910####################
2025-02-01 19:01:11,778 - INFO - Epoch 910: train_loss=nan
2025-02-01 19:01:11,934 - INFO - Epoch 910: train_loss=nan
2025-02-01 19:01:12,068 - INFO - Epoch 910: train_loss=nan
2025-02-01 19:01:12,463 - INFO - Epoch 910: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:12,467 - INFO - ####################Training epoch 911####################
2025-02-01 19:01:12,844 - INFO - Epoch 911: train_loss=nan
2025-02-01 19:01:13,001 - INFO - Epoch 911: train_loss=nan
2025-02-01 19:01:13,134 - INFO - Epoch 911: train_loss=nan
2025-02-01 19:01:13,530 - INFO - Epoch 911: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:13,533 - INFO - ####################Training epoch 912####################
2025-02-01 19:01:13,910 - INFO - Epoch 912: train_loss=nan
2025-02-01 19:01:14,067 - INFO - Epoch 912: train_loss=nan
2025-02-01 19:01:14,200 - INFO - Epoch 912: train_loss=nan
2025-02-01 19:01:14,598 - INFO - Epoch 912: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:14,601 - INFO - ####################Training epoch 913####################
2025-02-01 19:01:14,977 - INFO - Epoch 913: train_loss=nan
2025-02-01 19:01:15,134 - INFO - Epoch 913: train_loss=nan
2025-02-01 19:01:15,267 - INFO - Epoch 913: train_loss=nan
2025-02-01 19:01:15,666 - INFO - Epoch 913: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:15,669 - INFO - ####################Training epoch 914####################
2025-02-01 19:01:16,045 - INFO - Epoch 914: train_loss=nan
2025-02-01 19:01:16,201 - INFO - Epoch 914: train_loss=nan
2025-02-01 19:01:16,335 - INFO - Epoch 914: train_loss=nan
2025-02-01 19:01:16,732 - INFO - Epoch 914: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:16,735 - INFO - ####################Training epoch 915####################
2025-02-01 19:01:17,111 - INFO - Epoch 915: train_loss=nan
2025-02-01 19:01:17,268 - INFO - Epoch 915: train_loss=nan
2025-02-01 19:01:17,401 - INFO - Epoch 915: train_loss=nan
2025-02-01 19:01:17,797 - INFO - Epoch 915: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:17,800 - INFO - ####################Training epoch 916####################
2025-02-01 19:01:18,175 - INFO - Epoch 916: train_loss=nan
2025-02-01 19:01:18,331 - INFO - Epoch 916: train_loss=nan
2025-02-01 19:01:18,464 - INFO - Epoch 916: train_loss=nan
2025-02-01 19:01:18,861 - INFO - Epoch 916: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:18,865 - INFO - ####################Training epoch 917####################
2025-02-01 19:01:19,241 - INFO - Epoch 917: train_loss=nan
2025-02-01 19:01:19,398 - INFO - Epoch 917: train_loss=nan
2025-02-01 19:01:19,530 - INFO - Epoch 917: train_loss=nan
2025-02-01 19:01:19,926 - INFO - Epoch 917: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:19,930 - INFO - ####################Training epoch 918####################
2025-02-01 19:01:20,306 - INFO - Epoch 918: train_loss=nan
2025-02-01 19:01:20,463 - INFO - Epoch 918: train_loss=nan
2025-02-01 19:01:20,596 - INFO - Epoch 918: train_loss=nan
2025-02-01 19:01:20,992 - INFO - Epoch 918: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:20,995 - INFO - ####################Training epoch 919####################
2025-02-01 19:01:21,373 - INFO - Epoch 919: train_loss=nan
2025-02-01 19:01:21,529 - INFO - Epoch 919: train_loss=nan
2025-02-01 19:01:21,663 - INFO - Epoch 919: train_loss=nan
2025-02-01 19:01:22,060 - INFO - Epoch 919: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:22,063 - INFO - ####################Training epoch 920####################
2025-02-01 19:01:22,439 - INFO - Epoch 920: train_loss=nan
2025-02-01 19:01:22,596 - INFO - Epoch 920: train_loss=nan
2025-02-01 19:01:22,729 - INFO - Epoch 920: train_loss=nan
2025-02-01 19:01:23,130 - INFO - Epoch 920: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:23,133 - INFO - ####################Training epoch 921####################
2025-02-01 19:01:23,510 - INFO - Epoch 921: train_loss=nan
2025-02-01 19:01:23,667 - INFO - Epoch 921: train_loss=nan
2025-02-01 19:01:23,801 - INFO - Epoch 921: train_loss=nan
2025-02-01 19:01:24,199 - INFO - Epoch 921: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:24,202 - INFO - ####################Training epoch 922####################
2025-02-01 19:01:24,580 - INFO - Epoch 922: train_loss=nan
2025-02-01 19:01:24,736 - INFO - Epoch 922: train_loss=nan
2025-02-01 19:01:24,869 - INFO - Epoch 922: train_loss=nan
2025-02-01 19:01:25,266 - INFO - Epoch 922: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:25,269 - INFO - ####################Training epoch 923####################
2025-02-01 19:01:25,651 - INFO - Epoch 923: train_loss=nan
2025-02-01 19:01:25,807 - INFO - Epoch 923: train_loss=nan
2025-02-01 19:01:25,940 - INFO - Epoch 923: train_loss=nan
2025-02-01 19:01:26,334 - INFO - Epoch 923: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:26,338 - INFO - ####################Training epoch 924####################
2025-02-01 19:01:26,715 - INFO - Epoch 924: train_loss=nan
2025-02-01 19:01:26,871 - INFO - Epoch 924: train_loss=nan
2025-02-01 19:01:27,005 - INFO - Epoch 924: train_loss=nan
2025-02-01 19:01:27,402 - INFO - Epoch 924: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:27,409 - INFO - ####################Training epoch 925####################
2025-02-01 19:01:27,786 - INFO - Epoch 925: train_loss=nan
2025-02-01 19:01:27,944 - INFO - Epoch 925: train_loss=nan
2025-02-01 19:01:28,077 - INFO - Epoch 925: train_loss=nan
2025-02-01 19:01:28,472 - INFO - Epoch 925: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:28,475 - INFO - ####################Training epoch 926####################
2025-02-01 19:01:28,850 - INFO - Epoch 926: train_loss=nan
2025-02-01 19:01:29,007 - INFO - Epoch 926: train_loss=nan
2025-02-01 19:01:29,140 - INFO - Epoch 926: train_loss=nan
2025-02-01 19:01:29,630 - INFO - Epoch 926: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:29,633 - INFO - ####################Training epoch 927####################
2025-02-01 19:01:30,009 - INFO - Epoch 927: train_loss=nan
2025-02-01 19:01:30,166 - INFO - Epoch 927: train_loss=nan
2025-02-01 19:01:30,299 - INFO - Epoch 927: train_loss=nan
2025-02-01 19:01:30,699 - INFO - Epoch 927: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:30,703 - INFO - ####################Training epoch 928####################
2025-02-01 19:01:31,082 - INFO - Epoch 928: train_loss=nan
2025-02-01 19:01:31,238 - INFO - Epoch 928: train_loss=nan
2025-02-01 19:01:31,371 - INFO - Epoch 928: train_loss=nan
2025-02-01 19:01:31,768 - INFO - Epoch 928: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:31,772 - INFO - ####################Training epoch 929####################
2025-02-01 19:01:32,149 - INFO - Epoch 929: train_loss=nan
2025-02-01 19:01:32,306 - INFO - Epoch 929: train_loss=nan
2025-02-01 19:01:32,439 - INFO - Epoch 929: train_loss=nan
2025-02-01 19:01:32,837 - INFO - Epoch 929: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:32,841 - INFO - ####################Training epoch 930####################
2025-02-01 19:01:33,218 - INFO - Epoch 930: train_loss=nan
2025-02-01 19:01:33,374 - INFO - Epoch 930: train_loss=nan
2025-02-01 19:01:33,508 - INFO - Epoch 930: train_loss=nan
2025-02-01 19:01:33,908 - INFO - Epoch 930: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:33,911 - INFO - ####################Training epoch 931####################
2025-02-01 19:01:34,285 - INFO - Epoch 931: train_loss=nan
2025-02-01 19:01:34,442 - INFO - Epoch 931: train_loss=nan
2025-02-01 19:01:34,575 - INFO - Epoch 931: train_loss=nan
2025-02-01 19:01:34,974 - INFO - Epoch 931: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:34,977 - INFO - ####################Training epoch 932####################
2025-02-01 19:01:35,354 - INFO - Epoch 932: train_loss=nan
2025-02-01 19:01:35,510 - INFO - Epoch 932: train_loss=nan
2025-02-01 19:01:35,643 - INFO - Epoch 932: train_loss=nan
2025-02-01 19:01:36,040 - INFO - Epoch 932: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:36,044 - INFO - ####################Training epoch 933####################
2025-02-01 19:01:36,422 - INFO - Epoch 933: train_loss=nan
2025-02-01 19:01:36,579 - INFO - Epoch 933: train_loss=nan
2025-02-01 19:01:36,712 - INFO - Epoch 933: train_loss=nan
2025-02-01 19:01:37,109 - INFO - Epoch 933: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:37,113 - INFO - ####################Training epoch 934####################
2025-02-01 19:01:37,489 - INFO - Epoch 934: train_loss=nan
2025-02-01 19:01:37,646 - INFO - Epoch 934: train_loss=nan
2025-02-01 19:01:37,779 - INFO - Epoch 934: train_loss=nan
2025-02-01 19:01:38,175 - INFO - Epoch 934: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:38,179 - INFO - ####################Training epoch 935####################
2025-02-01 19:01:38,555 - INFO - Epoch 935: train_loss=nan
2025-02-01 19:01:38,712 - INFO - Epoch 935: train_loss=nan
2025-02-01 19:01:38,845 - INFO - Epoch 935: train_loss=nan
2025-02-01 19:01:39,237 - INFO - Epoch 935: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:39,241 - INFO - ####################Training epoch 936####################
2025-02-01 19:01:39,617 - INFO - Epoch 936: train_loss=nan
2025-02-01 19:01:39,774 - INFO - Epoch 936: train_loss=nan
2025-02-01 19:01:39,907 - INFO - Epoch 936: train_loss=nan
2025-02-01 19:01:40,301 - INFO - Epoch 936: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:40,305 - INFO - ####################Training epoch 937####################
2025-02-01 19:01:40,680 - INFO - Epoch 937: train_loss=nan
2025-02-01 19:01:40,837 - INFO - Epoch 937: train_loss=nan
2025-02-01 19:01:40,971 - INFO - Epoch 937: train_loss=nan
2025-02-01 19:01:41,365 - INFO - Epoch 937: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:41,369 - INFO - ####################Training epoch 938####################
2025-02-01 19:01:41,746 - INFO - Epoch 938: train_loss=nan
2025-02-01 19:01:41,902 - INFO - Epoch 938: train_loss=nan
2025-02-01 19:01:42,035 - INFO - Epoch 938: train_loss=nan
2025-02-01 19:01:42,430 - INFO - Epoch 938: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:42,434 - INFO - ####################Training epoch 939####################
2025-02-01 19:01:42,809 - INFO - Epoch 939: train_loss=nan
2025-02-01 19:01:42,965 - INFO - Epoch 939: train_loss=nan
2025-02-01 19:01:43,099 - INFO - Epoch 939: train_loss=nan
2025-02-01 19:01:43,494 - INFO - Epoch 939: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:43,498 - INFO - ####################Training epoch 940####################
2025-02-01 19:01:43,873 - INFO - Epoch 940: train_loss=nan
2025-02-01 19:01:44,030 - INFO - Epoch 940: train_loss=nan
2025-02-01 19:01:44,163 - INFO - Epoch 940: train_loss=nan
2025-02-01 19:01:44,557 - INFO - Epoch 940: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:44,560 - INFO - ####################Training epoch 941####################
2025-02-01 19:01:44,941 - INFO - Epoch 941: train_loss=nan
2025-02-01 19:01:45,097 - INFO - Epoch 941: train_loss=nan
2025-02-01 19:01:45,231 - INFO - Epoch 941: train_loss=nan
2025-02-01 19:01:45,628 - INFO - Epoch 941: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:45,631 - INFO - ####################Training epoch 942####################
2025-02-01 19:01:46,010 - INFO - Epoch 942: train_loss=nan
2025-02-01 19:01:46,167 - INFO - Epoch 942: train_loss=nan
2025-02-01 19:01:46,300 - INFO - Epoch 942: train_loss=nan
2025-02-01 19:01:46,698 - INFO - Epoch 942: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:46,702 - INFO - ####################Training epoch 943####################
2025-02-01 19:01:47,080 - INFO - Epoch 943: train_loss=nan
2025-02-01 19:01:47,238 - INFO - Epoch 943: train_loss=nan
2025-02-01 19:01:47,371 - INFO - Epoch 943: train_loss=nan
2025-02-01 19:01:47,768 - INFO - Epoch 943: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:47,771 - INFO - ####################Training epoch 944####################
2025-02-01 19:01:48,145 - INFO - Epoch 944: train_loss=nan
2025-02-01 19:01:48,302 - INFO - Epoch 944: train_loss=nan
2025-02-01 19:01:48,435 - INFO - Epoch 944: train_loss=nan
2025-02-01 19:01:48,830 - INFO - Epoch 944: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:48,834 - INFO - ####################Training epoch 945####################
2025-02-01 19:01:49,209 - INFO - Epoch 945: train_loss=nan
2025-02-01 19:01:49,365 - INFO - Epoch 945: train_loss=nan
2025-02-01 19:01:49,498 - INFO - Epoch 945: train_loss=nan
2025-02-01 19:01:49,895 - INFO - Epoch 945: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:49,899 - INFO - ####################Training epoch 946####################
2025-02-01 19:01:50,275 - INFO - Epoch 946: train_loss=nan
2025-02-01 19:01:50,432 - INFO - Epoch 946: train_loss=nan
2025-02-01 19:01:50,565 - INFO - Epoch 946: train_loss=nan
2025-02-01 19:01:50,964 - INFO - Epoch 946: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:50,968 - INFO - ####################Training epoch 947####################
2025-02-01 19:01:51,342 - INFO - Epoch 947: train_loss=nan
2025-02-01 19:01:51,498 - INFO - Epoch 947: train_loss=nan
2025-02-01 19:01:51,632 - INFO - Epoch 947: train_loss=nan
2025-02-01 19:01:52,028 - INFO - Epoch 947: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:52,031 - INFO - ####################Training epoch 948####################
2025-02-01 19:01:52,408 - INFO - Epoch 948: train_loss=nan
2025-02-01 19:01:52,565 - INFO - Epoch 948: train_loss=nan
2025-02-01 19:01:52,698 - INFO - Epoch 948: train_loss=nan
2025-02-01 19:01:53,100 - INFO - Epoch 948: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:53,104 - INFO - ####################Training epoch 949####################
2025-02-01 19:01:53,484 - INFO - Epoch 949: train_loss=nan
2025-02-01 19:01:53,640 - INFO - Epoch 949: train_loss=nan
2025-02-01 19:01:53,773 - INFO - Epoch 949: train_loss=nan
2025-02-01 19:01:54,169 - INFO - Epoch 949: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:54,176 - INFO - ####################Training epoch 950####################
2025-02-01 19:01:54,553 - INFO - Epoch 950: train_loss=nan
2025-02-01 19:01:54,709 - INFO - Epoch 950: train_loss=nan
2025-02-01 19:01:54,843 - INFO - Epoch 950: train_loss=nan
2025-02-01 19:01:55,237 - INFO - Epoch 950: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:55,241 - INFO - ####################Training epoch 951####################
2025-02-01 19:01:55,619 - INFO - Epoch 951: train_loss=nan
2025-02-01 19:01:55,776 - INFO - Epoch 951: train_loss=nan
2025-02-01 19:01:55,909 - INFO - Epoch 951: train_loss=nan
2025-02-01 19:01:56,307 - INFO - Epoch 951: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:56,311 - INFO - ####################Training epoch 952####################
2025-02-01 19:01:56,686 - INFO - Epoch 952: train_loss=nan
2025-02-01 19:01:56,842 - INFO - Epoch 952: train_loss=nan
2025-02-01 19:01:56,975 - INFO - Epoch 952: train_loss=nan
2025-02-01 19:01:57,373 - INFO - Epoch 952: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:57,377 - INFO - ####################Training epoch 953####################
2025-02-01 19:01:57,752 - INFO - Epoch 953: train_loss=nan
2025-02-01 19:01:57,908 - INFO - Epoch 953: train_loss=nan
2025-02-01 19:01:58,041 - INFO - Epoch 953: train_loss=nan
2025-02-01 19:01:58,440 - INFO - Epoch 953: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:58,443 - INFO - ####################Training epoch 954####################
2025-02-01 19:01:58,818 - INFO - Epoch 954: train_loss=nan
2025-02-01 19:01:58,974 - INFO - Epoch 954: train_loss=nan
2025-02-01 19:01:59,107 - INFO - Epoch 954: train_loss=nan
2025-02-01 19:01:59,505 - INFO - Epoch 954: val_loss=nan, val_acc=66.67%
2025-02-01 19:01:59,509 - INFO - ####################Training epoch 955####################
2025-02-01 19:01:59,885 - INFO - Epoch 955: train_loss=nan
2025-02-01 19:02:00,041 - INFO - Epoch 955: train_loss=nan
2025-02-01 19:02:00,174 - INFO - Epoch 955: train_loss=nan
2025-02-01 19:02:00,567 - INFO - Epoch 955: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:00,571 - INFO - ####################Training epoch 956####################
2025-02-01 19:02:00,945 - INFO - Epoch 956: train_loss=nan
2025-02-01 19:02:01,102 - INFO - Epoch 956: train_loss=nan
2025-02-01 19:02:01,234 - INFO - Epoch 956: train_loss=nan
2025-02-01 19:02:01,630 - INFO - Epoch 956: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:01,634 - INFO - ####################Training epoch 957####################
2025-02-01 19:02:02,011 - INFO - Epoch 957: train_loss=nan
2025-02-01 19:02:02,168 - INFO - Epoch 957: train_loss=nan
2025-02-01 19:02:02,302 - INFO - Epoch 957: train_loss=nan
2025-02-01 19:02:02,696 - INFO - Epoch 957: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:02,699 - INFO - ####################Training epoch 958####################
2025-02-01 19:02:03,076 - INFO - Epoch 958: train_loss=nan
2025-02-01 19:02:03,234 - INFO - Epoch 958: train_loss=nan
2025-02-01 19:02:03,367 - INFO - Epoch 958: train_loss=nan
2025-02-01 19:02:03,760 - INFO - Epoch 958: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:03,764 - INFO - ####################Training epoch 959####################
2025-02-01 19:02:04,144 - INFO - Epoch 959: train_loss=nan
2025-02-01 19:02:04,300 - INFO - Epoch 959: train_loss=nan
2025-02-01 19:02:04,433 - INFO - Epoch 959: train_loss=nan
2025-02-01 19:02:04,832 - INFO - Epoch 959: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:04,836 - INFO - ####################Training epoch 960####################
2025-02-01 19:02:05,214 - INFO - Epoch 960: train_loss=nan
2025-02-01 19:02:05,372 - INFO - Epoch 960: train_loss=nan
2025-02-01 19:02:05,506 - INFO - Epoch 960: train_loss=nan
2025-02-01 19:02:05,905 - INFO - Epoch 960: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:05,908 - INFO - ####################Training epoch 961####################
2025-02-01 19:02:06,288 - INFO - Epoch 961: train_loss=nan
2025-02-01 19:02:06,445 - INFO - Epoch 961: train_loss=nan
2025-02-01 19:02:06,578 - INFO - Epoch 961: train_loss=nan
2025-02-01 19:02:06,979 - INFO - Epoch 961: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:06,982 - INFO - ####################Training epoch 962####################
2025-02-01 19:02:07,361 - INFO - Epoch 962: train_loss=nan
2025-02-01 19:02:07,517 - INFO - Epoch 962: train_loss=nan
2025-02-01 19:02:07,651 - INFO - Epoch 962: train_loss=nan
2025-02-01 19:02:08,047 - INFO - Epoch 962: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:08,051 - INFO - ####################Training epoch 963####################
2025-02-01 19:02:08,431 - INFO - Epoch 963: train_loss=nan
2025-02-01 19:02:08,588 - INFO - Epoch 963: train_loss=nan
2025-02-01 19:02:08,722 - INFO - Epoch 963: train_loss=nan
2025-02-01 19:02:09,123 - INFO - Epoch 963: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:09,127 - INFO - ####################Training epoch 964####################
2025-02-01 19:02:09,504 - INFO - Epoch 964: train_loss=nan
2025-02-01 19:02:09,661 - INFO - Epoch 964: train_loss=nan
2025-02-01 19:02:09,794 - INFO - Epoch 964: train_loss=nan
2025-02-01 19:02:10,190 - INFO - Epoch 964: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:10,193 - INFO - ####################Training epoch 965####################
2025-02-01 19:02:10,571 - INFO - Epoch 965: train_loss=nan
2025-02-01 19:02:10,728 - INFO - Epoch 965: train_loss=nan
2025-02-01 19:02:10,862 - INFO - Epoch 965: train_loss=nan
2025-02-01 19:02:11,261 - INFO - Epoch 965: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:11,265 - INFO - ####################Training epoch 966####################
2025-02-01 19:02:11,639 - INFO - Epoch 966: train_loss=nan
2025-02-01 19:02:11,795 - INFO - Epoch 966: train_loss=nan
2025-02-01 19:02:11,929 - INFO - Epoch 966: train_loss=nan
2025-02-01 19:02:12,326 - INFO - Epoch 966: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:12,330 - INFO - ####################Training epoch 967####################
2025-02-01 19:02:12,705 - INFO - Epoch 967: train_loss=nan
2025-02-01 19:02:12,861 - INFO - Epoch 967: train_loss=nan
2025-02-01 19:02:12,994 - INFO - Epoch 967: train_loss=nan
2025-02-01 19:02:13,390 - INFO - Epoch 967: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:13,394 - INFO - ####################Training epoch 968####################
2025-02-01 19:02:13,770 - INFO - Epoch 968: train_loss=nan
2025-02-01 19:02:13,927 - INFO - Epoch 968: train_loss=nan
2025-02-01 19:02:14,060 - INFO - Epoch 968: train_loss=nan
2025-02-01 19:02:14,455 - INFO - Epoch 968: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:14,459 - INFO - ####################Training epoch 969####################
2025-02-01 19:02:14,833 - INFO - Epoch 969: train_loss=nan
2025-02-01 19:02:14,990 - INFO - Epoch 969: train_loss=nan
2025-02-01 19:02:15,123 - INFO - Epoch 969: train_loss=nan
2025-02-01 19:02:15,519 - INFO - Epoch 969: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:15,523 - INFO - ####################Training epoch 970####################
2025-02-01 19:02:15,904 - INFO - Epoch 970: train_loss=nan
2025-02-01 19:02:16,060 - INFO - Epoch 970: train_loss=nan
2025-02-01 19:02:16,193 - INFO - Epoch 970: train_loss=nan
2025-02-01 19:02:16,589 - INFO - Epoch 970: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:16,593 - INFO - ####################Training epoch 971####################
2025-02-01 19:02:16,970 - INFO - Epoch 971: train_loss=nan
2025-02-01 19:02:17,127 - INFO - Epoch 971: train_loss=nan
2025-02-01 19:02:17,260 - INFO - Epoch 971: train_loss=nan
2025-02-01 19:02:17,658 - INFO - Epoch 971: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:17,662 - INFO - ####################Training epoch 972####################
2025-02-01 19:02:18,038 - INFO - Epoch 972: train_loss=nan
2025-02-01 19:02:18,195 - INFO - Epoch 972: train_loss=nan
2025-02-01 19:02:18,328 - INFO - Epoch 972: train_loss=nan
2025-02-01 19:02:18,727 - INFO - Epoch 972: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:18,731 - INFO - ####################Training epoch 973####################
2025-02-01 19:02:19,109 - INFO - Epoch 973: train_loss=nan
2025-02-01 19:02:19,266 - INFO - Epoch 973: train_loss=nan
2025-02-01 19:02:19,400 - INFO - Epoch 973: train_loss=nan
2025-02-01 19:02:19,797 - INFO - Epoch 973: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:19,801 - INFO - ####################Training epoch 974####################
2025-02-01 19:02:20,177 - INFO - Epoch 974: train_loss=nan
2025-02-01 19:02:20,333 - INFO - Epoch 974: train_loss=nan
2025-02-01 19:02:20,466 - INFO - Epoch 974: train_loss=nan
2025-02-01 19:02:20,863 - INFO - Epoch 974: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:20,870 - INFO - ####################Training epoch 975####################
2025-02-01 19:02:21,248 - INFO - Epoch 975: train_loss=nan
2025-02-01 19:02:21,405 - INFO - Epoch 975: train_loss=nan
2025-02-01 19:02:21,538 - INFO - Epoch 975: train_loss=nan
2025-02-01 19:02:21,937 - INFO - Epoch 975: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:21,941 - INFO - ####################Training epoch 976####################
2025-02-01 19:02:22,321 - INFO - Epoch 976: train_loss=nan
2025-02-01 19:02:22,478 - INFO - Epoch 976: train_loss=nan
2025-02-01 19:02:22,611 - INFO - Epoch 976: train_loss=nan
2025-02-01 19:02:23,008 - INFO - Epoch 976: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:23,011 - INFO - ####################Training epoch 977####################
2025-02-01 19:02:23,391 - INFO - Epoch 977: train_loss=nan
2025-02-01 19:02:23,548 - INFO - Epoch 977: train_loss=nan
2025-02-01 19:02:23,682 - INFO - Epoch 977: train_loss=nan
2025-02-01 19:02:24,084 - INFO - Epoch 977: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:24,087 - INFO - ####################Training epoch 978####################
2025-02-01 19:02:24,465 - INFO - Epoch 978: train_loss=nan
2025-02-01 19:02:24,622 - INFO - Epoch 978: train_loss=nan
2025-02-01 19:02:24,755 - INFO - Epoch 978: train_loss=nan
2025-02-01 19:02:25,155 - INFO - Epoch 978: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:25,158 - INFO - ####################Training epoch 979####################
2025-02-01 19:02:25,537 - INFO - Epoch 979: train_loss=nan
2025-02-01 19:02:25,693 - INFO - Epoch 979: train_loss=nan
2025-02-01 19:02:25,826 - INFO - Epoch 979: train_loss=nan
2025-02-01 19:02:26,226 - INFO - Epoch 979: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:26,229 - INFO - ####################Training epoch 980####################
2025-02-01 19:02:26,607 - INFO - Epoch 980: train_loss=nan
2025-02-01 19:02:26,764 - INFO - Epoch 980: train_loss=nan
2025-02-01 19:02:26,898 - INFO - Epoch 980: train_loss=nan
2025-02-01 19:02:27,297 - INFO - Epoch 980: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:27,301 - INFO - ####################Training epoch 981####################
2025-02-01 19:02:27,675 - INFO - Epoch 981: train_loss=nan
2025-02-01 19:02:27,831 - INFO - Epoch 981: train_loss=nan
2025-02-01 19:02:27,964 - INFO - Epoch 981: train_loss=nan
2025-02-01 19:02:28,363 - INFO - Epoch 981: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:28,366 - INFO - ####################Training epoch 982####################
2025-02-01 19:02:28,742 - INFO - Epoch 982: train_loss=nan
2025-02-01 19:02:28,899 - INFO - Epoch 982: train_loss=nan
2025-02-01 19:02:29,033 - INFO - Epoch 982: train_loss=nan
2025-02-01 19:02:29,431 - INFO - Epoch 982: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:29,434 - INFO - ####################Training epoch 983####################
2025-02-01 19:02:29,814 - INFO - Epoch 983: train_loss=nan
2025-02-01 19:02:29,970 - INFO - Epoch 983: train_loss=nan
2025-02-01 19:02:30,103 - INFO - Epoch 983: train_loss=nan
2025-02-01 19:02:30,501 - INFO - Epoch 983: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:30,504 - INFO - ####################Training epoch 984####################
2025-02-01 19:02:30,882 - INFO - Epoch 984: train_loss=nan
2025-02-01 19:02:31,038 - INFO - Epoch 984: train_loss=nan
2025-02-01 19:02:31,171 - INFO - Epoch 984: train_loss=nan
2025-02-01 19:02:31,572 - INFO - Epoch 984: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:31,575 - INFO - ####################Training epoch 985####################
2025-02-01 19:02:31,951 - INFO - Epoch 985: train_loss=nan
2025-02-01 19:02:32,107 - INFO - Epoch 985: train_loss=nan
2025-02-01 19:02:32,241 - INFO - Epoch 985: train_loss=nan
2025-02-01 19:02:32,645 - INFO - Epoch 985: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:32,649 - INFO - ####################Training epoch 986####################
2025-02-01 19:02:33,026 - INFO - Epoch 986: train_loss=nan
2025-02-01 19:02:33,183 - INFO - Epoch 986: train_loss=nan
2025-02-01 19:02:33,316 - INFO - Epoch 986: train_loss=nan
2025-02-01 19:02:33,720 - INFO - Epoch 986: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:33,724 - INFO - ####################Training epoch 987####################
2025-02-01 19:02:34,100 - INFO - Epoch 987: train_loss=nan
2025-02-01 19:02:34,256 - INFO - Epoch 987: train_loss=nan
2025-02-01 19:02:34,390 - INFO - Epoch 987: train_loss=nan
2025-02-01 19:02:34,788 - INFO - Epoch 987: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:34,792 - INFO - ####################Training epoch 988####################
2025-02-01 19:02:35,169 - INFO - Epoch 988: train_loss=nan
2025-02-01 19:02:35,326 - INFO - Epoch 988: train_loss=nan
2025-02-01 19:02:35,459 - INFO - Epoch 988: train_loss=nan
2025-02-01 19:02:35,857 - INFO - Epoch 988: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:35,861 - INFO - ####################Training epoch 989####################
2025-02-01 19:02:36,240 - INFO - Epoch 989: train_loss=nan
2025-02-01 19:02:36,397 - INFO - Epoch 989: train_loss=nan
2025-02-01 19:02:36,531 - INFO - Epoch 989: train_loss=nan
2025-02-01 19:02:36,926 - INFO - Epoch 989: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:36,930 - INFO - ####################Training epoch 990####################
2025-02-01 19:02:37,310 - INFO - Epoch 990: train_loss=nan
2025-02-01 19:02:37,466 - INFO - Epoch 990: train_loss=nan
2025-02-01 19:02:37,600 - INFO - Epoch 990: train_loss=nan
2025-02-01 19:02:37,993 - INFO - Epoch 990: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:37,997 - INFO - ####################Training epoch 991####################
2025-02-01 19:02:38,375 - INFO - Epoch 991: train_loss=nan
2025-02-01 19:02:38,531 - INFO - Epoch 991: train_loss=nan
2025-02-01 19:02:38,664 - INFO - Epoch 991: train_loss=nan
2025-02-01 19:02:39,060 - INFO - Epoch 991: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:39,064 - INFO - ####################Training epoch 992####################
2025-02-01 19:02:39,441 - INFO - Epoch 992: train_loss=nan
2025-02-01 19:02:39,598 - INFO - Epoch 992: train_loss=nan
2025-02-01 19:02:39,731 - INFO - Epoch 992: train_loss=nan
2025-02-01 19:02:40,128 - INFO - Epoch 992: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:40,131 - INFO - ####################Training epoch 993####################
2025-02-01 19:02:40,507 - INFO - Epoch 993: train_loss=nan
2025-02-01 19:02:40,663 - INFO - Epoch 993: train_loss=nan
2025-02-01 19:02:40,797 - INFO - Epoch 993: train_loss=nan
2025-02-01 19:02:41,198 - INFO - Epoch 993: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:41,202 - INFO - ####################Training epoch 994####################
2025-02-01 19:02:41,575 - INFO - Epoch 994: train_loss=nan
2025-02-01 19:02:41,731 - INFO - Epoch 994: train_loss=nan
2025-02-01 19:02:41,864 - INFO - Epoch 994: train_loss=nan
2025-02-01 19:02:42,265 - INFO - Epoch 994: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:42,269 - INFO - ####################Training epoch 995####################
2025-02-01 19:02:42,645 - INFO - Epoch 995: train_loss=nan
2025-02-01 19:02:42,801 - INFO - Epoch 995: train_loss=nan
2025-02-01 19:02:42,935 - INFO - Epoch 995: train_loss=nan
2025-02-01 19:02:43,335 - INFO - Epoch 995: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:43,339 - INFO - ####################Training epoch 996####################
2025-02-01 19:02:43,714 - INFO - Epoch 996: train_loss=nan
2025-02-01 19:02:43,870 - INFO - Epoch 996: train_loss=nan
2025-02-01 19:02:44,003 - INFO - Epoch 996: train_loss=nan
2025-02-01 19:02:44,397 - INFO - Epoch 996: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:44,401 - INFO - ####################Training epoch 997####################
2025-02-01 19:02:44,776 - INFO - Epoch 997: train_loss=nan
2025-02-01 19:02:44,932 - INFO - Epoch 997: train_loss=nan
2025-02-01 19:02:45,065 - INFO - Epoch 997: train_loss=nan
2025-02-01 19:02:45,463 - INFO - Epoch 997: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:45,467 - INFO - ####################Training epoch 998####################
2025-02-01 19:02:45,843 - INFO - Epoch 998: train_loss=nan
2025-02-01 19:02:46,000 - INFO - Epoch 998: train_loss=nan
2025-02-01 19:02:46,133 - INFO - Epoch 998: train_loss=nan
2025-02-01 19:02:46,530 - INFO - Epoch 998: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:46,534 - INFO - ####################Training epoch 999####################
2025-02-01 19:02:46,910 - INFO - Epoch 999: train_loss=nan
2025-02-01 19:02:47,066 - INFO - Epoch 999: train_loss=nan
2025-02-01 19:02:47,199 - INFO - Epoch 999: train_loss=nan
2025-02-01 19:02:47,595 - INFO - Epoch 999: val_loss=nan, val_acc=66.67%
2025-02-01 19:02:47,752 - INFO - Model saved.
